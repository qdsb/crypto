{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPULN1SR9O2c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import yfinance as yf\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-REe-T66st5c",
        "outputId": "8801df6f-e49a-4779-e77a-a550827e279e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "gold = yf.download(tickers = \"GC=F\",\n",
        "                     period = \"max\",\n",
        "                     interval = \"1d\").reset_index()\n",
        "gold = gold.rename(columns={'Open': 'gold_open', 'High': 'gold_high', 'Low': 'gold_low', 'Close': 'gold_close', 'Adj Close': 'gold_adj_close', 'Volume': 'gold_volume'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdB40DsSs_ib",
        "outputId": "fbeedb1a-7e6f-4491-831e-fb7492a577af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "euro_usd = yf.download(tickers = \"EURUSD=X\",\n",
        "                     period = \"max\",\n",
        "                     interval = \"1d\").reset_index()\n",
        "euro_usd = euro_usd.rename(columns={'Open': 'euro_usd_open', 'High': 'euro_usd_high', 'Low': 'euro_usd_low', 'Close': 'euro_usd_close', 'Adj Close': 'euro_usd_adj_close', 'Volume': 'euro_usd_volume'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrY6WFw0tjfI",
        "outputId": "228def54-8de1-4afd-942a-927b88995897"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "sp500 = yf.download(tickers = \"^GSPC\",\n",
        "                     period = \"max\",\n",
        "                     interval = \"1d\").reset_index()\n",
        "sp500 = sp500.rename(columns={'Open': 'sp500_open', 'High': 'sp500_high', 'Low': 'sp500_low', 'Close': 'sp500_close', 'Adj Close': 'sp500_adj_close', 'Volume': 'sp500_volume'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2w3GPyMl245o",
        "outputId": "79c181a9-acbc-4ea5-c537-38835487ae3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "xmr = yf.Ticker(\"XMR-USD\")\n",
        "df = yf.download(tickers = \"XMR-USD\",\n",
        "                     period = \"max\",\n",
        "                     interval = \"1d\").reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "iKun4978CtGl",
        "outputId": "92ada746-0352-44c1-ba20-e03d0b73912c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Date        Open        High         Low       Close   Adj Close  \\\n",
              "0    2017-11-09  112.531998  123.404999  112.219002  120.779999  120.779999   \n",
              "1    2017-11-10  121.344002  121.665001  101.757004  105.585999  105.585999   \n",
              "2    2017-11-11  105.750000  127.106003  103.877998  119.615997  119.615997   \n",
              "3    2017-11-12  119.597000  133.675003  110.617996  123.856003  123.856003   \n",
              "4    2017-11-13  128.960007  136.528000  120.921997  123.402000  123.402000   \n",
              "...         ...         ...         ...         ...         ...         ...   \n",
              "2158 2023-10-07  151.988235  155.247528  151.100983  155.212143  155.212143   \n",
              "2159 2023-10-08  155.219528  156.482040  153.763336  156.191223  156.191223   \n",
              "2160 2023-10-09  156.190552  156.192932  151.908813  153.795502  153.795502   \n",
              "2161 2023-10-10  153.790405  154.468155  152.097107  152.215652  152.215652   \n",
              "2162 2023-10-11  152.362396  153.326172  151.109924  151.760925  151.760925   \n",
              "\n",
              "         Volume  price_increase  \n",
              "0      86864600             0.0  \n",
              "1      84614000             0.0  \n",
              "2     107708000             1.0  \n",
              "3     144948000             1.0  \n",
              "4     116200000             0.0  \n",
              "...         ...             ...  \n",
              "2158   61159796             1.0  \n",
              "2159   59858985             1.0  \n",
              "2160   61203300             0.0  \n",
              "2161   54504811             0.0  \n",
              "2162   55200560             0.0  \n",
              "\n",
              "[2163 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07c373c3-20d7-4223-8528-c71065592d8e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>price_increase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017-11-09</td>\n",
              "      <td>112.531998</td>\n",
              "      <td>123.404999</td>\n",
              "      <td>112.219002</td>\n",
              "      <td>120.779999</td>\n",
              "      <td>120.779999</td>\n",
              "      <td>86864600</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017-11-10</td>\n",
              "      <td>121.344002</td>\n",
              "      <td>121.665001</td>\n",
              "      <td>101.757004</td>\n",
              "      <td>105.585999</td>\n",
              "      <td>105.585999</td>\n",
              "      <td>84614000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017-11-11</td>\n",
              "      <td>105.750000</td>\n",
              "      <td>127.106003</td>\n",
              "      <td>103.877998</td>\n",
              "      <td>119.615997</td>\n",
              "      <td>119.615997</td>\n",
              "      <td>107708000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017-11-12</td>\n",
              "      <td>119.597000</td>\n",
              "      <td>133.675003</td>\n",
              "      <td>110.617996</td>\n",
              "      <td>123.856003</td>\n",
              "      <td>123.856003</td>\n",
              "      <td>144948000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017-11-13</td>\n",
              "      <td>128.960007</td>\n",
              "      <td>136.528000</td>\n",
              "      <td>120.921997</td>\n",
              "      <td>123.402000</td>\n",
              "      <td>123.402000</td>\n",
              "      <td>116200000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2158</th>\n",
              "      <td>2023-10-07</td>\n",
              "      <td>151.988235</td>\n",
              "      <td>155.247528</td>\n",
              "      <td>151.100983</td>\n",
              "      <td>155.212143</td>\n",
              "      <td>155.212143</td>\n",
              "      <td>61159796</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2159</th>\n",
              "      <td>2023-10-08</td>\n",
              "      <td>155.219528</td>\n",
              "      <td>156.482040</td>\n",
              "      <td>153.763336</td>\n",
              "      <td>156.191223</td>\n",
              "      <td>156.191223</td>\n",
              "      <td>59858985</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2160</th>\n",
              "      <td>2023-10-09</td>\n",
              "      <td>156.190552</td>\n",
              "      <td>156.192932</td>\n",
              "      <td>151.908813</td>\n",
              "      <td>153.795502</td>\n",
              "      <td>153.795502</td>\n",
              "      <td>61203300</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2161</th>\n",
              "      <td>2023-10-10</td>\n",
              "      <td>153.790405</td>\n",
              "      <td>154.468155</td>\n",
              "      <td>152.097107</td>\n",
              "      <td>152.215652</td>\n",
              "      <td>152.215652</td>\n",
              "      <td>54504811</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2162</th>\n",
              "      <td>2023-10-11</td>\n",
              "      <td>152.362396</td>\n",
              "      <td>153.326172</td>\n",
              "      <td>151.109924</td>\n",
              "      <td>151.760925</td>\n",
              "      <td>151.760925</td>\n",
              "      <td>55200560</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2163 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07c373c3-20d7-4223-8528-c71065592d8e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-07c373c3-20d7-4223-8528-c71065592d8e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-07c373c3-20d7-4223-8528-c71065592d8e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0d803e53-2e5a-462d-8ffb-8d9fbd954030\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0d803e53-2e5a-462d-8ffb-8d9fbd954030')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0d803e53-2e5a-462d-8ffb-8d9fbd954030 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "df.loc[0, \"price_increase\"] = 0\n",
        "for i in range(1, len(df)):\n",
        "  df.loc[i, \"price_increase\"] = 1 if df.loc[i-1, \"Close\"] < df.loc[i, \"Close\"] else 0\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cde-tC5t9vW"
      },
      "outputs": [],
      "source": [
        "df = df.merge(gold, on='Date', how='left').merge(euro_usd, on='Date', how='left').merge(sp500, on='Date', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MAtVWBU6LPy",
        "outputId": "caf0dee9-1f79-4ccf-8267-b70e6136d7b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=11NUjXNzuFnBd0MShJYq-RlrFeepMHUrA\n",
            "To: /content/XMR_hash.csv\n",
            "100% 181k/181k [00:00<00:00, 103MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1WUNRZJgU0f5NaC-6Z0n_mMvt6P9yNV1U\n",
            "To: /content/XMR_difficulty.csv\n",
            "100% 213k/213k [00:00<00:00, 114MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 11NUjXNzuFnBd0MShJYq-RlrFeepMHUrA\n",
        "!gdown 1WUNRZJgU0f5NaC-6Z0n_mMvt6P9yNV1U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30Jgn23rOtej"
      },
      "outputs": [],
      "source": [
        "date_parser = lambda x: datetime.strptime(x, \"%Y-%m-%dT%H:%M:%SZ\").date()\n",
        "\n",
        "xmr_hash = pd.read_csv(\"./XMR_hash.csv\", index_col=0, parse_dates=[\"time\"], date_parser=date_parser)\n",
        "xmr_difficulty = pd.read_csv(\"./XMR_difficulty.csv\", index_col=0, parse_dates=[\"time\"], date_parser=date_parser)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "iumZ4GPqPDkj",
        "outputId": "e843ce2b-88bf-4634-b11b-6312d066f309"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              hash       time        Open        High         Low       Close  \\\n",
              "0     2.338989e+08 2017-11-09  112.531998  123.404999  112.219002  120.779999   \n",
              "1     2.337782e+08 2017-11-10  121.344002  121.665001  101.757004  105.585999   \n",
              "2     2.337782e+08 2017-11-11  105.750000  127.106003  103.877998  119.615997   \n",
              "3     2.337782e+08 2017-11-12  119.597000  133.675003  110.617996  123.856003   \n",
              "4     2.337782e+08 2017-11-13  128.960007  136.528000  120.921997  123.402000   \n",
              "...            ...        ...         ...         ...         ...         ...   \n",
              "2146  2.857872e+09 2023-10-04  147.168442  150.702347  145.940781  150.469055   \n",
              "2147  2.831952e+09 2023-10-05  150.474197  151.328369  148.565491  149.623718   \n",
              "2148  3.106746e+09 2023-10-06  149.623337  152.669296  148.641647  151.992264   \n",
              "2149  2.815488e+09 2023-10-07  151.988235  155.247528  151.100983  155.212143   \n",
              "2150  2.773497e+09 2023-10-08  155.219528  156.482040  153.763336  156.191223   \n",
              "\n",
              "       Adj Close     Volume  price_increase    gold_open  ...  euro_usd_low  \\\n",
              "0     120.779999   86864600             0.0  1279.699951  ...      1.158641   \n",
              "1     105.585999   84614000             0.0  1283.500000  ...      1.162399   \n",
              "2     119.615997  107708000             1.0          NaN  ...           NaN   \n",
              "3     123.856003  144948000             1.0          NaN  ...           NaN   \n",
              "4     123.402000  116200000             0.0  1277.300049  ...      1.163873   \n",
              "...          ...        ...             ...          ...  ...           ...   \n",
              "2146  150.469055   59400400             1.0  1821.800049  ...      1.045369   \n",
              "2147  149.623718   55704972             0.0  1826.300049  ...      1.050089   \n",
              "2148  151.992264   49535004             1.0  1819.000000  ...      1.048394   \n",
              "2149  155.212143   61159796             1.0          NaN  ...           NaN   \n",
              "2150  156.191223   59858985             1.0          NaN  ...           NaN   \n",
              "\n",
              "      euro_usd_close  euro_usd_adj_close  euro_usd_volume   sp500_open  \\\n",
              "0           1.159689            1.159689              0.0  2584.000000   \n",
              "1           1.164687            1.164687              0.0  2580.179932   \n",
              "2                NaN                 NaN              NaN          NaN   \n",
              "3                NaN                 NaN              NaN          NaN   \n",
              "4           1.166113            1.166113              0.0  2576.530029   \n",
              "...              ...                 ...              ...          ...   \n",
              "2146        1.047230            1.047230              0.0  4233.830078   \n",
              "2147        1.050707            1.050707              0.0  4259.310059   \n",
              "2148        1.054663            1.054663              0.0  4234.790039   \n",
              "2149             NaN                 NaN              NaN          NaN   \n",
              "2150             NaN                 NaN              NaN          NaN   \n",
              "\n",
              "       sp500_high    sp500_low  sp500_close  sp500_adj_close  sp500_volume  \n",
              "0     2586.500000  2566.330078  2584.620117      2584.620117  3.844100e+09  \n",
              "1     2583.810059  2575.570068  2582.300049      2582.300049  3.489740e+09  \n",
              "2             NaN          NaN          NaN              NaN           NaN  \n",
              "3             NaN          NaN          NaN              NaN           NaN  \n",
              "4     2587.659912  2574.479980  2584.840088      2584.840088  3.405200e+09  \n",
              "...           ...          ...          ...              ...           ...  \n",
              "2146  4268.500000  4220.479980  4263.750000      4263.750000  3.777600e+09  \n",
              "2147  4267.129883  4225.910156  4258.189941      4258.189941  3.581470e+09  \n",
              "2148  4324.100098  4219.549805  4308.500000      4308.500000  3.902030e+09  \n",
              "2149          NaN          NaN          NaN              NaN           NaN  \n",
              "2150          NaN          NaN          NaN              NaN           NaN  \n",
              "\n",
              "[2151 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5764ffe7-55bf-4be1-b9d3-69517fde68db\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hash</th>\n",
              "      <th>time</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>price_increase</th>\n",
              "      <th>gold_open</th>\n",
              "      <th>...</th>\n",
              "      <th>euro_usd_low</th>\n",
              "      <th>euro_usd_close</th>\n",
              "      <th>euro_usd_adj_close</th>\n",
              "      <th>euro_usd_volume</th>\n",
              "      <th>sp500_open</th>\n",
              "      <th>sp500_high</th>\n",
              "      <th>sp500_low</th>\n",
              "      <th>sp500_close</th>\n",
              "      <th>sp500_adj_close</th>\n",
              "      <th>sp500_volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.338989e+08</td>\n",
              "      <td>2017-11-09</td>\n",
              "      <td>112.531998</td>\n",
              "      <td>123.404999</td>\n",
              "      <td>112.219002</td>\n",
              "      <td>120.779999</td>\n",
              "      <td>120.779999</td>\n",
              "      <td>86864600</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1279.699951</td>\n",
              "      <td>...</td>\n",
              "      <td>1.158641</td>\n",
              "      <td>1.159689</td>\n",
              "      <td>1.159689</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2584.000000</td>\n",
              "      <td>2586.500000</td>\n",
              "      <td>2566.330078</td>\n",
              "      <td>2584.620117</td>\n",
              "      <td>2584.620117</td>\n",
              "      <td>3.844100e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.337782e+08</td>\n",
              "      <td>2017-11-10</td>\n",
              "      <td>121.344002</td>\n",
              "      <td>121.665001</td>\n",
              "      <td>101.757004</td>\n",
              "      <td>105.585999</td>\n",
              "      <td>105.585999</td>\n",
              "      <td>84614000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1283.500000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.162399</td>\n",
              "      <td>1.164687</td>\n",
              "      <td>1.164687</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2580.179932</td>\n",
              "      <td>2583.810059</td>\n",
              "      <td>2575.570068</td>\n",
              "      <td>2582.300049</td>\n",
              "      <td>2582.300049</td>\n",
              "      <td>3.489740e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.337782e+08</td>\n",
              "      <td>2017-11-11</td>\n",
              "      <td>105.750000</td>\n",
              "      <td>127.106003</td>\n",
              "      <td>103.877998</td>\n",
              "      <td>119.615997</td>\n",
              "      <td>119.615997</td>\n",
              "      <td>107708000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.337782e+08</td>\n",
              "      <td>2017-11-12</td>\n",
              "      <td>119.597000</td>\n",
              "      <td>133.675003</td>\n",
              "      <td>110.617996</td>\n",
              "      <td>123.856003</td>\n",
              "      <td>123.856003</td>\n",
              "      <td>144948000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.337782e+08</td>\n",
              "      <td>2017-11-13</td>\n",
              "      <td>128.960007</td>\n",
              "      <td>136.528000</td>\n",
              "      <td>120.921997</td>\n",
              "      <td>123.402000</td>\n",
              "      <td>123.402000</td>\n",
              "      <td>116200000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1277.300049</td>\n",
              "      <td>...</td>\n",
              "      <td>1.163873</td>\n",
              "      <td>1.166113</td>\n",
              "      <td>1.166113</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2576.530029</td>\n",
              "      <td>2587.659912</td>\n",
              "      <td>2574.479980</td>\n",
              "      <td>2584.840088</td>\n",
              "      <td>2584.840088</td>\n",
              "      <td>3.405200e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2146</th>\n",
              "      <td>2.857872e+09</td>\n",
              "      <td>2023-10-04</td>\n",
              "      <td>147.168442</td>\n",
              "      <td>150.702347</td>\n",
              "      <td>145.940781</td>\n",
              "      <td>150.469055</td>\n",
              "      <td>150.469055</td>\n",
              "      <td>59400400</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1821.800049</td>\n",
              "      <td>...</td>\n",
              "      <td>1.045369</td>\n",
              "      <td>1.047230</td>\n",
              "      <td>1.047230</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4233.830078</td>\n",
              "      <td>4268.500000</td>\n",
              "      <td>4220.479980</td>\n",
              "      <td>4263.750000</td>\n",
              "      <td>4263.750000</td>\n",
              "      <td>3.777600e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2147</th>\n",
              "      <td>2.831952e+09</td>\n",
              "      <td>2023-10-05</td>\n",
              "      <td>150.474197</td>\n",
              "      <td>151.328369</td>\n",
              "      <td>148.565491</td>\n",
              "      <td>149.623718</td>\n",
              "      <td>149.623718</td>\n",
              "      <td>55704972</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1826.300049</td>\n",
              "      <td>...</td>\n",
              "      <td>1.050089</td>\n",
              "      <td>1.050707</td>\n",
              "      <td>1.050707</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4259.310059</td>\n",
              "      <td>4267.129883</td>\n",
              "      <td>4225.910156</td>\n",
              "      <td>4258.189941</td>\n",
              "      <td>4258.189941</td>\n",
              "      <td>3.581470e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2148</th>\n",
              "      <td>3.106746e+09</td>\n",
              "      <td>2023-10-06</td>\n",
              "      <td>149.623337</td>\n",
              "      <td>152.669296</td>\n",
              "      <td>148.641647</td>\n",
              "      <td>151.992264</td>\n",
              "      <td>151.992264</td>\n",
              "      <td>49535004</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1819.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.048394</td>\n",
              "      <td>1.054663</td>\n",
              "      <td>1.054663</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4234.790039</td>\n",
              "      <td>4324.100098</td>\n",
              "      <td>4219.549805</td>\n",
              "      <td>4308.500000</td>\n",
              "      <td>4308.500000</td>\n",
              "      <td>3.902030e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2149</th>\n",
              "      <td>2.815488e+09</td>\n",
              "      <td>2023-10-07</td>\n",
              "      <td>151.988235</td>\n",
              "      <td>155.247528</td>\n",
              "      <td>151.100983</td>\n",
              "      <td>155.212143</td>\n",
              "      <td>155.212143</td>\n",
              "      <td>61159796</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2150</th>\n",
              "      <td>2.773497e+09</td>\n",
              "      <td>2023-10-08</td>\n",
              "      <td>155.219528</td>\n",
              "      <td>156.482040</td>\n",
              "      <td>153.763336</td>\n",
              "      <td>156.191223</td>\n",
              "      <td>156.191223</td>\n",
              "      <td>59858985</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2151 rows × 27 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5764ffe7-55bf-4be1-b9d3-69517fde68db')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5764ffe7-55bf-4be1-b9d3-69517fde68db button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5764ffe7-55bf-4be1-b9d3-69517fde68db');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3531a722-4923-4d6b-b608-f1ec3c2c065a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3531a722-4923-4d6b-b608-f1ec3c2c065a')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3531a722-4923-4d6b-b608-f1ec3c2c065a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "dff = xmr_hash.sort_values(by=[\"time\", \"time_stamp\"]).drop_duplicates(subset=[\"time\"], keep=\"last\").merge(df, left_on=\"time\", right_on=\"Date\")\n",
        "dff = dff.drop(columns=[\"Date\", \"time_stamp\"])\n",
        "dff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "5h-Q_QSXPbBp",
        "outputId": "623ec19d-78e9-4c34-c9bf-ffc87f820119"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         time_stamp    difficulty       time          hash        Open  \\\n",
              "0     1510185600000  2.806786e+10 2017-11-09  2.338989e+08  112.531998   \n",
              "1     1510272000000  2.805339e+10 2017-11-10  2.337782e+08  121.344002   \n",
              "2     1510358400000  2.805339e+10 2017-11-11  2.337782e+08  105.750000   \n",
              "3     1510444800000  2.805339e+10 2017-11-12  2.337782e+08  119.597000   \n",
              "4     1510531200000  2.805339e+10 2017-11-13  2.337782e+08  128.960007   \n",
              "...             ...           ...        ...           ...         ...   \n",
              "2146  1696460400000  3.429447e+11 2023-10-04  2.857872e+09  147.168442   \n",
              "2147  1696546800000  3.398342e+11 2023-10-05  2.831952e+09  150.474197   \n",
              "2148  1696633200000  3.728095e+11 2023-10-06  3.106746e+09  149.623337   \n",
              "2149  1696719600000  3.378586e+11 2023-10-07  2.815488e+09  151.988235   \n",
              "2150  1696748400000  3.459221e+11 2023-10-08  2.773497e+09  155.219528   \n",
              "\n",
              "            High         Low       Close   Adj Close     Volume  ...  \\\n",
              "0     123.404999  112.219002  120.779999  120.779999   86864600  ...   \n",
              "1     121.665001  101.757004  105.585999  105.585999   84614000  ...   \n",
              "2     127.106003  103.877998  119.615997  119.615997  107708000  ...   \n",
              "3     133.675003  110.617996  123.856003  123.856003  144948000  ...   \n",
              "4     136.528000  120.921997  123.402000  123.402000  116200000  ...   \n",
              "...          ...         ...         ...         ...        ...  ...   \n",
              "2146  150.702347  145.940781  150.469055  150.469055   59400400  ...   \n",
              "2147  151.328369  148.565491  149.623718  149.623718   55704972  ...   \n",
              "2148  152.669296  148.641647  151.992264  151.992264   49535004  ...   \n",
              "2149  155.247528  151.100983  155.212143  155.212143   61159796  ...   \n",
              "2150  156.482040  153.763336  156.191223  156.191223   59858985  ...   \n",
              "\n",
              "      euro_usd_low  euro_usd_close  euro_usd_adj_close  euro_usd_volume  \\\n",
              "0         1.158641        1.159689            1.159689              0.0   \n",
              "1         1.162399        1.164687            1.164687              0.0   \n",
              "2              NaN             NaN                 NaN              NaN   \n",
              "3              NaN             NaN                 NaN              NaN   \n",
              "4         1.163873        1.166113            1.166113              0.0   \n",
              "...            ...             ...                 ...              ...   \n",
              "2146      1.045369        1.047230            1.047230              0.0   \n",
              "2147      1.050089        1.050707            1.050707              0.0   \n",
              "2148      1.048394        1.054663            1.054663              0.0   \n",
              "2149           NaN             NaN                 NaN              NaN   \n",
              "2150           NaN             NaN                 NaN              NaN   \n",
              "\n",
              "       sp500_open   sp500_high    sp500_low  sp500_close  sp500_adj_close  \\\n",
              "0     2584.000000  2586.500000  2566.330078  2584.620117      2584.620117   \n",
              "1     2580.179932  2583.810059  2575.570068  2582.300049      2582.300049   \n",
              "2             NaN          NaN          NaN          NaN              NaN   \n",
              "3             NaN          NaN          NaN          NaN              NaN   \n",
              "4     2576.530029  2587.659912  2574.479980  2584.840088      2584.840088   \n",
              "...           ...          ...          ...          ...              ...   \n",
              "2146  4233.830078  4268.500000  4220.479980  4263.750000      4263.750000   \n",
              "2147  4259.310059  4267.129883  4225.910156  4258.189941      4258.189941   \n",
              "2148  4234.790039  4324.100098  4219.549805  4308.500000      4308.500000   \n",
              "2149          NaN          NaN          NaN          NaN              NaN   \n",
              "2150          NaN          NaN          NaN          NaN              NaN   \n",
              "\n",
              "      sp500_volume  \n",
              "0     3.844100e+09  \n",
              "1     3.489740e+09  \n",
              "2              NaN  \n",
              "3              NaN  \n",
              "4     3.405200e+09  \n",
              "...            ...  \n",
              "2146  3.777600e+09  \n",
              "2147  3.581470e+09  \n",
              "2148  3.902030e+09  \n",
              "2149           NaN  \n",
              "2150           NaN  \n",
              "\n",
              "[2151 rows x 29 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-25d86043-5ba6-457d-be41-4e0e7842ae2c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time_stamp</th>\n",
              "      <th>difficulty</th>\n",
              "      <th>time</th>\n",
              "      <th>hash</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>...</th>\n",
              "      <th>euro_usd_low</th>\n",
              "      <th>euro_usd_close</th>\n",
              "      <th>euro_usd_adj_close</th>\n",
              "      <th>euro_usd_volume</th>\n",
              "      <th>sp500_open</th>\n",
              "      <th>sp500_high</th>\n",
              "      <th>sp500_low</th>\n",
              "      <th>sp500_close</th>\n",
              "      <th>sp500_adj_close</th>\n",
              "      <th>sp500_volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1510185600000</td>\n",
              "      <td>2.806786e+10</td>\n",
              "      <td>2017-11-09</td>\n",
              "      <td>2.338989e+08</td>\n",
              "      <td>112.531998</td>\n",
              "      <td>123.404999</td>\n",
              "      <td>112.219002</td>\n",
              "      <td>120.779999</td>\n",
              "      <td>120.779999</td>\n",
              "      <td>86864600</td>\n",
              "      <td>...</td>\n",
              "      <td>1.158641</td>\n",
              "      <td>1.159689</td>\n",
              "      <td>1.159689</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2584.000000</td>\n",
              "      <td>2586.500000</td>\n",
              "      <td>2566.330078</td>\n",
              "      <td>2584.620117</td>\n",
              "      <td>2584.620117</td>\n",
              "      <td>3.844100e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1510272000000</td>\n",
              "      <td>2.805339e+10</td>\n",
              "      <td>2017-11-10</td>\n",
              "      <td>2.337782e+08</td>\n",
              "      <td>121.344002</td>\n",
              "      <td>121.665001</td>\n",
              "      <td>101.757004</td>\n",
              "      <td>105.585999</td>\n",
              "      <td>105.585999</td>\n",
              "      <td>84614000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.162399</td>\n",
              "      <td>1.164687</td>\n",
              "      <td>1.164687</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2580.179932</td>\n",
              "      <td>2583.810059</td>\n",
              "      <td>2575.570068</td>\n",
              "      <td>2582.300049</td>\n",
              "      <td>2582.300049</td>\n",
              "      <td>3.489740e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1510358400000</td>\n",
              "      <td>2.805339e+10</td>\n",
              "      <td>2017-11-11</td>\n",
              "      <td>2.337782e+08</td>\n",
              "      <td>105.750000</td>\n",
              "      <td>127.106003</td>\n",
              "      <td>103.877998</td>\n",
              "      <td>119.615997</td>\n",
              "      <td>119.615997</td>\n",
              "      <td>107708000</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1510444800000</td>\n",
              "      <td>2.805339e+10</td>\n",
              "      <td>2017-11-12</td>\n",
              "      <td>2.337782e+08</td>\n",
              "      <td>119.597000</td>\n",
              "      <td>133.675003</td>\n",
              "      <td>110.617996</td>\n",
              "      <td>123.856003</td>\n",
              "      <td>123.856003</td>\n",
              "      <td>144948000</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1510531200000</td>\n",
              "      <td>2.805339e+10</td>\n",
              "      <td>2017-11-13</td>\n",
              "      <td>2.337782e+08</td>\n",
              "      <td>128.960007</td>\n",
              "      <td>136.528000</td>\n",
              "      <td>120.921997</td>\n",
              "      <td>123.402000</td>\n",
              "      <td>123.402000</td>\n",
              "      <td>116200000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.163873</td>\n",
              "      <td>1.166113</td>\n",
              "      <td>1.166113</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2576.530029</td>\n",
              "      <td>2587.659912</td>\n",
              "      <td>2574.479980</td>\n",
              "      <td>2584.840088</td>\n",
              "      <td>2584.840088</td>\n",
              "      <td>3.405200e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2146</th>\n",
              "      <td>1696460400000</td>\n",
              "      <td>3.429447e+11</td>\n",
              "      <td>2023-10-04</td>\n",
              "      <td>2.857872e+09</td>\n",
              "      <td>147.168442</td>\n",
              "      <td>150.702347</td>\n",
              "      <td>145.940781</td>\n",
              "      <td>150.469055</td>\n",
              "      <td>150.469055</td>\n",
              "      <td>59400400</td>\n",
              "      <td>...</td>\n",
              "      <td>1.045369</td>\n",
              "      <td>1.047230</td>\n",
              "      <td>1.047230</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4233.830078</td>\n",
              "      <td>4268.500000</td>\n",
              "      <td>4220.479980</td>\n",
              "      <td>4263.750000</td>\n",
              "      <td>4263.750000</td>\n",
              "      <td>3.777600e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2147</th>\n",
              "      <td>1696546800000</td>\n",
              "      <td>3.398342e+11</td>\n",
              "      <td>2023-10-05</td>\n",
              "      <td>2.831952e+09</td>\n",
              "      <td>150.474197</td>\n",
              "      <td>151.328369</td>\n",
              "      <td>148.565491</td>\n",
              "      <td>149.623718</td>\n",
              "      <td>149.623718</td>\n",
              "      <td>55704972</td>\n",
              "      <td>...</td>\n",
              "      <td>1.050089</td>\n",
              "      <td>1.050707</td>\n",
              "      <td>1.050707</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4259.310059</td>\n",
              "      <td>4267.129883</td>\n",
              "      <td>4225.910156</td>\n",
              "      <td>4258.189941</td>\n",
              "      <td>4258.189941</td>\n",
              "      <td>3.581470e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2148</th>\n",
              "      <td>1696633200000</td>\n",
              "      <td>3.728095e+11</td>\n",
              "      <td>2023-10-06</td>\n",
              "      <td>3.106746e+09</td>\n",
              "      <td>149.623337</td>\n",
              "      <td>152.669296</td>\n",
              "      <td>148.641647</td>\n",
              "      <td>151.992264</td>\n",
              "      <td>151.992264</td>\n",
              "      <td>49535004</td>\n",
              "      <td>...</td>\n",
              "      <td>1.048394</td>\n",
              "      <td>1.054663</td>\n",
              "      <td>1.054663</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4234.790039</td>\n",
              "      <td>4324.100098</td>\n",
              "      <td>4219.549805</td>\n",
              "      <td>4308.500000</td>\n",
              "      <td>4308.500000</td>\n",
              "      <td>3.902030e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2149</th>\n",
              "      <td>1696719600000</td>\n",
              "      <td>3.378586e+11</td>\n",
              "      <td>2023-10-07</td>\n",
              "      <td>2.815488e+09</td>\n",
              "      <td>151.988235</td>\n",
              "      <td>155.247528</td>\n",
              "      <td>151.100983</td>\n",
              "      <td>155.212143</td>\n",
              "      <td>155.212143</td>\n",
              "      <td>61159796</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2150</th>\n",
              "      <td>1696748400000</td>\n",
              "      <td>3.459221e+11</td>\n",
              "      <td>2023-10-08</td>\n",
              "      <td>2.773497e+09</td>\n",
              "      <td>155.219528</td>\n",
              "      <td>156.482040</td>\n",
              "      <td>153.763336</td>\n",
              "      <td>156.191223</td>\n",
              "      <td>156.191223</td>\n",
              "      <td>59858985</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2151 rows × 29 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25d86043-5ba6-457d-be41-4e0e7842ae2c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-25d86043-5ba6-457d-be41-4e0e7842ae2c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-25d86043-5ba6-457d-be41-4e0e7842ae2c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a74b0cdd-f676-4b1d-b26c-e8cfdb6edd75\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a74b0cdd-f676-4b1d-b26c-e8cfdb6edd75')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a74b0cdd-f676-4b1d-b26c-e8cfdb6edd75 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "dfff = xmr_difficulty.sort_values(by=[\"time\", \"time_stamp\"]).drop_duplicates(subset=[\"time\"], keep=\"last\").merge(dff, on=\"time\")\n",
        "dfff"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Missing Values"
      ],
      "metadata": {
        "id": "1nj1KAC7gT8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nF2nRkb0gS2G",
        "outputId": "de468613-d03b-4a34-a521-40dbd27f9a9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date                    0\n",
              "Open                    0\n",
              "High                    0\n",
              "Low                     0\n",
              "Close                   0\n",
              "Adj Close               0\n",
              "Volume                  0\n",
              "price_increase          0\n",
              "gold_open             675\n",
              "gold_high             675\n",
              "gold_low              675\n",
              "gold_close            675\n",
              "gold_adj_close        675\n",
              "gold_volume           675\n",
              "euro_usd_open         620\n",
              "euro_usd_high         620\n",
              "euro_usd_low          620\n",
              "euro_usd_close        620\n",
              "euro_usd_adj_close    620\n",
              "euro_usd_volume       620\n",
              "sp500_open            675\n",
              "sp500_high            675\n",
              "sp500_low             675\n",
              "sp500_close           675\n",
              "sp500_adj_close       675\n",
              "sp500_volume          675\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Test Split"
      ],
      "metadata": {
        "id": "Iv6EL6DagbBp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_WfIQwX9EDS",
        "outputId": "39688ca3-fadf-47f9-abc9-6ac0adf6e1f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-76-f22751a67258>:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  test = dfff[df[\"Date\"].isin(date_range)]\n"
          ]
        }
      ],
      "source": [
        "date_range = pd.date_range(start=\"2022-09-08\", end=\"2023-09-07\", freq='D')\n",
        "test = dfff[df[\"Date\"].isin(date_range)]\n",
        "train = dfff.drop(index=test.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b273CM6v9muV",
        "outputId": "2d2a76f8-61b5-4375-9cec-9787efc0e86c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1786, 28), (365, 28))"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "train.shape, test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "8zs7jSLh92hT",
        "outputId": "89956308-1a4c-42cf-8997-e0d1785b7f9b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7ba40797-c881-4341-83f8-4ac98b8a36ae\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time_stamp</th>\n",
              "      <th>difficulty</th>\n",
              "      <th>time</th>\n",
              "      <th>hash</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>...</th>\n",
              "      <th>euro_usd_low</th>\n",
              "      <th>euro_usd_close</th>\n",
              "      <th>euro_usd_adj_close</th>\n",
              "      <th>euro_usd_volume</th>\n",
              "      <th>sp500_open</th>\n",
              "      <th>sp500_high</th>\n",
              "      <th>sp500_low</th>\n",
              "      <th>sp500_close</th>\n",
              "      <th>sp500_adj_close</th>\n",
              "      <th>sp500_volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1510185600000</td>\n",
              "      <td>2.806786e+10</td>\n",
              "      <td>2017-11-09</td>\n",
              "      <td>2.338989e+08</td>\n",
              "      <td>112.531998</td>\n",
              "      <td>123.404999</td>\n",
              "      <td>112.219002</td>\n",
              "      <td>120.779999</td>\n",
              "      <td>120.779999</td>\n",
              "      <td>86864600</td>\n",
              "      <td>...</td>\n",
              "      <td>1.158641</td>\n",
              "      <td>1.159689</td>\n",
              "      <td>1.159689</td>\n",
              "      <td>0</td>\n",
              "      <td>2584.000000</td>\n",
              "      <td>2586.500000</td>\n",
              "      <td>2566.330078</td>\n",
              "      <td>2584.620117</td>\n",
              "      <td>2584.620117</td>\n",
              "      <td>3844100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1510272000000</td>\n",
              "      <td>2.805339e+10</td>\n",
              "      <td>2017-11-10</td>\n",
              "      <td>2.337782e+08</td>\n",
              "      <td>121.344002</td>\n",
              "      <td>121.665001</td>\n",
              "      <td>101.757004</td>\n",
              "      <td>105.585999</td>\n",
              "      <td>105.585999</td>\n",
              "      <td>84614000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.162399</td>\n",
              "      <td>1.164687</td>\n",
              "      <td>1.164687</td>\n",
              "      <td>0</td>\n",
              "      <td>2580.179932</td>\n",
              "      <td>2583.810059</td>\n",
              "      <td>2575.570068</td>\n",
              "      <td>2582.300049</td>\n",
              "      <td>2582.300049</td>\n",
              "      <td>3489740000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1510531200000</td>\n",
              "      <td>2.805339e+10</td>\n",
              "      <td>2017-11-13</td>\n",
              "      <td>2.337782e+08</td>\n",
              "      <td>128.960007</td>\n",
              "      <td>136.528000</td>\n",
              "      <td>120.921997</td>\n",
              "      <td>123.402000</td>\n",
              "      <td>123.402000</td>\n",
              "      <td>116200000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.163873</td>\n",
              "      <td>1.166113</td>\n",
              "      <td>1.166113</td>\n",
              "      <td>0</td>\n",
              "      <td>2576.530029</td>\n",
              "      <td>2587.659912</td>\n",
              "      <td>2574.479980</td>\n",
              "      <td>2584.840088</td>\n",
              "      <td>2584.840088</td>\n",
              "      <td>3405200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1510617600000</td>\n",
              "      <td>2.805339e+10</td>\n",
              "      <td>2017-11-14</td>\n",
              "      <td>2.337782e+08</td>\n",
              "      <td>123.615997</td>\n",
              "      <td>124.200996</td>\n",
              "      <td>118.625999</td>\n",
              "      <td>122.352997</td>\n",
              "      <td>122.352997</td>\n",
              "      <td>53544800</td>\n",
              "      <td>...</td>\n",
              "      <td>1.166330</td>\n",
              "      <td>1.166494</td>\n",
              "      <td>1.166494</td>\n",
              "      <td>0</td>\n",
              "      <td>2577.750000</td>\n",
              "      <td>2579.659912</td>\n",
              "      <td>2566.560059</td>\n",
              "      <td>2578.870117</td>\n",
              "      <td>2578.870117</td>\n",
              "      <td>3643580000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1510704000000</td>\n",
              "      <td>2.805339e+10</td>\n",
              "      <td>2017-11-15</td>\n",
              "      <td>2.337782e+08</td>\n",
              "      <td>122.240997</td>\n",
              "      <td>124.722000</td>\n",
              "      <td>119.192001</td>\n",
              "      <td>121.374001</td>\n",
              "      <td>121.374001</td>\n",
              "      <td>49976700</td>\n",
              "      <td>...</td>\n",
              "      <td>1.178606</td>\n",
              "      <td>1.179287</td>\n",
              "      <td>1.179287</td>\n",
              "      <td>0</td>\n",
              "      <td>2569.449951</td>\n",
              "      <td>2572.840088</td>\n",
              "      <td>2557.449951</td>\n",
              "      <td>2564.620117</td>\n",
              "      <td>2564.620117</td>\n",
              "      <td>3586590000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1472</th>\n",
              "      <td>1696287600000</td>\n",
              "      <td>3.644654e+11</td>\n",
              "      <td>2023-10-02</td>\n",
              "      <td>3.037211e+09</td>\n",
              "      <td>149.158157</td>\n",
              "      <td>149.989868</td>\n",
              "      <td>145.494705</td>\n",
              "      <td>146.203430</td>\n",
              "      <td>146.203430</td>\n",
              "      <td>62225244</td>\n",
              "      <td>...</td>\n",
              "      <td>1.049274</td>\n",
              "      <td>1.056524</td>\n",
              "      <td>1.056524</td>\n",
              "      <td>0</td>\n",
              "      <td>4284.520020</td>\n",
              "      <td>4300.580078</td>\n",
              "      <td>4260.209961</td>\n",
              "      <td>4288.390137</td>\n",
              "      <td>4288.390137</td>\n",
              "      <td>3938660000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1473</th>\n",
              "      <td>1696374000000</td>\n",
              "      <td>3.260903e+11</td>\n",
              "      <td>2023-10-03</td>\n",
              "      <td>2.717420e+09</td>\n",
              "      <td>146.193024</td>\n",
              "      <td>147.805603</td>\n",
              "      <td>145.165909</td>\n",
              "      <td>147.151352</td>\n",
              "      <td>147.151352</td>\n",
              "      <td>49389643</td>\n",
              "      <td>...</td>\n",
              "      <td>1.044987</td>\n",
              "      <td>1.048075</td>\n",
              "      <td>1.048075</td>\n",
              "      <td>0</td>\n",
              "      <td>4269.750000</td>\n",
              "      <td>4281.149902</td>\n",
              "      <td>4216.450195</td>\n",
              "      <td>4229.450195</td>\n",
              "      <td>4229.450195</td>\n",
              "      <td>3953830000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1474</th>\n",
              "      <td>1696460400000</td>\n",
              "      <td>3.429447e+11</td>\n",
              "      <td>2023-10-04</td>\n",
              "      <td>2.857872e+09</td>\n",
              "      <td>147.168442</td>\n",
              "      <td>150.702347</td>\n",
              "      <td>145.940781</td>\n",
              "      <td>150.469055</td>\n",
              "      <td>150.469055</td>\n",
              "      <td>59400400</td>\n",
              "      <td>...</td>\n",
              "      <td>1.045369</td>\n",
              "      <td>1.047230</td>\n",
              "      <td>1.047230</td>\n",
              "      <td>0</td>\n",
              "      <td>4233.830078</td>\n",
              "      <td>4268.500000</td>\n",
              "      <td>4220.479980</td>\n",
              "      <td>4263.750000</td>\n",
              "      <td>4263.750000</td>\n",
              "      <td>3777600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1475</th>\n",
              "      <td>1696546800000</td>\n",
              "      <td>3.398342e+11</td>\n",
              "      <td>2023-10-05</td>\n",
              "      <td>2.831952e+09</td>\n",
              "      <td>150.474197</td>\n",
              "      <td>151.328369</td>\n",
              "      <td>148.565491</td>\n",
              "      <td>149.623718</td>\n",
              "      <td>149.623718</td>\n",
              "      <td>55704972</td>\n",
              "      <td>...</td>\n",
              "      <td>1.050089</td>\n",
              "      <td>1.050707</td>\n",
              "      <td>1.050707</td>\n",
              "      <td>0</td>\n",
              "      <td>4259.310059</td>\n",
              "      <td>4267.129883</td>\n",
              "      <td>4225.910156</td>\n",
              "      <td>4258.189941</td>\n",
              "      <td>4258.189941</td>\n",
              "      <td>3581470000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1476</th>\n",
              "      <td>1696633200000</td>\n",
              "      <td>3.728095e+11</td>\n",
              "      <td>2023-10-06</td>\n",
              "      <td>3.106746e+09</td>\n",
              "      <td>149.623337</td>\n",
              "      <td>152.669296</td>\n",
              "      <td>148.641647</td>\n",
              "      <td>151.992264</td>\n",
              "      <td>151.992264</td>\n",
              "      <td>49535004</td>\n",
              "      <td>...</td>\n",
              "      <td>1.048394</td>\n",
              "      <td>1.054663</td>\n",
              "      <td>1.054663</td>\n",
              "      <td>0</td>\n",
              "      <td>4234.790039</td>\n",
              "      <td>4324.100098</td>\n",
              "      <td>4219.549805</td>\n",
              "      <td>4308.500000</td>\n",
              "      <td>4308.500000</td>\n",
              "      <td>3902030000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1226 rows × 29 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ba40797-c881-4341-83f8-4ac98b8a36ae')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7ba40797-c881-4341-83f8-4ac98b8a36ae button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7ba40797-c881-4341-83f8-4ac98b8a36ae');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f0f34d11-3385-4dd6-a56d-541535b924fd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f0f34d11-3385-4dd6-a56d-541535b924fd')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f0f34d11-3385-4dd6-a56d-541535b924fd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         time_stamp    difficulty       time          hash        Open  \\\n",
              "0     1510185600000  2.806786e+10 2017-11-09  2.338989e+08  112.531998   \n",
              "1     1510272000000  2.805339e+10 2017-11-10  2.337782e+08  121.344002   \n",
              "2     1510531200000  2.805339e+10 2017-11-13  2.337782e+08  128.960007   \n",
              "3     1510617600000  2.805339e+10 2017-11-14  2.337782e+08  123.615997   \n",
              "4     1510704000000  2.805339e+10 2017-11-15  2.337782e+08  122.240997   \n",
              "...             ...           ...        ...           ...         ...   \n",
              "1472  1696287600000  3.644654e+11 2023-10-02  3.037211e+09  149.158157   \n",
              "1473  1696374000000  3.260903e+11 2023-10-03  2.717420e+09  146.193024   \n",
              "1474  1696460400000  3.429447e+11 2023-10-04  2.857872e+09  147.168442   \n",
              "1475  1696546800000  3.398342e+11 2023-10-05  2.831952e+09  150.474197   \n",
              "1476  1696633200000  3.728095e+11 2023-10-06  3.106746e+09  149.623337   \n",
              "\n",
              "            High         Low       Close   Adj Close     Volume  ...  \\\n",
              "0     123.404999  112.219002  120.779999  120.779999   86864600  ...   \n",
              "1     121.665001  101.757004  105.585999  105.585999   84614000  ...   \n",
              "2     136.528000  120.921997  123.402000  123.402000  116200000  ...   \n",
              "3     124.200996  118.625999  122.352997  122.352997   53544800  ...   \n",
              "4     124.722000  119.192001  121.374001  121.374001   49976700  ...   \n",
              "...          ...         ...         ...         ...        ...  ...   \n",
              "1472  149.989868  145.494705  146.203430  146.203430   62225244  ...   \n",
              "1473  147.805603  145.165909  147.151352  147.151352   49389643  ...   \n",
              "1474  150.702347  145.940781  150.469055  150.469055   59400400  ...   \n",
              "1475  151.328369  148.565491  149.623718  149.623718   55704972  ...   \n",
              "1476  152.669296  148.641647  151.992264  151.992264   49535004  ...   \n",
              "\n",
              "      euro_usd_low  euro_usd_close  euro_usd_adj_close  euro_usd_volume  \\\n",
              "0         1.158641        1.159689            1.159689                0   \n",
              "1         1.162399        1.164687            1.164687                0   \n",
              "2         1.163873        1.166113            1.166113                0   \n",
              "3         1.166330        1.166494            1.166494                0   \n",
              "4         1.178606        1.179287            1.179287                0   \n",
              "...            ...             ...                 ...              ...   \n",
              "1472      1.049274        1.056524            1.056524                0   \n",
              "1473      1.044987        1.048075            1.048075                0   \n",
              "1474      1.045369        1.047230            1.047230                0   \n",
              "1475      1.050089        1.050707            1.050707                0   \n",
              "1476      1.048394        1.054663            1.054663                0   \n",
              "\n",
              "       sp500_open   sp500_high    sp500_low  sp500_close  sp500_adj_close  \\\n",
              "0     2584.000000  2586.500000  2566.330078  2584.620117      2584.620117   \n",
              "1     2580.179932  2583.810059  2575.570068  2582.300049      2582.300049   \n",
              "2     2576.530029  2587.659912  2574.479980  2584.840088      2584.840088   \n",
              "3     2577.750000  2579.659912  2566.560059  2578.870117      2578.870117   \n",
              "4     2569.449951  2572.840088  2557.449951  2564.620117      2564.620117   \n",
              "...           ...          ...          ...          ...              ...   \n",
              "1472  4284.520020  4300.580078  4260.209961  4288.390137      4288.390137   \n",
              "1473  4269.750000  4281.149902  4216.450195  4229.450195      4229.450195   \n",
              "1474  4233.830078  4268.500000  4220.479980  4263.750000      4263.750000   \n",
              "1475  4259.310059  4267.129883  4225.910156  4258.189941      4258.189941   \n",
              "1476  4234.790039  4324.100098  4219.549805  4308.500000      4308.500000   \n",
              "\n",
              "      sp500_volume  \n",
              "0       3844100000  \n",
              "1       3489740000  \n",
              "2       3405200000  \n",
              "3       3643580000  \n",
              "4       3586590000  \n",
              "...            ...  \n",
              "1472    3938660000  \n",
              "1473    3953830000  \n",
              "1474    3777600000  \n",
              "1475    3581470000  \n",
              "1476    3902030000  \n",
              "\n",
              "[1226 rows x 29 columns]"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCfl8PQbYgwN"
      },
      "source": [
        "## Train Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-b1glzJ_NQH"
      },
      "outputs": [],
      "source": [
        "X = train.drop(columns=[\"time_stamp\", \"price_increase\", \"time\"])\n",
        "y = train[\"price_increase\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uutonFuw93Ci"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_test = test.drop(columns=[\"time_stamp\", \"price_increase\", \"time\"])\n",
        "y_test = test[\"price_increase\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxdalnfoMYA-"
      },
      "source": [
        "## Experimenting with Machine Learning Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nf9auCTLMpsG"
      },
      "source": [
        "### Stochastic Gradient Descent Classifier\n",
        "\n",
        "Stochastic Gradient Descent (SGD) is a simple yet very efficient approach to fitting linear classifiers and regressors under convex loss functions such as (linear) Support Vector Machines and Logistic Regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLcL45WjM8pS"
      },
      "source": [
        "#### Training Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RjOPvs_A_mwr",
        "outputId": "d87710ab-742f-4b4c-e266-40e056a1ba9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "[CV 2/5; 137/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.792 total time=   0.0s\n",
            "[CV 3/5; 137/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 137/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 137/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 137/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.800 total time=   0.0s\n",
            "[CV 5/5; 137/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 137/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 1/5; 138/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 138/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.872 total time=   0.0s\n",
            "[CV 2/5; 138/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 138/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.860 total time=   0.0s\n",
            "[CV 3/5; 138/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 138/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.644 total time=   0.0s\n",
            "[CV 4/5; 138/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 138/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.916 total time=   0.0s\n",
            "[CV 5/5; 138/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 138/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.812 total time=   0.0s\n",
            "[CV 1/5; 139/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 139/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.744 total time=   0.0s\n",
            "[CV 2/5; 139/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 139/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 139/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 139/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 139/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 139/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.916 total time=   0.0s\n",
            "[CV 5/5; 139/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 139/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.936 total time=   0.0s\n",
            "[CV 1/5; 140/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 140/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.844 total time=   0.0s\n",
            "[CV 2/5; 140/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 140/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.812 total time=   0.0s\n",
            "[CV 3/5; 140/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 140/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.740 total time=   0.0s\n",
            "[CV 4/5; 140/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 140/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.672 total time=   0.0s\n",
            "[CV 5/5; 140/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 140/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 141/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 141/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.908 total time=   0.0s\n",
            "[CV 2/5; 141/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 141/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 3/5; 141/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 141/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.756 total time=   0.0s\n",
            "[CV 4/5; 141/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 141/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.852 total time=   0.0s\n",
            "[CV 5/5; 141/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 141/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.940 total time=   0.0s\n",
            "[CV 1/5; 142/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 142/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.828 total time=   0.0s\n",
            "[CV 2/5; 142/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 142/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.928 total time=   0.0s\n",
            "[CV 3/5; 142/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 142/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.708 total time=   0.0s\n",
            "[CV 4/5; 142/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 142/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.760 total time=   0.0s\n",
            "[CV 5/5; 142/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 142/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.908 total time=   0.0s\n",
            "[CV 1/5; 143/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 143/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 2/5; 143/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 143/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.748 total time=   0.0s\n",
            "[CV 3/5; 143/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 143/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.928 total time=   0.0s\n",
            "[CV 4/5; 143/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 143/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.824 total time=   0.0s\n",
            "[CV 5/5; 143/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 143/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.836 total time=   0.0s\n",
            "[CV 1/5; 144/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 1/5; 144/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.924 total time=   0.0s\n",
            "[CV 2/5; 144/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 2/5; 144/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 3/5; 144/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 3/5; 144/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.788 total time=   0.0s\n",
            "[CV 4/5; 144/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 4/5; 144/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.952 total time=   0.0s\n",
            "[CV 5/5; 144/1344] START alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 5/5; 144/1344] END alpha=1e-06, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 1/5; 145/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 145/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.916 total time=   0.0s\n",
            "[CV 2/5; 145/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 145/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.836 total time=   0.0s\n",
            "[CV 3/5; 145/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 145/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.892 total time=   0.0s\n",
            "[CV 4/5; 145/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 145/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.816 total time=   0.0s\n",
            "[CV 5/5; 145/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 145/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.776 total time=   0.0s\n",
            "[CV 1/5; 146/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 146/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.768 total time=   0.0s\n",
            "[CV 2/5; 146/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 146/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.904 total time=   0.0s\n",
            "[CV 3/5; 146/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 146/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.808 total time=   0.0s\n",
            "[CV 4/5; 146/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 146/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.896 total time=   0.0s\n",
            "[CV 5/5; 146/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 146/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.916 total time=   0.0s\n",
            "[CV 1/5; 147/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 147/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.896 total time=   0.0s\n",
            "[CV 2/5; 147/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 147/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.828 total time=   0.0s\n",
            "[CV 3/5; 147/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 147/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.968 total time=   0.0s\n",
            "[CV 4/5; 147/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 147/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.780 total time=   0.0s\n",
            "[CV 5/5; 147/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 147/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 1/5; 148/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 148/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.732 total time=   0.0s\n",
            "[CV 2/5; 148/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 148/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.764 total time=   0.0s\n",
            "[CV 3/5; 148/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 148/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.880 total time=   0.0s\n",
            "[CV 4/5; 148/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 148/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.824 total time=   0.0s\n",
            "[CV 5/5; 148/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 148/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.880 total time=   0.0s\n",
            "[CV 1/5; 149/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 149/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.796 total time=   0.0s\n",
            "[CV 2/5; 149/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 149/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.952 total time=   0.0s\n",
            "[CV 3/5; 149/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 149/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.884 total time=   0.0s\n",
            "[CV 4/5; 149/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 149/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 5/5; 149/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 149/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.880 total time=   0.0s\n",
            "[CV 1/5; 150/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 150/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.816 total time=   0.0s\n",
            "[CV 2/5; 150/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 150/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 150/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 150/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.844 total time=   0.0s\n",
            "[CV 4/5; 150/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 150/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.824 total time=   0.0s\n",
            "[CV 5/5; 150/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 150/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.832 total time=   0.0s\n",
            "[CV 1/5; 151/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 151/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.924 total time=   0.0s\n",
            "[CV 2/5; 151/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 151/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.956 total time=   0.0s\n",
            "[CV 3/5; 151/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 151/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.860 total time=   0.0s\n",
            "[CV 4/5; 151/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 151/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 151/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 151/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.840 total time=   0.0s\n",
            "[CV 1/5; 152/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 152/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.760 total time=   0.0s\n",
            "[CV 2/5; 152/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 152/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.884 total time=   0.0s\n",
            "[CV 3/5; 152/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 152/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.768 total time=   0.0s\n",
            "[CV 4/5; 152/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 152/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 152/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 152/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.956 total time=   0.0s\n",
            "[CV 1/5; 153/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 153/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.796 total time=   0.0s\n",
            "[CV 2/5; 153/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 153/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.676 total time=   0.0s\n",
            "[CV 3/5; 153/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 153/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.820 total time=   0.0s\n",
            "[CV 4/5; 153/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 153/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 153/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 153/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.924 total time=   0.0s\n",
            "[CV 1/5; 154/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 154/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.840 total time=   0.0s\n",
            "[CV 2/5; 154/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 154/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.932 total time=   0.0s\n",
            "[CV 3/5; 154/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 154/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.876 total time=   0.0s\n",
            "[CV 4/5; 154/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 154/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.820 total time=   0.0s\n",
            "[CV 5/5; 154/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 154/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.788 total time=   0.0s\n",
            "[CV 1/5; 155/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 155/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.820 total time=   0.0s\n",
            "[CV 2/5; 155/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 155/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.820 total time=   0.0s\n",
            "[CV 3/5; 155/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 155/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.828 total time=   0.0s\n",
            "[CV 4/5; 155/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 155/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.852 total time=   0.0s\n",
            "[CV 5/5; 155/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 155/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.868 total time=   0.0s\n",
            "[CV 1/5; 156/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 156/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.808 total time=   0.0s\n",
            "[CV 2/5; 156/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 156/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.892 total time=   0.0s\n",
            "[CV 3/5; 156/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 156/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.864 total time=   0.0s\n",
            "[CV 4/5; 156/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 156/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.916 total time=   0.0s\n",
            "[CV 5/5; 156/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 156/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.912 total time=   0.0s\n",
            "[CV 1/5; 157/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 157/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.856 total time=   0.0s\n",
            "[CV 2/5; 157/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 157/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.936 total time=   0.0s\n",
            "[CV 3/5; 157/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 157/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.796 total time=   0.0s\n",
            "[CV 4/5; 157/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 157/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.956 total time=   0.0s\n",
            "[CV 5/5; 157/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 157/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 1/5; 158/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 158/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.924 total time=   0.0s\n",
            "[CV 2/5; 158/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 158/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 158/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 158/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.820 total time=   0.0s\n",
            "[CV 4/5; 158/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 158/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.784 total time=   0.0s\n",
            "[CV 5/5; 158/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 158/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.844 total time=   0.0s\n",
            "[CV 1/5; 159/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 159/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.932 total time=   0.0s\n",
            "[CV 2/5; 159/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 159/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.892 total time=   0.0s\n",
            "[CV 3/5; 159/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 159/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.876 total time=   0.0s\n",
            "[CV 4/5; 159/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 159/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.904 total time=   0.0s\n",
            "[CV 5/5; 159/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 159/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.812 total time=   0.0s\n",
            "[CV 1/5; 160/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 1/5; 160/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.832 total time=   0.0s\n",
            "[CV 2/5; 160/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 2/5; 160/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.936 total time=   0.0s\n",
            "[CV 3/5; 160/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 3/5; 160/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.808 total time=   0.0s\n",
            "[CV 4/5; 160/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 4/5; 160/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.916 total time=   0.0s\n",
            "[CV 5/5; 160/1344] START alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 5/5; 160/1344] END alpha=1e-06, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 161/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 161/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.716 total time=   0.0s\n",
            "[CV 2/5; 161/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 161/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.704 total time=   0.0s\n",
            "[CV 3/5; 161/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 161/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.840 total time=   0.0s\n",
            "[CV 4/5; 161/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 161/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.796 total time=   0.0s\n",
            "[CV 5/5; 161/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 161/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.724 total time=   0.0s\n",
            "[CV 1/5; 162/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 162/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 2/5; 162/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 162/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.856 total time=   0.0s\n",
            "[CV 3/5; 162/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 162/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.756 total time=   0.0s\n",
            "[CV 4/5; 162/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 162/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.896 total time=   0.0s\n",
            "[CV 5/5; 162/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 162/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.708 total time=   0.0s\n",
            "[CV 1/5; 163/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 163/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.796 total time=   0.0s\n",
            "[CV 2/5; 163/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 163/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.916 total time=   0.0s\n",
            "[CV 3/5; 163/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 163/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.736 total time=   0.0s\n",
            "[CV 4/5; 163/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 163/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.864 total time=   0.0s\n",
            "[CV 5/5; 163/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 163/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.700 total time=   0.0s\n",
            "[CV 1/5; 164/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 164/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.756 total time=   0.0s\n",
            "[CV 2/5; 164/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 164/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 164/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 164/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.884 total time=   0.0s\n",
            "[CV 4/5; 164/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 164/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.744 total time=   0.0s\n",
            "[CV 5/5; 164/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 164/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.924 total time=   0.0s\n",
            "[CV 1/5; 165/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 165/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.832 total time=   0.0s\n",
            "[CV 2/5; 165/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 165/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.920 total time=   0.0s\n",
            "[CV 3/5; 165/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 165/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.748 total time=   0.0s\n",
            "[CV 4/5; 165/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 165/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.896 total time=   0.0s\n",
            "[CV 5/5; 165/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 165/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.816 total time=   0.0s\n",
            "[CV 1/5; 166/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 166/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.704 total time=   0.0s\n",
            "[CV 2/5; 166/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 166/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 3/5; 166/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 166/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.932 total time=   0.0s\n",
            "[CV 4/5; 166/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 166/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 5/5; 166/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 166/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.968 total time=   0.0s\n",
            "[CV 1/5; 167/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 167/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.952 total time=   0.0s\n",
            "[CV 2/5; 167/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 167/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.860 total time=   0.0s\n",
            "[CV 3/5; 167/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 167/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.780 total time=   0.0s\n",
            "[CV 4/5; 167/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 167/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.852 total time=   0.0s\n",
            "[CV 5/5; 167/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 167/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.872 total time=   0.0s\n",
            "[CV 1/5; 168/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 168/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.936 total time=   0.0s\n",
            "[CV 2/5; 168/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 168/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.860 total time=   0.0s\n",
            "[CV 3/5; 168/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 168/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.896 total time=   0.0s\n",
            "[CV 4/5; 168/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 168/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.872 total time=   0.0s\n",
            "[CV 5/5; 168/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 168/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.812 total time=   0.0s\n",
            "[CV 1/5; 169/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 169/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.816 total time=   0.0s\n",
            "[CV 2/5; 169/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 169/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.904 total time=   0.0s\n",
            "[CV 3/5; 169/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 169/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.940 total time=   0.0s\n",
            "[CV 4/5; 169/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 169/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.876 total time=   0.0s\n",
            "[CV 5/5; 169/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 169/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.904 total time=   0.0s\n",
            "[CV 1/5; 170/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 170/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 2/5; 170/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 170/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.900 total time=   0.0s\n",
            "[CV 3/5; 170/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 170/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 170/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 170/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.780 total time=   0.0s\n",
            "[CV 5/5; 170/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 170/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 1/5; 171/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 171/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 2/5; 171/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 171/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 3/5; 171/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 171/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.772 total time=   0.0s\n",
            "[CV 4/5; 171/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 171/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.908 total time=   0.0s\n",
            "[CV 5/5; 171/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 171/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.768 total time=   0.0s\n",
            "[CV 1/5; 172/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 172/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.868 total time=   0.0s\n",
            "[CV 2/5; 172/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 172/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.916 total time=   0.0s\n",
            "[CV 3/5; 172/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 172/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 172/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 172/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.756 total time=   0.0s\n",
            "[CV 5/5; 172/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 172/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.780 total time=   0.0s\n",
            "[CV 1/5; 173/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 173/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 173/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 173/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.796 total time=   0.0s\n",
            "[CV 3/5; 173/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 173/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.960 total time=   0.0s\n",
            "[CV 4/5; 173/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 173/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.832 total time=   0.0s\n",
            "[CV 5/5; 173/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 173/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 174/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 174/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.904 total time=   0.0s\n",
            "[CV 2/5; 174/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 174/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 174/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 174/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.884 total time=   0.0s\n",
            "[CV 4/5; 174/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 174/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 5/5; 174/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 174/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.896 total time=   0.0s\n",
            "[CV 1/5; 175/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 175/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.816 total time=   0.0s\n",
            "[CV 2/5; 175/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 175/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.836 total time=   0.0s\n",
            "[CV 3/5; 175/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 175/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 4/5; 175/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 175/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.820 total time=   0.0s\n",
            "[CV 5/5; 175/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 175/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.952 total time=   0.0s\n",
            "[CV 1/5; 176/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 1/5; 176/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.860 total time=   0.0s\n",
            "[CV 2/5; 176/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 2/5; 176/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.844 total time=   0.0s\n",
            "[CV 3/5; 176/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 3/5; 176/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.756 total time=   0.0s\n",
            "[CV 4/5; 176/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 4/5; 176/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.856 total time=   0.0s\n",
            "[CV 5/5; 176/1344] START alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 5/5; 176/1344] END alpha=1e-06, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.924 total time=   0.0s\n",
            "[CV 1/5; 177/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 177/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 177/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 177/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 177/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 177/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.820 total time=   0.0s\n",
            "[CV 4/5; 177/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 177/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.788 total time=   0.0s\n",
            "[CV 5/5; 177/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 177/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.864 total time=   0.0s\n",
            "[CV 1/5; 178/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 178/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.860 total time=   0.0s\n",
            "[CV 2/5; 178/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 178/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.912 total time=   0.0s\n",
            "[CV 3/5; 178/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 178/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.660 total time=   0.0s\n",
            "[CV 4/5; 178/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 178/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.836 total time=   0.0s\n",
            "[CV 5/5; 178/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 178/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 179/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 179/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.840 total time=   0.0s\n",
            "[CV 2/5; 179/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 179/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.684 total time=   0.0s\n",
            "[CV 3/5; 179/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 179/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 179/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 179/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.676 total time=   0.0s\n",
            "[CV 5/5; 179/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 179/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.808 total time=   0.0s\n",
            "[CV 1/5; 180/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 180/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.880 total time=   0.0s\n",
            "[CV 2/5; 180/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 180/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.780 total time=   0.0s\n",
            "[CV 3/5; 180/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 180/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.752 total time=   0.0s\n",
            "[CV 4/5; 180/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 180/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 180/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 180/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.792 total time=   0.0s\n",
            "[CV 1/5; 181/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 181/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.716 total time=   0.0s\n",
            "[CV 2/5; 181/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 181/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 181/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 181/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.832 total time=   0.0s\n",
            "[CV 4/5; 181/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 181/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 5/5; 181/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 181/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.856 total time=   0.0s\n",
            "[CV 1/5; 182/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 182/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.880 total time=   0.0s\n",
            "[CV 2/5; 182/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 182/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.812 total time=   0.0s\n",
            "[CV 3/5; 182/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 182/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 182/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 182/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.908 total time=   0.0s\n",
            "[CV 5/5; 182/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 182/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.968 total time=   0.0s\n",
            "[CV 1/5; 183/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 183/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.956 total time=   0.0s\n",
            "[CV 2/5; 183/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 183/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.844 total time=   0.0s\n",
            "[CV 3/5; 183/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 183/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.804 total time=   0.0s\n",
            "[CV 4/5; 183/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 183/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 5/5; 183/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 183/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.916 total time=   0.0s\n",
            "[CV 1/5; 184/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 184/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.768 total time=   0.0s\n",
            "[CV 2/5; 184/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 184/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.892 total time=   0.0s\n",
            "[CV 3/5; 184/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 184/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.864 total time=   0.0s\n",
            "[CV 4/5; 184/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 184/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.900 total time=   0.0s\n",
            "[CV 5/5; 184/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 184/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.892 total time=   0.0s\n",
            "[CV 1/5; 185/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 185/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.864 total time=   0.0s\n",
            "[CV 2/5; 185/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 185/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.900 total time=   0.0s\n",
            "[CV 3/5; 185/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 185/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.932 total time=   0.0s\n",
            "[CV 4/5; 185/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 185/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.824 total time=   0.0s\n",
            "[CV 5/5; 185/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 185/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.932 total time=   0.0s\n",
            "[CV 1/5; 186/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 186/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.872 total time=   0.0s\n",
            "[CV 2/5; 186/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 186/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.884 total time=   0.0s\n",
            "[CV 3/5; 186/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 186/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.680 total time=   0.0s\n",
            "[CV 4/5; 186/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 186/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 186/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 186/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.872 total time=   0.0s\n",
            "[CV 1/5; 187/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 187/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.776 total time=   0.0s\n",
            "[CV 2/5; 187/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 187/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.796 total time=   0.0s\n",
            "[CV 3/5; 187/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 187/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.860 total time=   0.0s\n",
            "[CV 4/5; 187/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 187/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 187/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 187/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 188/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 188/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.864 total time=   0.0s\n",
            "[CV 2/5; 188/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 188/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 188/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 188/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.912 total time=   0.0s\n",
            "[CV 4/5; 188/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 188/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.768 total time=   0.0s\n",
            "[CV 5/5; 188/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 188/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.820 total time=   0.0s\n",
            "[CV 1/5; 189/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 189/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 2/5; 189/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 189/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 189/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 189/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 189/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 189/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.920 total time=   0.0s\n",
            "[CV 5/5; 189/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 189/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 190/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 190/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.932 total time=   0.0s\n",
            "[CV 2/5; 190/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 190/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.928 total time=   0.0s\n",
            "[CV 3/5; 190/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 190/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.900 total time=   0.0s\n",
            "[CV 4/5; 190/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 190/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.836 total time=   0.0s\n",
            "[CV 5/5; 190/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 190/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.824 total time=   0.0s\n",
            "[CV 1/5; 191/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 191/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 2/5; 191/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 191/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.872 total time=   0.0s\n",
            "[CV 3/5; 191/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 191/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.804 total time=   0.0s\n",
            "[CV 4/5; 191/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 191/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.824 total time=   0.0s\n",
            "[CV 5/5; 191/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 191/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.836 total time=   0.0s\n",
            "[CV 1/5; 192/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 1/5; 192/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.852 total time=   0.0s\n",
            "[CV 2/5; 192/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 2/5; 192/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 3/5; 192/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 3/5; 192/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.712 total time=   0.0s\n",
            "[CV 4/5; 192/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 4/5; 192/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 192/1344] START alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 5/5; 192/1344] END alpha=1e-06, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.916 total time=   0.0s\n",
            "[CV 1/5; 193/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 193/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.864 total time=   0.0s\n",
            "[CV 2/5; 193/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 193/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.768 total time=   0.0s\n",
            "[CV 3/5; 193/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 193/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.708 total time=   0.0s\n",
            "[CV 4/5; 193/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 193/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 5/5; 193/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 193/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.800 total time=   0.0s\n",
            "[CV 1/5; 194/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 194/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.792 total time=   0.0s\n",
            "[CV 2/5; 194/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 194/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.924 total time=   0.0s\n",
            "[CV 3/5; 194/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 194/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.892 total time=   0.0s\n",
            "[CV 4/5; 194/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 194/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.872 total time=   0.0s\n",
            "[CV 5/5; 194/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 194/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.812 total time=   0.0s\n",
            "[CV 1/5; 195/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 195/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.960 total time=   0.0s\n",
            "[CV 2/5; 195/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 195/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.920 total time=   0.0s\n",
            "[CV 3/5; 195/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 195/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.744 total time=   0.0s\n",
            "[CV 4/5; 195/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 195/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.884 total time=   0.0s\n",
            "[CV 5/5; 195/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 195/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.880 total time=   0.0s\n",
            "[CV 1/5; 196/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 196/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.916 total time=   0.0s\n",
            "[CV 2/5; 196/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 196/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.796 total time=   0.0s\n",
            "[CV 3/5; 196/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 196/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.760 total time=   0.0s\n",
            "[CV 4/5; 196/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 196/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.928 total time=   0.0s\n",
            "[CV 5/5; 196/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 196/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.836 total time=   0.0s\n",
            "[CV 1/5; 197/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 197/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.924 total time=   0.0s\n",
            "[CV 2/5; 197/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 197/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.900 total time=   0.0s\n",
            "[CV 3/5; 197/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 197/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 197/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 197/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 5/5; 197/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 197/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.896 total time=   0.0s\n",
            "[CV 1/5; 198/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 198/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.912 total time=   0.0s\n",
            "[CV 2/5; 198/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 198/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 3/5; 198/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 198/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.820 total time=   0.0s\n",
            "[CV 4/5; 198/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 198/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 5/5; 198/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 198/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.900 total time=   0.0s\n",
            "[CV 1/5; 199/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 199/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 2/5; 199/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 199/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 199/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 199/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.916 total time=   0.0s\n",
            "[CV 4/5; 199/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 199/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 5/5; 199/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 199/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 1/5; 200/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 200/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.936 total time=   0.0s\n",
            "[CV 2/5; 200/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 200/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.920 total time=   0.0s\n",
            "[CV 3/5; 200/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 200/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.940 total time=   0.0s\n",
            "[CV 4/5; 200/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 200/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.936 total time=   0.0s\n",
            "[CV 5/5; 200/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 200/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.892 total time=   0.0s\n",
            "[CV 1/5; 201/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 201/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.860 total time=   0.0s\n",
            "[CV 2/5; 201/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 201/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.796 total time=   0.0s\n",
            "[CV 3/5; 201/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 201/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.912 total time=   0.0s\n",
            "[CV 4/5; 201/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 201/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.932 total time=   0.0s\n",
            "[CV 5/5; 201/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 201/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.824 total time=   0.0s\n",
            "[CV 1/5; 202/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 202/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.744 total time=   0.0s\n",
            "[CV 2/5; 202/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 202/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.884 total time=   0.0s\n",
            "[CV 3/5; 202/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 202/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.872 total time=   0.0s\n",
            "[CV 4/5; 202/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 202/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.896 total time=   0.0s\n",
            "[CV 5/5; 202/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 202/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 1/5; 203/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 203/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.868 total time=   0.0s\n",
            "[CV 2/5; 203/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 203/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.856 total time=   0.0s\n",
            "[CV 3/5; 203/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 203/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.776 total time=   0.0s\n",
            "[CV 4/5; 203/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 203/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.908 total time=   0.0s\n",
            "[CV 5/5; 203/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 203/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.912 total time=   0.0s\n",
            "[CV 1/5; 204/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 204/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.832 total time=   0.0s\n",
            "[CV 2/5; 204/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 204/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 3/5; 204/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 204/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.852 total time=   0.0s\n",
            "[CV 4/5; 204/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 204/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.884 total time=   0.0s\n",
            "[CV 5/5; 204/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 204/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.896 total time=   0.0s\n",
            "[CV 1/5; 205/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 205/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.952 total time=   0.0s\n",
            "[CV 2/5; 205/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 205/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.908 total time=   0.0s\n",
            "[CV 3/5; 205/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 205/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 205/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 205/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.968 total time=   0.0s\n",
            "[CV 5/5; 205/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 205/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.956 total time=   0.0s\n",
            "[CV 1/5; 206/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 206/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.908 total time=   0.0s\n",
            "[CV 2/5; 206/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 206/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 3/5; 206/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 206/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.952 total time=   0.0s\n",
            "[CV 4/5; 206/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 206/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.968 total time=   0.0s\n",
            "[CV 5/5; 206/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 206/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.956 total time=   0.0s\n",
            "[CV 1/5; 207/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 207/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.956 total time=   0.0s\n",
            "[CV 2/5; 207/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 207/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.956 total time=   0.0s\n",
            "[CV 3/5; 207/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 207/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 207/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 207/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 5/5; 207/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 207/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.924 total time=   0.0s\n",
            "[CV 1/5; 208/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 1/5; 208/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.908 total time=   0.0s\n",
            "[CV 2/5; 208/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 2/5; 208/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.860 total time=   0.0s\n",
            "[CV 3/5; 208/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 3/5; 208/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.896 total time=   0.0s\n",
            "[CV 4/5; 208/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 4/5; 208/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.908 total time=   0.0s\n",
            "[CV 5/5; 208/1344] START alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 5/5; 208/1344] END alpha=1e-05, loss=hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.904 total time=   0.0s\n",
            "[CV 1/5; 209/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 209/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.812 total time=   0.0s\n",
            "[CV 2/5; 209/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 209/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.916 total time=   0.0s\n",
            "[CV 3/5; 209/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 209/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.812 total time=   0.0s\n",
            "[CV 4/5; 209/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 209/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.800 total time=   0.0s\n",
            "[CV 5/5; 209/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 209/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.788 total time=   0.0s\n",
            "[CV 1/5; 210/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 210/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 210/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 210/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.852 total time=   0.0s\n",
            "[CV 3/5; 210/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 210/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.748 total time=   0.0s\n",
            "[CV 4/5; 210/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 210/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.936 total time=   0.0s\n",
            "[CV 5/5; 210/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 210/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.768 total time=   0.0s\n",
            "[CV 1/5; 211/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 211/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.916 total time=   0.0s\n",
            "[CV 2/5; 211/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 211/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.824 total time=   0.0s\n",
            "[CV 3/5; 211/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 211/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 211/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 211/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 5/5; 211/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 211/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.852 total time=   0.0s\n",
            "[CV 1/5; 212/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 212/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.740 total time=   0.0s\n",
            "[CV 2/5; 212/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 212/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.860 total time=   0.0s\n",
            "[CV 3/5; 212/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 212/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.884 total time=   0.0s\n",
            "[CV 4/5; 212/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 212/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.800 total time=   0.0s\n",
            "[CV 5/5; 212/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 212/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.908 total time=   0.0s\n",
            "[CV 1/5; 213/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 213/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.900 total time=   0.0s\n",
            "[CV 2/5; 213/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 213/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.852 total time=   0.0s\n",
            "[CV 3/5; 213/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 213/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 213/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 213/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.880 total time=   0.0s\n",
            "[CV 5/5; 213/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 213/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 1/5; 214/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 214/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.904 total time=   0.0s\n",
            "[CV 2/5; 214/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 214/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.992 total time=   0.0s\n",
            "[CV 3/5; 214/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 214/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 4/5; 214/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 214/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 5/5; 214/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 214/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.916 total time=   0.0s\n",
            "[CV 1/5; 215/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 215/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 2/5; 215/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 215/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 3/5; 215/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 215/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.952 total time=   0.0s\n",
            "[CV 4/5; 215/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 215/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 5/5; 215/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 215/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.932 total time=   0.0s\n",
            "[CV 1/5; 216/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 216/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.800 total time=   0.0s\n",
            "[CV 2/5; 216/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 216/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.880 total time=   0.0s\n",
            "[CV 3/5; 216/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 216/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 4/5; 216/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 216/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.968 total time=   0.0s\n",
            "[CV 5/5; 216/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 216/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.896 total time=   0.0s\n",
            "[CV 1/5; 217/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 217/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.840 total time=   0.0s\n",
            "[CV 2/5; 217/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 217/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.832 total time=   0.0s\n",
            "[CV 3/5; 217/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 217/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.880 total time=   0.0s\n",
            "[CV 4/5; 217/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 217/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.772 total time=   0.0s\n",
            "[CV 5/5; 217/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 217/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.908 total time=   0.0s\n",
            "[CV 1/5; 218/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 218/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.868 total time=   0.0s\n",
            "[CV 2/5; 218/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 218/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.800 total time=   0.0s\n",
            "[CV 3/5; 218/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 218/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 218/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 218/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 5/5; 218/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 218/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.868 total time=   0.0s\n",
            "[CV 1/5; 219/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 219/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.772 total time=   0.0s\n",
            "[CV 2/5; 219/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 219/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.900 total time=   0.0s\n",
            "[CV 3/5; 219/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 219/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.908 total time=   0.0s\n",
            "[CV 4/5; 219/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 219/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.808 total time=   0.0s\n",
            "[CV 5/5; 219/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 219/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.856 total time=   0.0s\n",
            "[CV 1/5; 220/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 220/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.804 total time=   0.0s\n",
            "[CV 2/5; 220/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 220/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.896 total time=   0.0s\n",
            "[CV 3/5; 220/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 220/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.900 total time=   0.0s\n",
            "[CV 4/5; 220/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 220/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.884 total time=   0.0s\n",
            "[CV 5/5; 220/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 220/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.908 total time=   0.0s\n",
            "[CV 1/5; 221/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 221/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.956 total time=   0.0s\n",
            "[CV 2/5; 221/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 221/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 3/5; 221/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 221/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.852 total time=   0.0s\n",
            "[CV 4/5; 221/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 221/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 5/5; 221/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 221/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 222/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 222/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.904 total time=   0.0s\n",
            "[CV 2/5; 222/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 222/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 222/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 222/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 222/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 222/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.944 total time=   0.0s\n",
            "[CV 5/5; 222/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 222/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 223/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 223/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.968 total time=   0.0s\n",
            "[CV 2/5; 223/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 223/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 3/5; 223/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 223/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.868 total time=   0.0s\n",
            "[CV 4/5; 223/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 223/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 223/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 223/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.968 total time=   0.0s\n",
            "[CV 1/5; 224/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 1/5; 224/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.908 total time=   0.0s\n",
            "[CV 2/5; 224/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 2/5; 224/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 3/5; 224/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 3/5; 224/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 224/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 4/5; 224/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.932 total time=   0.0s\n",
            "[CV 5/5; 224/1344] START alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 5/5; 224/1344] END alpha=1e-05, loss=hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.920 total time=   0.0s\n",
            "[CV 1/5; 225/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 225/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.768 total time=   0.0s\n",
            "[CV 2/5; 225/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 225/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.932 total time=   0.0s\n",
            "[CV 3/5; 225/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 225/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.696 total time=   0.0s\n",
            "[CV 4/5; 225/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 225/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.872 total time=   0.0s\n",
            "[CV 5/5; 225/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 225/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.916 total time=   0.0s\n",
            "[CV 1/5; 226/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 226/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.900 total time=   0.0s\n",
            "[CV 2/5; 226/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 226/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.744 total time=   0.0s\n",
            "[CV 3/5; 226/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 226/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.796 total time=   0.0s\n",
            "[CV 4/5; 226/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 226/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.956 total time=   0.0s\n",
            "[CV 5/5; 226/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 226/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 227/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 227/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 227/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 227/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 227/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 227/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.724 total time=   0.0s\n",
            "[CV 4/5; 227/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 227/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.916 total time=   0.0s\n",
            "[CV 5/5; 227/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 227/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.908 total time=   0.0s\n",
            "[CV 1/5; 228/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 228/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.768 total time=   0.0s\n",
            "[CV 2/5; 228/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 228/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.956 total time=   0.0s\n",
            "[CV 3/5; 228/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 228/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.928 total time=   0.0s\n",
            "[CV 4/5; 228/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 228/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.720 total time=   0.0s\n",
            "[CV 5/5; 228/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 228/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.816 total time=   0.0s\n",
            "[CV 1/5; 229/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 229/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 2/5; 229/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 229/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 229/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 229/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.920 total time=   0.0s\n",
            "[CV 4/5; 229/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 229/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 5/5; 229/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 229/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.892 total time=   0.0s\n",
            "[CV 1/5; 230/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 230/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.916 total time=   0.0s\n",
            "[CV 2/5; 230/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 230/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 230/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 230/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.828 total time=   0.0s\n",
            "[CV 4/5; 230/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 230/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.928 total time=   0.0s\n",
            "[CV 5/5; 230/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 230/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 231/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 231/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 2/5; 231/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 231/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 231/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 231/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 4/5; 231/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 231/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.952 total time=   0.0s\n",
            "[CV 5/5; 231/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 231/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.936 total time=   0.0s\n",
            "[CV 1/5; 232/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 232/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 232/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 232/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.876 total time=   0.0s\n",
            "[CV 3/5; 232/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 232/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.856 total time=   0.0s\n",
            "[CV 4/5; 232/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 232/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.944 total time=   0.0s\n",
            "[CV 5/5; 232/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 232/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 233/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 233/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.840 total time=   0.0s\n",
            "[CV 2/5; 233/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 233/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.832 total time=   0.0s\n",
            "[CV 3/5; 233/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 233/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.936 total time=   0.0s\n",
            "[CV 4/5; 233/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 233/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.912 total time=   0.0s\n",
            "[CV 5/5; 233/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 233/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.836 total time=   0.0s\n",
            "[CV 1/5; 234/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 234/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.960 total time=   0.0s\n",
            "[CV 2/5; 234/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 234/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.892 total time=   0.0s\n",
            "[CV 3/5; 234/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 234/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.876 total time=   0.0s\n",
            "[CV 4/5; 234/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 234/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.900 total time=   0.0s\n",
            "[CV 5/5; 234/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 234/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.944 total time=   0.0s\n",
            "[CV 1/5; 235/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 235/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.952 total time=   0.0s\n",
            "[CV 2/5; 235/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 235/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.748 total time=   0.0s\n",
            "[CV 3/5; 235/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 235/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.896 total time=   0.0s\n",
            "[CV 4/5; 235/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 235/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.924 total time=   0.0s\n",
            "[CV 5/5; 235/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 235/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.856 total time=   0.0s\n",
            "[CV 1/5; 236/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 236/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.892 total time=   0.0s\n",
            "[CV 2/5; 236/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 236/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.880 total time=   0.0s\n",
            "[CV 3/5; 236/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 236/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.924 total time=   0.0s\n",
            "[CV 4/5; 236/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 236/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.928 total time=   0.0s\n",
            "[CV 5/5; 236/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 236/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.768 total time=   0.0s\n",
            "[CV 1/5; 237/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 237/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 2/5; 237/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 237/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 237/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 237/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.856 total time=   0.0s\n",
            "[CV 4/5; 237/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 237/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 237/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 237/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 238/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 238/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.896 total time=   0.0s\n",
            "[CV 2/5; 238/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 238/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.956 total time=   0.0s\n",
            "[CV 3/5; 238/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 238/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.812 total time=   0.0s\n",
            "[CV 4/5; 238/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 238/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.792 total time=   0.0s\n",
            "[CV 5/5; 238/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 238/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.944 total time=   0.0s\n",
            "[CV 1/5; 239/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 239/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 2/5; 239/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 239/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 3/5; 239/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 239/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.868 total time=   0.0s\n",
            "[CV 4/5; 239/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 239/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.952 total time=   0.0s\n",
            "[CV 5/5; 239/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 239/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.956 total time=   0.0s\n",
            "[CV 1/5; 240/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 1/5; 240/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.788 total time=   0.0s\n",
            "[CV 2/5; 240/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 2/5; 240/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 240/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 3/5; 240/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 240/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 4/5; 240/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.912 total time=   0.0s\n",
            "[CV 5/5; 240/1344] START alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 5/5; 240/1344] END alpha=1e-05, loss=hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.872 total time=   0.0s\n",
            "[CV 1/5; 241/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 241/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06;, score=0.884 total time=   0.0s\n",
            "[CV 2/5; 241/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 241/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 3/5; 241/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 241/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06;, score=0.808 total time=   0.0s\n",
            "[CV 4/5; 241/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 241/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06;, score=0.780 total time=   0.0s\n",
            "[CV 5/5; 241/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 241/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06;, score=0.896 total time=   0.0s\n",
            "[CV 1/5; 242/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 242/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05;, score=0.784 total time=   0.0s\n",
            "[CV 2/5; 242/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 242/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 242/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 242/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05;, score=0.836 total time=   0.0s\n",
            "[CV 4/5; 242/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 242/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05;, score=0.900 total time=   0.0s\n",
            "[CV 5/5; 242/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 242/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05;, score=0.804 total time=   0.0s\n",
            "[CV 1/5; 243/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 243/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001;, score=0.876 total time=   0.0s\n",
            "[CV 2/5; 243/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 243/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001;, score=0.908 total time=   0.0s\n",
            "[CV 3/5; 243/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 243/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001;, score=0.812 total time=   0.0s\n",
            "[CV 4/5; 243/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 243/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001;, score=0.856 total time=   0.0s\n",
            "[CV 5/5; 243/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 243/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001;, score=0.892 total time=   0.0s\n",
            "[CV 1/5; 244/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 244/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001;, score=0.824 total time=   0.0s\n",
            "[CV 2/5; 244/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 244/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001;, score=0.900 total time=   0.0s\n",
            "[CV 3/5; 244/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 244/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001;, score=0.720 total time=   0.0s\n",
            "[CV 4/5; 244/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 244/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001;, score=0.820 total time=   0.0s\n",
            "[CV 5/5; 244/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 244/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001;, score=0.824 total time=   0.0s\n",
            "[CV 1/5; 245/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 245/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06;, score=0.916 total time=   0.0s\n",
            "[CV 2/5; 245/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 245/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 3/5; 245/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 245/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 245/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 245/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06;, score=0.924 total time=   0.0s\n",
            "[CV 5/5; 245/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 245/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06;, score=0.916 total time=   0.0s\n",
            "[CV 1/5; 246/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 246/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 2/5; 246/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 246/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 3/5; 246/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 246/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05;, score=0.872 total time=   0.0s\n",
            "[CV 4/5; 246/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 246/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05;, score=0.932 total time=   0.0s\n",
            "[CV 5/5; 246/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 246/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05;, score=0.912 total time=   0.0s\n",
            "[CV 1/5; 247/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 247/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 2/5; 247/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 247/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 3/5; 247/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 247/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001;, score=0.932 total time=   0.0s\n",
            "[CV 4/5; 247/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 247/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 5/5; 247/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 247/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 1/5; 248/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 248/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 2/5; 248/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 248/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 248/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 248/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001;, score=0.896 total time=   0.0s\n",
            "[CV 4/5; 248/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 248/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 5/5; 248/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 248/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 249/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 249/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.956 total time=   0.0s\n",
            "[CV 2/5; 249/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 249/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 3/5; 249/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 249/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.952 total time=   0.0s\n",
            "[CV 4/5; 249/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 249/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 249/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 249/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 250/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 250/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.936 total time=   0.0s\n",
            "[CV 2/5; 250/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 250/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.860 total time=   0.0s\n",
            "[CV 3/5; 250/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 250/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.796 total time=   0.0s\n",
            "[CV 4/5; 250/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 250/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.872 total time=   0.0s\n",
            "[CV 5/5; 250/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 250/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.920 total time=   0.0s\n",
            "[CV 1/5; 251/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 251/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.820 total time=   0.0s\n",
            "[CV 2/5; 251/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 251/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.876 total time=   0.0s\n",
            "[CV 3/5; 251/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 251/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.876 total time=   0.0s\n",
            "[CV 4/5; 251/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 251/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 251/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 251/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.800 total time=   0.0s\n",
            "[CV 1/5; 252/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 252/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.952 total time=   0.0s\n",
            "[CV 2/5; 252/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 252/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.804 total time=   0.0s\n",
            "[CV 3/5; 252/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 252/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.820 total time=   0.0s\n",
            "[CV 4/5; 252/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 252/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.828 total time=   0.0s\n",
            "[CV 5/5; 252/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 252/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.804 total time=   0.0s\n",
            "[CV 1/5; 253/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 253/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06;, score=0.956 total time=   0.0s\n",
            "[CV 2/5; 253/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 253/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06;, score=0.992 total time=   0.0s\n",
            "[CV 3/5; 253/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 253/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06;, score=0.940 total time=   0.0s\n",
            "[CV 4/5; 253/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 253/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06;, score=0.952 total time=   0.0s\n",
            "[CV 5/5; 253/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 253/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06;, score=0.900 total time=   0.0s\n",
            "[CV 1/5; 254/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 254/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 2/5; 254/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 254/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 254/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 254/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05;, score=0.924 total time=   0.0s\n",
            "[CV 4/5; 254/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 254/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 254/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 254/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05;, score=0.908 total time=   0.0s\n",
            "[CV 1/5; 255/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 255/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001;, score=0.924 total time=   0.0s\n",
            "[CV 2/5; 255/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 255/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 3/5; 255/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 255/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 255/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 255/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001;, score=0.956 total time=   0.0s\n",
            "[CV 5/5; 255/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 255/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 256/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 1/5; 256/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=0.001;, score=0.944 total time=   0.0s\n",
            "[CV 2/5; 256/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 2/5; 256/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 256/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 3/5; 256/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 4/5; 256/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 4/5; 256/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 5/5; 256/1344] START alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 5/5; 256/1344] END alpha=1e-05, loss=log_loss, max_iter=1000, penalty=None, tol=0.001;, score=0.940 total time=   0.0s\n",
            "[CV 1/5; 257/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 257/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06;, score=0.696 total time=   0.0s\n",
            "[CV 2/5; 257/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 257/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06;, score=0.824 total time=   0.0s\n",
            "[CV 3/5; 257/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 257/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06;, score=0.896 total time=   0.0s\n",
            "[CV 4/5; 257/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 257/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06;, score=0.804 total time=   0.0s\n",
            "[CV 5/5; 257/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 257/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06;, score=0.920 total time=   0.0s\n",
            "[CV 1/5; 258/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 258/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05;, score=0.840 total time=   0.0s\n",
            "[CV 2/5; 258/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 258/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05;, score=0.824 total time=   0.0s\n",
            "[CV 3/5; 258/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 258/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05;, score=0.840 total time=   0.0s\n",
            "[CV 4/5; 258/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 258/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 5/5; 258/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 258/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05;, score=0.900 total time=   0.0s\n",
            "[CV 1/5; 259/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 259/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 259/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 259/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001;, score=0.772 total time=   0.0s\n",
            "[CV 3/5; 259/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 259/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001;, score=0.952 total time=   0.0s\n",
            "[CV 4/5; 259/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 259/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001;, score=0.732 total time=   0.0s\n",
            "[CV 5/5; 259/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 259/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001;, score=0.832 total time=   0.0s\n",
            "[CV 1/5; 260/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 260/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001;, score=0.836 total time=   0.0s\n",
            "[CV 2/5; 260/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 260/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001;, score=0.796 total time=   0.0s\n",
            "[CV 3/5; 260/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 260/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001;, score=0.832 total time=   0.0s\n",
            "[CV 4/5; 260/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 260/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001;, score=0.816 total time=   0.0s\n",
            "[CV 5/5; 260/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 260/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001;, score=0.896 total time=   0.0s\n",
            "[CV 1/5; 261/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 261/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06;, score=0.956 total time=   0.0s\n",
            "[CV 2/5; 261/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 261/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06;, score=0.936 total time=   0.0s\n",
            "[CV 3/5; 261/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 261/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06;, score=0.952 total time=   0.0s\n",
            "[CV 4/5; 261/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 261/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 5/5; 261/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 261/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06;, score=0.900 total time=   0.0s\n",
            "[CV 1/5; 262/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 262/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05;, score=0.968 total time=   0.0s\n",
            "[CV 2/5; 262/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 262/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05;, score=0.956 total time=   0.0s\n",
            "[CV 3/5; 262/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 262/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05;, score=0.828 total time=   0.0s\n",
            "[CV 4/5; 262/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 262/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05;, score=0.916 total time=   0.0s\n",
            "[CV 5/5; 262/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 262/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05;, score=0.892 total time=   0.0s\n",
            "[CV 1/5; 263/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 263/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 2/5; 263/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 263/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 263/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 263/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001;, score=0.932 total time=   0.0s\n",
            "[CV 4/5; 263/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 263/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 263/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 263/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 1/5; 264/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 264/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001;, score=0.900 total time=   0.0s\n",
            "[CV 2/5; 264/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 264/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 264/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 264/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001;, score=0.940 total time=   0.0s\n",
            "[CV 4/5; 264/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 264/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001;, score=0.904 total time=   0.0s\n",
            "[CV 5/5; 264/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 264/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 1/5; 265/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 265/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.808 total time=   0.0s\n",
            "[CV 2/5; 265/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 265/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.936 total time=   0.0s\n",
            "[CV 3/5; 265/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 265/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.868 total time=   0.0s\n",
            "[CV 4/5; 265/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 265/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.904 total time=   0.0s\n",
            "[CV 5/5; 265/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 265/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.916 total time=   0.0s\n",
            "[CV 1/5; 266/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 266/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.860 total time=   0.0s\n",
            "[CV 2/5; 266/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 266/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.916 total time=   0.0s\n",
            "[CV 3/5; 266/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 266/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.808 total time=   0.0s\n",
            "[CV 4/5; 266/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 266/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.828 total time=   0.0s\n",
            "[CV 5/5; 266/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 266/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.796 total time=   0.0s\n",
            "[CV 1/5; 267/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 267/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.912 total time=   0.0s\n",
            "[CV 2/5; 267/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 267/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.812 total time=   0.0s\n",
            "[CV 3/5; 267/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 267/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.688 total time=   0.0s\n",
            "[CV 4/5; 267/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 267/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.828 total time=   0.0s\n",
            "[CV 5/5; 267/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 267/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.880 total time=   0.0s\n",
            "[CV 1/5; 268/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 268/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.892 total time=   0.0s\n",
            "[CV 2/5; 268/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 268/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.900 total time=   0.0s\n",
            "[CV 3/5; 268/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 268/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.852 total time=   0.0s\n",
            "[CV 4/5; 268/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 268/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.864 total time=   0.0s\n",
            "[CV 5/5; 268/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 268/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.820 total time=   0.0s\n",
            "[CV 1/5; 269/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 269/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 2/5; 269/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 269/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 269/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 269/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06;, score=0.916 total time=   0.0s\n",
            "[CV 4/5; 269/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 269/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 5/5; 269/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 269/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 270/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 270/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 2/5; 270/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 270/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05;, score=0.912 total time=   0.0s\n",
            "[CV 3/5; 270/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 270/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05;, score=0.896 total time=   0.0s\n",
            "[CV 4/5; 270/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 270/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 5/5; 270/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 270/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05;, score=0.944 total time=   0.0s\n",
            "[CV 1/5; 271/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 271/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 2/5; 271/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 271/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001;, score=0.928 total time=   0.0s\n",
            "[CV 3/5; 271/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 271/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 271/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 271/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 5/5; 271/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 271/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 1/5; 272/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 1/5; 272/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 2/5; 272/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 2/5; 272/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=0.001;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 272/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 3/5; 272/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=0.001;, score=0.908 total time=   0.0s\n",
            "[CV 4/5; 272/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 4/5; 272/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 272/1344] START alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 5/5; 272/1344] END alpha=1e-05, loss=log_loss, max_iter=10000, penalty=None, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 273/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 273/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06;, score=0.792 total time=   0.0s\n",
            "[CV 2/5; 273/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 273/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06;, score=0.876 total time=   0.0s\n",
            "[CV 3/5; 273/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 273/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 273/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 273/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06;, score=0.872 total time=   0.0s\n",
            "[CV 5/5; 273/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 273/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 1/5; 274/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 274/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 274/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 274/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05;, score=0.864 total time=   0.0s\n",
            "[CV 3/5; 274/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 274/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05;, score=0.784 total time=   0.0s\n",
            "[CV 4/5; 274/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 274/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05;, score=0.920 total time=   0.0s\n",
            "[CV 5/5; 274/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 274/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 1/5; 275/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 275/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001;, score=0.884 total time=   0.0s\n",
            "[CV 2/5; 275/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 275/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001;, score=0.744 total time=   0.0s\n",
            "[CV 3/5; 275/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 275/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 275/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 275/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 5/5; 275/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 275/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001;, score=0.872 total time=   0.0s\n",
            "[CV 1/5; 276/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 276/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001;, score=0.944 total time=   0.0s\n",
            "[CV 2/5; 276/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 276/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001;, score=0.784 total time=   0.0s\n",
            "[CV 3/5; 276/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 276/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001;, score=0.916 total time=   0.0s\n",
            "[CV 4/5; 276/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 276/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001;, score=0.760 total time=   0.0s\n",
            "[CV 5/5; 276/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 276/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001;, score=0.620 total time=   0.0s\n",
            "[CV 1/5; 277/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 277/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 2/5; 277/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 277/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06;, score=0.896 total time=   0.0s\n",
            "[CV 3/5; 277/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 277/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06;, score=0.940 total time=   0.0s\n",
            "[CV 4/5; 277/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 277/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 277/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 277/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06;, score=0.956 total time=   0.0s\n",
            "[CV 1/5; 278/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 278/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 278/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 278/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 278/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 278/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05;, score=0.916 total time=   0.0s\n",
            "[CV 4/5; 278/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 278/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05;, score=0.960 total time=   0.0s\n",
            "[CV 5/5; 278/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 278/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 279/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 279/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001;, score=0.952 total time=   0.0s\n",
            "[CV 2/5; 279/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 279/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001;, score=0.880 total time=   0.0s\n",
            "[CV 3/5; 279/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 279/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001;, score=0.876 total time=   0.0s\n",
            "[CV 4/5; 279/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 279/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001;, score=0.936 total time=   0.0s\n",
            "[CV 5/5; 279/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 279/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 280/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 280/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 2/5; 280/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 280/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 280/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 280/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001;, score=0.968 total time=   0.0s\n",
            "[CV 4/5; 280/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 280/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 280/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 280/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001;, score=0.912 total time=   0.0s\n",
            "[CV 1/5; 281/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 281/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.792 total time=   0.0s\n",
            "[CV 2/5; 281/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 281/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 3/5; 281/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 281/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.936 total time=   0.0s\n",
            "[CV 4/5; 281/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 281/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.800 total time=   0.0s\n",
            "[CV 5/5; 281/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 281/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.924 total time=   0.0s\n",
            "[CV 1/5; 282/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 282/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.784 total time=   0.0s\n",
            "[CV 2/5; 282/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 282/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 282/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 282/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.652 total time=   0.0s\n",
            "[CV 4/5; 282/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 282/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 282/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 282/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.824 total time=   0.0s\n",
            "[CV 1/5; 283/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 283/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 283/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 283/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 283/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 283/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 283/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 283/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.868 total time=   0.0s\n",
            "[CV 5/5; 283/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 283/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.912 total time=   0.0s\n",
            "[CV 1/5; 284/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 284/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.908 total time=   0.0s\n",
            "[CV 2/5; 284/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 284/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 3/5; 284/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 284/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.852 total time=   0.0s\n",
            "[CV 4/5; 284/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 284/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 284/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 284/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.872 total time=   0.0s\n",
            "[CV 1/5; 285/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 285/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 2/5; 285/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 285/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06;, score=0.896 total time=   0.0s\n",
            "[CV 3/5; 285/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 285/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 285/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 285/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06;, score=0.836 total time=   0.0s\n",
            "[CV 5/5; 285/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 285/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06;, score=0.920 total time=   0.0s\n",
            "[CV 1/5; 286/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 286/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05;, score=0.928 total time=   0.0s\n",
            "[CV 2/5; 286/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 286/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 3/5; 286/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 286/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05;, score=0.908 total time=   0.0s\n",
            "[CV 4/5; 286/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 286/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 5/5; 286/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 286/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05;, score=0.936 total time=   0.0s\n",
            "[CV 1/5; 287/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 287/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 287/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 287/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 3/5; 287/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 287/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001;, score=0.860 total time=   0.0s\n",
            "[CV 4/5; 287/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 287/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001;, score=0.936 total time=   0.0s\n",
            "[CV 5/5; 287/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 287/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 288/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 1/5; 288/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=0.001;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 288/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 2/5; 288/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 3/5; 288/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 3/5; 288/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 4/5; 288/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 4/5; 288/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=0.001;, score=0.884 total time=   0.0s\n",
            "[CV 5/5; 288/1344] START alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 5/5; 288/1344] END alpha=1e-05, loss=log_loss, max_iter=100000, penalty=None, tol=0.001;, score=0.880 total time=   0.0s\n",
            "[CV 1/5; 289/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 289/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.780 total time=   0.0s\n",
            "[CV 2/5; 289/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 289/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.952 total time=   0.0s\n",
            "[CV 3/5; 289/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 289/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.864 total time=   0.0s\n",
            "[CV 4/5; 289/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 289/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.796 total time=   0.0s\n",
            "[CV 5/5; 289/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 289/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.884 total time=   0.0s\n",
            "[CV 1/5; 290/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 290/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.776 total time=   0.0s\n",
            "[CV 2/5; 290/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 290/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.804 total time=   0.0s\n",
            "[CV 3/5; 290/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 290/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.744 total time=   0.0s\n",
            "[CV 4/5; 290/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 290/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.884 total time=   0.0s\n",
            "[CV 5/5; 290/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 290/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.876 total time=   0.0s\n",
            "[CV 1/5; 291/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 291/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.864 total time=   0.0s\n",
            "[CV 2/5; 291/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 291/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.856 total time=   0.0s\n",
            "[CV 3/5; 291/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 291/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.912 total time=   0.0s\n",
            "[CV 4/5; 291/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 291/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 291/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 291/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.788 total time=   0.0s\n",
            "[CV 1/5; 292/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 292/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.760 total time=   0.0s\n",
            "[CV 2/5; 292/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 292/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.820 total time=   0.0s\n",
            "[CV 3/5; 292/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 292/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.920 total time=   0.0s\n",
            "[CV 4/5; 292/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 292/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.784 total time=   0.0s\n",
            "[CV 5/5; 292/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 292/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.820 total time=   0.0s\n",
            "[CV 1/5; 293/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 293/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.900 total time=   0.0s\n",
            "[CV 2/5; 293/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 293/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 293/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 293/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.924 total time=   0.0s\n",
            "[CV 4/5; 293/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 293/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.916 total time=   0.0s\n",
            "[CV 5/5; 293/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 293/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.856 total time=   0.0s\n",
            "[CV 1/5; 294/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 294/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.852 total time=   0.0s\n",
            "[CV 2/5; 294/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 294/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 294/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 294/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.868 total time=   0.0s\n",
            "[CV 4/5; 294/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 294/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.884 total time=   0.0s\n",
            "[CV 5/5; 294/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 294/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 295/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 295/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.876 total time=   0.0s\n",
            "[CV 2/5; 295/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 295/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 295/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 295/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.896 total time=   0.0s\n",
            "[CV 4/5; 295/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 295/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 295/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 295/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.932 total time=   0.0s\n",
            "[CV 1/5; 296/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 296/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 2/5; 296/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 296/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.832 total time=   0.0s\n",
            "[CV 3/5; 296/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 296/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.900 total time=   0.0s\n",
            "[CV 4/5; 296/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 296/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 296/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 296/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 1/5; 297/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 297/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.712 total time=   0.0s\n",
            "[CV 2/5; 297/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 297/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.936 total time=   0.0s\n",
            "[CV 3/5; 297/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 297/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.808 total time=   0.0s\n",
            "[CV 4/5; 297/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 297/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.800 total time=   0.0s\n",
            "[CV 5/5; 297/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 297/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.816 total time=   0.0s\n",
            "[CV 1/5; 298/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 298/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.708 total time=   0.0s\n",
            "[CV 2/5; 298/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 298/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.860 total time=   0.0s\n",
            "[CV 3/5; 298/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 298/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.772 total time=   0.0s\n",
            "[CV 4/5; 298/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 298/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.912 total time=   0.0s\n",
            "[CV 5/5; 298/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 298/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.936 total time=   0.0s\n",
            "[CV 1/5; 299/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 299/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.872 total time=   0.0s\n",
            "[CV 2/5; 299/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 299/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.900 total time=   0.0s\n",
            "[CV 3/5; 299/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 299/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.796 total time=   0.0s\n",
            "[CV 4/5; 299/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 299/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.812 total time=   0.0s\n",
            "[CV 5/5; 299/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 299/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.852 total time=   0.0s\n",
            "[CV 1/5; 300/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 300/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.904 total time=   0.0s\n",
            "[CV 2/5; 300/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 300/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.856 total time=   0.0s\n",
            "[CV 3/5; 300/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 300/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.928 total time=   0.0s\n",
            "[CV 4/5; 300/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 300/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.832 total time=   0.0s\n",
            "[CV 5/5; 300/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 300/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 1/5; 301/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 301/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.908 total time=   0.0s\n",
            "[CV 2/5; 301/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 301/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 301/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 301/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.960 total time=   0.0s\n",
            "[CV 4/5; 301/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 301/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.876 total time=   0.0s\n",
            "[CV 5/5; 301/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 301/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 1/5; 302/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 302/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 2/5; 302/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 302/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 302/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 302/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.968 total time=   0.0s\n",
            "[CV 4/5; 302/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 302/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 5/5; 302/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 302/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.956 total time=   0.0s\n",
            "[CV 1/5; 303/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 303/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.924 total time=   0.0s\n",
            "[CV 2/5; 303/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 303/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 303/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 303/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.836 total time=   0.0s\n",
            "[CV 4/5; 303/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 303/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 303/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 303/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.900 total time=   0.0s\n",
            "[CV 1/5; 304/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 1/5; 304/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.944 total time=   0.0s\n",
            "[CV 2/5; 304/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 2/5; 304/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 3/5; 304/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 3/5; 304/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.896 total time=   0.0s\n",
            "[CV 4/5; 304/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 4/5; 304/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.968 total time=   0.0s\n",
            "[CV 5/5; 304/1344] START alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 5/5; 304/1344] END alpha=1e-05, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.872 total time=   0.0s\n",
            "[CV 1/5; 305/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 305/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.868 total time=   0.0s\n",
            "[CV 2/5; 305/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 305/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.860 total time=   0.0s\n",
            "[CV 3/5; 305/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 305/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.836 total time=   0.0s\n",
            "[CV 4/5; 305/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 305/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.784 total time=   0.0s\n",
            "[CV 5/5; 305/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 305/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.836 total time=   0.0s\n",
            "[CV 1/5; 306/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 306/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 306/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 306/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.832 total time=   0.0s\n",
            "[CV 3/5; 306/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 306/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.820 total time=   0.0s\n",
            "[CV 4/5; 306/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 306/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.812 total time=   0.0s\n",
            "[CV 5/5; 306/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 306/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 1/5; 307/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 307/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.804 total time=   0.0s\n",
            "[CV 2/5; 307/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 307/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.868 total time=   0.0s\n",
            "[CV 3/5; 307/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 307/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.924 total time=   0.0s\n",
            "[CV 4/5; 307/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 307/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.796 total time=   0.0s\n",
            "[CV 5/5; 307/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 307/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 1/5; 308/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 308/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.772 total time=   0.0s\n",
            "[CV 2/5; 308/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 308/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.776 total time=   0.0s\n",
            "[CV 3/5; 308/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 308/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.796 total time=   0.0s\n",
            "[CV 4/5; 308/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 308/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.776 total time=   0.0s\n",
            "[CV 5/5; 308/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 308/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 309/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 309/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.856 total time=   0.0s\n",
            "[CV 2/5; 309/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 309/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 309/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 309/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 309/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 309/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 5/5; 309/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 309/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.932 total time=   0.0s\n",
            "[CV 1/5; 310/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 310/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.952 total time=   0.0s\n",
            "[CV 2/5; 310/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 310/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 310/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 310/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.836 total time=   0.0s\n",
            "[CV 4/5; 310/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 310/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.924 total time=   0.0s\n",
            "[CV 5/5; 310/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 310/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 1/5; 311/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 311/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.884 total time=   0.0s\n",
            "[CV 2/5; 311/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 311/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 3/5; 311/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 311/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.924 total time=   0.0s\n",
            "[CV 4/5; 311/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 311/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 311/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 311/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.924 total time=   0.0s\n",
            "[CV 1/5; 312/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 312/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.924 total time=   0.0s\n",
            "[CV 2/5; 312/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 312/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 312/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 312/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 4/5; 312/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 312/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.912 total time=   0.0s\n",
            "[CV 5/5; 312/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 312/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 313/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 313/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.908 total time=   0.0s\n",
            "[CV 2/5; 313/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 313/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.892 total time=   0.0s\n",
            "[CV 3/5; 313/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 313/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.744 total time=   0.0s\n",
            "[CV 4/5; 313/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 313/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.884 total time=   0.0s\n",
            "[CV 5/5; 313/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 313/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.880 total time=   0.0s\n",
            "[CV 1/5; 314/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 314/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.784 total time=   0.0s\n",
            "[CV 2/5; 314/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 314/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.804 total time=   0.0s\n",
            "[CV 3/5; 314/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 314/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.892 total time=   0.0s\n",
            "[CV 4/5; 314/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 314/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.788 total time=   0.0s\n",
            "[CV 5/5; 314/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 314/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.776 total time=   0.0s\n",
            "[CV 1/5; 315/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 315/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 315/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 315/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.892 total time=   0.0s\n",
            "[CV 3/5; 315/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 315/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.772 total time=   0.0s\n",
            "[CV 4/5; 315/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 315/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.932 total time=   0.0s\n",
            "[CV 5/5; 315/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 315/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.716 total time=   0.0s\n",
            "[CV 1/5; 316/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 316/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.732 total time=   0.0s\n",
            "[CV 2/5; 316/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 316/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.940 total time=   0.0s\n",
            "[CV 3/5; 316/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 316/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.812 total time=   0.0s\n",
            "[CV 4/5; 316/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 316/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.864 total time=   0.0s\n",
            "[CV 5/5; 316/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 316/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.956 total time=   0.0s\n",
            "[CV 1/5; 317/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 317/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.956 total time=   0.0s\n",
            "[CV 2/5; 317/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 317/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 317/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 317/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.892 total time=   0.0s\n",
            "[CV 4/5; 317/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 317/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 317/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 317/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 318/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 318/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.952 total time=   0.0s\n",
            "[CV 2/5; 318/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 318/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 318/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 318/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.932 total time=   0.0s\n",
            "[CV 4/5; 318/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 318/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.920 total time=   0.0s\n",
            "[CV 5/5; 318/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 318/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.884 total time=   0.0s\n",
            "[CV 1/5; 319/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 319/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 2/5; 319/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 319/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 3/5; 319/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 319/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.884 total time=   0.0s\n",
            "[CV 4/5; 319/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 319/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 319/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 319/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.908 total time=   0.0s\n",
            "[CV 1/5; 320/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 1/5; 320/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 2/5; 320/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 2/5; 320/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.940 total time=   0.0s\n",
            "[CV 3/5; 320/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 3/5; 320/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 4/5; 320/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 4/5; 320/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.824 total time=   0.0s\n",
            "[CV 5/5; 320/1344] START alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 5/5; 320/1344] END alpha=1e-05, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 321/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 321/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.776 total time=   0.0s\n",
            "[CV 2/5; 321/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 321/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.824 total time=   0.0s\n",
            "[CV 3/5; 321/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 321/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 321/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 321/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.764 total time=   0.0s\n",
            "[CV 5/5; 321/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 321/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.732 total time=   0.0s\n",
            "[CV 1/5; 322/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 322/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.916 total time=   0.0s\n",
            "[CV 2/5; 322/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 322/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 3/5; 322/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 322/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.856 total time=   0.0s\n",
            "[CV 4/5; 322/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 322/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.944 total time=   0.0s\n",
            "[CV 5/5; 322/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 322/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.840 total time=   0.0s\n",
            "[CV 1/5; 323/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 323/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.740 total time=   0.0s\n",
            "[CV 2/5; 323/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 323/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.812 total time=   0.0s\n",
            "[CV 3/5; 323/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 323/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.812 total time=   0.0s\n",
            "[CV 4/5; 323/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 323/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.864 total time=   0.0s\n",
            "[CV 5/5; 323/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 323/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.812 total time=   0.0s\n",
            "[CV 1/5; 324/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 324/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.916 total time=   0.0s\n",
            "[CV 2/5; 324/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 324/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 324/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 324/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.804 total time=   0.0s\n",
            "[CV 4/5; 324/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 324/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.900 total time=   0.0s\n",
            "[CV 5/5; 324/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 324/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.676 total time=   0.0s\n",
            "[CV 1/5; 325/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 325/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 325/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 325/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.852 total time=   0.0s\n",
            "[CV 3/5; 325/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 325/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.892 total time=   0.0s\n",
            "[CV 4/5; 325/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 325/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.960 total time=   0.0s\n",
            "[CV 5/5; 325/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 325/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.952 total time=   0.0s\n",
            "[CV 1/5; 326/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 326/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 326/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 326/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 326/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 326/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.904 total time=   0.0s\n",
            "[CV 4/5; 326/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 326/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.928 total time=   0.0s\n",
            "[CV 5/5; 326/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 326/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 327/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 327/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.896 total time=   0.0s\n",
            "[CV 2/5; 327/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 327/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.956 total time=   0.0s\n",
            "[CV 3/5; 327/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 327/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.912 total time=   0.0s\n",
            "[CV 4/5; 327/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 327/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.932 total time=   0.0s\n",
            "[CV 5/5; 327/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 327/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.956 total time=   0.0s\n",
            "[CV 1/5; 328/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 328/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 2/5; 328/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 328/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.956 total time=   0.0s\n",
            "[CV 3/5; 328/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 328/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.868 total time=   0.0s\n",
            "[CV 4/5; 328/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 328/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.828 total time=   0.0s\n",
            "[CV 5/5; 328/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 328/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.936 total time=   0.0s\n",
            "[CV 1/5; 329/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 329/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.904 total time=   0.0s\n",
            "[CV 2/5; 329/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 329/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.844 total time=   0.0s\n",
            "[CV 3/5; 329/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 329/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.856 total time=   0.0s\n",
            "[CV 4/5; 329/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 329/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.732 total time=   0.0s\n",
            "[CV 5/5; 329/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 329/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.872 total time=   0.0s\n",
            "[CV 1/5; 330/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 330/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.740 total time=   0.0s\n",
            "[CV 2/5; 330/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 330/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 330/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 330/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.924 total time=   0.0s\n",
            "[CV 4/5; 330/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 330/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.908 total time=   0.0s\n",
            "[CV 5/5; 330/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 330/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 331/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 331/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.904 total time=   0.0s\n",
            "[CV 2/5; 331/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 331/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.920 total time=   0.0s\n",
            "[CV 3/5; 331/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 331/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 4/5; 331/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 331/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.928 total time=   0.0s\n",
            "[CV 5/5; 331/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 331/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 1/5; 332/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 332/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.924 total time=   0.0s\n",
            "[CV 2/5; 332/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 332/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.880 total time=   0.0s\n",
            "[CV 3/5; 332/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 332/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.852 total time=   0.0s\n",
            "[CV 4/5; 332/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 332/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 5/5; 332/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 332/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.836 total time=   0.0s\n",
            "[CV 1/5; 333/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 333/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.956 total time=   0.0s\n",
            "[CV 2/5; 333/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 333/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 3/5; 333/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 333/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.968 total time=   0.0s\n",
            "[CV 4/5; 333/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 333/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.908 total time=   0.0s\n",
            "[CV 5/5; 333/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 333/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.952 total time=   0.0s\n",
            "[CV 1/5; 334/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 334/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 2/5; 334/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 334/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 334/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 334/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.896 total time=   0.0s\n",
            "[CV 4/5; 334/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 334/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 334/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 334/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.864 total time=   0.0s\n",
            "[CV 1/5; 335/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 335/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 2/5; 335/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 335/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.852 total time=   0.0s\n",
            "[CV 3/5; 335/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 335/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.868 total time=   0.0s\n",
            "[CV 4/5; 335/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 335/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.956 total time=   0.0s\n",
            "[CV 5/5; 335/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 335/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.952 total time=   0.0s\n",
            "[CV 1/5; 336/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 1/5; 336/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.780 total time=   0.0s\n",
            "[CV 2/5; 336/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 2/5; 336/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.916 total time=   0.0s\n",
            "[CV 3/5; 336/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 3/5; 336/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.712 total time=   0.0s\n",
            "[CV 4/5; 336/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 4/5; 336/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 336/1344] START alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 5/5; 336/1344] END alpha=1e-05, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 337/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 337/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.760 total time=   0.0s\n",
            "[CV 2/5; 337/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 337/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.884 total time=   0.0s\n",
            "[CV 3/5; 337/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 337/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 337/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 337/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.880 total time=   0.0s\n",
            "[CV 5/5; 337/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 337/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.872 total time=   0.0s\n",
            "[CV 1/5; 338/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 338/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.796 total time=   0.0s\n",
            "[CV 2/5; 338/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 338/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.876 total time=   0.0s\n",
            "[CV 3/5; 338/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 338/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.788 total time=   0.0s\n",
            "[CV 4/5; 338/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 338/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.952 total time=   0.0s\n",
            "[CV 5/5; 338/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 338/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.836 total time=   0.0s\n",
            "[CV 1/5; 339/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 339/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.692 total time=   0.0s\n",
            "[CV 2/5; 339/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 339/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.772 total time=   0.0s\n",
            "[CV 3/5; 339/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 339/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.884 total time=   0.0s\n",
            "[CV 4/5; 339/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 339/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.828 total time=   0.0s\n",
            "[CV 5/5; 339/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 339/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 1/5; 340/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 340/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.904 total time=   0.0s\n",
            "[CV 2/5; 340/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 340/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 3/5; 340/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 340/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.748 total time=   0.0s\n",
            "[CV 4/5; 340/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 340/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.864 total time=   0.0s\n",
            "[CV 5/5; 340/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 340/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.944 total time=   0.0s\n",
            "[CV 1/5; 341/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 341/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.968 total time=   0.0s\n",
            "[CV 2/5; 341/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 341/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 3/5; 341/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 341/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.924 total time=   0.0s\n",
            "[CV 4/5; 341/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 341/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 5/5; 341/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 341/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.956 total time=   0.0s\n",
            "[CV 1/5; 342/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 342/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.840 total time=   0.0s\n",
            "[CV 2/5; 342/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 342/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 342/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 342/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 342/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 342/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.936 total time=   0.0s\n",
            "[CV 5/5; 342/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 342/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.908 total time=   0.0s\n",
            "[CV 1/5; 343/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 343/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.960 total time=   0.0s\n",
            "[CV 2/5; 343/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 343/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 3/5; 343/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 343/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 343/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 343/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.884 total time=   0.0s\n",
            "[CV 5/5; 343/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 343/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.924 total time=   0.0s\n",
            "[CV 1/5; 344/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 344/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 2/5; 344/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 344/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 344/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 344/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 344/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 344/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.864 total time=   0.0s\n",
            "[CV 5/5; 344/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 344/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.944 total time=   0.0s\n",
            "[CV 1/5; 345/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 345/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 345/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 345/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.820 total time=   0.0s\n",
            "[CV 3/5; 345/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 345/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.920 total time=   0.0s\n",
            "[CV 4/5; 345/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 345/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.936 total time=   0.0s\n",
            "[CV 5/5; 345/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 345/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.932 total time=   0.0s\n",
            "[CV 1/5; 346/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 346/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.760 total time=   0.0s\n",
            "[CV 2/5; 346/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 346/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.916 total time=   0.0s\n",
            "[CV 3/5; 346/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 346/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.788 total time=   0.0s\n",
            "[CV 4/5; 346/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 346/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.924 total time=   0.0s\n",
            "[CV 5/5; 346/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 346/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.864 total time=   0.0s\n",
            "[CV 1/5; 347/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 347/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.892 total time=   0.0s\n",
            "[CV 2/5; 347/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 347/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.796 total time=   0.0s\n",
            "[CV 3/5; 347/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 347/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.740 total time=   0.0s\n",
            "[CV 4/5; 347/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 347/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.820 total time=   0.0s\n",
            "[CV 5/5; 347/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 347/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 1/5; 348/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 348/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.856 total time=   0.0s\n",
            "[CV 2/5; 348/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 348/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.708 total time=   0.0s\n",
            "[CV 3/5; 348/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 348/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.852 total time=   0.0s\n",
            "[CV 4/5; 348/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 348/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.864 total time=   0.0s\n",
            "[CV 5/5; 348/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 348/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.912 total time=   0.0s\n",
            "[CV 1/5; 349/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 349/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 2/5; 349/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 349/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.912 total time=   0.0s\n",
            "[CV 3/5; 349/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 349/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.952 total time=   0.0s\n",
            "[CV 4/5; 349/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 349/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.916 total time=   0.0s\n",
            "[CV 5/5; 349/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 349/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.968 total time=   0.0s\n",
            "[CV 1/5; 350/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 350/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 2/5; 350/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 350/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 350/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 350/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.884 total time=   0.0s\n",
            "[CV 4/5; 350/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 350/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.868 total time=   0.0s\n",
            "[CV 5/5; 350/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 350/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.952 total time=   0.0s\n",
            "[CV 1/5; 351/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 351/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 2/5; 351/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 351/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.872 total time=   0.0s\n",
            "[CV 3/5; 351/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 351/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.920 total time=   0.0s\n",
            "[CV 4/5; 351/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 351/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.924 total time=   0.0s\n",
            "[CV 5/5; 351/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 351/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 352/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 1/5; 352/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.956 total time=   0.0s\n",
            "[CV 2/5; 352/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 2/5; 352/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 352/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 3/5; 352/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.808 total time=   0.0s\n",
            "[CV 4/5; 352/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 4/5; 352/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.932 total time=   0.0s\n",
            "[CV 5/5; 352/1344] START alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 5/5; 352/1344] END alpha=1e-05, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 353/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 353/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.784 total time=   0.0s\n",
            "[CV 2/5; 353/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 353/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.884 total time=   0.0s\n",
            "[CV 3/5; 353/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 353/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.764 total time=   0.0s\n",
            "[CV 4/5; 353/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 353/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.880 total time=   0.0s\n",
            "[CV 5/5; 353/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 353/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.940 total time=   0.0s\n",
            "[CV 1/5; 354/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 354/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.932 total time=   0.0s\n",
            "[CV 2/5; 354/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 354/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.944 total time=   0.0s\n",
            "[CV 3/5; 354/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 354/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.796 total time=   0.0s\n",
            "[CV 4/5; 354/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 354/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.732 total time=   0.0s\n",
            "[CV 5/5; 354/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 354/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.820 total time=   0.0s\n",
            "[CV 1/5; 355/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 355/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.844 total time=   0.0s\n",
            "[CV 2/5; 355/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 355/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.860 total time=   0.0s\n",
            "[CV 3/5; 355/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 355/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.844 total time=   0.0s\n",
            "[CV 4/5; 355/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 355/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 355/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 355/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.864 total time=   0.0s\n",
            "[CV 1/5; 356/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 356/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.812 total time=   0.0s\n",
            "[CV 2/5; 356/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 356/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.816 total time=   0.0s\n",
            "[CV 3/5; 356/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 356/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.884 total time=   0.0s\n",
            "[CV 4/5; 356/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 356/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.908 total time=   0.0s\n",
            "[CV 5/5; 356/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 356/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.908 total time=   0.0s\n",
            "[CV 1/5; 357/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 357/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.936 total time=   0.0s\n",
            "[CV 2/5; 357/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 357/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.864 total time=   0.0s\n",
            "[CV 3/5; 357/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 357/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.968 total time=   0.0s\n",
            "[CV 4/5; 357/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 357/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.956 total time=   0.0s\n",
            "[CV 5/5; 357/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 357/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.860 total time=   0.0s\n",
            "[CV 1/5; 358/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 358/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.900 total time=   0.0s\n",
            "[CV 2/5; 358/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 358/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.880 total time=   0.0s\n",
            "[CV 3/5; 358/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 358/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.960 total time=   0.0s\n",
            "[CV 4/5; 358/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 358/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 5/5; 358/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 358/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.936 total time=   0.0s\n",
            "[CV 1/5; 359/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 359/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 359/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 359/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 359/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 359/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 4/5; 359/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 359/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 5/5; 359/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 359/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.932 total time=   0.0s\n",
            "[CV 1/5; 360/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 360/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 2/5; 360/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 360/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 360/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 360/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.936 total time=   0.0s\n",
            "[CV 4/5; 360/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 360/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.992 total time=   0.0s\n",
            "[CV 5/5; 360/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 360/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.944 total time=   0.0s\n",
            "[CV 1/5; 361/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 361/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.856 total time=   0.0s\n",
            "[CV 2/5; 361/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 361/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 361/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 361/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.880 total time=   0.0s\n",
            "[CV 4/5; 361/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 361/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.764 total time=   0.0s\n",
            "[CV 5/5; 361/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 361/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 362/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 362/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.764 total time=   0.0s\n",
            "[CV 2/5; 362/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 362/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 362/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 362/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.900 total time=   0.0s\n",
            "[CV 4/5; 362/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 362/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 362/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 362/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.920 total time=   0.0s\n",
            "[CV 1/5; 363/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 363/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.820 total time=   0.0s\n",
            "[CV 2/5; 363/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 363/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.956 total time=   0.0s\n",
            "[CV 3/5; 363/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 363/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.864 total time=   0.0s\n",
            "[CV 4/5; 363/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 363/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 5/5; 363/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 363/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 1/5; 364/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 364/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.912 total time=   0.0s\n",
            "[CV 2/5; 364/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 364/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.920 total time=   0.0s\n",
            "[CV 3/5; 364/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 364/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 4/5; 364/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 364/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.808 total time=   0.0s\n",
            "[CV 5/5; 364/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 364/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.896 total time=   0.0s\n",
            "[CV 1/5; 365/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 365/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 365/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 365/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.920 total time=   0.0s\n",
            "[CV 3/5; 365/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 365/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.952 total time=   0.0s\n",
            "[CV 4/5; 365/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 365/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.856 total time=   0.0s\n",
            "[CV 5/5; 365/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 365/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.924 total time=   0.0s\n",
            "[CV 1/5; 366/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 366/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.960 total time=   0.0s\n",
            "[CV 2/5; 366/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 366/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 366/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 366/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.804 total time=   0.0s\n",
            "[CV 4/5; 366/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 366/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 366/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 366/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.916 total time=   0.0s\n",
            "[CV 1/5; 367/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 367/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 367/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 367/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 3/5; 367/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 367/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.900 total time=   0.0s\n",
            "[CV 4/5; 367/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 367/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 5/5; 367/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 367/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 1/5; 368/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 1/5; 368/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.904 total time=   0.0s\n",
            "[CV 2/5; 368/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 2/5; 368/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 368/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 3/5; 368/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.920 total time=   0.0s\n",
            "[CV 4/5; 368/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 4/5; 368/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.952 total time=   0.0s\n",
            "[CV 5/5; 368/1344] START alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 5/5; 368/1344] END alpha=1e-05, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.944 total time=   0.0s\n",
            "[CV 1/5; 369/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 369/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.748 total time=   0.0s\n",
            "[CV 2/5; 369/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 369/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.820 total time=   0.0s\n",
            "[CV 3/5; 369/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 369/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.860 total time=   0.0s\n",
            "[CV 4/5; 369/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 369/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.916 total time=   0.0s\n",
            "[CV 5/5; 369/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 369/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 1/5; 370/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 370/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 2/5; 370/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 370/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.904 total time=   0.0s\n",
            "[CV 3/5; 370/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 370/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.844 total time=   0.0s\n",
            "[CV 4/5; 370/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 370/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.932 total time=   0.0s\n",
            "[CV 5/5; 370/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 370/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.924 total time=   0.0s\n",
            "[CV 1/5; 371/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 371/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.868 total time=   0.0s\n",
            "[CV 2/5; 371/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 371/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.928 total time=   0.0s\n",
            "[CV 3/5; 371/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 371/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.804 total time=   0.0s\n",
            "[CV 4/5; 371/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 371/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.904 total time=   0.0s\n",
            "[CV 5/5; 371/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 371/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.820 total time=   0.0s\n",
            "[CV 1/5; 372/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 372/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.904 total time=   0.0s\n",
            "[CV 2/5; 372/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 372/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.900 total time=   0.0s\n",
            "[CV 3/5; 372/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 372/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.752 total time=   0.0s\n",
            "[CV 4/5; 372/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 372/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.772 total time=   0.0s\n",
            "[CV 5/5; 372/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 372/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.860 total time=   0.0s\n",
            "[CV 1/5; 373/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 373/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.916 total time=   0.0s\n",
            "[CV 2/5; 373/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 373/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 373/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 373/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.884 total time=   0.0s\n",
            "[CV 4/5; 373/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 373/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.880 total time=   0.0s\n",
            "[CV 5/5; 373/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 373/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 1/5; 374/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 374/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.904 total time=   0.0s\n",
            "[CV 2/5; 374/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 374/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.956 total time=   0.0s\n",
            "[CV 3/5; 374/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 374/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 374/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 374/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.920 total time=   0.0s\n",
            "[CV 5/5; 374/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 374/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 375/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 375/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 2/5; 375/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 375/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 3/5; 375/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 375/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 375/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 375/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 5/5; 375/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 375/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.968 total time=   0.0s\n",
            "[CV 1/5; 376/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 376/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.956 total time=   0.0s\n",
            "[CV 2/5; 376/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 376/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 376/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 376/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 4/5; 376/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 376/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.956 total time=   0.0s\n",
            "[CV 5/5; 376/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 376/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.836 total time=   0.0s\n",
            "[CV 1/5; 377/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 377/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.956 total time=   0.0s\n",
            "[CV 2/5; 377/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 377/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.908 total time=   0.0s\n",
            "[CV 3/5; 377/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 377/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.916 total time=   0.0s\n",
            "[CV 4/5; 377/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 377/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.896 total time=   0.0s\n",
            "[CV 5/5; 377/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 377/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.900 total time=   0.0s\n",
            "[CV 1/5; 378/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 378/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 378/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 378/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.920 total time=   0.0s\n",
            "[CV 3/5; 378/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 378/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.816 total time=   0.0s\n",
            "[CV 4/5; 378/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 378/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 378/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 378/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.820 total time=   0.0s\n",
            "[CV 1/5; 379/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 379/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.804 total time=   0.0s\n",
            "[CV 2/5; 379/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 379/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.844 total time=   0.0s\n",
            "[CV 3/5; 379/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 379/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.776 total time=   0.0s\n",
            "[CV 4/5; 379/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 379/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.884 total time=   0.0s\n",
            "[CV 5/5; 379/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 379/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.788 total time=   0.0s\n",
            "[CV 1/5; 380/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 380/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 2/5; 380/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 380/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.832 total time=   0.0s\n",
            "[CV 3/5; 380/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 380/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.812 total time=   0.0s\n",
            "[CV 4/5; 380/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 380/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.860 total time=   0.0s\n",
            "[CV 5/5; 380/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 380/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.788 total time=   0.0s\n",
            "[CV 1/5; 381/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 381/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.840 total time=   0.0s\n",
            "[CV 2/5; 381/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 381/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.952 total time=   0.0s\n",
            "[CV 3/5; 381/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 381/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 381/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 381/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 381/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 381/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 382/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 382/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.916 total time=   0.0s\n",
            "[CV 2/5; 382/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 382/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 382/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 382/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.960 total time=   0.0s\n",
            "[CV 4/5; 382/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 382/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.876 total time=   0.0s\n",
            "[CV 5/5; 382/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 382/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 383/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 383/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.960 total time=   0.0s\n",
            "[CV 2/5; 383/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 383/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 3/5; 383/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 383/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.928 total time=   0.0s\n",
            "[CV 4/5; 383/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 383/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 5/5; 383/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 383/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.936 total time=   0.0s\n",
            "[CV 1/5; 384/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 1/5; 384/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.912 total time=   0.0s\n",
            "[CV 2/5; 384/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 2/5; 384/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 384/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 3/5; 384/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.844 total time=   0.0s\n",
            "[CV 4/5; 384/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 4/5; 384/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.928 total time=   0.0s\n",
            "[CV 5/5; 384/1344] START alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 5/5; 384/1344] END alpha=1e-05, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.936 total time=   0.0s\n",
            "[CV 1/5; 385/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 385/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.880 total time=   0.0s\n",
            "[CV 2/5; 385/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 385/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.876 total time=   0.0s\n",
            "[CV 3/5; 385/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 385/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.840 total time=   0.0s\n",
            "[CV 4/5; 385/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 385/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.880 total time=   0.0s\n",
            "[CV 5/5; 385/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 385/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.876 total time=   0.0s\n",
            "[CV 1/5; 386/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 386/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.884 total time=   0.0s\n",
            "[CV 2/5; 386/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 386/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.808 total time=   0.0s\n",
            "[CV 3/5; 386/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 386/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.884 total time=   0.0s\n",
            "[CV 4/5; 386/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 386/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.800 total time=   0.0s\n",
            "[CV 5/5; 386/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 386/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.852 total time=   0.0s\n",
            "[CV 1/5; 387/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 387/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.864 total time=   0.0s\n",
            "[CV 2/5; 387/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 387/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 3/5; 387/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 387/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 387/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 387/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.764 total time=   0.0s\n",
            "[CV 5/5; 387/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 387/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.776 total time=   0.0s\n",
            "[CV 1/5; 388/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 388/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.812 total time=   0.0s\n",
            "[CV 2/5; 388/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 388/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.920 total time=   0.0s\n",
            "[CV 3/5; 388/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 388/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.788 total time=   0.0s\n",
            "[CV 4/5; 388/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 388/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 5/5; 388/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 388/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.784 total time=   0.0s\n",
            "[CV 1/5; 389/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 389/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.960 total time=   0.0s\n",
            "[CV 2/5; 389/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 389/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 389/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 389/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.960 total time=   0.0s\n",
            "[CV 4/5; 389/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 389/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 389/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 389/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.936 total time=   0.0s\n",
            "[CV 1/5; 390/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 390/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.952 total time=   0.0s\n",
            "[CV 2/5; 390/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 390/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 390/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 390/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.936 total time=   0.0s\n",
            "[CV 4/5; 390/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 390/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.968 total time=   0.0s\n",
            "[CV 5/5; 390/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 390/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.932 total time=   0.0s\n",
            "[CV 1/5; 391/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 391/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 2/5; 391/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 391/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 391/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 391/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 391/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 391/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.936 total time=   0.0s\n",
            "[CV 5/5; 391/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 391/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 392/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 392/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.952 total time=   0.0s\n",
            "[CV 2/5; 392/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 392/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.892 total time=   0.0s\n",
            "[CV 3/5; 392/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 392/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.912 total time=   0.0s\n",
            "[CV 4/5; 392/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 392/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 392/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 392/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 393/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 393/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.940 total time=   0.0s\n",
            "[CV 2/5; 393/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 393/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.904 total time=   0.0s\n",
            "[CV 3/5; 393/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 393/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.908 total time=   0.0s\n",
            "[CV 4/5; 393/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 393/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.940 total time=   0.0s\n",
            "[CV 5/5; 393/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 393/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.836 total time=   0.0s\n",
            "[CV 1/5; 394/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 394/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.808 total time=   0.0s\n",
            "[CV 2/5; 394/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 394/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.880 total time=   0.0s\n",
            "[CV 3/5; 394/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 394/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.892 total time=   0.0s\n",
            "[CV 4/5; 394/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 394/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.804 total time=   0.0s\n",
            "[CV 5/5; 394/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 394/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 1/5; 395/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 395/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 2/5; 395/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 395/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.800 total time=   0.0s\n",
            "[CV 3/5; 395/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 395/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.936 total time=   0.0s\n",
            "[CV 4/5; 395/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 395/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.852 total time=   0.0s\n",
            "[CV 5/5; 395/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 395/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.900 total time=   0.0s\n",
            "[CV 1/5; 396/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 396/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.804 total time=   0.0s\n",
            "[CV 2/5; 396/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 396/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.844 total time=   0.0s\n",
            "[CV 3/5; 396/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 396/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.864 total time=   0.0s\n",
            "[CV 4/5; 396/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 396/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.884 total time=   0.0s\n",
            "[CV 5/5; 396/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 396/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.880 total time=   0.0s\n",
            "[CV 1/5; 397/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 397/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 2/5; 397/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 397/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 397/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 397/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 397/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 397/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 5/5; 397/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 397/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.952 total time=   0.0s\n",
            "[CV 1/5; 398/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 398/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.968 total time=   0.0s\n",
            "[CV 2/5; 398/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 398/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 3/5; 398/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 398/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.912 total time=   0.0s\n",
            "[CV 4/5; 398/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 398/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 5/5; 398/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 398/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 399/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 399/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 2/5; 399/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 399/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.956 total time=   0.0s\n",
            "[CV 3/5; 399/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 399/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.924 total time=   0.0s\n",
            "[CV 4/5; 399/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 399/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.992 total time=   0.0s\n",
            "[CV 5/5; 399/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 399/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 1/5; 400/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 1/5; 400/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 2/5; 400/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 2/5; 400/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 3/5; 400/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 3/5; 400/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 4/5; 400/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 4/5; 400/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.992 total time=   0.0s\n",
            "[CV 5/5; 400/1344] START alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 5/5; 400/1344] END alpha=0.0001, loss=hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 401/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 401/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.864 total time=   0.0s\n",
            "[CV 2/5; 401/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 401/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 401/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 401/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.924 total time=   0.0s\n",
            "[CV 4/5; 401/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 401/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.788 total time=   0.0s\n",
            "[CV 5/5; 401/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 401/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.856 total time=   0.0s\n",
            "[CV 1/5; 402/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 402/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.768 total time=   0.0s\n",
            "[CV 2/5; 402/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 402/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 402/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 402/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.768 total time=   0.0s\n",
            "[CV 4/5; 402/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 402/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.788 total time=   0.0s\n",
            "[CV 5/5; 402/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 402/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.876 total time=   0.0s\n",
            "[CV 1/5; 403/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 403/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.880 total time=   0.0s\n",
            "[CV 2/5; 403/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 403/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.860 total time=   0.0s\n",
            "[CV 3/5; 403/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 403/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.740 total time=   0.0s\n",
            "[CV 4/5; 403/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 403/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 403/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 403/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.788 total time=   0.0s\n",
            "[CV 1/5; 404/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 404/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.840 total time=   0.0s\n",
            "[CV 2/5; 404/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 404/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 404/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 404/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.828 total time=   0.0s\n",
            "[CV 4/5; 404/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 404/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.736 total time=   0.0s\n",
            "[CV 5/5; 404/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 404/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 1/5; 405/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 405/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.956 total time=   0.0s\n",
            "[CV 2/5; 405/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 405/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.992 total time=   0.0s\n",
            "[CV 3/5; 405/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 405/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.920 total time=   0.0s\n",
            "[CV 4/5; 405/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 405/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.956 total time=   0.0s\n",
            "[CV 5/5; 405/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 405/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 1/5; 406/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 406/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 406/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 406/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 3/5; 406/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 406/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.920 total time=   0.0s\n",
            "[CV 4/5; 406/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 406/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.952 total time=   0.0s\n",
            "[CV 5/5; 406/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 406/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 1/5; 407/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 407/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 2/5; 407/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 407/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 407/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 407/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.932 total time=   0.0s\n",
            "[CV 4/5; 407/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 407/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 407/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 407/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 408/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 408/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 2/5; 408/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 408/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.944 total time=   0.0s\n",
            "[CV 3/5; 408/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 408/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 4/5; 408/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 408/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.932 total time=   0.0s\n",
            "[CV 5/5; 408/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 408/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.968 total time=   0.0s\n",
            "[CV 1/5; 409/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 409/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.872 total time=   0.0s\n",
            "[CV 2/5; 409/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 409/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.832 total time=   0.0s\n",
            "[CV 3/5; 409/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 409/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.836 total time=   0.0s\n",
            "[CV 4/5; 409/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 409/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.956 total time=   0.0s\n",
            "[CV 5/5; 409/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 409/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.856 total time=   0.0s\n",
            "[CV 1/5; 410/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 410/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.872 total time=   0.0s\n",
            "[CV 2/5; 410/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 410/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.872 total time=   0.0s\n",
            "[CV 3/5; 410/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 410/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.856 total time=   0.0s\n",
            "[CV 4/5; 410/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 410/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.828 total time=   0.0s\n",
            "[CV 5/5; 410/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 410/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.924 total time=   0.0s\n",
            "[CV 1/5; 411/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 411/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.808 total time=   0.0s\n",
            "[CV 2/5; 411/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 411/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.800 total time=   0.0s\n",
            "[CV 3/5; 411/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 411/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.772 total time=   0.0s\n",
            "[CV 4/5; 411/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 411/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.820 total time=   0.0s\n",
            "[CV 5/5; 411/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 411/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 1/5; 412/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 412/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.852 total time=   0.0s\n",
            "[CV 2/5; 412/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 412/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.928 total time=   0.0s\n",
            "[CV 3/5; 412/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 412/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.892 total time=   0.0s\n",
            "[CV 4/5; 412/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 412/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 5/5; 412/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 412/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.868 total time=   0.0s\n",
            "[CV 1/5; 413/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 413/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.936 total time=   0.0s\n",
            "[CV 2/5; 413/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 413/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 413/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 413/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.928 total time=   0.0s\n",
            "[CV 4/5; 413/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 413/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.968 total time=   0.0s\n",
            "[CV 5/5; 413/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 413/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.952 total time=   0.0s\n",
            "[CV 1/5; 414/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 414/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.916 total time=   0.0s\n",
            "[CV 2/5; 414/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 414/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 3/5; 414/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 414/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.916 total time=   0.0s\n",
            "[CV 4/5; 414/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 414/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.912 total time=   0.0s\n",
            "[CV 5/5; 414/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 414/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 1/5; 415/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 415/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 2/5; 415/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 415/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 415/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 415/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 4/5; 415/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 415/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 415/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 415/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.896 total time=   0.0s\n",
            "[CV 1/5; 416/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 1/5; 416/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 2/5; 416/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 2/5; 416/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 416/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 3/5; 416/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.952 total time=   0.0s\n",
            "[CV 4/5; 416/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 4/5; 416/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 416/1344] START alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 5/5; 416/1344] END alpha=0.0001, loss=hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 417/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 417/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.900 total time=   0.0s\n",
            "[CV 2/5; 417/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 417/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.844 total time=   0.0s\n",
            "[CV 3/5; 417/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 417/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.776 total time=   0.0s\n",
            "[CV 4/5; 417/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 417/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 417/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 417/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.760 total time=   0.0s\n",
            "[CV 1/5; 418/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 418/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.844 total time=   0.0s\n",
            "[CV 2/5; 418/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 418/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 3/5; 418/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 418/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 4/5; 418/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 418/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.780 total time=   0.0s\n",
            "[CV 5/5; 418/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 418/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.868 total time=   0.0s\n",
            "[CV 1/5; 419/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 419/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.856 total time=   0.0s\n",
            "[CV 2/5; 419/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 419/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.760 total time=   0.0s\n",
            "[CV 3/5; 419/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 419/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.820 total time=   0.0s\n",
            "[CV 4/5; 419/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 419/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 5/5; 419/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 419/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.760 total time=   0.0s\n",
            "[CV 1/5; 420/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 420/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.824 total time=   0.0s\n",
            "[CV 2/5; 420/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 420/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.816 total time=   0.0s\n",
            "[CV 3/5; 420/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 420/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.832 total time=   0.0s\n",
            "[CV 4/5; 420/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 420/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.808 total time=   0.0s\n",
            "[CV 5/5; 420/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 420/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 421/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 421/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.952 total time=   0.0s\n",
            "[CV 2/5; 421/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 421/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.916 total time=   0.0s\n",
            "[CV 3/5; 421/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 421/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.892 total time=   0.0s\n",
            "[CV 4/5; 421/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 421/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.916 total time=   0.0s\n",
            "[CV 5/5; 421/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 421/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.924 total time=   0.0s\n",
            "[CV 1/5; 422/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 422/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.952 total time=   0.0s\n",
            "[CV 2/5; 422/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 422/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 422/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 422/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.968 total time=   0.0s\n",
            "[CV 4/5; 422/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 422/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 5/5; 422/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 422/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.952 total time=   0.0s\n",
            "[CV 1/5; 423/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 423/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.968 total time=   0.0s\n",
            "[CV 2/5; 423/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 423/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 423/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 423/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.960 total time=   0.0s\n",
            "[CV 4/5; 423/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 423/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.952 total time=   0.0s\n",
            "[CV 5/5; 423/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 423/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.904 total time=   0.0s\n",
            "[CV 1/5; 424/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 424/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.924 total time=   0.0s\n",
            "[CV 2/5; 424/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 424/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 424/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 424/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 424/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 424/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 5/5; 424/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 424/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.956 total time=   0.0s\n",
            "[CV 1/5; 425/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 425/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.844 total time=   0.0s\n",
            "[CV 2/5; 425/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 425/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.952 total time=   0.0s\n",
            "[CV 3/5; 425/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 425/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.852 total time=   0.0s\n",
            "[CV 4/5; 425/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 425/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.936 total time=   0.0s\n",
            "[CV 5/5; 425/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 425/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.872 total time=   0.0s\n",
            "[CV 1/5; 426/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 426/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.796 total time=   0.0s\n",
            "[CV 2/5; 426/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 426/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.924 total time=   0.0s\n",
            "[CV 3/5; 426/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 426/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.860 total time=   0.0s\n",
            "[CV 4/5; 426/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 426/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 5/5; 426/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 426/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.724 total time=   0.0s\n",
            "[CV 1/5; 427/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 427/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.856 total time=   0.0s\n",
            "[CV 2/5; 427/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 427/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.900 total time=   0.0s\n",
            "[CV 3/5; 427/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 427/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.732 total time=   0.0s\n",
            "[CV 4/5; 427/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 427/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.876 total time=   0.0s\n",
            "[CV 5/5; 427/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 427/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.880 total time=   0.0s\n",
            "[CV 1/5; 428/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 428/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 2/5; 428/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 428/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.816 total time=   0.0s\n",
            "[CV 3/5; 428/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 428/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.868 total time=   0.0s\n",
            "[CV 4/5; 428/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 428/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.896 total time=   0.0s\n",
            "[CV 5/5; 428/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 428/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.800 total time=   0.0s\n",
            "[CV 1/5; 429/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 429/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.952 total time=   0.0s\n",
            "[CV 2/5; 429/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 429/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 3/5; 429/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 429/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.908 total time=   0.0s\n",
            "[CV 4/5; 429/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 429/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 5/5; 429/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 429/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 430/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 430/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.960 total time=   0.0s\n",
            "[CV 2/5; 430/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 430/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 430/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 430/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.876 total time=   0.0s\n",
            "[CV 4/5; 430/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 430/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.956 total time=   0.0s\n",
            "[CV 5/5; 430/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 430/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.932 total time=   0.0s\n",
            "[CV 1/5; 431/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 431/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 2/5; 431/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 431/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 3/5; 431/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 431/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.904 total time=   0.0s\n",
            "[CV 4/5; 431/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 431/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.968 total time=   0.0s\n",
            "[CV 5/5; 431/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 431/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 432/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 1/5; 432/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 2/5; 432/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 2/5; 432/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 432/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 3/5; 432/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.916 total time=   0.0s\n",
            "[CV 4/5; 432/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 4/5; 432/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.968 total time=   0.0s\n",
            "[CV 5/5; 432/1344] START alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 5/5; 432/1344] END alpha=0.0001, loss=hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.952 total time=   0.0s\n",
            "[CV 1/5; 433/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 433/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06;, score=0.932 total time=   0.0s\n",
            "[CV 2/5; 433/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 433/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06;, score=0.836 total time=   0.0s\n",
            "[CV 3/5; 433/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 433/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 433/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 433/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06;, score=0.808 total time=   0.0s\n",
            "[CV 5/5; 433/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 433/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06;, score=0.808 total time=   0.0s\n",
            "[CV 1/5; 434/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 434/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05;, score=0.928 total time=   0.0s\n",
            "[CV 2/5; 434/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 434/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05;, score=0.844 total time=   0.0s\n",
            "[CV 3/5; 434/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 434/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05;, score=0.820 total time=   0.0s\n",
            "[CV 4/5; 434/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 434/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05;, score=0.792 total time=   0.0s\n",
            "[CV 5/5; 434/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 434/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05;, score=0.864 total time=   0.0s\n",
            "[CV 1/5; 435/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 435/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001;, score=0.840 total time=   0.0s\n",
            "[CV 2/5; 435/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 435/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 3/5; 435/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 435/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001;, score=0.852 total time=   0.0s\n",
            "[CV 4/5; 435/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 435/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001;, score=0.816 total time=   0.0s\n",
            "[CV 5/5; 435/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 435/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001;, score=0.924 total time=   0.0s\n",
            "[CV 1/5; 436/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 436/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001;, score=0.812 total time=   0.0s\n",
            "[CV 2/5; 436/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 436/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001;, score=0.840 total time=   0.0s\n",
            "[CV 3/5; 436/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 436/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001;, score=0.816 total time=   0.0s\n",
            "[CV 4/5; 436/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 436/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001;, score=0.836 total time=   0.0s\n",
            "[CV 5/5; 436/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 436/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001;, score=0.788 total time=   0.0s\n",
            "[CV 1/5; 437/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 437/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 2/5; 437/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 437/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 437/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 437/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06;, score=0.936 total time=   0.0s\n",
            "[CV 4/5; 437/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 437/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 5/5; 437/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 437/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 1/5; 438/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 438/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05;, score=0.952 total time=   0.0s\n",
            "[CV 2/5; 438/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 438/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 3/5; 438/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 438/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05;, score=0.916 total time=   0.0s\n",
            "[CV 4/5; 438/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 438/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 5/5; 438/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 438/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05;, score=0.932 total time=   0.0s\n",
            "[CV 1/5; 439/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 439/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 2/5; 439/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 439/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 439/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 439/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 4/5; 439/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 439/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 5/5; 439/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 439/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001;, score=0.952 total time=   0.0s\n",
            "[CV 1/5; 440/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 440/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001;, score=0.952 total time=   0.0s\n",
            "[CV 2/5; 440/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 440/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 440/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 440/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 4/5; 440/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 440/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001;, score=0.956 total time=   0.0s\n",
            "[CV 5/5; 440/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 440/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 1/5; 441/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 441/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.876 total time=   0.0s\n",
            "[CV 2/5; 441/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 441/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.856 total time=   0.0s\n",
            "[CV 3/5; 441/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 441/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.744 total time=   0.0s\n",
            "[CV 4/5; 441/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 441/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.956 total time=   0.0s\n",
            "[CV 5/5; 441/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 441/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.900 total time=   0.0s\n",
            "[CV 1/5; 442/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 442/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.824 total time=   0.0s\n",
            "[CV 2/5; 442/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 442/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 3/5; 442/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 442/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.896 total time=   0.0s\n",
            "[CV 4/5; 442/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 442/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.824 total time=   0.0s\n",
            "[CV 5/5; 442/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 442/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.792 total time=   0.0s\n",
            "[CV 1/5; 443/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 443/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.952 total time=   0.0s\n",
            "[CV 2/5; 443/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 443/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.880 total time=   0.0s\n",
            "[CV 3/5; 443/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 443/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.924 total time=   0.0s\n",
            "[CV 4/5; 443/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 443/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.872 total time=   0.0s\n",
            "[CV 5/5; 443/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 443/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.900 total time=   0.0s\n",
            "[CV 1/5; 444/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 444/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.732 total time=   0.0s\n",
            "[CV 2/5; 444/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 444/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.836 total time=   0.0s\n",
            "[CV 3/5; 444/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 444/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.928 total time=   0.0s\n",
            "[CV 4/5; 444/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 444/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.928 total time=   0.0s\n",
            "[CV 5/5; 444/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 444/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.908 total time=   0.0s\n",
            "[CV 1/5; 445/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 445/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 2/5; 445/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 445/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 3/5; 445/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 445/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06;, score=0.936 total time=   0.0s\n",
            "[CV 4/5; 445/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 445/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06;, score=0.992 total time=   0.0s\n",
            "[CV 5/5; 445/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 445/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06;, score=0.952 total time=   0.0s\n",
            "[CV 1/5; 446/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 446/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05;, score=0.960 total time=   0.0s\n",
            "[CV 2/5; 446/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 446/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 446/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 446/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05;, score=0.960 total time=   0.0s\n",
            "[CV 4/5; 446/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 446/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05;, score=0.956 total time=   0.0s\n",
            "[CV 5/5; 446/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 446/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05;, score=0.952 total time=   0.0s\n",
            "[CV 1/5; 447/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 447/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 2/5; 447/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 447/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 447/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 447/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001;, score=0.924 total time=   0.0s\n",
            "[CV 4/5; 447/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 447/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 447/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 447/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001;, score=0.968 total time=   0.0s\n",
            "[CV 1/5; 448/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 1/5; 448/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=0.001;, score=0.940 total time=   0.0s\n",
            "[CV 2/5; 448/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 2/5; 448/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 448/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 3/5; 448/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=0.001;, score=0.936 total time=   0.0s\n",
            "[CV 4/5; 448/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 4/5; 448/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 448/1344] START alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 5/5; 448/1344] END alpha=0.0001, loss=log_loss, max_iter=1000, penalty=None, tol=0.001;, score=0.936 total time=   0.0s\n",
            "[CV 1/5; 449/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 449/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06;, score=0.856 total time=   0.0s\n",
            "[CV 2/5; 449/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 449/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06;, score=0.900 total time=   0.0s\n",
            "[CV 3/5; 449/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 449/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06;, score=0.840 total time=   0.0s\n",
            "[CV 4/5; 449/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 449/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06;, score=0.784 total time=   0.0s\n",
            "[CV 5/5; 449/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 449/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06;, score=0.880 total time=   0.0s\n",
            "[CV 1/5; 450/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 450/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 2/5; 450/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 450/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 450/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 450/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05;, score=0.884 total time=   0.0s\n",
            "[CV 4/5; 450/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 450/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05;, score=0.880 total time=   0.0s\n",
            "[CV 5/5; 450/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 450/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05;, score=0.820 total time=   0.0s\n",
            "[CV 1/5; 451/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 451/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001;, score=0.820 total time=   0.0s\n",
            "[CV 2/5; 451/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 451/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001;, score=0.872 total time=   0.0s\n",
            "[CV 3/5; 451/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 451/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001;, score=0.920 total time=   0.0s\n",
            "[CV 4/5; 451/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 451/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001;, score=0.800 total time=   0.0s\n",
            "[CV 5/5; 451/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 451/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001;, score=0.804 total time=   0.0s\n",
            "[CV 1/5; 452/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 452/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001;, score=0.836 total time=   0.0s\n",
            "[CV 2/5; 452/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 452/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001;, score=0.836 total time=   0.0s\n",
            "[CV 3/5; 452/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 452/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001;, score=0.928 total time=   0.0s\n",
            "[CV 4/5; 452/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 452/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001;, score=0.860 total time=   0.0s\n",
            "[CV 5/5; 452/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 452/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001;, score=0.892 total time=   0.0s\n",
            "[CV 1/5; 453/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 453/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 2/5; 453/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 453/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 453/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 453/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06;, score=0.928 total time=   0.0s\n",
            "[CV 4/5; 453/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 453/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06;, score=0.924 total time=   0.0s\n",
            "[CV 5/5; 453/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 453/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 1/5; 454/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 454/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 2/5; 454/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 454/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 454/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 454/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 454/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 454/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05;, score=0.920 total time=   0.0s\n",
            "[CV 5/5; 454/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 454/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 1/5; 455/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 455/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 2/5; 455/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 455/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 3/5; 455/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 455/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 455/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 455/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001;, score=0.952 total time=   0.0s\n",
            "[CV 5/5; 455/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 455/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001;, score=0.980 total time=   0.0s\n",
            "[CV 1/5; 456/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 456/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001;, score=0.968 total time=   0.0s\n",
            "[CV 2/5; 456/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 456/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 456/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 456/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 456/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 456/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 456/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 456/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001;, score=0.956 total time=   0.0s\n",
            "[CV 1/5; 457/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 457/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.896 total time=   0.0s\n",
            "[CV 2/5; 457/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 457/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.896 total time=   0.0s\n",
            "[CV 3/5; 457/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 457/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.844 total time=   0.0s\n",
            "[CV 4/5; 457/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 457/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.884 total time=   0.0s\n",
            "[CV 5/5; 457/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 457/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.792 total time=   0.0s\n",
            "[CV 1/5; 458/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 458/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.836 total time=   0.0s\n",
            "[CV 2/5; 458/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 458/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 458/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 458/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.952 total time=   0.0s\n",
            "[CV 4/5; 458/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 458/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.852 total time=   0.0s\n",
            "[CV 5/5; 458/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 458/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.936 total time=   0.0s\n",
            "[CV 1/5; 459/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 459/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.924 total time=   0.0s\n",
            "[CV 2/5; 459/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 459/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 459/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 459/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 459/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 459/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 5/5; 459/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 459/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.924 total time=   0.0s\n",
            "[CV 1/5; 460/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 460/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.824 total time=   0.0s\n",
            "[CV 2/5; 460/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 460/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.952 total time=   0.0s\n",
            "[CV 3/5; 460/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 460/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.856 total time=   0.0s\n",
            "[CV 4/5; 460/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 460/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.824 total time=   0.0s\n",
            "[CV 5/5; 460/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 460/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.916 total time=   0.0s\n",
            "[CV 1/5; 461/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 461/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06;, score=0.956 total time=   0.0s\n",
            "[CV 2/5; 461/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 461/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 461/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 461/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06;, score=0.868 total time=   0.0s\n",
            "[CV 4/5; 461/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 461/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 461/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 461/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 1/5; 462/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 462/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05;, score=0.956 total time=   0.0s\n",
            "[CV 2/5; 462/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 462/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 462/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 462/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05;, score=0.916 total time=   0.0s\n",
            "[CV 4/5; 462/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 462/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 462/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 462/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 463/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 463/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 2/5; 463/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 463/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 463/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 463/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001;, score=0.920 total time=   0.0s\n",
            "[CV 4/5; 463/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 463/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 5/5; 463/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 463/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001;, score=0.952 total time=   0.0s\n",
            "[CV 1/5; 464/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 1/5; 464/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 2/5; 464/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 2/5; 464/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=0.001;, score=0.936 total time=   0.0s\n",
            "[CV 3/5; 464/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 3/5; 464/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 4/5; 464/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 4/5; 464/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=0.001;, score=0.952 total time=   0.0s\n",
            "[CV 5/5; 464/1344] START alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 5/5; 464/1344] END alpha=0.0001, loss=log_loss, max_iter=10000, penalty=None, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 465/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 465/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06;, score=0.876 total time=   0.0s\n",
            "[CV 2/5; 465/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 465/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06;, score=0.904 total time=   0.0s\n",
            "[CV 3/5; 465/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 465/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06;, score=0.764 total time=   0.0s\n",
            "[CV 4/5; 465/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 465/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06;, score=0.852 total time=   0.0s\n",
            "[CV 5/5; 465/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 465/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06;, score=0.784 total time=   0.0s\n",
            "[CV 1/5; 466/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 466/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 466/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 466/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05;, score=0.928 total time=   0.0s\n",
            "[CV 3/5; 466/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 466/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05;, score=0.720 total time=   0.0s\n",
            "[CV 4/5; 466/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 466/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05;, score=0.920 total time=   0.0s\n",
            "[CV 5/5; 466/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 466/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05;, score=0.832 total time=   0.0s\n",
            "[CV 1/5; 467/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 467/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001;, score=0.804 total time=   0.0s\n",
            "[CV 2/5; 467/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 467/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001;, score=0.832 total time=   0.0s\n",
            "[CV 3/5; 467/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 467/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001;, score=0.816 total time=   0.0s\n",
            "[CV 4/5; 467/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 467/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001;, score=0.884 total time=   0.0s\n",
            "[CV 5/5; 467/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 467/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001;, score=0.776 total time=   0.0s\n",
            "[CV 1/5; 468/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 468/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001;, score=0.916 total time=   0.0s\n",
            "[CV 2/5; 468/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 468/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001;, score=0.952 total time=   0.0s\n",
            "[CV 3/5; 468/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 468/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001;, score=0.788 total time=   0.0s\n",
            "[CV 4/5; 468/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 468/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001;, score=0.792 total time=   0.0s\n",
            "[CV 5/5; 468/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 468/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001;, score=0.904 total time=   0.0s\n",
            "[CV 1/5; 469/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 469/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06;, score=0.968 total time=   0.0s\n",
            "[CV 2/5; 469/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 469/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 469/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 469/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06;, score=0.960 total time=   0.0s\n",
            "[CV 4/5; 469/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 469/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06;, score=0.968 total time=   0.0s\n",
            "[CV 5/5; 469/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 469/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 470/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 470/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05;, score=0.956 total time=   0.0s\n",
            "[CV 2/5; 470/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 470/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 3/5; 470/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 470/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 470/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 470/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 470/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 470/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 471/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 471/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 2/5; 471/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 471/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 471/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 471/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001;, score=0.952 total time=   0.0s\n",
            "[CV 4/5; 471/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 471/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001;, score=0.952 total time=   0.0s\n",
            "[CV 5/5; 471/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 471/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001;, score=0.936 total time=   0.0s\n",
            "[CV 1/5; 472/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 472/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 2/5; 472/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 472/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 472/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 472/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 472/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 472/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 472/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 472/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 1/5; 473/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 473/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.836 total time=   0.0s\n",
            "[CV 2/5; 473/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 473/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.876 total time=   0.0s\n",
            "[CV 3/5; 473/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 473/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.764 total time=   0.0s\n",
            "[CV 4/5; 473/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 473/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.884 total time=   0.0s\n",
            "[CV 5/5; 473/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 473/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.828 total time=   0.0s\n",
            "[CV 1/5; 474/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 474/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.852 total time=   0.0s\n",
            "[CV 2/5; 474/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 474/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.872 total time=   0.0s\n",
            "[CV 3/5; 474/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 474/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.792 total time=   0.0s\n",
            "[CV 4/5; 474/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 474/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.956 total time=   0.0s\n",
            "[CV 5/5; 474/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 474/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.912 total time=   0.0s\n",
            "[CV 1/5; 475/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 475/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.820 total time=   0.0s\n",
            "[CV 2/5; 475/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 475/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.844 total time=   0.0s\n",
            "[CV 3/5; 475/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 475/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 475/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 475/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.816 total time=   0.0s\n",
            "[CV 5/5; 475/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 475/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.920 total time=   0.0s\n",
            "[CV 1/5; 476/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 476/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.936 total time=   0.0s\n",
            "[CV 2/5; 476/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 476/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.896 total time=   0.0s\n",
            "[CV 3/5; 476/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 476/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 4/5; 476/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 476/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.932 total time=   0.0s\n",
            "[CV 5/5; 476/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 476/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.880 total time=   0.0s\n",
            "[CV 1/5; 477/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 477/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06;, score=0.952 total time=   0.0s\n",
            "[CV 2/5; 477/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 477/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 477/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 477/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06;, score=0.952 total time=   0.0s\n",
            "[CV 4/5; 477/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 477/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 477/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 477/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 478/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 478/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05;, score=0.968 total time=   0.0s\n",
            "[CV 2/5; 478/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 478/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 478/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 478/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 478/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 478/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 5/5; 478/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 478/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05;, score=0.952 total time=   0.0s\n",
            "[CV 1/5; 479/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 479/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 2/5; 479/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 479/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 479/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 479/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001;, score=0.924 total time=   0.0s\n",
            "[CV 4/5; 479/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 479/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 479/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 479/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 480/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 1/5; 480/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 2/5; 480/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 2/5; 480/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=0.001;, score=0.944 total time=   0.0s\n",
            "[CV 3/5; 480/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 3/5; 480/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=0.001;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 480/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 4/5; 480/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 5/5; 480/1344] START alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 5/5; 480/1344] END alpha=0.0001, loss=log_loss, max_iter=100000, penalty=None, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 1/5; 481/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 481/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 2/5; 481/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 481/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 3/5; 481/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 481/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.680 total time=   0.0s\n",
            "[CV 4/5; 481/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 481/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.864 total time=   0.0s\n",
            "[CV 5/5; 481/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 481/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.968 total time=   0.0s\n",
            "[CV 1/5; 482/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 482/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.804 total time=   0.0s\n",
            "[CV 2/5; 482/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 482/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 3/5; 482/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 482/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.904 total time=   0.0s\n",
            "[CV 4/5; 482/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 482/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.992 total time=   0.0s\n",
            "[CV 5/5; 482/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 482/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 483/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 483/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.968 total time=   0.0s\n",
            "[CV 2/5; 483/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 483/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.796 total time=   0.0s\n",
            "[CV 3/5; 483/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 483/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.772 total time=   0.0s\n",
            "[CV 4/5; 483/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 483/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.860 total time=   0.0s\n",
            "[CV 5/5; 483/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 483/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 484/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 484/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 2/5; 484/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 484/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.940 total time=   0.0s\n",
            "[CV 3/5; 484/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 484/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 484/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 484/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.896 total time=   0.0s\n",
            "[CV 5/5; 484/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 484/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 1/5; 485/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 485/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 2/5; 485/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 485/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 485/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 485/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.936 total time=   0.0s\n",
            "[CV 4/5; 485/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 485/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.920 total time=   0.0s\n",
            "[CV 5/5; 485/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 485/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.968 total time=   0.0s\n",
            "[CV 1/5; 486/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 486/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.968 total time=   0.0s\n",
            "[CV 2/5; 486/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 486/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 486/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 486/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.916 total time=   0.0s\n",
            "[CV 4/5; 486/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 486/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.936 total time=   0.0s\n",
            "[CV 5/5; 486/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 486/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 487/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 487/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 2/5; 487/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 487/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 487/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 487/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 4/5; 487/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 487/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 5/5; 487/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 487/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.980 total time=   0.0s\n",
            "[CV 1/5; 488/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 488/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 2/5; 488/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 488/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 488/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 488/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 488/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 488/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 5/5; 488/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 488/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.952 total time=   0.0s\n",
            "[CV 1/5; 489/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 489/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.956 total time=   0.0s\n",
            "[CV 2/5; 489/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 489/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 489/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 489/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.776 total time=   0.0s\n",
            "[CV 4/5; 489/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 489/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.912 total time=   0.0s\n",
            "[CV 5/5; 489/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 489/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 1/5; 490/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 490/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.944 total time=   0.0s\n",
            "[CV 2/5; 490/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 490/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.928 total time=   0.0s\n",
            "[CV 3/5; 490/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 490/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.916 total time=   0.0s\n",
            "[CV 4/5; 490/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 490/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.900 total time=   0.0s\n",
            "[CV 5/5; 490/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 490/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.920 total time=   0.0s\n",
            "[CV 1/5; 491/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 491/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.884 total time=   0.0s\n",
            "[CV 2/5; 491/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 491/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 491/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 491/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 4/5; 491/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 491/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.768 total time=   0.0s\n",
            "[CV 5/5; 491/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 491/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 492/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 492/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.852 total time=   0.0s\n",
            "[CV 2/5; 492/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 492/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 3/5; 492/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 492/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.684 total time=   0.0s\n",
            "[CV 4/5; 492/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 492/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 5/5; 492/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 492/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 493/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 493/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.900 total time=   0.0s\n",
            "[CV 2/5; 493/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 493/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 3/5; 493/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 493/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 493/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 493/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 493/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 493/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 494/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 494/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 2/5; 494/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 494/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 494/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 494/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 494/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 494/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 494/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 494/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 495/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 495/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 2/5; 495/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 495/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 495/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 495/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 495/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 495/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 495/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 495/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 496/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 1/5; 496/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 2/5; 496/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 2/5; 496/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.952 total time=   0.0s\n",
            "[CV 3/5; 496/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 3/5; 496/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 496/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 4/5; 496/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 496/1344] START alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 5/5; 496/1344] END alpha=0.0001, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.908 total time=   0.0s\n",
            "[CV 1/5; 497/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 497/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.928 total time=   0.0s\n",
            "[CV 2/5; 497/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 497/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 497/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 497/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 4/5; 497/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 497/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.808 total time=   0.0s\n",
            "[CV 5/5; 497/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 497/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 1/5; 498/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 498/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.828 total time=   0.0s\n",
            "[CV 2/5; 498/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 498/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.900 total time=   0.0s\n",
            "[CV 3/5; 498/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 498/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.952 total time=   0.0s\n",
            "[CV 4/5; 498/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 498/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.920 total time=   0.0s\n",
            "[CV 5/5; 498/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 498/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.796 total time=   0.0s\n",
            "[CV 1/5; 499/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 499/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 499/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 499/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.832 total time=   0.0s\n",
            "[CV 3/5; 499/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 499/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.952 total time=   0.0s\n",
            "[CV 4/5; 499/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 499/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.748 total time=   0.0s\n",
            "[CV 5/5; 499/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 499/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 1/5; 500/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 500/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.864 total time=   0.0s\n",
            "[CV 2/5; 500/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 500/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.752 total time=   0.0s\n",
            "[CV 3/5; 500/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 500/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.792 total time=   0.0s\n",
            "[CV 4/5; 500/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 500/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.956 total time=   0.0s\n",
            "[CV 5/5; 500/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 500/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 1/5; 501/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 501/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.884 total time=   0.0s\n",
            "[CV 2/5; 501/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 501/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 501/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 501/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.952 total time=   0.0s\n",
            "[CV 4/5; 501/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 501/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.896 total time=   0.0s\n",
            "[CV 5/5; 501/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 501/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 1/5; 502/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 502/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 2/5; 502/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 502/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 502/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 502/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.936 total time=   0.0s\n",
            "[CV 4/5; 502/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 502/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.956 total time=   0.0s\n",
            "[CV 5/5; 502/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 502/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.956 total time=   0.0s\n",
            "[CV 1/5; 503/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 503/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 2/5; 503/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 503/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 503/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 503/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.912 total time=   0.0s\n",
            "[CV 4/5; 503/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 503/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 503/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 503/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.908 total time=   0.0s\n",
            "[CV 1/5; 504/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 504/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 2/5; 504/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 504/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 504/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 504/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.928 total time=   0.0s\n",
            "[CV 4/5; 504/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 504/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 504/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 504/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 505/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 505/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.872 total time=   0.0s\n",
            "[CV 2/5; 505/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 505/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.824 total time=   0.0s\n",
            "[CV 3/5; 505/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 505/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.952 total time=   0.0s\n",
            "[CV 4/5; 505/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 505/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.836 total time=   0.0s\n",
            "[CV 5/5; 505/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 505/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.936 total time=   0.0s\n",
            "[CV 1/5; 506/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 506/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.928 total time=   0.0s\n",
            "[CV 2/5; 506/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 506/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 506/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 506/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 506/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 506/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 506/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 506/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.796 total time=   0.0s\n",
            "[CV 1/5; 507/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 507/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 507/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 507/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 507/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 507/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.924 total time=   0.0s\n",
            "[CV 4/5; 507/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 507/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.956 total time=   0.0s\n",
            "[CV 5/5; 507/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 507/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.860 total time=   0.0s\n",
            "[CV 1/5; 508/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 508/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.840 total time=   0.0s\n",
            "[CV 2/5; 508/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 508/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 508/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 508/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.828 total time=   0.0s\n",
            "[CV 4/5; 508/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 508/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 508/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 508/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.968 total time=   0.0s\n",
            "[CV 1/5; 509/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 509/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.916 total time=   0.0s\n",
            "[CV 2/5; 509/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 509/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 509/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 509/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 509/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 509/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.920 total time=   0.0s\n",
            "[CV 5/5; 509/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 509/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 510/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 510/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 2/5; 510/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 510/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 3/5; 510/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 510/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 510/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 510/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 5/5; 510/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 510/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 1/5; 511/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 511/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 2/5; 511/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 511/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 511/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 511/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.960 total time=   0.0s\n",
            "[CV 4/5; 511/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 511/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 5/5; 511/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 511/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.936 total time=   0.0s\n",
            "[CV 1/5; 512/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 1/5; 512/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 2/5; 512/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 2/5; 512/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 3/5; 512/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 3/5; 512/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.916 total time=   0.0s\n",
            "[CV 4/5; 512/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 4/5; 512/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.920 total time=   0.0s\n",
            "[CV 5/5; 512/1344] START alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 5/5; 512/1344] END alpha=0.0001, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.956 total time=   0.0s\n",
            "[CV 1/5; 513/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 513/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.792 total time=   0.0s\n",
            "[CV 2/5; 513/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 513/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.732 total time=   0.0s\n",
            "[CV 3/5; 513/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 513/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.736 total time=   0.0s\n",
            "[CV 4/5; 513/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 513/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.908 total time=   0.0s\n",
            "[CV 5/5; 513/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 513/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 1/5; 514/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 514/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.880 total time=   0.0s\n",
            "[CV 2/5; 514/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 514/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 514/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 514/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.924 total time=   0.0s\n",
            "[CV 4/5; 514/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 514/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.836 total time=   0.0s\n",
            "[CV 5/5; 514/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 514/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 1/5; 515/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 515/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.932 total time=   0.0s\n",
            "[CV 2/5; 515/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 515/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.832 total time=   0.0s\n",
            "[CV 3/5; 515/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 515/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.928 total time=   0.0s\n",
            "[CV 4/5; 515/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 515/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.732 total time=   0.0s\n",
            "[CV 5/5; 515/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 515/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 1/5; 516/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 516/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 2/5; 516/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 516/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.916 total time=   0.0s\n",
            "[CV 3/5; 516/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 516/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 4/5; 516/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 516/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.920 total time=   0.0s\n",
            "[CV 5/5; 516/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 516/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 517/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 517/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.932 total time=   0.0s\n",
            "[CV 2/5; 517/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 517/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.936 total time=   0.0s\n",
            "[CV 3/5; 517/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 517/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.912 total time=   0.0s\n",
            "[CV 4/5; 517/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 517/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 517/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 517/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 518/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 518/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.960 total time=   0.0s\n",
            "[CV 2/5; 518/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 518/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 3/5; 518/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 518/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.900 total time=   0.0s\n",
            "[CV 4/5; 518/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 518/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 5/5; 518/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 518/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.952 total time=   0.0s\n",
            "[CV 1/5; 519/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 519/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.916 total time=   0.0s\n",
            "[CV 2/5; 519/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 519/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 519/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 519/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.960 total time=   0.0s\n",
            "[CV 4/5; 519/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 519/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 519/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 519/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.896 total time=   0.0s\n",
            "[CV 1/5; 520/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 520/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.944 total time=   0.0s\n",
            "[CV 2/5; 520/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 520/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 3/5; 520/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 520/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.928 total time=   0.0s\n",
            "[CV 4/5; 520/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 520/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 5/5; 520/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 520/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.956 total time=   0.0s\n",
            "[CV 1/5; 521/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 521/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.864 total time=   0.0s\n",
            "[CV 2/5; 521/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 521/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.892 total time=   0.0s\n",
            "[CV 3/5; 521/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 521/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.732 total time=   0.0s\n",
            "[CV 4/5; 521/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 521/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.956 total time=   0.0s\n",
            "[CV 5/5; 521/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 521/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.932 total time=   0.0s\n",
            "[CV 1/5; 522/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 522/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.784 total time=   0.0s\n",
            "[CV 2/5; 522/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 522/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.992 total time=   0.0s\n",
            "[CV 3/5; 522/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 522/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 4/5; 522/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 522/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 5/5; 522/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 522/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.952 total time=   0.0s\n",
            "[CV 1/5; 523/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 523/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.952 total time=   0.0s\n",
            "[CV 2/5; 523/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 523/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 523/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 523/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.916 total time=   0.0s\n",
            "[CV 4/5; 523/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 523/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.900 total time=   0.0s\n",
            "[CV 5/5; 523/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 523/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.904 total time=   0.0s\n",
            "[CV 1/5; 524/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 524/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.788 total time=   0.0s\n",
            "[CV 2/5; 524/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 524/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.944 total time=   0.0s\n",
            "[CV 3/5; 524/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 524/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.852 total time=   0.0s\n",
            "[CV 4/5; 524/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 524/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.876 total time=   0.0s\n",
            "[CV 5/5; 524/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 524/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 525/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 525/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.904 total time=   0.0s\n",
            "[CV 2/5; 525/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 525/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 3/5; 525/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 525/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 525/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 525/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 525/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 525/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.956 total time=   0.0s\n",
            "[CV 1/5; 526/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 526/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 2/5; 526/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 526/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 526/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 526/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 526/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 526/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 526/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 526/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.956 total time=   0.0s\n",
            "[CV 1/5; 527/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 527/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.960 total time=   0.0s\n",
            "[CV 2/5; 527/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 527/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 527/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 527/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 527/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 527/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.956 total time=   0.0s\n",
            "[CV 5/5; 527/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 527/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 1/5; 528/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 1/5; 528/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 2/5; 528/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 2/5; 528/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 528/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 3/5; 528/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.900 total time=   0.0s\n",
            "[CV 4/5; 528/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 4/5; 528/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.952 total time=   0.0s\n",
            "[CV 5/5; 528/1344] START alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 5/5; 528/1344] END alpha=0.0001, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 529/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 529/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.796 total time=   0.0s\n",
            "[CV 2/5; 529/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 529/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.768 total time=   0.0s\n",
            "[CV 3/5; 529/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 529/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.844 total time=   0.0s\n",
            "[CV 4/5; 529/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 529/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.932 total time=   0.0s\n",
            "[CV 5/5; 529/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 529/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.712 total time=   0.0s\n",
            "[CV 1/5; 530/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 530/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 530/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 530/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.828 total time=   0.0s\n",
            "[CV 3/5; 530/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 530/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.720 total time=   0.0s\n",
            "[CV 4/5; 530/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 530/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.916 total time=   0.0s\n",
            "[CV 5/5; 530/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 530/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.760 total time=   0.0s\n",
            "[CV 1/5; 531/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 531/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 531/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 531/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.780 total time=   0.0s\n",
            "[CV 3/5; 531/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 531/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.868 total time=   0.0s\n",
            "[CV 4/5; 531/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 531/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.788 total time=   0.0s\n",
            "[CV 5/5; 531/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 531/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.784 total time=   0.0s\n",
            "[CV 1/5; 532/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 532/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.840 total time=   0.0s\n",
            "[CV 2/5; 532/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 532/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 3/5; 532/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 532/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.876 total time=   0.0s\n",
            "[CV 4/5; 532/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 532/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.920 total time=   0.0s\n",
            "[CV 5/5; 532/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 532/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.864 total time=   0.0s\n",
            "[CV 1/5; 533/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 533/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 2/5; 533/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 533/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 533/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 533/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.960 total time=   0.0s\n",
            "[CV 4/5; 533/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 533/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.992 total time=   0.0s\n",
            "[CV 5/5; 533/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 533/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 534/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 534/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 2/5; 534/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 534/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 534/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 534/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.904 total time=   0.0s\n",
            "[CV 4/5; 534/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 534/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 534/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 534/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 1/5; 535/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 535/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 2/5; 535/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 535/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 535/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 535/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 535/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 535/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.960 total time=   0.0s\n",
            "[CV 5/5; 535/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 535/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 536/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 536/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.924 total time=   0.0s\n",
            "[CV 2/5; 536/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 536/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 3/5; 536/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 536/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.920 total time=   0.0s\n",
            "[CV 4/5; 536/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 536/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 5/5; 536/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 536/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.932 total time=   0.0s\n",
            "[CV 1/5; 537/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 537/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.868 total time=   0.0s\n",
            "[CV 2/5; 537/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 537/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 3/5; 537/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 537/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 537/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 537/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.900 total time=   0.0s\n",
            "[CV 5/5; 537/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 537/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.876 total time=   0.0s\n",
            "[CV 1/5; 538/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 538/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.932 total time=   0.0s\n",
            "[CV 2/5; 538/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 538/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.816 total time=   0.0s\n",
            "[CV 3/5; 538/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 538/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.728 total time=   0.0s\n",
            "[CV 4/5; 538/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 538/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 538/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 538/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.896 total time=   0.0s\n",
            "[CV 1/5; 539/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 539/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.868 total time=   0.0s\n",
            "[CV 2/5; 539/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 539/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 3/5; 539/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 539/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.936 total time=   0.0s\n",
            "[CV 4/5; 539/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 539/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 539/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 539/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.896 total time=   0.0s\n",
            "[CV 1/5; 540/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 540/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 2/5; 540/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 540/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.804 total time=   0.0s\n",
            "[CV 3/5; 540/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 540/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 540/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 540/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.952 total time=   0.0s\n",
            "[CV 5/5; 540/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 540/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.860 total time=   0.0s\n",
            "[CV 1/5; 541/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 541/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.960 total time=   0.0s\n",
            "[CV 2/5; 541/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 541/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 541/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 541/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.936 total time=   0.0s\n",
            "[CV 4/5; 541/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 541/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.924 total time=   0.0s\n",
            "[CV 5/5; 541/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 541/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.932 total time=   0.0s\n",
            "[CV 1/5; 542/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 542/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.928 total time=   0.0s\n",
            "[CV 2/5; 542/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 542/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 542/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 542/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.924 total time=   0.0s\n",
            "[CV 4/5; 542/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 542/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.992 total time=   0.0s\n",
            "[CV 5/5; 542/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 542/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.936 total time=   0.0s\n",
            "[CV 1/5; 543/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 543/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.968 total time=   0.0s\n",
            "[CV 2/5; 543/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 543/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 543/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 543/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.960 total time=   0.0s\n",
            "[CV 4/5; 543/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 543/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.960 total time=   0.0s\n",
            "[CV 5/5; 543/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 543/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 544/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 1/5; 544/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.956 total time=   0.0s\n",
            "[CV 2/5; 544/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 2/5; 544/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 544/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 3/5; 544/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 544/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 4/5; 544/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 544/1344] START alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 5/5; 544/1344] END alpha=0.0001, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.932 total time=   0.0s\n",
            "[CV 1/5; 545/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 545/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 545/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 545/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 3/5; 545/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 545/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.676 total time=   0.0s\n",
            "[CV 4/5; 545/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 545/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.804 total time=   0.0s\n",
            "[CV 5/5; 545/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 545/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.804 total time=   0.0s\n",
            "[CV 1/5; 546/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 546/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.836 total time=   0.0s\n",
            "[CV 2/5; 546/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 546/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.804 total time=   0.0s\n",
            "[CV 3/5; 546/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 546/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.952 total time=   0.0s\n",
            "[CV 4/5; 546/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 546/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.788 total time=   0.0s\n",
            "[CV 5/5; 546/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 546/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.892 total time=   0.0s\n",
            "[CV 1/5; 547/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 547/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.956 total time=   0.0s\n",
            "[CV 2/5; 547/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 547/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 3/5; 547/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 547/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 4/5; 547/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 547/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.836 total time=   0.0s\n",
            "[CV 5/5; 547/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 547/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 548/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 548/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.744 total time=   0.0s\n",
            "[CV 2/5; 548/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 548/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 548/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 548/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.916 total time=   0.0s\n",
            "[CV 4/5; 548/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 548/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.916 total time=   0.0s\n",
            "[CV 5/5; 548/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 548/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.932 total time=   0.0s\n",
            "[CV 1/5; 549/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 549/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.968 total time=   0.0s\n",
            "[CV 2/5; 549/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 549/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 549/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 549/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.896 total time=   0.0s\n",
            "[CV 4/5; 549/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 549/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 5/5; 549/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 549/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 550/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 550/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.956 total time=   0.0s\n",
            "[CV 2/5; 550/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 550/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 550/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 550/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.900 total time=   0.0s\n",
            "[CV 4/5; 550/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 550/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.944 total time=   0.0s\n",
            "[CV 5/5; 550/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 550/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.912 total time=   0.0s\n",
            "[CV 1/5; 551/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 551/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.912 total time=   0.0s\n",
            "[CV 2/5; 551/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 551/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.924 total time=   0.0s\n",
            "[CV 3/5; 551/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 551/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 4/5; 551/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 551/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.960 total time=   0.0s\n",
            "[CV 5/5; 551/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 551/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 552/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 552/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 2/5; 552/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 552/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 3/5; 552/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 552/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.896 total time=   0.0s\n",
            "[CV 4/5; 552/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 552/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.992 total time=   0.0s\n",
            "[CV 5/5; 552/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 552/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 1/5; 553/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 553/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.884 total time=   0.0s\n",
            "[CV 2/5; 553/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 553/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.860 total time=   0.0s\n",
            "[CV 3/5; 553/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 553/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.908 total time=   0.0s\n",
            "[CV 4/5; 553/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 553/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.900 total time=   0.0s\n",
            "[CV 5/5; 553/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 553/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.824 total time=   0.0s\n",
            "[CV 1/5; 554/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 554/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.852 total time=   0.0s\n",
            "[CV 2/5; 554/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 554/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.928 total time=   0.0s\n",
            "[CV 3/5; 554/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 554/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.900 total time=   0.0s\n",
            "[CV 4/5; 554/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 554/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 554/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 554/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.924 total time=   0.0s\n",
            "[CV 1/5; 555/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 555/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 2/5; 555/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 555/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.832 total time=   0.0s\n",
            "[CV 3/5; 555/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 555/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.928 total time=   0.0s\n",
            "[CV 4/5; 555/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 555/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.820 total time=   0.0s\n",
            "[CV 5/5; 555/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 555/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 556/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 556/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.856 total time=   0.0s\n",
            "[CV 2/5; 556/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 556/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.836 total time=   0.0s\n",
            "[CV 3/5; 556/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 556/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.908 total time=   0.0s\n",
            "[CV 4/5; 556/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 556/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 556/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 556/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.896 total time=   0.0s\n",
            "[CV 1/5; 557/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 557/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.908 total time=   0.0s\n",
            "[CV 2/5; 557/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 557/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 557/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 557/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.932 total time=   0.0s\n",
            "[CV 4/5; 557/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 557/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.952 total time=   0.0s\n",
            "[CV 5/5; 557/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 557/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 1/5; 558/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 558/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.960 total time=   0.0s\n",
            "[CV 2/5; 558/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 558/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.956 total time=   0.0s\n",
            "[CV 3/5; 558/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 558/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 4/5; 558/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 558/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 558/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 558/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 559/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 559/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 2/5; 559/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 559/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 3/5; 559/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 559/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 559/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 559/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 5/5; 559/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 559/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 560/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 1/5; 560/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 2/5; 560/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 2/5; 560/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 560/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 3/5; 560/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 4/5; 560/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 4/5; 560/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 560/1344] START alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 5/5; 560/1344] END alpha=0.0001, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 561/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 561/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.940 total time=   0.0s\n",
            "[CV 2/5; 561/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 561/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 561/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 561/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.784 total time=   0.0s\n",
            "[CV 4/5; 561/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 561/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.732 total time=   0.0s\n",
            "[CV 5/5; 561/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 561/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.880 total time=   0.0s\n",
            "[CV 1/5; 562/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 562/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.800 total time=   0.0s\n",
            "[CV 2/5; 562/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 562/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.784 total time=   0.0s\n",
            "[CV 3/5; 562/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 562/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.760 total time=   0.0s\n",
            "[CV 4/5; 562/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 562/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.880 total time=   0.0s\n",
            "[CV 5/5; 562/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 562/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.876 total time=   0.0s\n",
            "[CV 1/5; 563/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 563/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.916 total time=   0.0s\n",
            "[CV 2/5; 563/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 563/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.924 total time=   0.0s\n",
            "[CV 3/5; 563/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 563/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.828 total time=   0.0s\n",
            "[CV 4/5; 563/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 563/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.732 total time=   0.0s\n",
            "[CV 5/5; 563/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 563/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 1/5; 564/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 564/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.800 total time=   0.0s\n",
            "[CV 2/5; 564/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 564/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.800 total time=   0.0s\n",
            "[CV 3/5; 564/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 564/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.828 total time=   0.0s\n",
            "[CV 4/5; 564/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 564/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.820 total time=   0.0s\n",
            "[CV 5/5; 564/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 564/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 565/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 565/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 2/5; 565/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 565/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 565/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 565/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.932 total time=   0.0s\n",
            "[CV 4/5; 565/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 565/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.928 total time=   0.0s\n",
            "[CV 5/5; 565/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 565/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 1/5; 566/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 566/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.872 total time=   0.0s\n",
            "[CV 2/5; 566/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 566/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.944 total time=   0.0s\n",
            "[CV 3/5; 566/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 566/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 566/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 566/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 566/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 566/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 1/5; 567/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 567/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.952 total time=   0.0s\n",
            "[CV 2/5; 567/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 567/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 567/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 567/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 567/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 567/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.936 total time=   0.0s\n",
            "[CV 5/5; 567/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 567/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 1/5; 568/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 568/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.916 total time=   0.0s\n",
            "[CV 2/5; 568/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 568/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 568/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 568/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 4/5; 568/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 568/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 568/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 568/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.844 total time=   0.0s\n",
            "[CV 1/5; 569/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 569/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.936 total time=   0.0s\n",
            "[CV 2/5; 569/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 569/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 569/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 569/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 4/5; 569/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 569/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 5/5; 569/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 569/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.820 total time=   0.0s\n",
            "[CV 1/5; 570/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 570/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 2/5; 570/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 570/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.836 total time=   0.0s\n",
            "[CV 3/5; 570/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 570/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.836 total time=   0.0s\n",
            "[CV 4/5; 570/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 570/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.896 total time=   0.0s\n",
            "[CV 5/5; 570/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 570/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.944 total time=   0.0s\n",
            "[CV 1/5; 571/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 571/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.816 total time=   0.0s\n",
            "[CV 2/5; 571/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 571/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 3/5; 571/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 571/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.800 total time=   0.0s\n",
            "[CV 4/5; 571/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 571/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.868 total time=   0.0s\n",
            "[CV 5/5; 571/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 571/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.900 total time=   0.0s\n",
            "[CV 1/5; 572/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 572/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.868 total time=   0.0s\n",
            "[CV 2/5; 572/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 572/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 572/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 572/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 572/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 572/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 572/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 572/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.920 total time=   0.0s\n",
            "[CV 1/5; 573/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 573/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 2/5; 573/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 573/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 573/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 573/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.940 total time=   0.0s\n",
            "[CV 4/5; 573/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 573/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 573/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 573/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 1/5; 574/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 574/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.944 total time=   0.0s\n",
            "[CV 2/5; 574/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 574/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 574/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 574/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.920 total time=   0.0s\n",
            "[CV 4/5; 574/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 574/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 574/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 574/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 575/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 575/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 2/5; 575/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 575/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 575/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 575/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 4/5; 575/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 575/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 575/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 575/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.920 total time=   0.0s\n",
            "[CV 1/5; 576/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 1/5; 576/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 2/5; 576/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 2/5; 576/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 576/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 3/5; 576/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.940 total time=   0.0s\n",
            "[CV 4/5; 576/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 4/5; 576/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.992 total time=   0.0s\n",
            "[CV 5/5; 576/1344] START alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 5/5; 576/1344] END alpha=0.0001, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.920 total time=   0.0s\n",
            "[CV 1/5; 577/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 577/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.620 total time=   0.0s\n",
            "[CV 2/5; 577/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 577/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.724 total time=   0.0s\n",
            "[CV 3/5; 577/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 577/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.608 total time=   0.0s\n",
            "[CV 4/5; 577/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 577/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.720 total time=   0.0s\n",
            "[CV 5/5; 577/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 577/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.588 total time=   0.0s\n",
            "[CV 1/5; 578/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 578/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.624 total time=   0.0s\n",
            "[CV 2/5; 578/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 578/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.676 total time=   0.0s\n",
            "[CV 3/5; 578/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 578/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.668 total time=   0.0s\n",
            "[CV 4/5; 578/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 578/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.676 total time=   0.0s\n",
            "[CV 5/5; 578/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 578/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.632 total time=   0.0s\n",
            "[CV 1/5; 579/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 579/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.584 total time=   0.0s\n",
            "[CV 2/5; 579/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 579/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.660 total time=   0.0s\n",
            "[CV 3/5; 579/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 579/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.652 total time=   0.0s\n",
            "[CV 4/5; 579/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 579/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.680 total time=   0.0s\n",
            "[CV 5/5; 579/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 579/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.592 total time=   0.0s\n",
            "[CV 1/5; 580/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 580/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.632 total time=   0.0s\n",
            "[CV 2/5; 580/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 580/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.624 total time=   0.0s\n",
            "[CV 3/5; 580/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 580/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.652 total time=   0.0s\n",
            "[CV 4/5; 580/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 580/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.708 total time=   0.0s\n",
            "[CV 5/5; 580/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 580/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.592 total time=   0.0s\n",
            "[CV 1/5; 581/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 581/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.748 total time=   0.0s\n",
            "[CV 2/5; 581/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 581/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.728 total time=   0.0s\n",
            "[CV 3/5; 581/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 581/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.840 total time=   0.0s\n",
            "[CV 4/5; 581/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 581/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.828 total time=   0.0s\n",
            "[CV 5/5; 581/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 581/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.744 total time=   0.0s\n",
            "[CV 1/5; 582/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 582/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.764 total time=   0.0s\n",
            "[CV 2/5; 582/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 582/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.800 total time=   0.0s\n",
            "[CV 3/5; 582/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 582/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.816 total time=   0.0s\n",
            "[CV 4/5; 582/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 582/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.828 total time=   0.0s\n",
            "[CV 5/5; 582/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 582/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.740 total time=   0.0s\n",
            "[CV 1/5; 583/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 583/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.752 total time=   0.0s\n",
            "[CV 2/5; 583/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 583/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.804 total time=   0.0s\n",
            "[CV 3/5; 583/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 583/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.860 total time=   0.0s\n",
            "[CV 4/5; 583/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 583/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.828 total time=   0.0s\n",
            "[CV 5/5; 583/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 583/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.748 total time=   0.0s\n",
            "[CV 1/5; 584/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 584/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.784 total time=   0.0s\n",
            "[CV 2/5; 584/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 584/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.772 total time=   0.0s\n",
            "[CV 3/5; 584/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 584/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.800 total time=   0.0s\n",
            "[CV 4/5; 584/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 584/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.816 total time=   0.0s\n",
            "[CV 5/5; 584/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 584/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.748 total time=   0.0s\n",
            "[CV 1/5; 585/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 585/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.640 total time=   0.0s\n",
            "[CV 2/5; 585/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 585/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.676 total time=   0.0s\n",
            "[CV 3/5; 585/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 585/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.724 total time=   0.0s\n",
            "[CV 4/5; 585/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 585/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.692 total time=   0.0s\n",
            "[CV 5/5; 585/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 585/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.612 total time=   0.0s\n",
            "[CV 1/5; 586/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 586/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.608 total time=   0.0s\n",
            "[CV 2/5; 586/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 586/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.632 total time=   0.0s\n",
            "[CV 3/5; 586/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 586/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.668 total time=   0.0s\n",
            "[CV 4/5; 586/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 586/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.736 total time=   0.0s\n",
            "[CV 5/5; 586/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 586/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.608 total time=   0.0s\n",
            "[CV 1/5; 587/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 587/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.604 total time=   0.0s\n",
            "[CV 2/5; 587/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 587/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.692 total time=   0.0s\n",
            "[CV 3/5; 587/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 587/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.652 total time=   0.0s\n",
            "[CV 4/5; 587/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 587/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.732 total time=   0.0s\n",
            "[CV 5/5; 587/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 587/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.600 total time=   0.0s\n",
            "[CV 1/5; 588/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 588/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.644 total time=   0.0s\n",
            "[CV 2/5; 588/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 588/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.672 total time=   0.0s\n",
            "[CV 3/5; 588/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 588/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.680 total time=   0.0s\n",
            "[CV 4/5; 588/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 588/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.688 total time=   0.0s\n",
            "[CV 5/5; 588/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 588/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.612 total time=   0.0s\n",
            "[CV 1/5; 589/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 589/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.928 total time=   0.0s\n",
            "[CV 2/5; 589/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 589/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.904 total time=   0.0s\n",
            "[CV 3/5; 589/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 589/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.936 total time=   0.0s\n",
            "[CV 4/5; 589/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 589/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.936 total time=   0.0s\n",
            "[CV 5/5; 589/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 589/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.904 total time=   0.0s\n",
            "[CV 1/5; 590/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 590/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.932 total time=   0.0s\n",
            "[CV 2/5; 590/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 590/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 3/5; 590/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 590/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.932 total time=   0.0s\n",
            "[CV 4/5; 590/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 590/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 590/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 590/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.868 total time=   0.0s\n",
            "[CV 1/5; 591/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 591/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.844 total time=   0.0s\n",
            "[CV 2/5; 591/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 591/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.880 total time=   0.0s\n",
            "[CV 3/5; 591/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 591/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.924 total time=   0.0s\n",
            "[CV 4/5; 591/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 591/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.936 total time=   0.0s\n",
            "[CV 5/5; 591/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 591/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.916 total time=   0.0s\n",
            "[CV 1/5; 592/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 1/5; 592/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 592/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 2/5; 592/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.900 total time=   0.0s\n",
            "[CV 3/5; 592/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 3/5; 592/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.896 total time=   0.0s\n",
            "[CV 4/5; 592/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 4/5; 592/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.940 total time=   0.0s\n",
            "[CV 5/5; 592/1344] START alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 5/5; 592/1344] END alpha=0.01, loss=hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.912 total time=   0.0s\n",
            "[CV 1/5; 593/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 593/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.616 total time=   0.0s\n",
            "[CV 2/5; 593/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 593/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.640 total time=   0.0s\n",
            "[CV 3/5; 593/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 593/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.724 total time=   0.0s\n",
            "[CV 4/5; 593/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 593/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.692 total time=   0.0s\n",
            "[CV 5/5; 593/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 593/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.632 total time=   0.0s\n",
            "[CV 1/5; 594/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 594/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.600 total time=   0.0s\n",
            "[CV 2/5; 594/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 594/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.736 total time=   0.0s\n",
            "[CV 3/5; 594/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 594/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.684 total time=   0.0s\n",
            "[CV 4/5; 594/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 594/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.736 total time=   0.0s\n",
            "[CV 5/5; 594/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 594/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.604 total time=   0.0s\n",
            "[CV 1/5; 595/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 595/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.600 total time=   0.0s\n",
            "[CV 2/5; 595/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 595/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.712 total time=   0.0s\n",
            "[CV 3/5; 595/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 595/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.680 total time=   0.0s\n",
            "[CV 4/5; 595/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 595/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.648 total time=   0.0s\n",
            "[CV 5/5; 595/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 595/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.624 total time=   0.0s\n",
            "[CV 1/5; 596/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 596/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.620 total time=   0.0s\n",
            "[CV 2/5; 596/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 596/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.684 total time=   0.0s\n",
            "[CV 3/5; 596/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 596/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.680 total time=   0.0s\n",
            "[CV 4/5; 596/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 596/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.696 total time=   0.0s\n",
            "[CV 5/5; 596/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 596/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.604 total time=   0.0s\n",
            "[CV 1/5; 597/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 597/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.780 total time=   0.0s\n",
            "[CV 2/5; 597/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 597/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.832 total time=   0.0s\n",
            "[CV 3/5; 597/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 597/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.816 total time=   0.0s\n",
            "[CV 4/5; 597/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 597/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 597/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 597/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.780 total time=   0.0s\n",
            "[CV 1/5; 598/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 598/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.792 total time=   0.0s\n",
            "[CV 2/5; 598/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 598/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 598/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 598/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.840 total time=   0.0s\n",
            "[CV 4/5; 598/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 598/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.836 total time=   0.0s\n",
            "[CV 5/5; 598/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 598/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 599/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 599/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.764 total time=   0.0s\n",
            "[CV 2/5; 599/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 599/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.776 total time=   0.0s\n",
            "[CV 3/5; 599/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 599/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.860 total time=   0.0s\n",
            "[CV 4/5; 599/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 599/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.828 total time=   0.0s\n",
            "[CV 5/5; 599/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 599/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.752 total time=   0.0s\n",
            "[CV 1/5; 600/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 600/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.764 total time=   0.0s\n",
            "[CV 2/5; 600/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 600/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.784 total time=   0.0s\n",
            "[CV 3/5; 600/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 600/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.872 total time=   0.0s\n",
            "[CV 4/5; 600/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 600/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.828 total time=   0.0s\n",
            "[CV 5/5; 600/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 600/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.736 total time=   0.0s\n",
            "[CV 1/5; 601/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 601/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.620 total time=   0.0s\n",
            "[CV 2/5; 601/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 601/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.684 total time=   0.0s\n",
            "[CV 3/5; 601/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 601/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.728 total time=   0.0s\n",
            "[CV 4/5; 601/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 601/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.704 total time=   0.0s\n",
            "[CV 5/5; 601/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 601/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.708 total time=   0.0s\n",
            "[CV 1/5; 602/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 602/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.612 total time=   0.0s\n",
            "[CV 2/5; 602/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 602/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.648 total time=   0.0s\n",
            "[CV 3/5; 602/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 602/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.672 total time=   0.0s\n",
            "[CV 4/5; 602/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 602/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.716 total time=   0.0s\n",
            "[CV 5/5; 602/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 602/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.640 total time=   0.0s\n",
            "[CV 1/5; 603/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 603/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.600 total time=   0.0s\n",
            "[CV 2/5; 603/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 603/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.696 total time=   0.0s\n",
            "[CV 3/5; 603/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 603/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.664 total time=   0.0s\n",
            "[CV 4/5; 603/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 603/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.680 total time=   0.0s\n",
            "[CV 5/5; 603/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 603/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.604 total time=   0.0s\n",
            "[CV 1/5; 604/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 604/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.588 total time=   0.0s\n",
            "[CV 2/5; 604/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 604/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.760 total time=   0.0s\n",
            "[CV 3/5; 604/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 604/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.740 total time=   0.0s\n",
            "[CV 4/5; 604/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 604/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.748 total time=   0.0s\n",
            "[CV 5/5; 604/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 604/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.608 total time=   0.0s\n",
            "[CV 1/5; 605/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 605/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.876 total time=   0.0s\n",
            "[CV 2/5; 605/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 605/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.892 total time=   0.0s\n",
            "[CV 3/5; 605/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 605/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 605/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 605/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.952 total time=   0.4s\n",
            "[CV 5/5; 605/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 605/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.920 total time=   0.0s\n",
            "[CV 1/5; 606/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 606/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.936 total time=   0.0s\n",
            "[CV 2/5; 606/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 606/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.900 total time=   0.0s\n",
            "[CV 3/5; 606/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 606/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.928 total time=   0.0s\n",
            "[CV 4/5; 606/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 606/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.916 total time=   0.0s\n",
            "[CV 5/5; 606/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 606/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.908 total time=   0.0s\n",
            "[CV 1/5; 607/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 607/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.892 total time=   0.0s\n",
            "[CV 2/5; 607/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 607/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.900 total time=   0.0s\n",
            "[CV 3/5; 607/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 607/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.932 total time=   0.0s\n",
            "[CV 4/5; 607/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 607/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 5/5; 607/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 607/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.916 total time=   0.0s\n",
            "[CV 1/5; 608/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 1/5; 608/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.896 total time=   0.0s\n",
            "[CV 2/5; 608/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 2/5; 608/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.924 total time=   0.0s\n",
            "[CV 3/5; 608/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 3/5; 608/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 608/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 4/5; 608/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.944 total time=   0.0s\n",
            "[CV 5/5; 608/1344] START alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 5/5; 608/1344] END alpha=0.01, loss=hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.852 total time=   0.0s\n",
            "[CV 1/5; 609/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 609/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.588 total time=   0.0s\n",
            "[CV 2/5; 609/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 609/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.608 total time=   0.0s\n",
            "[CV 3/5; 609/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 609/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.696 total time=   0.0s\n",
            "[CV 4/5; 609/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 609/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.712 total time=   0.0s\n",
            "[CV 5/5; 609/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 609/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.608 total time=   0.0s\n",
            "[CV 1/5; 610/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 610/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.640 total time=   0.0s\n",
            "[CV 2/5; 610/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 610/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.688 total time=   0.0s\n",
            "[CV 3/5; 610/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 610/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.672 total time=   0.0s\n",
            "[CV 4/5; 610/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 610/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.680 total time=   0.0s\n",
            "[CV 5/5; 610/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 610/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.604 total time=   0.0s\n",
            "[CV 1/5; 611/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 611/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.628 total time=   0.0s\n",
            "[CV 2/5; 611/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 611/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.616 total time=   0.0s\n",
            "[CV 3/5; 611/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 611/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.676 total time=   0.0s\n",
            "[CV 4/5; 611/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 611/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.656 total time=   0.0s\n",
            "[CV 5/5; 611/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 611/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.612 total time=   0.0s\n",
            "[CV 1/5; 612/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 612/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.624 total time=   0.0s\n",
            "[CV 2/5; 612/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 612/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.700 total time=   0.0s\n",
            "[CV 3/5; 612/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 612/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.652 total time=   0.0s\n",
            "[CV 4/5; 612/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 612/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.708 total time=   0.0s\n",
            "[CV 5/5; 612/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 612/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.600 total time=   0.0s\n",
            "[CV 1/5; 613/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 613/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.792 total time=   0.0s\n",
            "[CV 2/5; 613/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 613/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.760 total time=   0.0s\n",
            "[CV 3/5; 613/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 613/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.868 total time=   0.0s\n",
            "[CV 4/5; 613/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 613/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 613/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 613/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.748 total time=   0.0s\n",
            "[CV 1/5; 614/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 614/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.748 total time=   0.0s\n",
            "[CV 2/5; 614/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 614/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 614/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 614/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.784 total time=   0.0s\n",
            "[CV 4/5; 614/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 614/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.836 total time=   0.0s\n",
            "[CV 5/5; 614/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 614/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.724 total time=   0.0s\n",
            "[CV 1/5; 615/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 615/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.792 total time=   0.0s\n",
            "[CV 2/5; 615/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 615/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.744 total time=   0.0s\n",
            "[CV 3/5; 615/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 615/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.816 total time=   0.0s\n",
            "[CV 4/5; 615/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 615/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.824 total time=   0.0s\n",
            "[CV 5/5; 615/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 615/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.740 total time=   0.0s\n",
            "[CV 1/5; 616/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 616/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.720 total time=   0.0s\n",
            "[CV 2/5; 616/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 616/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.764 total time=   0.0s\n",
            "[CV 3/5; 616/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 616/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.836 total time=   0.0s\n",
            "[CV 4/5; 616/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 616/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.820 total time=   0.0s\n",
            "[CV 5/5; 616/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 616/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.736 total time=   0.0s\n",
            "[CV 1/5; 617/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 617/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.640 total time=   0.0s\n",
            "[CV 2/5; 617/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 617/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.672 total time=   0.0s\n",
            "[CV 3/5; 617/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 617/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.656 total time=   0.0s\n",
            "[CV 4/5; 617/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 617/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.688 total time=   0.0s\n",
            "[CV 5/5; 617/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 617/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.588 total time=   0.0s\n",
            "[CV 1/5; 618/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 618/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.648 total time=   0.0s\n",
            "[CV 2/5; 618/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 618/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.708 total time=   0.0s\n",
            "[CV 3/5; 618/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 618/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.720 total time=   0.0s\n",
            "[CV 4/5; 618/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 618/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.736 total time=   0.0s\n",
            "[CV 5/5; 618/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 618/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.624 total time=   0.0s\n",
            "[CV 1/5; 619/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 619/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.616 total time=   0.0s\n",
            "[CV 2/5; 619/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 619/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.732 total time=   0.0s\n",
            "[CV 3/5; 619/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 619/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.712 total time=   0.0s\n",
            "[CV 4/5; 619/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 619/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.648 total time=   0.0s\n",
            "[CV 5/5; 619/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 619/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.592 total time=   0.0s\n",
            "[CV 1/5; 620/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 620/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.616 total time=   0.0s\n",
            "[CV 2/5; 620/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 620/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.736 total time=   0.0s\n",
            "[CV 3/5; 620/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 620/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.728 total time=   0.0s\n",
            "[CV 4/5; 620/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 620/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.700 total time=   0.0s\n",
            "[CV 5/5; 620/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 620/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.708 total time=   0.0s\n",
            "[CV 1/5; 621/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 621/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 621/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 621/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.896 total time=   0.0s\n",
            "[CV 3/5; 621/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 621/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.932 total time=   0.0s\n",
            "[CV 4/5; 621/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 621/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.920 total time=   0.0s\n",
            "[CV 5/5; 621/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 621/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.912 total time=   0.0s\n",
            "[CV 1/5; 622/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 622/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.916 total time=   0.0s\n",
            "[CV 2/5; 622/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 622/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 3/5; 622/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 622/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.928 total time=   0.0s\n",
            "[CV 4/5; 622/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 622/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 5/5; 622/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 622/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.920 total time=   0.0s\n",
            "[CV 1/5; 623/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 623/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.884 total time=   0.0s\n",
            "[CV 2/5; 623/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 623/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.896 total time=   0.0s\n",
            "[CV 3/5; 623/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 623/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.916 total time=   0.0s\n",
            "[CV 4/5; 623/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 623/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.924 total time=   0.0s\n",
            "[CV 5/5; 623/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 623/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.912 total time=   0.0s\n",
            "[CV 1/5; 624/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 1/5; 624/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.880 total time=   0.0s\n",
            "[CV 2/5; 624/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 2/5; 624/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.856 total time=   0.0s\n",
            "[CV 3/5; 624/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 3/5; 624/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.924 total time=   0.0s\n",
            "[CV 4/5; 624/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 4/5; 624/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.916 total time=   0.0s\n",
            "[CV 5/5; 624/1344] START alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 5/5; 624/1344] END alpha=0.01, loss=hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.872 total time=   0.0s\n",
            "[CV 1/5; 625/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 625/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06;, score=0.796 total time=   0.0s\n",
            "[CV 2/5; 625/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 625/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06;, score=0.660 total time=   0.0s\n",
            "[CV 3/5; 625/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 625/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06;, score=0.700 total time=   0.0s\n",
            "[CV 4/5; 625/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 625/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06;, score=0.772 total time=   0.0s\n",
            "[CV 5/5; 625/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 625/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06;, score=0.732 total time=   0.0s\n",
            "[CV 1/5; 626/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 626/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05;, score=0.748 total time=   0.0s\n",
            "[CV 2/5; 626/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 626/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05;, score=0.632 total time=   0.0s\n",
            "[CV 3/5; 626/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 626/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05;, score=0.676 total time=   0.0s\n",
            "[CV 4/5; 626/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 626/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05;, score=0.752 total time=   0.0s\n",
            "[CV 5/5; 626/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 626/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05;, score=0.708 total time=   0.0s\n",
            "[CV 1/5; 627/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 627/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001;, score=0.808 total time=   0.0s\n",
            "[CV 2/5; 627/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 627/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001;, score=0.656 total time=   0.0s\n",
            "[CV 3/5; 627/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 627/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001;, score=0.684 total time=   0.0s\n",
            "[CV 4/5; 627/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 627/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001;, score=0.716 total time=   0.0s\n",
            "[CV 5/5; 627/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 627/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001;, score=0.692 total time=   0.0s\n",
            "[CV 1/5; 628/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 628/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001;, score=0.696 total time=   0.0s\n",
            "[CV 2/5; 628/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 628/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001;, score=0.744 total time=   0.0s\n",
            "[CV 3/5; 628/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 628/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001;, score=0.624 total time=   0.0s\n",
            "[CV 4/5; 628/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 628/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001;, score=0.724 total time=   0.0s\n",
            "[CV 5/5; 628/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 628/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001;, score=0.668 total time=   0.0s\n",
            "[CV 1/5; 629/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 629/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06;, score=0.868 total time=   0.0s\n",
            "[CV 2/5; 629/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 629/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06;, score=0.828 total time=   0.0s\n",
            "[CV 3/5; 629/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 629/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06;, score=0.884 total time=   0.0s\n",
            "[CV 4/5; 629/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 629/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06;, score=0.884 total time=   0.0s\n",
            "[CV 5/5; 629/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 629/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06;, score=0.840 total time=   0.0s\n",
            "[CV 1/5; 630/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 630/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05;, score=0.864 total time=   0.0s\n",
            "[CV 2/5; 630/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 630/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05;, score=0.860 total time=   0.0s\n",
            "[CV 3/5; 630/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 630/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05;, score=0.876 total time=   0.0s\n",
            "[CV 4/5; 630/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 630/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05;, score=0.820 total time=   0.0s\n",
            "[CV 5/5; 630/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 630/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05;, score=0.840 total time=   0.0s\n",
            "[CV 1/5; 631/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 631/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001;, score=0.856 total time=   0.0s\n",
            "[CV 2/5; 631/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 631/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001;, score=0.840 total time=   0.0s\n",
            "[CV 3/5; 631/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 631/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001;, score=0.880 total time=   0.0s\n",
            "[CV 4/5; 631/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 631/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 631/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 631/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001;, score=0.804 total time=   0.0s\n",
            "[CV 1/5; 632/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 632/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001;, score=0.760 total time=   0.0s\n",
            "[CV 2/5; 632/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 632/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001;, score=0.792 total time=   0.0s\n",
            "[CV 3/5; 632/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 632/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001;, score=0.724 total time=   0.0s\n",
            "[CV 4/5; 632/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 632/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001;, score=0.836 total time=   0.0s\n",
            "[CV 5/5; 632/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 632/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001;, score=0.764 total time=   0.0s\n",
            "[CV 1/5; 633/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 633/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.704 total time=   0.0s\n",
            "[CV 2/5; 633/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 633/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.772 total time=   0.0s\n",
            "[CV 3/5; 633/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 633/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.852 total time=   0.0s\n",
            "[CV 4/5; 633/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 633/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.728 total time=   0.0s\n",
            "[CV 5/5; 633/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 633/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.784 total time=   0.0s\n",
            "[CV 1/5; 634/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 634/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.736 total time=   0.0s\n",
            "[CV 2/5; 634/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 634/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.692 total time=   0.0s\n",
            "[CV 3/5; 634/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 634/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.740 total time=   0.0s\n",
            "[CV 4/5; 634/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 634/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.744 total time=   0.0s\n",
            "[CV 5/5; 634/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 634/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 635/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 635/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.732 total time=   0.0s\n",
            "[CV 2/5; 635/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 635/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.624 total time=   0.0s\n",
            "[CV 3/5; 635/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 635/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.688 total time=   0.0s\n",
            "[CV 4/5; 635/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 635/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.736 total time=   0.0s\n",
            "[CV 5/5; 635/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 635/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.712 total time=   0.0s\n",
            "[CV 1/5; 636/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 636/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.800 total time=   0.0s\n",
            "[CV 2/5; 636/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 636/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.720 total time=   0.0s\n",
            "[CV 3/5; 636/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 636/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.672 total time=   0.0s\n",
            "[CV 4/5; 636/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 636/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.720 total time=   0.0s\n",
            "[CV 5/5; 636/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 636/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.656 total time=   0.0s\n",
            "[CV 1/5; 637/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 637/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06;, score=0.936 total time=   0.1s\n",
            "[CV 2/5; 637/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 637/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06;, score=0.920 total time=   0.1s\n",
            "[CV 3/5; 637/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 637/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06;, score=0.932 total time=   0.1s\n",
            "[CV 4/5; 637/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 637/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06;, score=0.932 total time=   0.1s\n",
            "[CV 5/5; 637/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 637/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06;, score=0.936 total time=   0.1s\n",
            "[CV 1/5; 638/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 638/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05;, score=0.928 total time=   0.1s\n",
            "[CV 2/5; 638/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 638/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05;, score=0.920 total time=   0.1s\n",
            "[CV 3/5; 638/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 638/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05;, score=0.928 total time=   0.1s\n",
            "[CV 4/5; 638/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 638/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05;, score=0.940 total time=   0.1s\n",
            "[CV 5/5; 638/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 638/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05;, score=0.936 total time=   0.1s\n",
            "[CV 1/5; 639/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 639/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001;, score=0.932 total time=   0.0s\n",
            "[CV 2/5; 639/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 639/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001;, score=0.916 total time=   0.0s\n",
            "[CV 3/5; 639/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 639/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001;, score=0.924 total time=   0.0s\n",
            "[CV 4/5; 639/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 639/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001;, score=0.924 total time=   0.0s\n",
            "[CV 5/5; 639/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 639/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001;, score=0.932 total time=   0.0s\n",
            "[CV 1/5; 640/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 1/5; 640/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=0.001;, score=0.912 total time=   0.0s\n",
            "[CV 2/5; 640/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 2/5; 640/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=0.001;, score=0.880 total time=   0.0s\n",
            "[CV 3/5; 640/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 3/5; 640/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=0.001;, score=0.908 total time=   0.0s\n",
            "[CV 4/5; 640/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 4/5; 640/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=0.001;, score=0.916 total time=   0.0s\n",
            "[CV 5/5; 640/1344] START alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 5/5; 640/1344] END alpha=0.01, loss=log_loss, max_iter=1000, penalty=None, tol=0.001;, score=0.908 total time=   0.0s\n",
            "[CV 1/5; 641/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 641/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06;, score=0.664 total time=   0.0s\n",
            "[CV 2/5; 641/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 641/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06;, score=0.636 total time=   0.0s\n",
            "[CV 3/5; 641/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 641/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06;, score=0.628 total time=   0.0s\n",
            "[CV 4/5; 641/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 641/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06;, score=0.736 total time=   0.0s\n",
            "[CV 5/5; 641/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 641/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06;, score=0.632 total time=   0.0s\n",
            "[CV 1/5; 642/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 642/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05;, score=0.784 total time=   0.0s\n",
            "[CV 2/5; 642/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 642/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05;, score=0.732 total time=   0.0s\n",
            "[CV 3/5; 642/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 642/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05;, score=0.764 total time=   0.0s\n",
            "[CV 4/5; 642/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 642/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05;, score=0.632 total time=   0.0s\n",
            "[CV 5/5; 642/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 642/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05;, score=0.700 total time=   0.0s\n",
            "[CV 1/5; 643/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 643/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001;, score=0.700 total time=   0.0s\n",
            "[CV 2/5; 643/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 643/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001;, score=0.724 total time=   0.0s\n",
            "[CV 3/5; 643/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 643/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001;, score=0.704 total time=   0.0s\n",
            "[CV 4/5; 643/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 643/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001;, score=0.704 total time=   0.0s\n",
            "[CV 5/5; 643/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 643/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001;, score=0.836 total time=   0.0s\n",
            "[CV 1/5; 644/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 644/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001;, score=0.800 total time=   0.0s\n",
            "[CV 2/5; 644/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 644/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001;, score=0.664 total time=   0.0s\n",
            "[CV 3/5; 644/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 644/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001;, score=0.612 total time=   0.0s\n",
            "[CV 4/5; 644/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 644/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001;, score=0.668 total time=   0.0s\n",
            "[CV 5/5; 644/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 644/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001;, score=0.700 total time=   0.0s\n",
            "[CV 1/5; 645/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 645/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06;, score=0.860 total time=   0.0s\n",
            "[CV 2/5; 645/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 645/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06;, score=0.828 total time=   0.0s\n",
            "[CV 3/5; 645/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 645/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06;, score=0.868 total time=   0.0s\n",
            "[CV 4/5; 645/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 645/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06;, score=0.896 total time=   0.0s\n",
            "[CV 5/5; 645/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 645/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 1/5; 646/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 646/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05;, score=0.868 total time=   0.0s\n",
            "[CV 2/5; 646/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 646/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05;, score=0.796 total time=   0.0s\n",
            "[CV 3/5; 646/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 646/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 646/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 646/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 646/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 646/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05;, score=0.836 total time=   0.0s\n",
            "[CV 1/5; 647/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 647/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001;, score=0.844 total time=   0.0s\n",
            "[CV 2/5; 647/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 647/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001;, score=0.824 total time=   0.0s\n",
            "[CV 3/5; 647/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 647/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001;, score=0.872 total time=   0.0s\n",
            "[CV 4/5; 647/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 647/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001;, score=0.880 total time=   0.0s\n",
            "[CV 5/5; 647/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 647/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001;, score=0.860 total time=   0.0s\n",
            "[CV 1/5; 648/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 648/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001;, score=0.828 total time=   0.0s\n",
            "[CV 2/5; 648/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 648/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001;, score=0.828 total time=   0.0s\n",
            "[CV 3/5; 648/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 648/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001;, score=0.860 total time=   0.0s\n",
            "[CV 4/5; 648/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 648/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001;, score=0.884 total time=   0.0s\n",
            "[CV 5/5; 648/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 648/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001;, score=0.860 total time=   0.0s\n",
            "[CV 1/5; 649/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 649/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.804 total time=   0.0s\n",
            "[CV 2/5; 649/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 649/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.712 total time=   0.0s\n",
            "[CV 3/5; 649/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 649/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.756 total time=   0.0s\n",
            "[CV 4/5; 649/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 649/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.704 total time=   0.0s\n",
            "[CV 5/5; 649/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 649/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.740 total time=   0.0s\n",
            "[CV 1/5; 650/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 650/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.700 total time=   0.0s\n",
            "[CV 2/5; 650/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 650/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.748 total time=   0.0s\n",
            "[CV 3/5; 650/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 650/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.760 total time=   0.0s\n",
            "[CV 4/5; 650/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 650/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 5/5; 650/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 650/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.796 total time=   0.0s\n",
            "[CV 1/5; 651/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 651/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.736 total time=   0.0s\n",
            "[CV 2/5; 651/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 651/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.700 total time=   0.0s\n",
            "[CV 3/5; 651/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 651/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.728 total time=   0.0s\n",
            "[CV 4/5; 651/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 651/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.660 total time=   0.0s\n",
            "[CV 5/5; 651/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 651/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.800 total time=   0.0s\n",
            "[CV 1/5; 652/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 652/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.800 total time=   0.0s\n",
            "[CV 2/5; 652/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 652/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.668 total time=   0.0s\n",
            "[CV 3/5; 652/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 652/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.720 total time=   0.0s\n",
            "[CV 4/5; 652/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 652/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.728 total time=   0.0s\n",
            "[CV 5/5; 652/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 652/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.728 total time=   0.0s\n",
            "[CV 1/5; 653/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 653/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06;, score=0.936 total time=   0.5s\n",
            "[CV 2/5; 653/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 653/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06;, score=0.924 total time=   0.5s\n",
            "[CV 3/5; 653/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 653/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06;, score=0.936 total time=   0.5s\n",
            "[CV 4/5; 653/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 653/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06;, score=0.936 total time=   0.5s\n",
            "[CV 5/5; 653/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 653/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06;, score=0.932 total time=   0.5s\n",
            "[CV 1/5; 654/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 654/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05;, score=0.932 total time=   0.1s\n",
            "[CV 2/5; 654/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 654/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05;, score=0.916 total time=   0.1s\n",
            "[CV 3/5; 654/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 654/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05;, score=0.936 total time=   0.1s\n",
            "[CV 4/5; 654/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 654/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05;, score=0.936 total time=   0.1s\n",
            "[CV 5/5; 654/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 654/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05;, score=0.936 total time=   0.1s\n",
            "[CV 1/5; 655/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 655/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001;, score=0.924 total time=   0.0s\n",
            "[CV 2/5; 655/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 655/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001;, score=0.904 total time=   0.0s\n",
            "[CV 3/5; 655/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 655/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001;, score=0.916 total time=   0.0s\n",
            "[CV 4/5; 655/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 655/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001;, score=0.928 total time=   0.0s\n",
            "[CV 5/5; 655/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 655/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001;, score=0.936 total time=   0.0s\n",
            "[CV 1/5; 656/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 1/5; 656/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=0.001;, score=0.928 total time=   0.0s\n",
            "[CV 2/5; 656/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 2/5; 656/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=0.001;, score=0.892 total time=   0.0s\n",
            "[CV 3/5; 656/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 3/5; 656/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=0.001;, score=0.912 total time=   0.0s\n",
            "[CV 4/5; 656/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 4/5; 656/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=0.001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 656/1344] START alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 5/5; 656/1344] END alpha=0.01, loss=log_loss, max_iter=10000, penalty=None, tol=0.001;, score=0.916 total time=   0.0s\n",
            "[CV 1/5; 657/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 657/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06;, score=0.704 total time=   0.0s\n",
            "[CV 2/5; 657/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 657/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06;, score=0.724 total time=   0.0s\n",
            "[CV 3/5; 657/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 657/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06;, score=0.744 total time=   0.0s\n",
            "[CV 4/5; 657/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 657/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06;, score=0.780 total time=   0.0s\n",
            "[CV 5/5; 657/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 657/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06;, score=0.696 total time=   0.0s\n",
            "[CV 1/5; 658/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 658/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05;, score=0.756 total time=   0.0s\n",
            "[CV 2/5; 658/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 658/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05;, score=0.704 total time=   0.0s\n",
            "[CV 3/5; 658/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 658/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05;, score=0.708 total time=   0.0s\n",
            "[CV 4/5; 658/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 658/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05;, score=0.608 total time=   0.0s\n",
            "[CV 5/5; 658/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 658/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05;, score=0.696 total time=   0.0s\n",
            "[CV 1/5; 659/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 659/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001;, score=0.796 total time=   0.0s\n",
            "[CV 2/5; 659/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 659/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001;, score=0.688 total time=   0.0s\n",
            "[CV 3/5; 659/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 659/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001;, score=0.624 total time=   0.0s\n",
            "[CV 4/5; 659/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 659/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001;, score=0.640 total time=   0.0s\n",
            "[CV 5/5; 659/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 659/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001;, score=0.804 total time=   0.0s\n",
            "[CV 1/5; 660/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 660/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001;, score=0.784 total time=   0.0s\n",
            "[CV 2/5; 660/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 660/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001;, score=0.648 total time=   0.0s\n",
            "[CV 3/5; 660/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 660/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001;, score=0.708 total time=   0.0s\n",
            "[CV 4/5; 660/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 660/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001;, score=0.616 total time=   0.0s\n",
            "[CV 5/5; 660/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 660/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001;, score=0.700 total time=   0.0s\n",
            "[CV 1/5; 661/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 661/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06;, score=0.892 total time=   0.0s\n",
            "[CV 2/5; 661/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 661/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06;, score=0.840 total time=   0.0s\n",
            "[CV 3/5; 661/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 661/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06;, score=0.868 total time=   0.0s\n",
            "[CV 4/5; 661/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 661/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06;, score=0.896 total time=   0.0s\n",
            "[CV 5/5; 661/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 661/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06;, score=0.840 total time=   0.0s\n",
            "[CV 1/5; 662/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 662/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05;, score=0.868 total time=   0.0s\n",
            "[CV 2/5; 662/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 662/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05;, score=0.780 total time=   0.0s\n",
            "[CV 3/5; 662/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 662/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05;, score=0.876 total time=   0.0s\n",
            "[CV 4/5; 662/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 662/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 662/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 662/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 1/5; 663/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 663/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001;, score=0.872 total time=   0.0s\n",
            "[CV 2/5; 663/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 663/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001;, score=0.836 total time=   0.0s\n",
            "[CV 3/5; 663/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 663/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001;, score=0.868 total time=   0.0s\n",
            "[CV 4/5; 663/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 663/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001;, score=0.936 total time=   0.0s\n",
            "[CV 5/5; 663/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 663/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 664/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 664/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001;, score=0.808 total time=   0.0s\n",
            "[CV 2/5; 664/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 664/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001;, score=0.832 total time=   0.0s\n",
            "[CV 3/5; 664/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 664/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001;, score=0.876 total time=   0.0s\n",
            "[CV 4/5; 664/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 664/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001;, score=0.836 total time=   0.0s\n",
            "[CV 5/5; 664/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 664/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001;, score=0.804 total time=   0.0s\n",
            "[CV 1/5; 665/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 665/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.804 total time=   0.0s\n",
            "[CV 2/5; 665/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 665/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.688 total time=   0.0s\n",
            "[CV 3/5; 665/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 665/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.748 total time=   0.0s\n",
            "[CV 4/5; 665/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 665/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.656 total time=   0.0s\n",
            "[CV 5/5; 665/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 665/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.676 total time=   0.0s\n",
            "[CV 1/5; 666/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 666/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.752 total time=   0.0s\n",
            "[CV 2/5; 666/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 666/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.744 total time=   0.0s\n",
            "[CV 3/5; 666/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 666/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.644 total time=   0.0s\n",
            "[CV 4/5; 666/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 666/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.680 total time=   0.0s\n",
            "[CV 5/5; 666/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 666/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.824 total time=   0.0s\n",
            "[CV 1/5; 667/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 667/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.776 total time=   0.0s\n",
            "[CV 2/5; 667/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 667/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.704 total time=   0.0s\n",
            "[CV 3/5; 667/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 667/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.772 total time=   0.0s\n",
            "[CV 4/5; 667/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 667/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.732 total time=   0.0s\n",
            "[CV 5/5; 667/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 667/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.680 total time=   0.0s\n",
            "[CV 1/5; 668/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 668/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.840 total time=   0.0s\n",
            "[CV 2/5; 668/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 668/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.684 total time=   0.0s\n",
            "[CV 3/5; 668/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 668/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.740 total time=   0.0s\n",
            "[CV 4/5; 668/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 668/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.620 total time=   0.0s\n",
            "[CV 5/5; 668/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 668/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.800 total time=   0.0s\n",
            "[CV 1/5; 669/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 669/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06;, score=0.932 total time=   0.5s\n",
            "[CV 2/5; 669/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 669/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06;, score=0.924 total time=   0.5s\n",
            "[CV 3/5; 669/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 669/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06;, score=0.932 total time=   0.4s\n",
            "[CV 4/5; 669/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 669/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06;, score=0.940 total time=   0.5s\n",
            "[CV 5/5; 669/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 669/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06;, score=0.952 total time=   0.7s\n",
            "[CV 1/5; 670/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 670/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05;, score=0.916 total time=   0.0s\n",
            "[CV 2/5; 670/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 670/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05;, score=0.920 total time=   0.1s\n",
            "[CV 3/5; 670/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 670/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05;, score=0.932 total time=   0.1s\n",
            "[CV 4/5; 670/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 670/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05;, score=0.936 total time=   0.1s\n",
            "[CV 5/5; 670/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 670/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05;, score=0.940 total time=   0.1s\n",
            "[CV 1/5; 671/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 671/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001;, score=0.928 total time=   0.0s\n",
            "[CV 2/5; 671/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 671/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001;, score=0.916 total time=   0.0s\n",
            "[CV 3/5; 671/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 671/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001;, score=0.924 total time=   0.0s\n",
            "[CV 4/5; 671/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 671/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001;, score=0.924 total time=   0.0s\n",
            "[CV 5/5; 671/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 671/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001;, score=0.936 total time=   0.0s\n",
            "[CV 1/5; 672/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 1/5; 672/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=0.001;, score=0.928 total time=   0.0s\n",
            "[CV 2/5; 672/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 2/5; 672/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=0.001;, score=0.884 total time=   0.0s\n",
            "[CV 3/5; 672/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 3/5; 672/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=0.001;, score=0.924 total time=   0.0s\n",
            "[CV 4/5; 672/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 4/5; 672/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=0.001;, score=0.908 total time=   0.0s\n",
            "[CV 5/5; 672/1344] START alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 5/5; 672/1344] END alpha=0.01, loss=log_loss, max_iter=100000, penalty=None, tol=0.001;, score=0.856 total time=   0.0s\n",
            "[CV 1/5; 673/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 673/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.936 total time=   0.1s\n",
            "[CV 2/5; 673/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 673/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.968 total time=   0.1s\n",
            "[CV 3/5; 673/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 673/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.948 total time=   0.1s\n",
            "[CV 4/5; 673/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 673/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.948 total time=   0.1s\n",
            "[CV 5/5; 673/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 673/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.948 total time=   0.1s\n",
            "[CV 1/5; 674/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 674/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.964 total time=   0.1s\n",
            "[CV 2/5; 674/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 674/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.952 total time=   0.1s\n",
            "[CV 3/5; 674/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 674/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.952 total time=   0.1s\n",
            "[CV 4/5; 674/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 674/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.952 total time=   0.1s\n",
            "[CV 5/5; 674/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 674/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.948 total time=   0.1s\n",
            "[CV 1/5; 675/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 675/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.948 total time=   0.1s\n",
            "[CV 2/5; 675/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 675/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.960 total time=   0.1s\n",
            "[CV 3/5; 675/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 675/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.960 total time=   0.0s\n",
            "[CV 4/5; 675/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 675/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 5/5; 675/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 675/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 676/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 676/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.944 total time=   0.0s\n",
            "[CV 2/5; 676/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 676/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 3/5; 676/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 676/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 676/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 676/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.940 total time=   0.0s\n",
            "[CV 5/5; 676/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 676/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 677/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 677/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 2/5; 677/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 677/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.952 total time=   0.0s\n",
            "[CV 3/5; 677/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 677/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.952 total time=   0.0s\n",
            "[CV 4/5; 677/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 677/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.924 total time=   0.0s\n",
            "[CV 5/5; 677/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 677/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.956 total time=   0.0s\n",
            "[CV 1/5; 678/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 678/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 2/5; 678/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 678/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 3/5; 678/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 678/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 678/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 678/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.952 total time=   0.0s\n",
            "[CV 5/5; 678/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 678/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 679/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 679/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 679/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 679/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 679/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 679/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.916 total time=   0.0s\n",
            "[CV 4/5; 679/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 679/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 5/5; 679/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 679/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 680/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 680/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.940 total time=   0.0s\n",
            "[CV 2/5; 680/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 680/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.952 total time=   0.0s\n",
            "[CV 3/5; 680/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 680/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.944 total time=   0.1s\n",
            "[CV 4/5; 680/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 680/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 680/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 680/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.940 total time=   0.0s\n",
            "[CV 1/5; 681/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 681/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.948 total time=   0.1s\n",
            "[CV 2/5; 681/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 681/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.964 total time=   0.1s\n",
            "[CV 3/5; 681/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 681/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.956 total time=   0.1s\n",
            "[CV 4/5; 681/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 681/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.948 total time=   0.1s\n",
            "[CV 5/5; 681/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 681/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.952 total time=   0.1s\n",
            "[CV 1/5; 682/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 682/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.948 total time=   0.1s\n",
            "[CV 2/5; 682/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 682/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.968 total time=   0.1s\n",
            "[CV 3/5; 682/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 682/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.948 total time=   0.1s\n",
            "[CV 4/5; 682/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 682/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.948 total time=   0.1s\n",
            "[CV 5/5; 682/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 682/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.952 total time=   0.1s\n",
            "[CV 1/5; 683/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 683/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.960 total time=   0.1s\n",
            "[CV 2/5; 683/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 683/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.968 total time=   0.1s\n",
            "[CV 3/5; 683/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 683/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.960 total time=   0.1s\n",
            "[CV 4/5; 683/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 683/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.940 total time=   0.1s\n",
            "[CV 5/5; 683/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 683/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.948 total time=   0.1s\n",
            "[CV 1/5; 684/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 684/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.956 total time=   0.1s\n",
            "[CV 2/5; 684/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 684/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.968 total time=   0.1s\n",
            "[CV 3/5; 684/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 684/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.960 total time=   0.1s\n",
            "[CV 4/5; 684/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 684/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.940 total time=   0.1s\n",
            "[CV 5/5; 684/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 684/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.944 total time=   0.1s\n",
            "[CV 1/5; 685/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 685/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.956 total time=   0.0s\n",
            "[CV 2/5; 685/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 685/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 3/5; 685/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 685/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 4/5; 685/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 685/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.936 total time=   0.0s\n",
            "[CV 5/5; 685/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 685/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 686/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 686/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 2/5; 686/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 686/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 686/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 686/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 686/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 686/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 686/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 686/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.952 total time=   0.0s\n",
            "[CV 1/5; 687/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 687/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 2/5; 687/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 687/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 3/5; 687/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 687/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 687/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 687/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 5/5; 687/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 687/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 688/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 1/5; 688/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.928 total time=   0.0s\n",
            "[CV 2/5; 688/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 688/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 688/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 3/5; 688/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 688/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 4/5; 688/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 688/1344] START alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 5/5; 688/1344] END alpha=0.01, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 689/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 689/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.952 total time=   0.3s\n",
            "[CV 2/5; 689/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 689/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.952 total time=   0.3s\n",
            "[CV 3/5; 689/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 689/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.944 total time=   0.3s\n",
            "[CV 4/5; 689/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 689/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.952 total time=   0.3s\n",
            "[CV 5/5; 689/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 689/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.948 total time=   0.3s\n",
            "[CV 1/5; 690/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 690/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.924 total time=   0.3s\n",
            "[CV 2/5; 690/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 690/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.968 total time=   0.3s\n",
            "[CV 3/5; 690/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 690/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.952 total time=   0.3s\n",
            "[CV 4/5; 690/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 690/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.948 total time=   0.3s\n",
            "[CV 5/5; 690/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 690/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.948 total time=   0.3s\n",
            "[CV 1/5; 691/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 691/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.940 total time=   0.3s\n",
            "[CV 2/5; 691/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 691/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.964 total time=   0.3s\n",
            "[CV 3/5; 691/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 691/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.948 total time=   0.3s\n",
            "[CV 4/5; 691/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 691/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.948 total time=   0.3s\n",
            "[CV 5/5; 691/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 691/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.940 total time=   0.3s\n",
            "[CV 1/5; 692/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 692/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.928 total time=   0.3s\n",
            "[CV 2/5; 692/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 692/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.968 total time=   0.3s\n",
            "[CV 3/5; 692/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 692/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.948 total time=   0.3s\n",
            "[CV 4/5; 692/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 692/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.952 total time=   0.3s\n",
            "[CV 5/5; 692/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 692/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.948 total time=   0.3s\n",
            "[CV 1/5; 693/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 693/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 2/5; 693/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 693/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 3/5; 693/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 693/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.960 total time=   0.0s\n",
            "[CV 4/5; 693/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 693/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 5/5; 693/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 693/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 1/5; 694/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 694/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.952 total time=   0.0s\n",
            "[CV 2/5; 694/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 694/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.952 total time=   0.0s\n",
            "[CV 3/5; 694/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 694/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.968 total time=   0.0s\n",
            "[CV 4/5; 694/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 694/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.912 total time=   0.0s\n",
            "[CV 5/5; 694/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 694/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.936 total time=   0.0s\n",
            "[CV 1/5; 695/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 695/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 2/5; 695/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 695/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 695/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 695/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.952 total time=   0.0s\n",
            "[CV 4/5; 695/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 695/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 695/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 695/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 1/5; 696/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 696/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.936 total time=   0.0s\n",
            "[CV 2/5; 696/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 696/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 3/5; 696/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 696/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 696/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 696/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.940 total time=   0.0s\n",
            "[CV 5/5; 696/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 696/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 697/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 697/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.956 total time=   0.5s\n",
            "[CV 2/5; 697/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 697/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.968 total time=   0.5s\n",
            "[CV 3/5; 697/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 697/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.948 total time=   0.5s\n",
            "[CV 4/5; 697/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 697/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.936 total time=   0.6s\n",
            "[CV 5/5; 697/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 697/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.948 total time=   0.9s\n",
            "[CV 1/5; 698/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 698/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.940 total time=   0.9s\n",
            "[CV 2/5; 698/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 698/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.968 total time=   0.6s\n",
            "[CV 3/5; 698/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 698/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.948 total time=   0.5s\n",
            "[CV 4/5; 698/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 698/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.944 total time=   0.5s\n",
            "[CV 5/5; 698/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 698/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.952 total time=   0.5s\n",
            "[CV 1/5; 699/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 699/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.940 total time=   0.5s\n",
            "[CV 2/5; 699/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 699/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.972 total time=   0.5s\n",
            "[CV 3/5; 699/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 699/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.960 total time=   0.5s\n",
            "[CV 4/5; 699/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 699/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.948 total time=   0.5s\n",
            "[CV 5/5; 699/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 699/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.952 total time=   0.5s\n",
            "[CV 1/5; 700/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 700/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.952 total time=   0.5s\n",
            "[CV 2/5; 700/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 700/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.972 total time=   0.5s\n",
            "[CV 3/5; 700/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 700/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.952 total time=   0.5s\n",
            "[CV 4/5; 700/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 700/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.952 total time=   0.5s\n",
            "[CV 5/5; 700/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 700/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.952 total time=   0.5s\n",
            "[CV 1/5; 701/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 701/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.952 total time=   0.0s\n",
            "[CV 2/5; 701/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 701/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 3/5; 701/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 701/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.952 total time=   0.0s\n",
            "[CV 4/5; 701/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 701/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.940 total time=   0.0s\n",
            "[CV 5/5; 701/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 701/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.956 total time=   0.3s\n",
            "[CV 1/5; 702/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 702/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 2/5; 702/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 702/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.952 total time=   0.0s\n",
            "[CV 3/5; 702/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 702/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 4/5; 702/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 702/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.944 total time=   0.0s\n",
            "[CV 5/5; 702/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 702/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.952 total time=   0.0s\n",
            "[CV 1/5; 703/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 703/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 2/5; 703/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 703/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.932 total time=   0.0s\n",
            "[CV 3/5; 703/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 703/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.936 total time=   0.0s\n",
            "[CV 4/5; 703/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 703/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.956 total time=   0.0s\n",
            "[CV 5/5; 703/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 703/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.932 total time=   0.0s\n",
            "[CV 1/5; 704/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 1/5; 704/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 2/5; 704/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 2/5; 704/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 704/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 3/5; 704/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.940 total time=   0.0s\n",
            "[CV 4/5; 704/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 4/5; 704/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.932 total time=   0.0s\n",
            "[CV 5/5; 704/1344] START alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 5/5; 704/1344] END alpha=0.01, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.944 total time=   0.0s\n",
            "[CV 1/5; 705/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 705/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.928 total time=   3.3s\n",
            "[CV 2/5; 705/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 705/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.968 total time=   3.3s\n",
            "[CV 3/5; 705/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 705/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.956 total time=   2.9s\n",
            "[CV 4/5; 705/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 705/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.948 total time=   2.9s\n",
            "[CV 5/5; 705/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 705/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.948 total time=   3.5s\n",
            "[CV 1/5; 706/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 706/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.948 total time=   3.0s\n",
            "[CV 2/5; 706/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 706/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.968 total time=   2.9s\n",
            "[CV 3/5; 706/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 706/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.960 total time=   2.8s\n",
            "[CV 4/5; 706/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 706/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.948 total time=   3.7s\n",
            "[CV 5/5; 706/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 706/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.944 total time=   2.9s\n",
            "[CV 1/5; 707/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 707/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.952 total time=   2.9s\n",
            "[CV 2/5; 707/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 707/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.948 total time=   2.9s\n",
            "[CV 3/5; 707/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 707/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.944 total time=   3.6s\n",
            "[CV 4/5; 707/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 707/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.940 total time=   2.9s\n",
            "[CV 5/5; 707/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 707/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.948 total time=   3.1s\n",
            "[CV 1/5; 708/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 708/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.960 total time=   2.9s\n",
            "[CV 2/5; 708/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 708/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.968 total time=   3.7s\n",
            "[CV 3/5; 708/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 708/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.956 total time=   2.8s\n",
            "[CV 4/5; 708/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 708/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.940 total time=   2.9s\n",
            "[CV 5/5; 708/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 708/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.948 total time=   2.8s\n",
            "[CV 1/5; 709/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 709/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.940 total time=   0.0s\n",
            "[CV 2/5; 709/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 709/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 709/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 709/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.952 total time=   0.0s\n",
            "[CV 4/5; 709/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 709/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 709/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 709/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 710/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 710/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 2/5; 710/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 710/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 3/5; 710/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 710/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 710/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 710/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.952 total time=   0.0s\n",
            "[CV 5/5; 710/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 710/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.956 total time=   0.0s\n",
            "[CV 1/5; 711/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 711/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.960 total time=   0.0s\n",
            "[CV 2/5; 711/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 711/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 3/5; 711/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 711/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.952 total time=   0.0s\n",
            "[CV 4/5; 711/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 711/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.952 total time=   0.0s\n",
            "[CV 5/5; 711/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 711/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 712/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 712/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 2/5; 712/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 712/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.952 total time=   5.5s\n",
            "[CV 3/5; 712/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 712/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.952 total time=   0.0s\n",
            "[CV 4/5; 712/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 712/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.952 total time=   4.8s\n",
            "[CV 5/5; 712/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 712/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.952 total time=   0.0s\n",
            "[CV 1/5; 713/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 713/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.952 total time=   5.7s\n",
            "[CV 2/5; 713/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 713/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.968 total time=   5.0s\n",
            "[CV 3/5; 713/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 713/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.956 total time=   5.7s\n",
            "[CV 4/5; 713/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 713/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.952 total time=   5.0s\n",
            "[CV 5/5; 713/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 713/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.944 total time=   5.7s\n",
            "[CV 1/5; 714/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 714/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.924 total time=   5.8s\n",
            "[CV 2/5; 714/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 714/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.968 total time=   5.4s\n",
            "[CV 3/5; 714/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 714/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.960 total time=   5.3s\n",
            "[CV 4/5; 714/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 714/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.940 total time=   5.0s\n",
            "[CV 5/5; 714/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 714/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.948 total time=   5.8s\n",
            "[CV 1/5; 715/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 715/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.952 total time=   5.6s\n",
            "[CV 2/5; 715/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 715/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.964 total time=   5.8s\n",
            "[CV 3/5; 715/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 715/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.956 total time=   5.1s\n",
            "[CV 4/5; 715/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 715/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.944 total time=   5.9s\n",
            "[CV 5/5; 715/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 715/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.952 total time=   5.0s\n",
            "[CV 1/5; 716/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 716/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.956 total time=   5.7s\n",
            "[CV 2/5; 716/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 716/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.968 total time=   5.0s\n",
            "[CV 3/5; 716/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 716/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.940 total time=   5.5s\n",
            "[CV 4/5; 716/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 716/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.948 total time=   5.2s\n",
            "[CV 5/5; 716/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 716/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.944 total time=   4.9s\n",
            "[CV 1/5; 717/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 717/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 2/5; 717/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 717/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.952 total time=   0.0s\n",
            "[CV 3/5; 717/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 717/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 717/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 717/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 717/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 717/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.952 total time=   0.0s\n",
            "[CV 1/5; 718/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 718/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 2/5; 718/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 718/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 3/5; 718/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 718/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 718/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 718/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 5/5; 718/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 718/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.944 total time=   3.4s\n",
            "[CV 1/5; 719/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 719/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.932 total time=   0.0s\n",
            "[CV 2/5; 719/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 719/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 3/5; 719/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 719/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.896 total time=   0.0s\n",
            "[CV 4/5; 719/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 719/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 719/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 719/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 720/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 1/5; 720/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 2/5; 720/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 2/5; 720/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 3/5; 720/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 3/5; 720/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 720/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 4/5; 720/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.952 total time=   0.0s\n",
            "[CV 5/5; 720/1344] START alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 5/5; 720/1344] END alpha=0.01, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.952 total time=   0.0s\n",
            "[CV 1/5; 721/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 721/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.876 total time=   0.0s\n",
            "[CV 2/5; 721/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 721/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.780 total time=   0.0s\n",
            "[CV 3/5; 721/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 721/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.904 total time=   0.0s\n",
            "[CV 4/5; 721/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 721/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.860 total time=   0.0s\n",
            "[CV 5/5; 721/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 721/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.776 total time=   0.0s\n",
            "[CV 1/5; 722/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 722/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 722/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 722/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.804 total time=   0.0s\n",
            "[CV 3/5; 722/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 722/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.724 total time=   0.0s\n",
            "[CV 4/5; 722/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 722/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.868 total time=   0.0s\n",
            "[CV 5/5; 722/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 722/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 723/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 723/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.880 total time=   0.0s\n",
            "[CV 2/5; 723/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 723/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.920 total time=   0.0s\n",
            "[CV 3/5; 723/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 723/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.780 total time=   0.0s\n",
            "[CV 4/5; 723/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 723/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.772 total time=   0.0s\n",
            "[CV 5/5; 723/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 723/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 1/5; 724/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 724/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.748 total time=   0.0s\n",
            "[CV 2/5; 724/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 724/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.852 total time=   0.0s\n",
            "[CV 3/5; 724/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 724/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.940 total time=   0.0s\n",
            "[CV 4/5; 724/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 724/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.872 total time=   0.0s\n",
            "[CV 5/5; 724/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 724/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.884 total time=   0.0s\n",
            "[CV 1/5; 725/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 725/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.620 total time=   0.0s\n",
            "[CV 2/5; 725/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 725/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.712 total time=   0.0s\n",
            "[CV 3/5; 725/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 725/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.720 total time=   0.0s\n",
            "[CV 4/5; 725/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 725/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.584 total time=   0.0s\n",
            "[CV 5/5; 725/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 725/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.560 total time=   0.0s\n",
            "[CV 1/5; 726/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 726/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.732 total time=   0.0s\n",
            "[CV 2/5; 726/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 726/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 726/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 726/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.644 total time=   0.0s\n",
            "[CV 4/5; 726/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 726/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.528 total time=   0.0s\n",
            "[CV 5/5; 726/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 726/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.612 total time=   0.0s\n",
            "[CV 1/5; 727/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 727/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.544 total time=   0.0s\n",
            "[CV 2/5; 727/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 727/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.588 total time=   0.0s\n",
            "[CV 3/5; 727/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 727/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.688 total time=   0.0s\n",
            "[CV 4/5; 727/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 727/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.632 total time=   0.0s\n",
            "[CV 5/5; 727/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 727/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.572 total time=   0.0s\n",
            "[CV 1/5; 728/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 728/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.552 total time=   0.0s\n",
            "[CV 2/5; 728/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 728/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.584 total time=   0.0s\n",
            "[CV 3/5; 728/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 728/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.568 total time=   0.0s\n",
            "[CV 4/5; 728/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 728/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.716 total time=   0.0s\n",
            "[CV 5/5; 728/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 728/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.608 total time=   0.0s\n",
            "[CV 1/5; 729/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 729/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.772 total time=   0.0s\n",
            "[CV 2/5; 729/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 729/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.684 total time=   0.0s\n",
            "[CV 3/5; 729/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 729/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.852 total time=   0.0s\n",
            "[CV 4/5; 729/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 729/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.884 total time=   0.0s\n",
            "[CV 5/5; 729/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 729/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.748 total time=   0.0s\n",
            "[CV 1/5; 730/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 730/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.740 total time=   0.0s\n",
            "[CV 2/5; 730/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 730/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.740 total time=   0.0s\n",
            "[CV 3/5; 730/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 730/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.756 total time=   0.0s\n",
            "[CV 4/5; 730/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 730/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.832 total time=   0.0s\n",
            "[CV 5/5; 730/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 730/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.732 total time=   0.0s\n",
            "[CV 1/5; 731/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 731/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.748 total time=   0.0s\n",
            "[CV 2/5; 731/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 731/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 731/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 731/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.716 total time=   0.0s\n",
            "[CV 4/5; 731/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 731/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.824 total time=   0.0s\n",
            "[CV 5/5; 731/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 731/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.716 total time=   0.0s\n",
            "[CV 1/5; 732/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 732/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.636 total time=   0.0s\n",
            "[CV 2/5; 732/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 732/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.772 total time=   0.0s\n",
            "[CV 3/5; 732/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 732/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.856 total time=   0.0s\n",
            "[CV 4/5; 732/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 732/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.652 total time=   0.0s\n",
            "[CV 5/5; 732/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 732/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 733/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 733/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 2/5; 733/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 733/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 733/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 733/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.952 total time=   0.0s\n",
            "[CV 4/5; 733/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 733/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.996 total time=   0.0s\n",
            "[CV 5/5; 733/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 733/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 734/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 734/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 2/5; 734/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 734/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 734/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 734/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 4/5; 734/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 734/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 5/5; 734/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 734/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.968 total time=   0.0s\n",
            "[CV 1/5; 735/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 735/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.952 total time=   0.0s\n",
            "[CV 2/5; 735/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 735/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 3/5; 735/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 735/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 735/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 735/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 735/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 735/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.956 total time=   0.0s\n",
            "[CV 1/5; 736/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 1/5; 736/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 2/5; 736/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 2/5; 736/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 736/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 3/5; 736/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.924 total time=   0.0s\n",
            "[CV 4/5; 736/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 4/5; 736/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.944 total time=   0.0s\n",
            "[CV 5/5; 736/1344] START alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 5/5; 736/1344] END alpha=0.01, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 737/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 737/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.896 total time=   0.0s\n",
            "[CV 2/5; 737/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 737/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.924 total time=   0.0s\n",
            "[CV 3/5; 737/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 737/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.892 total time=   0.0s\n",
            "[CV 4/5; 737/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 737/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.820 total time=   0.0s\n",
            "[CV 5/5; 737/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 737/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.852 total time=   0.0s\n",
            "[CV 1/5; 738/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 738/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.724 total time=   0.0s\n",
            "[CV 2/5; 738/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 738/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.908 total time=   0.0s\n",
            "[CV 3/5; 738/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 738/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.696 total time=   0.0s\n",
            "[CV 4/5; 738/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 738/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.920 total time=   0.0s\n",
            "[CV 5/5; 738/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 738/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.824 total time=   0.0s\n",
            "[CV 1/5; 739/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 739/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.892 total time=   0.0s\n",
            "[CV 2/5; 739/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 739/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.832 total time=   0.0s\n",
            "[CV 3/5; 739/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 739/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.800 total time=   0.0s\n",
            "[CV 4/5; 739/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 739/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.728 total time=   0.0s\n",
            "[CV 5/5; 739/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 739/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.884 total time=   0.0s\n",
            "[CV 1/5; 740/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 740/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.720 total time=   0.0s\n",
            "[CV 2/5; 740/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 740/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.824 total time=   0.0s\n",
            "[CV 3/5; 740/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 740/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.796 total time=   0.0s\n",
            "[CV 4/5; 740/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 740/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.644 total time=   0.0s\n",
            "[CV 5/5; 740/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 740/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.756 total time=   0.0s\n",
            "[CV 1/5; 741/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 741/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.644 total time=   0.0s\n",
            "[CV 2/5; 741/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 741/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.876 total time=   0.0s\n",
            "[CV 3/5; 741/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 741/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 4/5; 741/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 741/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.680 total time=   0.0s\n",
            "[CV 5/5; 741/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 741/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 742/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 742/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.572 total time=   0.0s\n",
            "[CV 2/5; 742/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 742/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.660 total time=   0.0s\n",
            "[CV 3/5; 742/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 742/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.492 total time=   0.0s\n",
            "[CV 4/5; 742/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 742/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.908 total time=   0.0s\n",
            "[CV 5/5; 742/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 742/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.700 total time=   0.0s\n",
            "[CV 1/5; 743/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 743/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.548 total time=   0.0s\n",
            "[CV 2/5; 743/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 743/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.516 total time=   0.0s\n",
            "[CV 3/5; 743/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 743/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.608 total time=   0.0s\n",
            "[CV 4/5; 743/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 743/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.736 total time=   0.0s\n",
            "[CV 5/5; 743/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 743/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.584 total time=   0.0s\n",
            "[CV 1/5; 744/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 744/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.548 total time=   0.0s\n",
            "[CV 2/5; 744/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 744/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.692 total time=   0.0s\n",
            "[CV 3/5; 744/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 744/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.500 total time=   0.0s\n",
            "[CV 4/5; 744/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 744/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.604 total time=   0.0s\n",
            "[CV 5/5; 744/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 744/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.884 total time=   0.0s\n",
            "[CV 1/5; 745/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 745/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.764 total time=   0.0s\n",
            "[CV 2/5; 745/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 745/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.740 total time=   0.0s\n",
            "[CV 3/5; 745/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 745/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.912 total time=   0.0s\n",
            "[CV 4/5; 745/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 745/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.912 total time=   0.0s\n",
            "[CV 5/5; 745/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 745/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.712 total time=   0.0s\n",
            "[CV 1/5; 746/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 746/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.752 total time=   0.0s\n",
            "[CV 2/5; 746/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 746/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.832 total time=   0.0s\n",
            "[CV 3/5; 746/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 746/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.844 total time=   0.0s\n",
            "[CV 4/5; 746/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 746/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.868 total time=   0.0s\n",
            "[CV 5/5; 746/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 746/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 1/5; 747/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 747/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.784 total time=   0.0s\n",
            "[CV 2/5; 747/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 747/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 3/5; 747/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 747/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.856 total time=   0.0s\n",
            "[CV 4/5; 747/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 747/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.640 total time=   0.0s\n",
            "[CV 5/5; 747/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 747/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.840 total time=   0.0s\n",
            "[CV 1/5; 748/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 748/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.656 total time=   0.0s\n",
            "[CV 2/5; 748/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 748/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.872 total time=   0.0s\n",
            "[CV 3/5; 748/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 748/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.936 total time=   0.0s\n",
            "[CV 4/5; 748/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 748/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.928 total time=   0.0s\n",
            "[CV 5/5; 748/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 748/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.788 total time=   0.0s\n",
            "[CV 1/5; 749/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 749/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.956 total time=   0.0s\n",
            "[CV 2/5; 749/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 749/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.956 total time=   0.0s\n",
            "[CV 3/5; 749/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 749/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 749/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 749/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.960 total time=   0.0s\n",
            "[CV 5/5; 749/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 749/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 1/5; 750/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 750/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 2/5; 750/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 750/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 750/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 750/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 750/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 750/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.936 total time=   0.0s\n",
            "[CV 5/5; 750/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 750/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 751/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 751/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.928 total time=   0.0s\n",
            "[CV 2/5; 751/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 751/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 751/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 751/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.960 total time=   0.0s\n",
            "[CV 4/5; 751/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 751/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 5/5; 751/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 751/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 752/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 1/5; 752/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.952 total time=   0.0s\n",
            "[CV 2/5; 752/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 2/5; 752/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 752/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 3/5; 752/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.916 total time=   0.0s\n",
            "[CV 4/5; 752/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 4/5; 752/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.956 total time=   0.0s\n",
            "[CV 5/5; 752/1344] START alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 5/5; 752/1344] END alpha=0.01, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.884 total time=   0.0s\n",
            "[CV 1/5; 753/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 753/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.812 total time=   0.0s\n",
            "[CV 2/5; 753/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 753/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.876 total time=   0.0s\n",
            "[CV 3/5; 753/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 753/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.792 total time=   0.0s\n",
            "[CV 4/5; 753/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 753/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 753/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 753/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 754/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 754/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.916 total time=   0.0s\n",
            "[CV 2/5; 754/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 754/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.728 total time=   0.0s\n",
            "[CV 3/5; 754/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 754/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.764 total time=   0.0s\n",
            "[CV 4/5; 754/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 754/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.748 total time=   0.0s\n",
            "[CV 5/5; 754/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 754/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.824 total time=   0.0s\n",
            "[CV 1/5; 755/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 755/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.756 total time=   0.0s\n",
            "[CV 2/5; 755/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 755/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.856 total time=   0.0s\n",
            "[CV 3/5; 755/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 755/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 755/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 755/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.956 total time=   0.0s\n",
            "[CV 5/5; 755/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 755/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 756/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 756/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.748 total time=   0.0s\n",
            "[CV 2/5; 756/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 756/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.832 total time=   0.0s\n",
            "[CV 3/5; 756/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 756/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.752 total time=   0.0s\n",
            "[CV 4/5; 756/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 756/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.676 total time=   0.0s\n",
            "[CV 5/5; 756/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 756/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.664 total time=   0.0s\n",
            "[CV 1/5; 757/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 757/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.556 total time=   0.0s\n",
            "[CV 2/5; 757/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 757/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.512 total time=   0.0s\n",
            "[CV 3/5; 757/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 757/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.584 total time=   0.0s\n",
            "[CV 4/5; 757/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 757/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.568 total time=   0.0s\n",
            "[CV 5/5; 757/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 757/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.588 total time=   0.0s\n",
            "[CV 1/5; 758/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 758/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.556 total time=   0.0s\n",
            "[CV 2/5; 758/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 758/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.596 total time=   0.0s\n",
            "[CV 3/5; 758/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 758/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.772 total time=   0.0s\n",
            "[CV 4/5; 758/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 758/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.604 total time=   0.0s\n",
            "[CV 5/5; 758/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 758/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.544 total time=   0.0s\n",
            "[CV 1/5; 759/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 759/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.596 total time=   0.0s\n",
            "[CV 2/5; 759/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 759/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.716 total time=   0.0s\n",
            "[CV 3/5; 759/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 759/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.532 total time=   0.0s\n",
            "[CV 4/5; 759/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 759/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.636 total time=   0.0s\n",
            "[CV 5/5; 759/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 759/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.748 total time=   0.0s\n",
            "[CV 1/5; 760/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 760/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.548 total time=   0.0s\n",
            "[CV 2/5; 760/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 760/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.644 total time=   0.0s\n",
            "[CV 3/5; 760/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 760/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.528 total time=   0.0s\n",
            "[CV 4/5; 760/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 760/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.648 total time=   0.0s\n",
            "[CV 5/5; 760/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 760/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.676 total time=   0.0s\n",
            "[CV 1/5; 761/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 761/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.860 total time=   0.0s\n",
            "[CV 2/5; 761/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 761/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.924 total time=   0.0s\n",
            "[CV 3/5; 761/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 761/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.808 total time=   0.0s\n",
            "[CV 4/5; 761/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 761/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.960 total time=   0.0s\n",
            "[CV 5/5; 761/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 761/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.784 total time=   0.0s\n",
            "[CV 1/5; 762/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 762/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.704 total time=   0.0s\n",
            "[CV 2/5; 762/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 762/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.756 total time=   0.0s\n",
            "[CV 3/5; 762/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 762/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.736 total time=   0.0s\n",
            "[CV 4/5; 762/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 762/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.832 total time=   0.0s\n",
            "[CV 5/5; 762/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 762/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.720 total time=   0.0s\n",
            "[CV 1/5; 763/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 763/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.836 total time=   0.0s\n",
            "[CV 2/5; 763/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 763/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.908 total time=   0.0s\n",
            "[CV 3/5; 763/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 763/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 763/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 763/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.856 total time=   0.0s\n",
            "[CV 5/5; 763/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 763/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.740 total time=   0.0s\n",
            "[CV 1/5; 764/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 764/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.900 total time=   0.0s\n",
            "[CV 2/5; 764/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 764/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.700 total time=   0.0s\n",
            "[CV 3/5; 764/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 764/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.896 total time=   0.0s\n",
            "[CV 4/5; 764/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 764/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.908 total time=   0.0s\n",
            "[CV 5/5; 764/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 764/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.872 total time=   0.0s\n",
            "[CV 1/5; 765/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 765/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.940 total time=   0.0s\n",
            "[CV 2/5; 765/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 765/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.956 total time=   0.0s\n",
            "[CV 3/5; 765/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 765/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.952 total time=   0.0s\n",
            "[CV 4/5; 765/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 765/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.968 total time=   0.0s\n",
            "[CV 5/5; 765/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 765/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 766/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 766/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 2/5; 766/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 766/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 766/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 766/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 766/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 766/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 766/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 766/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 1/5; 767/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 767/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 2/5; 767/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 767/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 3/5; 767/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 767/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 767/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 767/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.920 total time=   0.0s\n",
            "[CV 5/5; 767/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 767/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.924 total time=   0.0s\n",
            "[CV 1/5; 768/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 1/5; 768/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.952 total time=   0.0s\n",
            "[CV 2/5; 768/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 2/5; 768/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 3/5; 768/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 3/5; 768/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.952 total time=   0.0s\n",
            "[CV 4/5; 768/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 4/5; 768/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.968 total time=   0.0s\n",
            "[CV 5/5; 768/1344] START alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 5/5; 768/1344] END alpha=0.01, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 769/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 769/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.540 total time=   0.0s\n",
            "[CV 2/5; 769/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 769/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 769/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 769/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 769/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 769/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 769/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 769/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 770/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 770/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.564 total time=   0.0s\n",
            "[CV 2/5; 770/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 770/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.480 total time=   0.0s\n",
            "[CV 3/5; 770/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 770/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 770/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 770/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.484 total time=   0.0s\n",
            "[CV 5/5; 770/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 770/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 771/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 771/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 771/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 771/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 771/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 771/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.512 total time=   0.0s\n",
            "[CV 4/5; 771/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 771/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 771/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 771/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.496 total time=   0.0s\n",
            "[CV 1/5; 772/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 772/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.504 total time=   0.0s\n",
            "[CV 2/5; 772/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 772/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.472 total time=   0.0s\n",
            "[CV 3/5; 772/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 772/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 772/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 772/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.468 total time=   0.0s\n",
            "[CV 5/5; 772/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 772/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 773/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 773/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 773/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 773/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 773/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 773/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.1s\n",
            "[CV 4/5; 773/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 773/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.1s\n",
            "[CV 5/5; 773/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 773/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 774/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 774/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 774/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 774/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.528 total time=   0.1s\n",
            "[CV 3/5; 774/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 774/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 774/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 774/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 774/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 774/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 775/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 775/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 775/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 775/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 775/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 775/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 775/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 775/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 775/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 775/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 776/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 776/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 776/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 776/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 776/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 776/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 776/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 776/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 776/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 776/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 777/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 777/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 777/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 777/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 3/5; 777/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 777/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 4/5; 777/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 777/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.1s\n",
            "[CV 5/5; 777/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 777/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 1/5; 778/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 778/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 778/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 778/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 778/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 778/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 778/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 778/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 778/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 778/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 779/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 779/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 779/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 779/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 779/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 779/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 779/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 779/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 779/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 779/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 780/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 780/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 780/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 780/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 780/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 780/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 780/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 780/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 780/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 780/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 781/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 781/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 781/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 781/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 3/5; 781/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 781/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.568 total time=   0.0s\n",
            "[CV 4/5; 781/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 781/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.496 total time=   0.0s\n",
            "[CV 5/5; 781/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 781/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 782/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 782/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.540 total time=   0.0s\n",
            "[CV 2/5; 782/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 782/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 782/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 782/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.504 total time=   0.0s\n",
            "[CV 4/5; 782/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 782/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.504 total time=   0.0s\n",
            "[CV 5/5; 782/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 782/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.616 total time=   0.0s\n",
            "[CV 1/5; 783/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 783/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 783/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 783/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.504 total time=   0.0s\n",
            "[CV 3/5; 783/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 783/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.504 total time=   0.0s\n",
            "[CV 4/5; 783/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 783/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 783/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 783/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 784/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 1/5; 784/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.564 total time=   0.0s\n",
            "[CV 2/5; 784/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 2/5; 784/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 784/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 3/5; 784/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 4/5; 784/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 4/5; 784/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.504 total time=   0.0s\n",
            "[CV 5/5; 784/1344] START alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 5/5; 784/1344] END alpha=1, loss=hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.556 total time=   0.0s\n",
            "[CV 1/5; 785/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 785/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.532 total time=   0.1s\n",
            "[CV 2/5; 785/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 785/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 785/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 785/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 785/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 785/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 785/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 785/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.1s\n",
            "[CV 1/5; 786/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 786/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 786/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 786/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 786/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 786/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.516 total time=   0.0s\n",
            "[CV 4/5; 786/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 786/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 786/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 786/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 787/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 787/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 787/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 787/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 3/5; 787/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 787/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.460 total time=   0.0s\n",
            "[CV 4/5; 787/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 787/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.460 total time=   0.0s\n",
            "[CV 5/5; 787/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 787/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.556 total time=   0.0s\n",
            "[CV 1/5; 788/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 788/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 788/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 788/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 788/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 788/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.460 total time=   0.0s\n",
            "[CV 4/5; 788/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 788/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.508 total time=   0.0s\n",
            "[CV 5/5; 788/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 788/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.500 total time=   0.0s\n",
            "[CV 1/5; 789/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 789/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.480 total time=   0.2s\n",
            "[CV 2/5; 789/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 789/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 789/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 789/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 4/5; 789/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 789/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.2s\n",
            "[CV 5/5; 789/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 789/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 790/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 790/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 790/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 790/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 790/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 790/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 790/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 790/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 790/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 790/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 791/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 791/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 791/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 791/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 791/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 791/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 791/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 791/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 791/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 791/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 792/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 792/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 792/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 792/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 792/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 792/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 792/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 792/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 792/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 792/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 793/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 793/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 793/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 793/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.2s\n",
            "[CV 3/5; 793/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 793/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.2s\n",
            "[CV 4/5; 793/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 793/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.2s\n",
            "[CV 5/5; 793/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 793/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.2s\n",
            "[CV 1/5; 794/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 794/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 794/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 794/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 794/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 794/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 794/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 794/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 794/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 794/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 795/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 795/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 795/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 795/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 795/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 795/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 795/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 795/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 795/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 795/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 796/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 796/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 796/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 796/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 796/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 796/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 796/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 796/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 796/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 796/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 797/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 797/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.552 total time=   0.1s\n",
            "[CV 2/5; 797/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 797/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.524 total time=   0.1s\n",
            "[CV 3/5; 797/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 797/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.500 total time=   0.2s\n",
            "[CV 4/5; 797/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 797/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.524 total time=   0.2s\n",
            "[CV 5/5; 797/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 797/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.580 total time=   0.2s\n",
            "[CV 1/5; 798/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 798/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 798/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 798/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.528 total time=   0.0s\n",
            "[CV 3/5; 798/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 798/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.576 total time=   0.0s\n",
            "[CV 4/5; 798/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 798/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.504 total time=   0.0s\n",
            "[CV 5/5; 798/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 798/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 1/5; 799/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 799/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 799/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 799/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.496 total time=   0.0s\n",
            "[CV 3/5; 799/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 799/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.552 total time=   0.0s\n",
            "[CV 4/5; 799/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 799/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.500 total time=   0.0s\n",
            "[CV 5/5; 799/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 799/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.528 total time=   0.0s\n",
            "[CV 1/5; 800/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 1/5; 800/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 800/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 2/5; 800/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.528 total time=   0.0s\n",
            "[CV 3/5; 800/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 3/5; 800/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 800/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 4/5; 800/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 5/5; 800/1344] START alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 5/5; 800/1344] END alpha=1, loss=hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 1/5; 801/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 801/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 801/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 801/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 801/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 801/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 801/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 801/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 801/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 801/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 802/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 802/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 802/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 802/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 802/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 802/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.452 total time=   0.0s\n",
            "[CV 4/5; 802/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 802/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 802/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 802/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 803/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 803/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 2/5; 803/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 803/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 3/5; 803/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 803/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 803/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 803/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.452 total time=   0.0s\n",
            "[CV 5/5; 803/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 803/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.504 total time=   0.0s\n",
            "[CV 1/5; 804/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 804/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 804/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 804/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 804/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 804/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 804/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 804/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 804/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 804/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 805/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 805/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 805/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 805/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.2s\n",
            "[CV 3/5; 805/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 805/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 805/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 805/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.2s\n",
            "[CV 5/5; 805/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 805/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.2s\n",
            "[CV 1/5; 806/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 806/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 806/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 806/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 806/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 806/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 806/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 806/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 806/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 806/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 807/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 807/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 807/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 807/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 807/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 807/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 807/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 807/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 807/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 807/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 808/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 808/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 808/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 808/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 808/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 808/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 808/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 808/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 808/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 808/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 809/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 809/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 809/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 809/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.2s\n",
            "[CV 3/5; 809/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 809/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 809/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 809/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 809/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 809/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 810/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 810/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 810/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 810/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 810/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 810/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 810/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 810/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 810/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 810/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 811/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 811/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 811/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 811/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 811/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 811/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 811/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 811/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 811/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 811/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 812/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 812/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 812/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 812/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 812/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 812/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 812/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 812/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 812/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 812/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 813/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 813/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.544 total time=   0.1s\n",
            "[CV 2/5; 813/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 813/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.504 total time=   0.1s\n",
            "[CV 3/5; 813/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 813/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.520 total time=   0.1s\n",
            "[CV 4/5; 813/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 813/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.508 total time=   0.1s\n",
            "[CV 5/5; 813/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 813/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.524 total time=   0.1s\n",
            "[CV 1/5; 814/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 814/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 814/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 814/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.528 total time=   0.0s\n",
            "[CV 3/5; 814/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 814/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.508 total time=   0.0s\n",
            "[CV 4/5; 814/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 814/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 814/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 814/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 815/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 815/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 815/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 815/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.504 total time=   0.0s\n",
            "[CV 3/5; 815/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 815/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.528 total time=   0.0s\n",
            "[CV 4/5; 815/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 815/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 5/5; 815/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 815/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 1/5; 816/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 1/5; 816/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.536 total time=   0.0s\n",
            "[CV 2/5; 816/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 2/5; 816/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.560 total time=   0.0s\n",
            "[CV 3/5; 816/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 3/5; 816/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 816/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 4/5; 816/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.488 total time=   0.0s\n",
            "[CV 5/5; 816/1344] START alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 5/5; 816/1344] END alpha=1, loss=hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.576 total time=   0.0s\n",
            "[CV 1/5; 817/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 817/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 2/5; 817/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 817/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06;, score=0.512 total time=   0.0s\n",
            "[CV 3/5; 817/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 817/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06;, score=0.492 total time=   0.0s\n",
            "[CV 4/5; 817/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 817/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 817/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 817/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 818/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 818/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05;, score=0.572 total time=   0.0s\n",
            "[CV 2/5; 818/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 818/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05;, score=0.512 total time=   0.0s\n",
            "[CV 3/5; 818/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 818/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05;, score=0.488 total time=   0.0s\n",
            "[CV 4/5; 818/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 818/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 818/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 818/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 819/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 819/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001;, score=0.544 total time=   0.0s\n",
            "[CV 2/5; 819/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 819/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 3/5; 819/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 819/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001;, score=0.508 total time=   0.0s\n",
            "[CV 4/5; 819/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 819/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 819/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 819/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001;, score=0.548 total time=   0.0s\n",
            "[CV 1/5; 820/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 820/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001;, score=0.544 total time=   0.0s\n",
            "[CV 2/5; 820/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 820/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 820/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 820/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 820/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 820/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001;, score=0.508 total time=   0.0s\n",
            "[CV 5/5; 820/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 820/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 821/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 821/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 821/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 821/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 821/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 821/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 821/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 821/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 821/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 821/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 822/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 822/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 822/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 822/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 822/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 822/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 822/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 822/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 822/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 822/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 823/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 823/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 823/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 823/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 823/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 823/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 823/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 823/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 823/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 823/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 824/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 824/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 824/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 824/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 824/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 824/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 824/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 824/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 824/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 824/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 825/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 825/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 825/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 825/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 825/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 825/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 825/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 825/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 825/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 825/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 826/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 826/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 826/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 826/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 826/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 826/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 826/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 826/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 826/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 826/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 827/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 827/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 827/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 827/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 827/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 827/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 827/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 827/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 827/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 827/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 828/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 828/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 828/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 828/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 828/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 828/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 828/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 828/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 828/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 828/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 829/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 829/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06;, score=0.536 total time=   0.1s\n",
            "[CV 2/5; 829/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 829/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06;, score=0.504 total time=   0.1s\n",
            "[CV 3/5; 829/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 829/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06;, score=0.564 total time=   0.1s\n",
            "[CV 4/5; 829/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 829/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06;, score=0.584 total time=   0.1s\n",
            "[CV 5/5; 829/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 829/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06;, score=0.636 total time=   0.1s\n",
            "[CV 1/5; 830/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 830/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05;, score=0.564 total time=   0.0s\n",
            "[CV 2/5; 830/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 830/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05;, score=0.624 total time=   0.0s\n",
            "[CV 3/5; 830/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 830/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05;, score=0.592 total time=   0.0s\n",
            "[CV 4/5; 830/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 830/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05;, score=0.544 total time=   0.0s\n",
            "[CV 5/5; 830/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 830/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05;, score=0.532 total time=   0.0s\n",
            "[CV 1/5; 831/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 831/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001;, score=0.568 total time=   0.0s\n",
            "[CV 2/5; 831/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 831/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001;, score=0.544 total time=   0.0s\n",
            "[CV 3/5; 831/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 831/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001;, score=0.600 total time=   0.0s\n",
            "[CV 4/5; 831/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 831/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001;, score=0.540 total time=   0.0s\n",
            "[CV 5/5; 831/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 831/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 832/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 1/5; 832/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=0.001;, score=0.548 total time=   0.0s\n",
            "[CV 2/5; 832/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 2/5; 832/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=0.001;, score=0.528 total time=   0.0s\n",
            "[CV 3/5; 832/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 3/5; 832/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=0.001;, score=0.528 total time=   0.0s\n",
            "[CV 4/5; 832/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 4/5; 832/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=0.001;, score=0.492 total time=   0.0s\n",
            "[CV 5/5; 832/1344] START alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 5/5; 832/1344] END alpha=1, loss=log_loss, max_iter=1000, penalty=None, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 833/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 833/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 833/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 833/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 833/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 833/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06;, score=0.496 total time=   0.0s\n",
            "[CV 4/5; 833/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 833/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 833/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 833/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 834/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 834/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 834/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 834/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05;, score=0.516 total time=   0.0s\n",
            "[CV 3/5; 834/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 834/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05;, score=0.496 total time=   0.0s\n",
            "[CV 4/5; 834/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 834/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05;, score=0.532 total time=   0.0s\n",
            "[CV 5/5; 834/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 834/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05;, score=0.568 total time=   0.0s\n",
            "[CV 1/5; 835/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 835/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 835/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 835/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 835/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 835/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 835/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 835/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 835/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 835/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 836/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 836/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 836/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 836/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001;, score=0.500 total time=   0.0s\n",
            "[CV 3/5; 836/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 836/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 836/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 836/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 836/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 836/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001;, score=0.488 total time=   0.0s\n",
            "[CV 1/5; 837/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 837/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 837/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 837/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 837/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 837/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 837/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 837/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 837/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 837/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 838/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 838/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 838/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 838/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 838/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 838/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 838/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 838/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 838/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 838/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 839/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 839/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 839/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 839/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 839/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 839/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 839/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 839/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 839/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 839/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 840/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 840/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 840/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 840/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 840/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 840/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 840/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 840/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 840/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 840/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 841/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 841/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 841/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 841/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 841/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 841/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 841/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 841/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 841/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 841/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 842/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 842/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 842/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 842/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 842/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 842/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 842/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 842/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 842/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 842/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 843/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 843/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 843/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 843/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 843/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 843/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 843/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 843/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 843/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 843/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 844/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 844/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 844/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 844/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 844/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 844/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 844/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 844/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 844/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 844/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 845/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 845/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06;, score=0.672 total time=   0.1s\n",
            "[CV 2/5; 845/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 845/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06;, score=0.624 total time=   0.1s\n",
            "[CV 3/5; 845/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 845/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06;, score=0.596 total time=   0.1s\n",
            "[CV 4/5; 845/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 845/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06;, score=0.592 total time=   0.1s\n",
            "[CV 5/5; 845/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 845/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06;, score=0.528 total time=   0.1s\n",
            "[CV 1/5; 846/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 846/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05;, score=0.592 total time=   0.0s\n",
            "[CV 2/5; 846/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 846/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05;, score=0.496 total time=   0.0s\n",
            "[CV 3/5; 846/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 846/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05;, score=0.544 total time=   0.0s\n",
            "[CV 4/5; 846/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 846/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05;, score=0.568 total time=   0.0s\n",
            "[CV 5/5; 846/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 846/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05;, score=0.660 total time=   0.0s\n",
            "[CV 1/5; 847/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 847/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001;, score=0.552 total time=   0.0s\n",
            "[CV 2/5; 847/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 847/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001;, score=0.536 total time=   0.0s\n",
            "[CV 3/5; 847/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 847/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001;, score=0.560 total time=   0.0s\n",
            "[CV 4/5; 847/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 847/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001;, score=0.536 total time=   0.0s\n",
            "[CV 5/5; 847/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 847/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001;, score=0.608 total time=   0.0s\n",
            "[CV 1/5; 848/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 1/5; 848/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=0.001;, score=0.568 total time=   0.0s\n",
            "[CV 2/5; 848/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 2/5; 848/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=0.001;, score=0.608 total time=   0.0s\n",
            "[CV 3/5; 848/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 3/5; 848/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=0.001;, score=0.536 total time=   0.0s\n",
            "[CV 4/5; 848/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 4/5; 848/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=0.001;, score=0.544 total time=   0.0s\n",
            "[CV 5/5; 848/1344] START alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 5/5; 848/1344] END alpha=1, loss=log_loss, max_iter=10000, penalty=None, tol=0.001;, score=0.528 total time=   0.0s\n",
            "[CV 1/5; 849/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 849/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 849/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 849/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 849/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 849/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 849/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 849/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 849/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 849/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 850/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 850/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05;, score=0.556 total time=   0.0s\n",
            "[CV 2/5; 850/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 850/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05;, score=0.536 total time=   0.0s\n",
            "[CV 3/5; 850/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 850/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 850/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 850/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05;, score=0.536 total time=   0.0s\n",
            "[CV 5/5; 850/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 850/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 851/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 851/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 851/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 851/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001;, score=0.512 total time=   0.0s\n",
            "[CV 3/5; 851/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 851/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 851/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 851/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 851/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 851/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 852/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 852/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 852/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 852/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 852/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 852/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 852/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 852/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001;, score=0.488 total time=   0.0s\n",
            "[CV 5/5; 852/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 852/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 853/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 853/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 853/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 853/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 853/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 853/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 853/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 853/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 853/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 853/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 854/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 854/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 854/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 854/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 854/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 854/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 854/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 854/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 854/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 854/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 855/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 855/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 855/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 855/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 855/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 855/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 855/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 855/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 855/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 855/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 856/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 856/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 856/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 856/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 856/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 856/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 856/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 856/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 856/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 856/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 857/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 857/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 857/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 857/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 857/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 857/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 857/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 857/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 857/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 857/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 858/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 858/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 858/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 858/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 858/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 858/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 858/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 858/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 858/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 858/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 859/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 859/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 859/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 859/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 859/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 859/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 859/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 859/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 859/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 859/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 860/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 860/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 860/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 860/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 860/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 860/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 860/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 860/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 860/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 860/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 861/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 861/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06;, score=0.588 total time=   0.1s\n",
            "[CV 2/5; 861/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 861/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06;, score=0.492 total time=   0.1s\n",
            "[CV 3/5; 861/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 861/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06;, score=0.572 total time=   0.1s\n",
            "[CV 4/5; 861/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 861/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06;, score=0.556 total time=   0.1s\n",
            "[CV 5/5; 861/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 861/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06;, score=0.628 total time=   0.1s\n",
            "[CV 1/5; 862/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 862/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05;, score=0.572 total time=   0.0s\n",
            "[CV 2/5; 862/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 862/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05;, score=0.512 total time=   0.0s\n",
            "[CV 3/5; 862/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 862/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05;, score=0.544 total time=   0.0s\n",
            "[CV 4/5; 862/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 862/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05;, score=0.560 total time=   0.0s\n",
            "[CV 5/5; 862/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 862/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05;, score=0.548 total time=   0.0s\n",
            "[CV 1/5; 863/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 863/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001;, score=0.628 total time=   0.0s\n",
            "[CV 2/5; 863/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 863/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001;, score=0.508 total time=   0.0s\n",
            "[CV 3/5; 863/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 863/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001;, score=0.584 total time=   0.0s\n",
            "[CV 4/5; 863/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 863/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001;, score=0.564 total time=   0.0s\n",
            "[CV 5/5; 863/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 863/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001;, score=0.636 total time=   0.0s\n",
            "[CV 1/5; 864/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 1/5; 864/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=0.001;, score=0.536 total time=   0.0s\n",
            "[CV 2/5; 864/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 2/5; 864/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=0.001;, score=0.580 total time=   0.0s\n",
            "[CV 3/5; 864/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 3/5; 864/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 4/5; 864/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 4/5; 864/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=0.001;, score=0.544 total time=   0.0s\n",
            "[CV 5/5; 864/1344] START alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 5/5; 864/1344] END alpha=1, loss=log_loss, max_iter=100000, penalty=None, tol=0.001;, score=0.548 total time=   0.0s\n",
            "[CV 1/5; 865/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 865/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.576 total time=   0.0s\n",
            "[CV 2/5; 865/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 865/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 865/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 865/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.576 total time=   0.0s\n",
            "[CV 4/5; 865/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 865/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.588 total time=   0.0s\n",
            "[CV 5/5; 865/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 865/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.532 total time=   0.0s\n",
            "[CV 1/5; 866/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 866/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.656 total time=   0.0s\n",
            "[CV 2/5; 866/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 866/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.560 total time=   0.0s\n",
            "[CV 3/5; 866/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 866/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.564 total time=   0.0s\n",
            "[CV 4/5; 866/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 866/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.552 total time=   0.0s\n",
            "[CV 5/5; 866/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 866/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.532 total time=   0.0s\n",
            "[CV 1/5; 867/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 867/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.640 total time=   0.0s\n",
            "[CV 2/5; 867/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 867/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 3/5; 867/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 867/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.552 total time=   0.0s\n",
            "[CV 4/5; 867/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 867/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.552 total time=   0.0s\n",
            "[CV 5/5; 867/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 867/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.532 total time=   0.0s\n",
            "[CV 1/5; 868/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 868/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.564 total time=   0.0s\n",
            "[CV 2/5; 868/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 868/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.516 total time=   0.0s\n",
            "[CV 3/5; 868/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 868/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.564 total time=   0.0s\n",
            "[CV 4/5; 868/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 868/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.588 total time=   0.0s\n",
            "[CV 5/5; 868/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 868/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.532 total time=   0.0s\n",
            "[CV 1/5; 869/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 869/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 869/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 869/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 869/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 869/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 869/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 869/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 869/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 869/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 870/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 870/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 870/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 870/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 870/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 870/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.960 total time=   0.0s\n",
            "[CV 4/5; 870/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 870/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 870/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 870/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 871/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 871/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 871/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 871/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 871/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 871/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 871/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 871/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 871/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 871/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 872/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 872/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.916 total time=   0.0s\n",
            "[CV 2/5; 872/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 872/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 872/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 872/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 872/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 872/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 872/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 872/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 873/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 873/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 873/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 873/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 873/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 873/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 873/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 873/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 873/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 873/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 874/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 874/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 874/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 874/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 874/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 874/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 874/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 874/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 874/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 874/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 875/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 875/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 875/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 875/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 875/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 875/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 875/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 875/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 875/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 875/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 876/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 876/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 876/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 876/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 876/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 876/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 876/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 876/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 876/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 876/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 877/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 877/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 2/5; 877/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 877/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.552 total time=   0.1s\n",
            "[CV 3/5; 877/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 877/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.828 total time=   0.1s\n",
            "[CV 4/5; 877/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 877/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.636 total time=   0.1s\n",
            "[CV 5/5; 877/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 877/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.924 total time=   0.1s\n",
            "[CV 1/5; 878/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 878/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.824 total time=   0.1s\n",
            "[CV 2/5; 878/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 878/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.840 total time=   0.0s\n",
            "[CV 3/5; 878/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 878/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.812 total time=   0.1s\n",
            "[CV 4/5; 878/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 878/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.896 total time=   0.1s\n",
            "[CV 5/5; 878/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 878/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.864 total time=   0.0s\n",
            "[CV 1/5; 879/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 879/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.924 total time=   0.0s\n",
            "[CV 2/5; 879/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 879/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.924 total time=   0.0s\n",
            "[CV 3/5; 879/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 879/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.772 total time=   0.0s\n",
            "[CV 4/5; 879/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 879/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.680 total time=   0.0s\n",
            "[CV 5/5; 879/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 879/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.844 total time=   0.0s\n",
            "[CV 1/5; 880/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 1/5; 880/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.896 total time=   0.0s\n",
            "[CV 2/5; 880/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 2/5; 880/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.860 total time=   0.0s\n",
            "[CV 3/5; 880/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 3/5; 880/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.732 total time=   0.0s\n",
            "[CV 4/5; 880/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 4/5; 880/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.776 total time=   0.0s\n",
            "[CV 5/5; 880/1344] START alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 5/5; 880/1344] END alpha=1, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.756 total time=   0.0s\n",
            "[CV 1/5; 881/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 881/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.636 total time=   0.0s\n",
            "[CV 2/5; 881/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 881/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 881/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 881/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.560 total time=   0.0s\n",
            "[CV 4/5; 881/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 881/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.548 total time=   0.0s\n",
            "[CV 5/5; 881/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 881/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.576 total time=   0.0s\n",
            "[CV 1/5; 882/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 882/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.600 total time=   0.0s\n",
            "[CV 2/5; 882/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 882/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.516 total time=   0.0s\n",
            "[CV 3/5; 882/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 882/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.564 total time=   0.0s\n",
            "[CV 4/5; 882/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 882/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.556 total time=   0.0s\n",
            "[CV 5/5; 882/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 882/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.532 total time=   0.0s\n",
            "[CV 1/5; 883/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 883/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.660 total time=   0.0s\n",
            "[CV 2/5; 883/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 883/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.516 total time=   0.0s\n",
            "[CV 3/5; 883/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 883/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.560 total time=   0.0s\n",
            "[CV 4/5; 883/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 883/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.544 total time=   0.0s\n",
            "[CV 5/5; 883/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 883/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.532 total time=   0.0s\n",
            "[CV 1/5; 884/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 884/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.628 total time=   0.0s\n",
            "[CV 2/5; 884/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 884/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 884/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 884/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.564 total time=   0.0s\n",
            "[CV 4/5; 884/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 884/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.552 total time=   0.0s\n",
            "[CV 5/5; 884/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 884/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.532 total time=   0.0s\n",
            "[CV 1/5; 885/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 885/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 885/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 885/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 885/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 885/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 885/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 885/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 885/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 885/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 886/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 886/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 886/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 886/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 886/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 886/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 886/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 886/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 886/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 886/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 887/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 887/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 887/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 887/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 887/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 887/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 887/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 887/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 887/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 887/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 888/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 888/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 888/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 888/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 888/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 888/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 888/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 888/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.804 total time=   0.0s\n",
            "[CV 5/5; 888/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 888/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 889/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 889/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 889/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 889/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 889/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 889/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 889/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 889/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 889/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 889/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 890/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 890/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 890/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 890/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 890/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 890/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 890/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 890/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 890/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 890/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 891/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 891/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 891/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 891/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 891/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 891/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 891/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 891/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 891/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 891/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.528 total time=   0.0s\n",
            "[CV 1/5; 892/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 892/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 892/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 892/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 892/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 892/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 892/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 892/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 892/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 892/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 893/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 893/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.840 total time=   0.3s\n",
            "[CV 2/5; 893/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 893/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.876 total time=   0.4s\n",
            "[CV 3/5; 893/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 893/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.852 total time=   0.2s\n",
            "[CV 4/5; 893/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 893/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.956 total time=   0.2s\n",
            "[CV 5/5; 893/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 893/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.912 total time=   0.4s\n",
            "[CV 1/5; 894/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 894/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.920 total time=   0.1s\n",
            "[CV 2/5; 894/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 894/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.708 total time=   0.0s\n",
            "[CV 3/5; 894/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 894/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.868 total time=   0.0s\n",
            "[CV 4/5; 894/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 894/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.868 total time=   0.0s\n",
            "[CV 5/5; 894/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 894/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.916 total time=   0.0s\n",
            "[CV 1/5; 895/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 895/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.900 total time=   0.0s\n",
            "[CV 2/5; 895/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 895/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.748 total time=   0.0s\n",
            "[CV 3/5; 895/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 895/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.872 total time=   0.0s\n",
            "[CV 4/5; 895/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 895/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 895/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 895/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.828 total time=   0.0s\n",
            "[CV 1/5; 896/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 1/5; 896/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.788 total time=   0.0s\n",
            "[CV 2/5; 896/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 2/5; 896/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.824 total time=   0.0s\n",
            "[CV 3/5; 896/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 3/5; 896/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.768 total time=   0.0s\n",
            "[CV 4/5; 896/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 4/5; 896/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.724 total time=   0.0s\n",
            "[CV 5/5; 896/1344] START alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 5/5; 896/1344] END alpha=1, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.732 total time=   0.0s\n",
            "[CV 1/5; 897/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 897/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.600 total time=   0.0s\n",
            "[CV 2/5; 897/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 897/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.516 total time=   0.0s\n",
            "[CV 3/5; 897/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 897/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.560 total time=   0.0s\n",
            "[CV 4/5; 897/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 897/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.588 total time=   0.0s\n",
            "[CV 5/5; 897/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 897/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.528 total time=   0.0s\n",
            "[CV 1/5; 898/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 898/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.560 total time=   0.0s\n",
            "[CV 2/5; 898/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 898/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.540 total time=   0.0s\n",
            "[CV 3/5; 898/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 898/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.560 total time=   0.0s\n",
            "[CV 4/5; 898/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 898/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.552 total time=   0.0s\n",
            "[CV 5/5; 898/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 898/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.528 total time=   0.0s\n",
            "[CV 1/5; 899/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 899/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.668 total time=   0.0s\n",
            "[CV 2/5; 899/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 899/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 3/5; 899/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 899/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.568 total time=   0.0s\n",
            "[CV 4/5; 899/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 899/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.552 total time=   0.0s\n",
            "[CV 5/5; 899/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 899/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.528 total time=   0.0s\n",
            "[CV 1/5; 900/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 900/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.580 total time=   0.0s\n",
            "[CV 2/5; 900/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 900/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.552 total time=   0.0s\n",
            "[CV 3/5; 900/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 900/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.608 total time=   0.0s\n",
            "[CV 4/5; 900/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 900/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.544 total time=   0.0s\n",
            "[CV 5/5; 900/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 900/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.536 total time=   0.0s\n",
            "[CV 1/5; 901/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 901/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 901/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 901/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 901/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 901/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 901/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 901/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 901/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 901/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.780 total time=   6.2s\n",
            "[CV 1/5; 902/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 902/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.568 total time=   7.4s\n",
            "[CV 2/5; 902/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 902/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 902/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 902/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 902/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 902/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 902/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 902/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 903/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 903/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 903/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 903/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 903/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 903/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 903/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 903/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 903/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 903/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 904/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 904/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 904/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 904/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 904/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 904/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 904/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 904/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 904/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 904/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 905/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 905/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 905/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 905/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 905/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 905/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 905/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 905/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 905/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 905/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 906/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 906/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 906/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 906/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 906/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 906/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.668 total time=   0.0s\n",
            "[CV 4/5; 906/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 906/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 906/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 906/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 907/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 907/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 907/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 907/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 907/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 907/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 907/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 907/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 907/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 907/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 908/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 908/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 908/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 908/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 908/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 908/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 908/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 908/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 908/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 908/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 909/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 909/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.836 total time=   0.3s\n",
            "[CV 2/5; 909/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 909/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.880 total time=   2.3s\n",
            "[CV 3/5; 909/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 909/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.892 total time=   0.1s\n",
            "[CV 4/5; 909/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 909/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.884 total time=   3.0s\n",
            "[CV 5/5; 909/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 909/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.768 total time=   0.5s\n",
            "[CV 1/5; 910/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 910/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.844 total time=   0.0s\n",
            "[CV 2/5; 910/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 910/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.740 total time=   1.5s\n",
            "[CV 3/5; 910/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 910/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.832 total time=   2.1s\n",
            "[CV 4/5; 910/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 910/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.844 total time=   0.4s\n",
            "[CV 5/5; 910/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 910/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.892 total time=   0.0s\n",
            "[CV 1/5; 911/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 911/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.836 total time=   0.2s\n",
            "[CV 2/5; 911/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 911/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.640 total time=   0.0s\n",
            "[CV 3/5; 911/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 911/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.792 total time=   0.0s\n",
            "[CV 4/5; 911/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 911/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.820 total time=   0.0s\n",
            "[CV 5/5; 911/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 911/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.896 total time=   0.0s\n",
            "[CV 1/5; 912/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 1/5; 912/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.668 total time=   0.1s\n",
            "[CV 2/5; 912/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 2/5; 912/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.676 total time=   0.0s\n",
            "[CV 3/5; 912/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 3/5; 912/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.800 total time=   0.0s\n",
            "[CV 4/5; 912/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 4/5; 912/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.700 total time=   0.0s\n",
            "[CV 5/5; 912/1344] START alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 5/5; 912/1344] END alpha=1, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.672 total time=   0.1s\n",
            "[CV 1/5; 913/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 913/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.768 total time=   0.0s\n",
            "[CV 2/5; 913/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 913/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.916 total time=   0.0s\n",
            "[CV 3/5; 913/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 913/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.840 total time=   0.0s\n",
            "[CV 4/5; 913/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 913/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.960 total time=   0.0s\n",
            "[CV 5/5; 913/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 913/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.728 total time=   0.0s\n",
            "[CV 1/5; 914/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 914/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.812 total time=   0.0s\n",
            "[CV 2/5; 914/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 914/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.756 total time=   0.0s\n",
            "[CV 3/5; 914/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 914/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 914/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 914/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.696 total time=   0.0s\n",
            "[CV 5/5; 914/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 914/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.844 total time=   0.0s\n",
            "[CV 1/5; 915/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 915/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.684 total time=   0.0s\n",
            "[CV 2/5; 915/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 915/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.708 total time=   0.0s\n",
            "[CV 3/5; 915/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 915/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.840 total time=   0.0s\n",
            "[CV 4/5; 915/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 915/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.912 total time=   0.0s\n",
            "[CV 5/5; 915/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 915/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.728 total time=   0.0s\n",
            "[CV 1/5; 916/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 916/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.956 total time=   0.0s\n",
            "[CV 2/5; 916/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 916/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.812 total time=   0.0s\n",
            "[CV 3/5; 916/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 916/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.712 total time=   0.0s\n",
            "[CV 4/5; 916/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 916/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 5/5; 916/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 916/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.888 total time=   0.0s\n",
            "[CV 1/5; 917/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 917/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 917/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 917/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 917/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 917/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 917/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 917/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 917/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 917/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 918/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 918/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 918/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 918/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 918/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 918/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 918/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 918/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 918/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 918/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 919/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 919/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 919/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 919/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 919/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 919/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 919/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 919/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 919/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 919/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 920/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 920/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 920/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 920/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 920/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 920/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 920/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 920/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 920/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 920/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 921/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 921/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 921/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 921/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 921/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 921/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 921/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 921/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 921/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 921/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 922/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 922/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 922/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 922/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 922/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 922/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 922/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 922/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 922/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 922/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 923/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 923/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 923/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 923/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 923/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 923/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 923/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 923/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 923/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 923/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 924/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 924/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 924/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 924/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 924/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 924/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 924/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 924/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 924/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 924/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 925/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 925/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 2/5; 925/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 925/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.936 total time=   0.0s\n",
            "[CV 3/5; 925/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 925/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 925/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 925/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.960 total time=   0.0s\n",
            "[CV 5/5; 925/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 925/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 926/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 926/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 2/5; 926/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 926/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 3/5; 926/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 926/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.936 total time=   0.0s\n",
            "[CV 4/5; 926/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 926/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 5/5; 926/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 926/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 927/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 927/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.968 total time=   0.0s\n",
            "[CV 2/5; 927/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 927/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.920 total time=   0.0s\n",
            "[CV 3/5; 927/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 927/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 4/5; 927/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 927/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.544 total time=   0.0s\n",
            "[CV 5/5; 927/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 927/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.876 total time=   0.0s\n",
            "[CV 1/5; 928/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 1/5; 928/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.932 total time=   0.0s\n",
            "[CV 2/5; 928/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 2/5; 928/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.932 total time=   0.0s\n",
            "[CV 3/5; 928/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 3/5; 928/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 4/5; 928/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 4/5; 928/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.884 total time=   0.0s\n",
            "[CV 5/5; 928/1344] START alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 5/5; 928/1344] END alpha=1, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.924 total time=   0.0s\n",
            "[CV 1/5; 929/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 929/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.924 total time=   0.0s\n",
            "[CV 2/5; 929/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 929/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.856 total time=   0.0s\n",
            "[CV 3/5; 929/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 929/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.752 total time=   0.0s\n",
            "[CV 4/5; 929/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 929/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.936 total time=   0.0s\n",
            "[CV 5/5; 929/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 929/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.908 total time=   0.0s\n",
            "[CV 1/5; 930/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 930/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.700 total time=   0.0s\n",
            "[CV 2/5; 930/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 930/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 930/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 930/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.708 total time=   0.0s\n",
            "[CV 4/5; 930/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 930/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.808 total time=   0.0s\n",
            "[CV 5/5; 930/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 930/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.668 total time=   0.0s\n",
            "[CV 1/5; 931/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 931/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.676 total time=   0.0s\n",
            "[CV 2/5; 931/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 931/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.844 total time=   0.0s\n",
            "[CV 3/5; 931/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 931/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.756 total time=   0.0s\n",
            "[CV 4/5; 931/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 931/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.800 total time=   0.0s\n",
            "[CV 5/5; 931/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 931/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.784 total time=   0.0s\n",
            "[CV 1/5; 932/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 932/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.748 total time=   0.0s\n",
            "[CV 2/5; 932/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 932/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.756 total time=   0.0s\n",
            "[CV 3/5; 932/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 932/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.864 total time=   0.0s\n",
            "[CV 4/5; 932/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 932/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.728 total time=   0.0s\n",
            "[CV 5/5; 932/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 932/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.860 total time=   0.0s\n",
            "[CV 1/5; 933/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 933/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 933/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 933/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 933/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 933/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 933/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 933/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 933/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 933/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 934/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 934/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 934/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 934/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 934/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 934/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 934/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 934/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 934/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 934/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 935/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 935/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 935/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 935/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 935/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 935/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 935/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 935/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 935/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 935/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 936/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 936/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 936/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 936/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 936/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 936/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 936/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 936/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 936/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 936/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 937/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 937/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 937/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 937/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 937/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 937/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 937/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 937/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 937/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 937/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 938/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 938/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 938/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 938/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 938/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 938/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 938/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 938/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 938/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 938/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 939/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 939/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 939/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 939/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 939/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 939/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 939/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 939/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 939/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 939/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 940/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 940/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 940/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 940/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 940/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 940/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 940/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 940/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 940/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 940/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 941/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 941/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.968 total time=   0.0s\n",
            "[CV 2/5; 941/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 941/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 941/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 941/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 941/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 941/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.952 total time=   0.1s\n",
            "[CV 5/5; 941/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 941/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 1/5; 942/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 942/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.936 total time=   0.0s\n",
            "[CV 2/5; 942/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 942/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.932 total time=   0.0s\n",
            "[CV 3/5; 942/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 942/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.928 total time=   0.0s\n",
            "[CV 4/5; 942/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 942/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 942/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 942/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.708 total time=   0.0s\n",
            "[CV 1/5; 943/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 943/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.968 total time=   0.0s\n",
            "[CV 2/5; 943/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 943/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 943/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 943/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.916 total time=   0.0s\n",
            "[CV 4/5; 943/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 943/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 5/5; 943/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 943/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.884 total time=   0.0s\n",
            "[CV 1/5; 944/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 1/5; 944/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 2/5; 944/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 2/5; 944/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.616 total time=   0.0s\n",
            "[CV 3/5; 944/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 3/5; 944/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.940 total time=   0.0s\n",
            "[CV 4/5; 944/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 4/5; 944/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 5/5; 944/1344] START alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 5/5; 944/1344] END alpha=1, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 945/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 945/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.900 total time=   0.0s\n",
            "[CV 2/5; 945/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 945/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.860 total time=   0.0s\n",
            "[CV 3/5; 945/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 945/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.828 total time=   0.0s\n",
            "[CV 4/5; 945/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 945/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.904 total time=   0.0s\n",
            "[CV 5/5; 945/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 945/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.732 total time=   0.0s\n",
            "[CV 1/5; 946/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 946/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.776 total time=   0.0s\n",
            "[CV 2/5; 946/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 946/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 3/5; 946/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 946/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 946/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 946/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.860 total time=   0.0s\n",
            "[CV 5/5; 946/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 946/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.892 total time=   0.0s\n",
            "[CV 1/5; 947/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 947/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.784 total time=   0.0s\n",
            "[CV 2/5; 947/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 947/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.792 total time=   0.0s\n",
            "[CV 3/5; 947/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 947/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.540 total time=   0.0s\n",
            "[CV 4/5; 947/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 947/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.820 total time=   0.0s\n",
            "[CV 5/5; 947/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 947/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.860 total time=   0.0s\n",
            "[CV 1/5; 948/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 948/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.720 total time=   0.0s\n",
            "[CV 2/5; 948/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 948/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.696 total time=   0.0s\n",
            "[CV 3/5; 948/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 948/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.840 total time=   0.0s\n",
            "[CV 4/5; 948/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 948/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.704 total time=   0.0s\n",
            "[CV 5/5; 948/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 948/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.748 total time=   0.0s\n",
            "[CV 1/5; 949/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 949/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 949/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 949/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 949/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 949/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 949/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 949/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 949/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 949/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 950/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 950/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 950/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 950/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 950/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 950/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 950/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 950/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 950/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 950/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 951/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 951/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 951/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 951/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 951/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 951/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 951/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 951/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 951/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 951/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 952/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 952/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 952/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 952/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 952/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 952/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 952/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 952/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 952/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 952/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 953/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 953/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 953/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 953/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 953/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 953/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 953/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 953/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 953/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 953/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 954/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 954/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 954/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 954/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 954/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 954/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 954/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 954/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 954/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 954/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 955/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 955/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 955/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 955/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 955/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 955/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 955/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 955/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 955/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 955/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 956/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 956/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 956/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 956/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 956/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 956/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 956/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 956/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 956/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 956/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 957/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 957/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.992 total time=   0.0s\n",
            "[CV 2/5; 957/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 957/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.792 total time=   0.3s\n",
            "[CV 3/5; 957/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 957/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 957/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 957/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.960 total time=   0.0s\n",
            "[CV 5/5; 957/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 957/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.956 total time=   0.0s\n",
            "[CV 1/5; 958/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 958/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.936 total time=   0.0s\n",
            "[CV 2/5; 958/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 958/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.956 total time=   0.0s\n",
            "[CV 3/5; 958/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 958/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 958/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 958/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.960 total time=   0.0s\n",
            "[CV 5/5; 958/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 958/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.892 total time=   0.0s\n",
            "[CV 1/5; 959/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 959/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.916 total time=   0.0s\n",
            "[CV 2/5; 959/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 959/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 3/5; 959/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 959/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.952 total time=   0.0s\n",
            "[CV 4/5; 959/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 959/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.916 total time=   0.0s\n",
            "[CV 5/5; 959/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 959/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.844 total time=   0.0s\n",
            "[CV 1/5; 960/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 1/5; 960/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.916 total time=   0.0s\n",
            "[CV 2/5; 960/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 2/5; 960/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 960/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 3/5; 960/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.532 total time=   0.0s\n",
            "[CV 4/5; 960/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 4/5; 960/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 5/5; 960/1344] START alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 5/5; 960/1344] END alpha=1, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.712 total time=   0.0s\n",
            "[CV 1/5; 961/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 961/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 961/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 961/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 961/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 961/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 961/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 961/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 961/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 961/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 962/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 962/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 962/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 962/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 962/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 962/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 962/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 962/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 962/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 962/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 963/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 963/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 963/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 963/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 963/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 963/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 963/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 963/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 963/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 963/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 964/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 964/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 964/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 964/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 964/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 964/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 964/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 964/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 964/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 964/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 965/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 965/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 965/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 965/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 965/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 965/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 965/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 965/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 965/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 965/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 966/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 966/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 966/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 966/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 966/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 966/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 966/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 966/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 966/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 966/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 967/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 967/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 967/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 967/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 967/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 967/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 967/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 967/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 967/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 967/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 968/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 968/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 968/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 968/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 968/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 968/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 968/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 968/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 968/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 968/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 969/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 969/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 969/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 969/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 969/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 969/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 969/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 969/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 969/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 969/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 970/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 970/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 970/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 970/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 970/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 970/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 970/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 970/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 970/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 970/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 971/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 971/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 971/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 971/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 971/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 971/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 971/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 971/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 971/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 971/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 972/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 972/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 972/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 972/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 972/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 972/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 972/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 972/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 972/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 972/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 973/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 973/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 973/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 973/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.480 total time=   0.0s\n",
            "[CV 3/5; 973/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 973/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.460 total time=   0.1s\n",
            "[CV 4/5; 973/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 973/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.472 total time=   0.0s\n",
            "[CV 5/5; 973/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 973/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.440 total time=   0.0s\n",
            "[CV 1/5; 974/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 974/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.540 total time=   0.0s\n",
            "[CV 2/5; 974/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 974/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.516 total time=   0.0s\n",
            "[CV 3/5; 974/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 974/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.548 total time=   0.0s\n",
            "[CV 4/5; 974/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 974/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.516 total time=   0.0s\n",
            "[CV 5/5; 974/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 974/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.464 total time=   0.0s\n",
            "[CV 1/5; 975/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 975/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.568 total time=   0.0s\n",
            "[CV 2/5; 975/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 975/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.500 total time=   0.0s\n",
            "[CV 3/5; 975/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 975/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.516 total time=   0.0s\n",
            "[CV 4/5; 975/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 975/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.472 total time=   0.0s\n",
            "[CV 5/5; 975/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 975/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.572 total time=   0.0s\n",
            "[CV 1/5; 976/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 1/5; 976/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.544 total time=   0.0s\n",
            "[CV 2/5; 976/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 2/5; 976/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.484 total time=   0.0s\n",
            "[CV 3/5; 976/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 3/5; 976/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.536 total time=   0.0s\n",
            "[CV 4/5; 976/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 4/5; 976/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.540 total time=   0.0s\n",
            "[CV 5/5; 976/1344] START alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 5/5; 976/1344] END alpha=10, loss=hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.568 total time=   0.0s\n",
            "[CV 1/5; 977/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 977/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 977/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 977/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 977/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 977/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 977/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 977/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 977/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 977/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 978/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 978/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 978/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 978/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 978/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 978/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 978/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 978/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 978/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 978/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 979/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 979/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 979/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 979/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 979/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 979/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 979/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 979/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 979/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 979/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 980/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 980/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 980/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 980/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 980/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 980/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 980/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 980/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 980/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 980/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 981/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 981/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 981/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 981/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 981/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 981/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 981/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 981/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 981/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 981/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 982/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 982/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 982/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 982/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 982/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 982/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 982/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 982/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 982/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 982/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 983/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 983/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 983/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 983/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 983/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 983/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 983/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 983/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 983/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 983/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 984/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 984/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 984/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 984/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 984/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 984/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 984/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 984/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 984/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 984/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 985/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 985/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 985/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 985/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 985/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 985/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 985/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 985/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 985/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 985/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 986/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 986/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 986/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 986/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 986/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 986/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 986/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 986/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 986/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 986/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 987/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 987/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 987/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 987/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 987/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 987/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 987/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 987/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 987/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 987/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 988/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 988/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 988/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 988/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 988/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 988/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 988/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 988/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 988/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 988/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 989/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 989/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.532 total time=   0.2s\n",
            "[CV 2/5; 989/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 989/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.536 total time=   0.4s\n",
            "[CV 3/5; 989/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 989/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.516 total time=   0.3s\n",
            "[CV 4/5; 989/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 989/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.536 total time=   0.4s\n",
            "[CV 5/5; 989/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 989/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.552 total time=   0.4s\n",
            "[CV 1/5; 990/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 990/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.440 total time=   0.0s\n",
            "[CV 2/5; 990/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 990/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.496 total time=   0.0s\n",
            "[CV 3/5; 990/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 990/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.504 total time=   0.1s\n",
            "[CV 4/5; 990/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 990/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.480 total time=   0.1s\n",
            "[CV 5/5; 990/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 990/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.492 total time=   0.1s\n",
            "[CV 1/5; 991/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 991/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.536 total time=   0.0s\n",
            "[CV 2/5; 991/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 991/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.512 total time=   0.0s\n",
            "[CV 3/5; 991/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 991/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 4/5; 991/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 991/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.504 total time=   0.0s\n",
            "[CV 5/5; 991/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 991/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.484 total time=   0.0s\n",
            "[CV 1/5; 992/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 1/5; 992/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 2/5; 992/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 2/5; 992/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.492 total time=   0.0s\n",
            "[CV 3/5; 992/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 3/5; 992/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.488 total time=   0.0s\n",
            "[CV 4/5; 992/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 4/5; 992/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.532 total time=   0.0s\n",
            "[CV 5/5; 992/1344] START alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 5/5; 992/1344] END alpha=10, loss=hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.420 total time=   0.0s\n",
            "[CV 1/5; 993/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 993/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 993/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 993/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 993/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 993/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 993/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 993/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 993/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 993/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 994/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 994/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 994/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 994/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 994/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 994/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 994/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 994/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 994/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 994/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 995/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 995/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 995/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 995/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 995/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 995/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 995/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 995/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 995/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 995/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 996/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 996/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 996/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 996/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 996/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 996/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 996/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 996/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 996/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 996/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 997/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 997/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 997/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 997/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 997/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 997/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 997/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 997/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 997/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 997/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 998/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 998/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 998/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 998/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 998/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 998/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 998/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 998/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 998/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 998/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 999/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 999/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 999/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 999/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 999/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 999/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 999/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 999/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 999/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 999/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1000/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 1000/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1000/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 1000/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1000/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 1000/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1000/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 1000/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1000/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 1000/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1001/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 1001/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1001/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 1001/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1001/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 1001/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1001/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 1001/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1001/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 1001/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1002/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 1002/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1002/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 1002/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1002/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 1002/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1002/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 1002/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1002/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 1002/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1003/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 1003/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1003/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 1003/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1003/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 1003/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1003/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 1003/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1003/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 1003/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1004/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 1004/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1004/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 1004/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1004/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 1004/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1004/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 1004/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1004/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 1004/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1005/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 1005/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.444 total time=   0.4s\n",
            "[CV 2/5; 1005/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 1005/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.508 total time=   0.2s\n",
            "[CV 3/5; 1005/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 1005/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.488 total time=   0.1s\n",
            "[CV 4/5; 1005/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 1005/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.488 total time=   1.5s\n",
            "[CV 5/5; 1005/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 1005/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.508 total time=   0.7s\n",
            "[CV 1/5; 1006/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 1006/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.456 total time=   0.1s\n",
            "[CV 2/5; 1006/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 1006/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.476 total time=   0.6s\n",
            "[CV 3/5; 1006/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 1006/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.532 total time=   0.4s\n",
            "[CV 4/5; 1006/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 1006/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.508 total time=   0.0s\n",
            "[CV 5/5; 1006/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 1006/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.496 total time=   0.0s\n",
            "[CV 1/5; 1007/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 1007/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.464 total time=   0.0s\n",
            "[CV 2/5; 1007/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 1007/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.488 total time=   0.0s\n",
            "[CV 3/5; 1007/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 1007/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1007/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 1007/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.460 total time=   0.0s\n",
            "[CV 5/5; 1007/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 1007/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.412 total time=   0.0s\n",
            "[CV 1/5; 1008/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 1/5; 1008/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.456 total time=   0.0s\n",
            "[CV 2/5; 1008/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 2/5; 1008/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.468 total time=   0.0s\n",
            "[CV 3/5; 1008/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 3/5; 1008/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 4/5; 1008/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 4/5; 1008/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 5/5; 1008/1344] START alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 5/5; 1008/1344] END alpha=10, loss=hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.408 total time=   0.0s\n",
            "[CV 1/5; 1009/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 1009/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06;, score=0.480 total time=   0.1s\n",
            "[CV 2/5; 1009/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 1009/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 3/5; 1009/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 1009/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 4/5; 1009/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 1009/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1009/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 1009/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1010/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 1010/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1010/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 1010/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1010/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 1010/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1010/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 1010/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1010/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 1010/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1011/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 1011/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1011/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 1011/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1011/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 1011/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1011/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 1011/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1011/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 1011/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1012/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 1012/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1012/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 1012/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1012/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 1012/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1012/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 1012/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1012/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 1012/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1013/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 1013/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06;, score=0.480 total time=   0.1s\n",
            "[CV 2/5; 1013/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 1013/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1013/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 1013/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 4/5; 1013/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 1013/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1013/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 1013/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1014/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 1014/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1014/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 1014/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1014/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 1014/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1014/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 1014/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1014/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 1014/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1015/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 1015/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1015/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 1015/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1015/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 1015/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1015/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 1015/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1015/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 1015/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1016/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 1016/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1016/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 1016/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1016/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 1016/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1016/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 1016/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1016/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 1016/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1017/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 1017/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1017/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 1017/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1017/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 1017/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 4/5; 1017/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 1017/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1017/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 1017/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1018/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 1018/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1018/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 1018/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1018/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 1018/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1018/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 1018/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1018/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 1018/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1019/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 1019/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1019/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 1019/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1019/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 1019/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1019/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 1019/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1019/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 1019/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1020/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 1020/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1020/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 1020/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1020/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 1020/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1020/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 1020/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1020/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 1020/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1021/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 1021/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06;, score=0.556 total time=   0.1s\n",
            "[CV 2/5; 1021/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 1021/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06;, score=0.536 total time=   0.1s\n",
            "[CV 3/5; 1021/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 1021/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06;, score=0.544 total time=   0.1s\n",
            "[CV 4/5; 1021/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 1021/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06;, score=0.516 total time=   0.1s\n",
            "[CV 5/5; 1021/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 1021/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06;, score=0.508 total time=   0.1s\n",
            "[CV 1/5; 1022/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 1022/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05;, score=0.540 total time=   0.0s\n",
            "[CV 2/5; 1022/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 1022/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05;, score=0.508 total time=   0.0s\n",
            "[CV 3/5; 1022/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 1022/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05;, score=0.528 total time=   0.0s\n",
            "[CV 4/5; 1022/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 1022/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05;, score=0.560 total time=   0.0s\n",
            "[CV 5/5; 1022/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 1022/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05;, score=0.536 total time=   0.1s\n",
            "[CV 1/5; 1023/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 1023/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001;, score=0.532 total time=   0.0s\n",
            "[CV 2/5; 1023/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 1023/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001;, score=0.488 total time=   0.0s\n",
            "[CV 3/5; 1023/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 1023/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001;, score=0.484 total time=   0.0s\n",
            "[CV 4/5; 1023/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 1023/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001;, score=0.496 total time=   0.0s\n",
            "[CV 5/5; 1023/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 1023/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001;, score=0.508 total time=   0.0s\n",
            "[CV 1/5; 1024/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 1/5; 1024/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1024/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 2/5; 1024/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=0.001;, score=0.548 total time=   0.0s\n",
            "[CV 3/5; 1024/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 3/5; 1024/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=0.001;, score=0.532 total time=   0.0s\n",
            "[CV 4/5; 1024/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 4/5; 1024/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1024/1344] START alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 5/5; 1024/1344] END alpha=10, loss=log_loss, max_iter=1000, penalty=None, tol=0.001;, score=0.456 total time=   0.0s\n",
            "[CV 1/5; 1025/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 1025/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1025/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 1025/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1025/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 1025/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1025/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 1025/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1025/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 1025/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1026/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 1026/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1026/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 1026/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1026/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 1026/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1026/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 1026/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1026/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 1026/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1027/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 1027/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1027/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 1027/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1027/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 1027/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1027/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 1027/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1027/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 1027/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1028/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 1028/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1028/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 1028/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1028/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 1028/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1028/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 1028/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1028/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 1028/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1029/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 1029/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06;, score=0.480 total time=   0.1s\n",
            "[CV 2/5; 1029/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 1029/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1029/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 1029/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1029/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 1029/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 5/5; 1029/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 1029/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1030/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 1030/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1030/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 1030/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1030/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 1030/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1030/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 1030/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1030/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 1030/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1031/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 1031/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1031/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 1031/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1031/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 1031/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1031/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 1031/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1031/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 1031/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1032/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 1032/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1032/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 1032/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1032/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 1032/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1032/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 1032/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1032/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 1032/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1033/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 1033/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1033/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 1033/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1033/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 1033/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1033/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 1033/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 5/5; 1033/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 1033/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1034/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 1034/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1034/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 1034/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1034/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 1034/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1034/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 1034/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1034/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 1034/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1035/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 1035/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1035/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 1035/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1035/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 1035/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1035/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 1035/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1035/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 1035/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1036/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 1036/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1036/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 1036/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1036/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 1036/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1036/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 1036/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1036/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 1036/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1037/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 1037/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06;, score=0.548 total time=   0.2s\n",
            "[CV 2/5; 1037/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 1037/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 3/5; 1037/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 1037/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06;, score=0.484 total time=   0.1s\n",
            "[CV 4/5; 1037/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 1037/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06;, score=0.524 total time=   0.3s\n",
            "[CV 5/5; 1037/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 1037/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06;, score=0.596 total time=   0.0s\n",
            "[CV 1/5; 1038/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 1038/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1038/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 1038/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05;, score=0.508 total time=   0.0s\n",
            "[CV 3/5; 1038/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 1038/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05;, score=0.500 total time=   0.0s\n",
            "[CV 4/5; 1038/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 1038/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05;, score=0.548 total time=   0.0s\n",
            "[CV 5/5; 1038/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 1038/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05;, score=0.436 total time=   0.0s\n",
            "[CV 1/5; 1039/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 1039/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001;, score=0.464 total time=   0.0s\n",
            "[CV 2/5; 1039/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 1039/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001;, score=0.508 total time=   0.0s\n",
            "[CV 3/5; 1039/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 1039/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001;, score=0.560 total time=   0.0s\n",
            "[CV 4/5; 1039/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 1039/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 5/5; 1039/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 1039/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001;, score=0.508 total time=   0.0s\n",
            "[CV 1/5; 1040/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 1/5; 1040/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=0.001;, score=0.540 total time=   0.0s\n",
            "[CV 2/5; 1040/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 2/5; 1040/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=0.001;, score=0.500 total time=   0.0s\n",
            "[CV 3/5; 1040/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 3/5; 1040/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=0.001;, score=0.460 total time=   0.0s\n",
            "[CV 4/5; 1040/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 4/5; 1040/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=0.001;, score=0.468 total time=   0.0s\n",
            "[CV 5/5; 1040/1344] START alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 5/5; 1040/1344] END alpha=10, loss=log_loss, max_iter=10000, penalty=None, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 1/5; 1041/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 1041/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1041/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 1041/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1041/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 1041/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1041/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 1041/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1041/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 1041/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1042/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 1042/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1042/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 1042/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1042/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 1042/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1042/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 1042/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1042/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 1042/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1043/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 1043/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1043/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 1043/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1043/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 1043/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1043/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 1043/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1043/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 1043/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1044/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 1044/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1044/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 1044/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1044/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 1044/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1044/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 1044/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1044/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 1044/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1045/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 1045/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06;, score=0.480 total time=   0.1s\n",
            "[CV 2/5; 1045/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 1045/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1045/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 1045/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1045/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 1045/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 5/5; 1045/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 1045/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1046/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 1046/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1046/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 1046/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1046/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 1046/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1046/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 1046/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1046/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 1046/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1047/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 1047/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1047/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 1047/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1047/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 1047/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1047/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 1047/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1047/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 1047/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1048/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 1048/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1048/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 1048/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1048/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 1048/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1048/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 1048/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1048/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 1048/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1049/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 1049/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1049/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 1049/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1049/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 1049/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1049/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 1049/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1049/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 1049/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1050/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 1050/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1050/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 1050/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1050/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 1050/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1050/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 1050/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1050/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 1050/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1051/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 1051/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1051/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 1051/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1051/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 1051/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1051/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 1051/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1051/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 1051/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1052/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 1052/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1052/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 1052/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1052/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 1052/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1052/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 1052/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1052/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 1052/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1053/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 1053/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06;, score=0.556 total time=   0.2s\n",
            "[CV 2/5; 1053/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 1053/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06;, score=0.512 total time=   0.3s\n",
            "[CV 3/5; 1053/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 1053/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06;, score=0.516 total time=   0.2s\n",
            "[CV 4/5; 1053/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 1053/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06;, score=0.528 total time=   0.4s\n",
            "[CV 5/5; 1053/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 1053/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06;, score=0.508 total time=   0.2s\n",
            "[CV 1/5; 1054/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 1054/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05;, score=0.508 total time=   0.0s\n",
            "[CV 2/5; 1054/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 1054/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05;, score=0.500 total time=   0.0s\n",
            "[CV 3/5; 1054/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 1054/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 4/5; 1054/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 1054/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05;, score=0.468 total time=   0.0s\n",
            "[CV 5/5; 1054/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 1054/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05;, score=0.540 total time=   0.0s\n",
            "[CV 1/5; 1055/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 1055/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001;, score=0.540 total time=   0.0s\n",
            "[CV 2/5; 1055/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 1055/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001;, score=0.496 total time=   0.0s\n",
            "[CV 3/5; 1055/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 1055/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 4/5; 1055/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 1055/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001;, score=0.500 total time=   0.0s\n",
            "[CV 5/5; 1055/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 1055/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001;, score=0.560 total time=   0.0s\n",
            "[CV 1/5; 1056/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 1/5; 1056/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=0.001;, score=0.512 total time=   0.0s\n",
            "[CV 2/5; 1056/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 2/5; 1056/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=0.001;, score=0.492 total time=   0.0s\n",
            "[CV 3/5; 1056/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 3/5; 1056/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1056/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 4/5; 1056/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=0.001;, score=0.532 total time=   0.0s\n",
            "[CV 5/5; 1056/1344] START alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 5/5; 1056/1344] END alpha=10, loss=log_loss, max_iter=100000, penalty=None, tol=0.001;, score=0.468 total time=   0.0s\n",
            "[CV 1/5; 1057/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 1057/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.496 total time=   0.0s\n",
            "[CV 2/5; 1057/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 1057/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 3/5; 1057/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 1057/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1057/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 1057/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.452 total time=   0.0s\n",
            "[CV 5/5; 1057/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 1057/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1058/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 1058/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1058/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 1058/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1058/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 1058/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1058/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 1058/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1058/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 1058/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.480 total time=   0.0s\n",
            "[CV 1/5; 1059/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 1059/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1059/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 1059/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1059/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 1059/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.484 total time=   0.0s\n",
            "[CV 4/5; 1059/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 1059/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1059/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 1059/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1060/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 1060/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1060/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 1060/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1060/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 1060/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.484 total time=   0.0s\n",
            "[CV 4/5; 1060/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 1060/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1060/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 1060/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1061/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 1061/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.480 total time=   0.1s\n",
            "[CV 2/5; 1061/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 1061/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 3/5; 1061/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 1061/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.1s\n",
            "[CV 4/5; 1061/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 1061/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.1s\n",
            "[CV 5/5; 1061/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 1061/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.1s"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[CV 1/5; 1062/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 1062/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1062/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 1062/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1062/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 1062/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1062/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 1062/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1062/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 1062/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1063/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 1063/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1063/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 1063/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1063/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 1063/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1063/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 1063/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1063/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 1063/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1064/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 1064/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1064/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 1064/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1064/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 1064/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1064/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 1064/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1064/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 1064/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1065/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 1065/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.480 total time=   0.1s\n",
            "[CV 2/5; 1065/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 1065/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.1s\n",
            "[CV 3/5; 1065/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 1065/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 4/5; 1065/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 1065/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.1s\n",
            "[CV 5/5; 1065/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 1065/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 1/5; 1066/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 1066/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1066/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 1066/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1066/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 1066/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1066/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 1066/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1066/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 1066/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.1s\n",
            "[CV 1/5; 1067/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 1067/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1067/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 1067/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1067/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 1067/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1067/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 1067/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1067/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 1067/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1068/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 1068/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1068/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 1068/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1068/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 1068/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1068/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 1068/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1068/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 1068/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1069/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 1069/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1069/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 1069/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.552 total time=   0.0s\n",
            "[CV 3/5; 1069/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 1069/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.576 total time=   0.1s\n",
            "[CV 4/5; 1069/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 1069/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.524 total time=   0.1s\n",
            "[CV 5/5; 1069/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 1069/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.532 total time=   0.0s\n",
            "[CV 1/5; 1070/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 1070/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1070/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 1070/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.512 total time=   0.0s\n",
            "[CV 3/5; 1070/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 1070/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.572 total time=   0.0s\n",
            "[CV 4/5; 1070/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 1070/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.552 total time=   0.1s\n",
            "[CV 5/5; 1070/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 1070/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.492 total time=   0.0s\n",
            "[CV 1/5; 1071/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 1071/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.512 total time=   0.0s\n",
            "[CV 2/5; 1071/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 1071/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.504 total time=   0.0s\n",
            "[CV 3/5; 1071/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 1071/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.536 total time=   0.0s\n",
            "[CV 4/5; 1071/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 1071/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.572 total time=   0.0s\n",
            "[CV 5/5; 1071/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 1071/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.552 total time=   0.0s\n",
            "[CV 1/5; 1072/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 1/5; 1072/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.536 total time=   0.0s\n",
            "[CV 2/5; 1072/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 2/5; 1072/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 3/5; 1072/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 3/5; 1072/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.560 total time=   0.0s\n",
            "[CV 4/5; 1072/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 4/5; 1072/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.552 total time=   0.0s\n",
            "[CV 5/5; 1072/1344] START alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 5/5; 1072/1344] END alpha=10, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.496 total time=   0.0s\n",
            "[CV 1/5; 1073/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 1073/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.500 total time=   0.1s\n",
            "[CV 2/5; 1073/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 1073/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.544 total time=   0.0s\n",
            "[CV 3/5; 1073/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 1073/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.496 total time=   0.2s\n",
            "[CV 4/5; 1073/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 1073/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.448 total time=   0.1s\n",
            "[CV 5/5; 1073/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 1073/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1074/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 1074/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1074/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 1074/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1074/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 1074/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1074/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 1074/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1074/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 1074/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1075/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 1075/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1075/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 1075/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1075/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 1075/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1075/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 1075/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1075/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 1075/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1076/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 1076/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1076/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 1076/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1076/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 1076/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1076/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 1076/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1076/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 1076/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1077/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 1077/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.480 total time=   0.1s\n",
            "[CV 2/5; 1077/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 1077/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.1s\n",
            "[CV 3/5; 1077/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 1077/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.1s\n",
            "[CV 4/5; 1077/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 1077/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.1s\n",
            "[CV 5/5; 1077/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 1077/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.2s\n",
            "[CV 1/5; 1078/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 1078/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1078/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 1078/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1078/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 1078/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1078/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 1078/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1078/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 1078/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1079/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 1079/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1079/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 1079/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1079/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 1079/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1079/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 1079/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1079/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 1079/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1080/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 1080/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1080/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 1080/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1080/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 1080/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1080/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 1080/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1080/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 1080/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1081/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 1081/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.480 total time=   0.1s\n",
            "[CV 2/5; 1081/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 1081/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.2s\n",
            "[CV 3/5; 1081/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 1081/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.1s\n",
            "[CV 4/5; 1081/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 1081/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.1s\n",
            "[CV 5/5; 1081/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 1081/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.3s\n",
            "[CV 1/5; 1082/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 1082/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1082/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 1082/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1082/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 1082/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.1s\n",
            "[CV 4/5; 1082/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 1082/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1082/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 1082/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.1s\n",
            "[CV 1/5; 1083/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 1083/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1083/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 1083/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1083/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 1083/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1083/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 1083/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1083/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 1083/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1084/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 1084/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1084/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 1084/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1084/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 1084/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1084/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 1084/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1084/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 1084/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1085/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 1085/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.568 total time=   0.6s\n",
            "[CV 2/5; 1085/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 1085/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.524 total time=   0.6s\n",
            "[CV 3/5; 1085/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 1085/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.512 total time=   0.5s\n",
            "[CV 4/5; 1085/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 1085/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.556 total time=   0.4s\n",
            "[CV 5/5; 1085/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 1085/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.640 total time=   0.1s\n",
            "[CV 1/5; 1086/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 1086/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.532 total time=   0.1s\n",
            "[CV 2/5; 1086/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 1086/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.504 total time=   0.1s\n",
            "[CV 3/5; 1086/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 1086/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.528 total time=   0.0s\n",
            "[CV 4/5; 1086/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 1086/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.512 total time=   0.1s\n",
            "[CV 5/5; 1086/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 1086/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.624 total time=   0.0s\n",
            "[CV 1/5; 1087/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 1087/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1087/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 1087/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.556 total time=   0.0s\n",
            "[CV 3/5; 1087/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 1087/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.500 total time=   0.0s\n",
            "[CV 4/5; 1087/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 1087/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.500 total time=   0.0s\n",
            "[CV 5/5; 1087/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 1087/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.536 total time=   0.0s\n",
            "[CV 1/5; 1088/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 1/5; 1088/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.620 total time=   0.0s\n",
            "[CV 2/5; 1088/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 2/5; 1088/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 3/5; 1088/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 3/5; 1088/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.568 total time=   0.0s\n",
            "[CV 4/5; 1088/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 4/5; 1088/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.540 total time=   0.0s\n",
            "[CV 5/5; 1088/1344] START alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 5/5; 1088/1344] END alpha=10, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.560 total time=   0.0s\n",
            "[CV 1/5; 1089/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 1089/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.520 total time=   0.5s\n",
            "[CV 2/5; 1089/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 1089/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.1s\n",
            "[CV 3/5; 1089/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 1089/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.1s\n",
            "[CV 4/5; 1089/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 1089/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1089/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 1089/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.512 total time=   0.1s\n",
            "[CV 1/5; 1090/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 1090/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.520 total time=   0.1s\n",
            "[CV 2/5; 1090/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 1090/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1090/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 1090/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1090/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 1090/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.452 total time=   0.0s\n",
            "[CV 5/5; 1090/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 1090/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.480 total time=   0.0s\n",
            "[CV 1/5; 1091/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 1091/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1091/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 1091/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1091/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 1091/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 4/5; 1091/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 1091/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1091/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 1091/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1092/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 1092/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1092/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 1092/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1092/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 1092/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1092/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 1092/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1092/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 1092/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1093/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 1093/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.480 total time=   0.1s\n",
            "[CV 2/5; 1093/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 1093/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.2s\n",
            "[CV 3/5; 1093/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 1093/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.1s\n",
            "[CV 4/5; 1093/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 1093/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.1s\n",
            "[CV 5/5; 1093/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 1093/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 1/5; 1094/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 1094/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1094/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 1094/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1094/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 1094/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1094/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 1094/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1094/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 1094/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1095/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 1095/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1095/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 1095/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1095/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 1095/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1095/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 1095/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1095/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 1095/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1096/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 1096/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1096/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 1096/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1096/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 1096/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1096/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 1096/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1096/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 1096/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1097/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 1097/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.520 total time=   0.2s\n",
            "[CV 2/5; 1097/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 1097/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.2s\n",
            "[CV 3/5; 1097/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 1097/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 4/5; 1097/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 1097/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.1s\n",
            "[CV 5/5; 1097/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 1097/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1098/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 1098/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1098/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 1098/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1098/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 1098/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1098/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 1098/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1098/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 1098/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1099/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 1099/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1099/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 1099/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1099/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 1099/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1099/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 1099/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1099/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 1099/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1100/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 1100/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1100/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 1100/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1100/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 1100/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1100/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 1100/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1100/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 1100/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1101/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 1101/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.532 total time=   0.6s\n",
            "[CV 2/5; 1101/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 1101/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.568 total time=   0.4s\n",
            "[CV 3/5; 1101/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 1101/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.528 total time=   0.4s\n",
            "[CV 4/5; 1101/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 1101/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.560 total time=   1.2s\n",
            "[CV 5/5; 1101/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 1101/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.672 total time=   0.2s\n",
            "[CV 1/5; 1102/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 1102/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1102/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 1102/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.580 total time=   0.0s\n",
            "[CV 3/5; 1102/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 1102/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.576 total time=   0.2s\n",
            "[CV 4/5; 1102/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 1102/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1102/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 1102/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.520 total time=   0.1s\n",
            "[CV 1/5; 1103/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 1103/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 2/5; 1103/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 1103/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.592 total time=   0.1s\n",
            "[CV 3/5; 1103/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 1103/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1103/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 1103/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.516 total time=   0.0s\n",
            "[CV 5/5; 1103/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 1103/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.632 total time=   0.0s\n",
            "[CV 1/5; 1104/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 1/5; 1104/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.528 total time=   0.0s\n",
            "[CV 2/5; 1104/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 2/5; 1104/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.488 total time=   0.0s\n",
            "[CV 3/5; 1104/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 3/5; 1104/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.516 total time=   0.0s\n",
            "[CV 4/5; 1104/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 4/5; 1104/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.548 total time=   0.0s\n",
            "[CV 5/5; 1104/1344] START alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 5/5; 1104/1344] END alpha=10, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.500 total time=   0.0s\n",
            "[CV 1/5; 1105/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 1105/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.968 total time=   0.0s\n",
            "[CV 2/5; 1105/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 1105/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 1105/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 1105/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.900 total time=   0.0s\n",
            "[CV 4/5; 1105/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 1105/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.672 total time=   0.0s\n",
            "[CV 5/5; 1105/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 1105/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.924 total time=   0.0s\n",
            "[CV 1/5; 1106/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 1106/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.776 total time=   0.0s\n",
            "[CV 2/5; 1106/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 1106/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.472 total time=   0.1s\n",
            "[CV 3/5; 1106/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 1106/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 1106/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 1106/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.912 total time=   0.0s\n",
            "[CV 5/5; 1106/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 1106/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.792 total time=   0.0s\n",
            "[CV 1/5; 1107/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 1107/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.816 total time=   0.0s\n",
            "[CV 2/5; 1107/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 1107/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.492 total time=   0.0s\n",
            "[CV 3/5; 1107/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 1107/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.592 total time=   0.0s\n",
            "[CV 4/5; 1107/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 1107/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1107/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 1107/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1108/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 1108/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1108/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 1108/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1108/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 1108/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1108/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 1108/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1108/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 1108/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.904 total time=   0.0s\n",
            "[CV 1/5; 1109/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 1109/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1109/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 1109/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1109/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 1109/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1109/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 1109/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1109/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 1109/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1110/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 1110/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1110/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 1110/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1110/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 1110/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1110/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 1110/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1110/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 1110/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1111/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 1111/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1111/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 1111/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1111/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 1111/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1111/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 1111/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1111/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 1111/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1112/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 1112/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1112/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 1112/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1112/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 1112/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1112/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 1112/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1112/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 1112/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1113/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 1113/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1113/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 1113/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1113/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 1113/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1113/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 1113/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1113/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 1113/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1114/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 1114/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1114/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 1114/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1114/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 1114/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1114/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 1114/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1114/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 1114/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1115/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 1115/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1115/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 1115/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1115/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 1115/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1115/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 1115/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1115/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 1115/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1116/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 1116/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1116/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 1116/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1116/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 1116/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1116/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 1116/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1116/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 1116/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1117/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 1117/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.572 total time=   0.0s\n",
            "[CV 2/5; 1117/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 1117/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.500 total time=   0.0s\n",
            "[CV 3/5; 1117/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 1117/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.488 total time=   0.0s\n",
            "[CV 4/5; 1117/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 1117/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.504 total time=   0.1s\n",
            "[CV 5/5; 1117/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 1117/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.544 total time=   0.0s\n",
            "[CV 1/5; 1118/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 1118/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.492 total time=   0.1s\n",
            "[CV 2/5; 1118/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 1118/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.504 total time=   0.0s\n",
            "[CV 3/5; 1118/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 1118/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.536 total time=   0.0s\n",
            "[CV 4/5; 1118/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 1118/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.540 total time=   0.1s\n",
            "[CV 5/5; 1118/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 1118/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.472 total time=   0.0s\n",
            "[CV 1/5; 1119/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 1119/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.448 total time=   0.0s\n",
            "[CV 2/5; 1119/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 1119/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.492 total time=   0.0s\n",
            "[CV 3/5; 1119/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 1119/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.512 total time=   0.0s\n",
            "[CV 4/5; 1119/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 1119/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.468 total time=   0.0s\n",
            "[CV 5/5; 1119/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 1119/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.508 total time=   0.0s\n",
            "[CV 1/5; 1120/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 1/5; 1120/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.560 total time=   0.0s\n",
            "[CV 2/5; 1120/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 2/5; 1120/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.468 total time=   0.0s\n",
            "[CV 3/5; 1120/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 3/5; 1120/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.544 total time=   0.0s\n",
            "[CV 4/5; 1120/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 4/5; 1120/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.472 total time=   0.0s\n",
            "[CV 5/5; 1120/1344] START alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 5/5; 1120/1344] END alpha=10, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.492 total time=   0.0s\n",
            "[CV 1/5; 1121/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 1121/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.908 total time=   0.0s\n",
            "[CV 2/5; 1121/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 1121/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 3/5; 1121/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 1121/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.728 total time=   0.0s\n",
            "[CV 4/5; 1121/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 1121/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.920 total time=   0.0s\n",
            "[CV 5/5; 1121/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 1121/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 1122/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 1122/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.784 total time=   0.0s\n",
            "[CV 2/5; 1122/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 1122/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 1122/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 1122/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.952 total time=   0.0s\n",
            "[CV 4/5; 1122/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 1122/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.716 total time=   0.1s\n",
            "[CV 5/5; 1122/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 1122/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.748 total time=   0.0s\n",
            "[CV 1/5; 1123/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 1123/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.528 total time=   0.0s\n",
            "[CV 2/5; 1123/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 1123/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.468 total time=   0.0s\n",
            "[CV 3/5; 1123/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 1123/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.908 total time=   0.0s\n",
            "[CV 4/5; 1123/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 1123/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.960 total time=   0.0s\n",
            "[CV 5/5; 1123/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 1123/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 1124/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 1124/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1124/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 1124/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1124/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 1124/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1124/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 1124/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1124/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 1124/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1125/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 1125/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1125/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 1125/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1125/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 1125/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1125/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 1125/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1125/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 1125/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1126/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 1126/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1126/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 1126/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1126/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 1126/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1126/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 1126/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1126/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 1126/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1127/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 1127/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1127/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 1127/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1127/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 1127/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1127/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 1127/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1127/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 1127/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1128/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 1128/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1128/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 1128/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1128/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 1128/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1128/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 1128/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1128/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 1128/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1129/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 1129/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1129/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 1129/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1129/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 1129/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1129/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 1129/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1129/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 1129/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1130/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 1130/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.520 total time=   0.1s\n",
            "[CV 2/5; 1130/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 1130/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1130/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 1130/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1130/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 1130/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1130/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 1130/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1131/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 1131/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1131/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 1131/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1131/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 1131/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1131/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 1131/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1131/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 1131/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1132/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 1132/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1132/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 1132/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1132/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 1132/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1132/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 1132/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1132/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 1132/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1133/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 1133/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.464 total time=   0.4s\n",
            "[CV 2/5; 1133/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 1133/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.532 total time=   0.4s\n",
            "[CV 3/5; 1133/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 1133/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.524 total time=   0.5s\n",
            "[CV 4/5; 1133/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 1133/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.600 total time=   0.6s\n",
            "[CV 5/5; 1133/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 1133/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.492 total time=   0.6s\n",
            "[CV 1/5; 1134/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 1134/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.448 total time=   0.5s\n",
            "[CV 2/5; 1134/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 1134/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.520 total time=   0.1s\n",
            "[CV 3/5; 1134/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 1134/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.520 total time=   0.1s\n",
            "[CV 4/5; 1134/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 1134/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.468 total time=   0.3s\n",
            "[CV 5/5; 1134/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 1134/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.488 total time=   0.3s\n",
            "[CV 1/5; 1135/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 1135/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.572 total time=   0.0s\n",
            "[CV 2/5; 1135/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 1135/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.456 total time=   0.0s\n",
            "[CV 3/5; 1135/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 1135/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.512 total time=   0.0s\n",
            "[CV 4/5; 1135/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 1135/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.464 total time=   0.0s\n",
            "[CV 5/5; 1135/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 1135/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.560 total time=   0.0s\n",
            "[CV 1/5; 1136/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 1/5; 1136/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.468 total time=   0.0s\n",
            "[CV 2/5; 1136/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 2/5; 1136/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.504 total time=   0.0s\n",
            "[CV 3/5; 1136/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 3/5; 1136/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.448 total time=   0.0s\n",
            "[CV 4/5; 1136/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 4/5; 1136/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.528 total time=   0.0s\n",
            "[CV 5/5; 1136/1344] START alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 5/5; 1136/1344] END alpha=10, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 1/5; 1137/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 1137/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 2/5; 1137/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 1137/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.968 total time=   0.0s\n",
            "[CV 3/5; 1137/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 1137/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.928 total time=   0.0s\n",
            "[CV 4/5; 1137/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 1137/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.936 total time=   0.0s\n",
            "[CV 5/5; 1137/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 1137/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 1138/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 1138/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.788 total time=   0.0s\n",
            "[CV 2/5; 1138/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 1138/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.692 total time=   0.1s\n",
            "[CV 3/5; 1138/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 1138/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.852 total time=   0.0s\n",
            "[CV 4/5; 1138/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 1138/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.708 total time=   0.0s\n",
            "[CV 5/5; 1138/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 1138/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.768 total time=   0.0s\n",
            "[CV 1/5; 1139/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 1139/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.528 total time=   0.0s\n",
            "[CV 2/5; 1139/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 1139/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.836 total time=   0.0s\n",
            "[CV 3/5; 1139/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 1139/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1139/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 1139/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.636 total time=   0.0s\n",
            "[CV 5/5; 1139/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 1139/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 1/5; 1140/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 1140/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1140/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 1140/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 3/5; 1140/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 1140/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1140/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 1140/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1140/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 1140/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1141/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 1141/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1141/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 1141/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1141/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 1141/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1141/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 1141/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1141/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 1141/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1142/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 1142/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1142/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 1142/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1142/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 1142/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1142/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 1142/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1142/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 1142/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1143/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 1143/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1143/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 1143/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1143/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 1143/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1143/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 1143/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1143/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 1143/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1144/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 1144/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1144/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 1144/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1144/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 1144/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1144/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 1144/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1144/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 1144/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1145/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 1145/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1145/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 1145/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1145/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 1145/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1145/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 1145/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1145/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 1145/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1146/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 1146/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1146/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 1146/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1146/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 1146/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1146/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 1146/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1146/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 1146/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.1s\n",
            "[CV 1/5; 1147/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 1147/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1147/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 1147/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1147/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 1147/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1147/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 1147/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1147/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 1147/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1148/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 1148/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1148/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 1148/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1148/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 1148/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1148/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 1148/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1148/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 1148/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1149/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 1149/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.532 total time=   4.1s\n",
            "[CV 2/5; 1149/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 1149/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.512 total time=   0.7s\n",
            "[CV 3/5; 1149/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 1149/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.524 total time=   0.9s\n",
            "[CV 4/5; 1149/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 1149/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.508 total time=   1.1s\n",
            "[CV 5/5; 1149/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 1149/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.568 total time=   0.7s\n",
            "[CV 1/5; 1150/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 1150/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.492 total time=   0.1s\n",
            "[CV 2/5; 1150/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 1150/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.552 total time=   0.0s\n",
            "[CV 3/5; 1150/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 1150/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.496 total time=   0.1s\n",
            "[CV 4/5; 1150/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 1150/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.456 total time=   0.1s\n",
            "[CV 5/5; 1150/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 1150/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.508 total time=   0.1s\n",
            "[CV 1/5; 1151/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 1151/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.564 total time=   0.0s\n",
            "[CV 2/5; 1151/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 1151/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.496 total time=   0.0s\n",
            "[CV 3/5; 1151/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 1151/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.488 total time=   0.0s\n",
            "[CV 4/5; 1151/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 1151/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.468 total time=   0.0s\n",
            "[CV 5/5; 1151/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 1151/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.460 total time=   0.0s\n",
            "[CV 1/5; 1152/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 1/5; 1152/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.540 total time=   0.0s\n",
            "[CV 2/5; 1152/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 2/5; 1152/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.512 total time=   0.0s\n",
            "[CV 3/5; 1152/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 3/5; 1152/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1152/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 4/5; 1152/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.464 total time=   0.0s\n",
            "[CV 5/5; 1152/1344] START alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 5/5; 1152/1344] END alpha=10, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.408 total time=   0.0s\n",
            "[CV 1/5; 1153/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 1153/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1153/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 1153/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1153/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 1153/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1153/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 1153/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1153/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 1153/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1154/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 1154/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1154/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 1154/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1154/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 1154/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1154/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 1154/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1154/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 1154/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1155/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 1155/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1155/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 1155/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1155/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 1155/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1155/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 1155/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1155/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 1155/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1156/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 1156/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1156/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 1156/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1156/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 1156/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1156/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 1156/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1156/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 1156/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1157/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 1157/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1157/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 1157/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1157/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 1157/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1157/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 1157/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1157/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 1157/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1158/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 1158/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1158/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 1158/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1158/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 1158/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1158/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 1158/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1158/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 1158/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1159/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 1159/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1159/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 1159/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1159/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 1159/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1159/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 1159/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1159/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 1159/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1160/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 1160/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1160/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 1160/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1160/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 1160/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1160/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 1160/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1160/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 1160/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1161/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 1161/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1161/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 1161/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1161/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 1161/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1161/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 1161/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1161/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 1161/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1162/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 1162/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1162/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 1162/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1162/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 1162/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1162/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 1162/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1162/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 1162/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1163/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 1163/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1163/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 1163/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1163/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 1163/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1163/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 1163/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1163/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 1163/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1164/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 1164/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1164/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 1164/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1164/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 1164/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1164/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 1164/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1164/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 1164/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1165/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 1165/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 2/5; 1165/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 1165/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1165/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 1165/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.540 total time=   0.0s\n",
            "[CV 4/5; 1165/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 1165/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.532 total time=   0.1s\n",
            "[CV 5/5; 1165/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 1165/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.580 total time=   0.1s\n",
            "[CV 1/5; 1166/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 1166/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.528 total time=   0.0s\n",
            "[CV 2/5; 1166/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 1166/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.476 total time=   0.1s\n",
            "[CV 3/5; 1166/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 1166/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.472 total time=   0.0s\n",
            "[CV 4/5; 1166/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 1166/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.476 total time=   0.1s\n",
            "[CV 5/5; 1166/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 1166/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.560 total time=   0.1s\n",
            "[CV 1/5; 1167/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 1167/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.572 total time=   0.0s\n",
            "[CV 2/5; 1167/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 1167/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.508 total time=   0.0s\n",
            "[CV 3/5; 1167/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 1167/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.536 total time=   0.0s\n",
            "[CV 4/5; 1167/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 1167/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.504 total time=   0.0s\n",
            "[CV 5/5; 1167/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 1167/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.440 total time=   0.0s\n",
            "[CV 1/5; 1168/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 1/5; 1168/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 2/5; 1168/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 2/5; 1168/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.536 total time=   0.0s\n",
            "[CV 3/5; 1168/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 3/5; 1168/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.556 total time=   0.0s\n",
            "[CV 4/5; 1168/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 4/5; 1168/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.464 total time=   0.0s\n",
            "[CV 5/5; 1168/1344] START alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 5/5; 1168/1344] END alpha=100, loss=hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.512 total time=   0.0s\n",
            "[CV 1/5; 1169/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 1169/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1169/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 1169/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1169/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 1169/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1169/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 1169/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1169/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 1169/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1170/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 1170/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1170/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 1170/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1170/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 1170/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1170/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 1170/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1170/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 1170/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1171/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 1171/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1171/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 1171/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1171/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 1171/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1171/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 1171/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1171/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 1171/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1172/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 1172/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1172/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 1172/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1172/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 1172/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1172/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 1172/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1172/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 1172/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1173/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 1173/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1173/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 1173/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1173/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 1173/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1173/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 1173/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1173/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 1173/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1174/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 1174/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1174/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 1174/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1174/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 1174/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1174/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 1174/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1174/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 1174/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1175/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 1175/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1175/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 1175/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1175/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 1175/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1175/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 1175/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1175/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 1175/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1176/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 1176/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1176/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 1176/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1176/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 1176/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1176/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 1176/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1176/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 1176/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1177/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 1177/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1177/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 1177/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1177/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 1177/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1177/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 1177/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1177/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 1177/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1178/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 1178/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1178/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 1178/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1178/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 1178/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1178/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 1178/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1178/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 1178/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1179/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 1179/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1179/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 1179/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1179/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 1179/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1179/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 1179/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1179/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 1179/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1180/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 1180/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1180/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 1180/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1180/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 1180/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1180/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 1180/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1180/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 1180/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1181/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 1181/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.452 total time=   0.3s\n",
            "[CV 2/5; 1181/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 1181/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.488 total time=   0.5s\n",
            "[CV 3/5; 1181/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 1181/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.536 total time=   0.5s\n",
            "[CV 4/5; 1181/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 1181/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.536 total time=   0.2s\n",
            "[CV 5/5; 1181/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 1181/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.432 total time=   0.3s\n",
            "[CV 1/5; 1182/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 1182/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.472 total time=   0.0s\n",
            "[CV 2/5; 1182/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 1182/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.500 total time=   0.0s\n",
            "[CV 3/5; 1182/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 1182/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.472 total time=   0.0s\n",
            "[CV 4/5; 1182/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 1182/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.500 total time=   0.0s\n",
            "[CV 5/5; 1182/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 1182/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.464 total time=   0.0s\n",
            "[CV 1/5; 1183/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 1183/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.516 total time=   0.0s\n",
            "[CV 2/5; 1183/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 1183/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.484 total time=   0.0s\n",
            "[CV 3/5; 1183/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 1183/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.456 total time=   0.0s\n",
            "[CV 4/5; 1183/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 1183/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.468 total time=   0.0s\n",
            "[CV 5/5; 1183/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 1183/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.544 total time=   0.0s\n",
            "[CV 1/5; 1184/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 1/5; 1184/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.532 total time=   0.0s\n",
            "[CV 2/5; 1184/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 2/5; 1184/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.500 total time=   0.0s\n",
            "[CV 3/5; 1184/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 3/5; 1184/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.464 total time=   0.0s\n",
            "[CV 4/5; 1184/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 4/5; 1184/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.456 total time=   0.0s\n",
            "[CV 5/5; 1184/1344] START alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 5/5; 1184/1344] END alpha=100, loss=hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.568 total time=   0.0s\n",
            "[CV 1/5; 1185/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 1185/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1185/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 1185/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1185/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 1185/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1185/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 1185/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1185/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 1185/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1186/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 1186/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1186/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 1186/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1186/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 1186/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1186/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 1186/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1186/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 1186/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1187/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 1187/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1187/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 1187/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1187/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 1187/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1187/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 1187/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1187/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 1187/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1188/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 1188/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1188/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 1188/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1188/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 1188/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1188/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 1188/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1188/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 1188/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1189/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 1189/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1189/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 1189/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1189/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 1189/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1189/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 1189/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1189/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 1189/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1190/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 1190/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1190/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 1190/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1190/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 1190/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1190/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 1190/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1190/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 1190/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1191/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 1191/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1191/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 1191/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1191/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 1191/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1191/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 1191/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1191/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 1191/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1192/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 1192/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1192/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 1192/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1192/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 1192/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1192/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 1192/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1192/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 1192/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1193/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 1193/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1193/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 1193/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1193/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 1193/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1193/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 1193/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1193/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 1193/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1194/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 1194/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1194/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 1194/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1194/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 1194/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1194/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 1194/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1194/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 1194/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1195/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 1195/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1195/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 1195/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1195/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 1195/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1195/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 1195/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1195/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 1195/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1196/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 1196/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1196/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 1196/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1196/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 1196/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1196/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 1196/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1196/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 1196/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1197/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 1197/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.496 total time=   0.2s\n",
            "[CV 2/5; 1197/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 1197/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.516 total time=   0.3s\n",
            "[CV 3/5; 1197/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 1197/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.516 total time=   0.3s\n",
            "[CV 4/5; 1197/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 1197/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.536 total time=   0.5s\n",
            "[CV 5/5; 1197/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 1197/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.588 total time=   0.1s\n",
            "[CV 1/5; 1198/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 1198/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.488 total time=   0.0s\n",
            "[CV 2/5; 1198/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 1198/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.480 total time=   0.0s\n",
            "[CV 3/5; 1198/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 1198/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.456 total time=   0.0s\n",
            "[CV 4/5; 1198/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 1198/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.480 total time=   0.0s\n",
            "[CV 5/5; 1198/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 1198/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.436 total time=   0.0s\n",
            "[CV 1/5; 1199/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 1199/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.540 total time=   0.0s\n",
            "[CV 2/5; 1199/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 1199/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1199/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 1199/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.456 total time=   0.0s\n",
            "[CV 4/5; 1199/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 1199/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.532 total time=   0.0s\n",
            "[CV 5/5; 1199/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 1199/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.440 total time=   0.0s\n",
            "[CV 1/5; 1200/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 1/5; 1200/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.460 total time=   0.0s\n",
            "[CV 2/5; 1200/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 2/5; 1200/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.500 total time=   0.0s\n",
            "[CV 3/5; 1200/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 3/5; 1200/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.528 total time=   0.0s\n",
            "[CV 4/5; 1200/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 4/5; 1200/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1200/1344] START alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 5/5; 1200/1344] END alpha=100, loss=hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.508 total time=   0.0s\n",
            "[CV 1/5; 1201/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 1201/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1201/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 1201/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1201/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 1201/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1201/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 1201/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1201/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 1201/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1202/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 1202/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1202/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 1202/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1202/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 1202/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1202/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 1202/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1202/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 1202/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1203/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 1203/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1203/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 1203/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1203/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 1203/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1203/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 1203/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1203/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 1203/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1204/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 1204/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1204/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 1204/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1204/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 1204/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1204/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 1204/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1204/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 1204/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1205/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 1205/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1205/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 1205/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1205/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 1205/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1205/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 1205/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1205/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 1205/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1206/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 1206/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1206/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 1206/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1206/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 1206/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1206/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 1206/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1206/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 1206/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1207/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 1207/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1207/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 1207/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1207/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 1207/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1207/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 1207/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1207/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 1207/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1208/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 1208/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1208/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 1208/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1208/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 1208/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1208/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 1208/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1208/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 1208/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1209/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 1209/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1209/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 1209/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1209/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 1209/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1209/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 1209/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1209/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 1209/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1210/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 1210/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1210/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 1210/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1210/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 1210/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1210/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 1210/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1210/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 1210/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1211/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 1211/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1211/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 1211/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1211/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 1211/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1211/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 1211/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1211/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 1211/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1212/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 1212/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1212/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 1212/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1212/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 1212/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1212/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 1212/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1212/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 1212/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1213/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 1213/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06;, score=0.480 total time=   0.1s\n",
            "[CV 2/5; 1213/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 1213/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06;, score=0.496 total time=   0.1s\n",
            "[CV 3/5; 1213/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 1213/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06;, score=0.544 total time=   0.1s\n",
            "[CV 4/5; 1213/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 1213/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06;, score=0.500 total time=   0.1s\n",
            "[CV 5/5; 1213/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 1213/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=1e-06;, score=0.544 total time=   0.0s\n",
            "[CV 1/5; 1214/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 1214/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05;, score=0.512 total time=   0.0s\n",
            "[CV 2/5; 1214/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 1214/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1214/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 1214/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05;, score=0.508 total time=   0.0s\n",
            "[CV 4/5; 1214/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 1214/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05;, score=0.468 total time=   0.0s\n",
            "[CV 5/5; 1214/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 1214/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=1e-05;, score=0.448 total time=   0.0s\n",
            "[CV 1/5; 1215/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 1215/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001;, score=0.532 total time=   0.0s\n",
            "[CV 2/5; 1215/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 1215/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001;, score=0.488 total time=   0.0s\n",
            "[CV 3/5; 1215/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 1215/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001;, score=0.488 total time=   0.0s\n",
            "[CV 4/5; 1215/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 1215/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001;, score=0.560 total time=   0.0s\n",
            "[CV 5/5; 1215/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 1215/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=0.0001;, score=0.560 total time=   0.0s\n",
            "[CV 1/5; 1216/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 1/5; 1216/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=0.001;, score=0.456 total time=   0.0s\n",
            "[CV 2/5; 1216/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 2/5; 1216/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=0.001;, score=0.484 total time=   0.0s\n",
            "[CV 3/5; 1216/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 3/5; 1216/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=0.001;, score=0.540 total time=   0.0s\n",
            "[CV 4/5; 1216/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 4/5; 1216/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=0.001;, score=0.528 total time=   0.0s\n",
            "[CV 5/5; 1216/1344] START alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 5/5; 1216/1344] END alpha=100, loss=log_loss, max_iter=1000, penalty=None, tol=0.001;, score=0.556 total time=   0.0s\n",
            "[CV 1/5; 1217/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 1217/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1217/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 1217/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1217/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 1217/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1217/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 1217/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1217/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 1217/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1218/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 1218/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1218/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 1218/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1218/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 1218/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1218/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 1218/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1218/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 1218/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1219/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 1219/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1219/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 1219/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1219/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 1219/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1219/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 1219/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1219/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 1219/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1220/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 1220/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1220/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 1220/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1220/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 1220/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1220/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 1220/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1220/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 1220/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1221/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 1221/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1221/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 1221/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1221/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 1221/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1221/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 1221/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1221/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 1221/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1222/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 1222/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1222/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 1222/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1222/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 1222/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1222/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 1222/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1222/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 1222/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1223/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 1223/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1223/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 1223/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1223/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 1223/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1223/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 1223/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1223/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 1223/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1224/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 1224/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1224/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 1224/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1224/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 1224/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1224/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 1224/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1224/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 1224/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1225/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 1225/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1225/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 1225/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1225/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 1225/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1225/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 1225/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1225/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 1225/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1226/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 1226/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1226/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 1226/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1226/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 1226/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1226/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 1226/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1226/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 1226/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1227/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 1227/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1227/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 1227/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1227/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 1227/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1227/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 1227/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1227/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 1227/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1228/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 1228/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1228/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 1228/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1228/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 1228/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1228/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 1228/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1228/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 1228/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1229/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 1229/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06;, score=0.528 total time=   0.1s\n",
            "[CV 2/5; 1229/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 1229/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06;, score=0.536 total time=   0.1s\n",
            "[CV 3/5; 1229/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 1229/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06;, score=0.512 total time=   0.2s\n",
            "[CV 4/5; 1229/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 1229/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06;, score=0.512 total time=   0.3s\n",
            "[CV 5/5; 1229/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 1229/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 1/5; 1230/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 1230/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05;, score=0.544 total time=   0.0s\n",
            "[CV 2/5; 1230/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 1230/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05;, score=0.500 total time=   0.0s\n",
            "[CV 3/5; 1230/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 1230/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05;, score=0.508 total time=   0.0s\n",
            "[CV 4/5; 1230/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 1230/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1230/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 1230/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=1e-05;, score=0.564 total time=   0.0s\n",
            "[CV 1/5; 1231/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 1231/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001;, score=0.472 total time=   0.0s\n",
            "[CV 2/5; 1231/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 1231/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001;, score=0.536 total time=   0.0s\n",
            "[CV 3/5; 1231/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 1231/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001;, score=0.552 total time=   0.0s\n",
            "[CV 4/5; 1231/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 1231/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1231/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 1231/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=0.0001;, score=0.572 total time=   0.0s\n",
            "[CV 1/5; 1232/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 1/5; 1232/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=0.001;, score=0.528 total time=   0.0s\n",
            "[CV 2/5; 1232/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 2/5; 1232/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=0.001;, score=0.508 total time=   0.0s\n",
            "[CV 3/5; 1232/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 3/5; 1232/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=0.001;, score=0.452 total time=   0.0s\n",
            "[CV 4/5; 1232/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 4/5; 1232/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 5/5; 1232/1344] START alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 5/5; 1232/1344] END alpha=100, loss=log_loss, max_iter=10000, penalty=None, tol=0.001;, score=0.532 total time=   0.0s\n",
            "[CV 1/5; 1233/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 1233/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1233/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 1233/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1233/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 1233/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1233/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 1233/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1233/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 1233/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1234/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 1234/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1234/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 1234/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1234/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 1234/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1234/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 1234/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1234/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 1234/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1235/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 1235/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1235/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 1235/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1235/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 1235/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1235/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 1235/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1235/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 1235/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1236/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 1236/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1236/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 1236/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1236/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 1236/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1236/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 1236/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1236/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 1236/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1237/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 1237/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1237/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 1237/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1237/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 1237/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1237/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 1237/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1237/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 1237/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1238/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 1238/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1238/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 1238/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1238/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 1238/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1238/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 1238/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1238/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 1238/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1239/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 1239/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1239/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 1239/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1239/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 1239/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1239/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 1239/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1239/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 1239/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1240/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 1240/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1240/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 1240/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1240/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 1240/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1240/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 1240/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1240/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 1240/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1241/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 1241/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1241/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 1241/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1241/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 1241/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1241/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 1241/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1241/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 1241/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1242/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 1242/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1242/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 1242/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1242/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 1242/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1242/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 1242/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1242/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 1242/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1243/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 1243/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1243/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 1243/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1243/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 1243/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1243/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 1243/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1243/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 1243/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1244/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 1244/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1244/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 1244/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1244/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 1244/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1244/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 1244/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1244/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 1244/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1245/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 1245/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06;, score=0.528 total time=   0.1s\n",
            "[CV 2/5; 1245/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 1245/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06;, score=0.496 total time=   0.0s\n",
            "[CV 3/5; 1245/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 1245/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06;, score=0.512 total time=   0.3s\n",
            "[CV 4/5; 1245/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 1245/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06;, score=0.468 total time=   0.0s\n",
            "[CV 5/5; 1245/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 1245/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=1e-06;, score=0.516 total time=   0.1s\n",
            "[CV 1/5; 1246/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 1246/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 2/5; 1246/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 1246/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05;, score=0.516 total time=   0.0s\n",
            "[CV 3/5; 1246/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 1246/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05;, score=0.460 total time=   0.0s\n",
            "[CV 4/5; 1246/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 1246/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05;, score=0.532 total time=   0.0s\n",
            "[CV 5/5; 1246/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 1246/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=1e-05;, score=0.556 total time=   0.0s\n",
            "[CV 1/5; 1247/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 1247/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001;, score=0.552 total time=   0.0s\n",
            "[CV 2/5; 1247/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 1247/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1247/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 1247/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001;, score=0.516 total time=   0.0s\n",
            "[CV 4/5; 1247/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 1247/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001;, score=0.468 total time=   0.0s\n",
            "[CV 5/5; 1247/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 1247/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=0.0001;, score=0.432 total time=   0.0s\n",
            "[CV 1/5; 1248/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 1/5; 1248/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=0.001;, score=0.516 total time=   0.0s\n",
            "[CV 2/5; 1248/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 2/5; 1248/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 3/5; 1248/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 3/5; 1248/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 4/5; 1248/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 4/5; 1248/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=0.001;, score=0.496 total time=   0.0s\n",
            "[CV 5/5; 1248/1344] START alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 5/5; 1248/1344] END alpha=100, loss=log_loss, max_iter=100000, penalty=None, tol=0.001;, score=0.560 total time=   0.0s\n",
            "[CV 1/5; 1249/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 1249/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1249/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 1249/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1249/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 1249/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1249/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 1249/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 5/5; 1249/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 1249/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1250/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 1250/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1250/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 1250/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1250/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 1250/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1250/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 1250/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1250/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 1250/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1251/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 1251/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1251/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 1251/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1251/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 1251/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1251/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 1251/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1251/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 1251/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1252/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 1252/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1252/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 1252/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1252/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 1252/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1252/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 1252/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1252/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 1252/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1253/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 1253/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.520 total time=   0.1s\n",
            "[CV 2/5; 1253/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 1253/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.1s\n",
            "[CV 3/5; 1253/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 1253/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.1s\n",
            "[CV 4/5; 1253/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 1253/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.1s\n",
            "[CV 5/5; 1253/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 1253/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 1/5; 1254/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 1254/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.520 total time=   0.1s\n",
            "[CV 2/5; 1254/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 1254/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.1s\n",
            "[CV 3/5; 1254/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 1254/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.1s\n",
            "[CV 4/5; 1254/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 1254/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.1s\n",
            "[CV 5/5; 1254/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 1254/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.1s\n",
            "[CV 1/5; 1255/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 1255/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1255/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 1255/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1255/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 1255/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1255/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 1255/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1255/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 1255/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1256/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 1256/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1256/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 1256/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1256/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 1256/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1256/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 1256/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1256/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 1256/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1257/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 1257/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.480 total time=   0.1s\n",
            "[CV 2/5; 1257/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 1257/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 3/5; 1257/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 1257/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 4/5; 1257/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 1257/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 5/5; 1257/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 1257/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 1/5; 1258/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 1258/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.480 total time=   0.1s\n",
            "[CV 2/5; 1258/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 1258/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.1s\n",
            "[CV 3/5; 1258/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 1258/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.1s\n",
            "[CV 4/5; 1258/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 1258/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.1s\n",
            "[CV 5/5; 1258/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 1258/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.1s\n",
            "[CV 1/5; 1259/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 1259/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1259/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 1259/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1259/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 1259/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1259/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 1259/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1259/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 1259/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1260/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 1260/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1260/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 1260/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1260/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 1260/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1260/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 1260/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1260/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 1260/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1261/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 1261/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.536 total time=   0.0s\n",
            "[CV 2/5; 1261/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 1261/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.520 total time=   0.0s\n",
            "[CV 3/5; 1261/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 1261/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.548 total time=   0.1s\n",
            "[CV 4/5; 1261/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 1261/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.480 total time=   0.1s\n",
            "[CV 5/5; 1261/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 1261/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-06;, score=0.432 total time=   0.0s\n",
            "[CV 1/5; 1262/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 1262/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.540 total time=   0.0s\n",
            "[CV 2/5; 1262/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 1262/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.500 total time=   0.0s\n",
            "[CV 3/5; 1262/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 1262/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.480 total time=   0.1s\n",
            "[CV 4/5; 1262/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 1262/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.540 total time=   0.1s\n",
            "[CV 5/5; 1262/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 1262/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1263/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 1263/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.484 total time=   0.0s\n",
            "[CV 2/5; 1263/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 1263/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.512 total time=   0.0s\n",
            "[CV 3/5; 1263/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 1263/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.540 total time=   0.0s\n",
            "[CV 4/5; 1263/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 1263/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.536 total time=   0.1s\n",
            "[CV 5/5; 1263/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 1263/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.0001;, score=0.456 total time=   0.0s\n",
            "[CV 1/5; 1264/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 1/5; 1264/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.540 total time=   0.0s\n",
            "[CV 2/5; 1264/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 2/5; 1264/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.508 total time=   0.0s\n",
            "[CV 3/5; 1264/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 3/5; 1264/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.484 total time=   0.0s\n",
            "[CV 4/5; 1264/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 4/5; 1264/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.492 total time=   0.0s\n",
            "[CV 5/5; 1264/1344] START alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 5/5; 1264/1344] END alpha=100, loss=squared_hinge, max_iter=1000, penalty=None, tol=0.001;, score=0.452 total time=   0.0s\n",
            "[CV 1/5; 1265/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 1265/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.480 total time=   0.4s\n",
            "[CV 2/5; 1265/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 1265/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.4s\n",
            "[CV 3/5; 1265/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 1265/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.4s\n",
            "[CV 4/5; 1265/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 1265/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.4s\n",
            "[CV 5/5; 1265/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 1265/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.7s\n",
            "[CV 1/5; 1266/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 1266/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.520 total time=   0.1s\n",
            "[CV 2/5; 1266/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 1266/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.1s\n",
            "[CV 3/5; 1266/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 1266/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.1s\n",
            "[CV 4/5; 1266/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 1266/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.1s\n",
            "[CV 5/5; 1266/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 1266/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.1s\n",
            "[CV 1/5; 1267/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 1267/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1267/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 1267/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1267/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 1267/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1267/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 1267/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1267/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 1267/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1268/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 1268/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1268/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 1268/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1268/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 1268/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1268/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 1268/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1268/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 1268/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1269/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 1269/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.520 total time=   0.8s\n",
            "[CV 2/5; 1269/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 1269/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.7s\n",
            "[CV 3/5; 1269/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 1269/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.7s\n",
            "[CV 4/5; 1269/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 1269/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.6s\n",
            "[CV 5/5; 1269/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 1269/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.6s\n",
            "[CV 1/5; 1270/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 1270/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.480 total time=   0.1s\n",
            "[CV 2/5; 1270/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 1270/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.1s\n",
            "[CV 3/5; 1270/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 1270/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.1s\n",
            "[CV 4/5; 1270/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 1270/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.1s\n",
            "[CV 5/5; 1270/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 1270/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.1s\n",
            "[CV 1/5; 1271/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 1271/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1271/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 1271/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1271/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 1271/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1271/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 1271/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1271/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 1271/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1272/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 1272/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1272/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 1272/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1272/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 1272/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1272/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 1272/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1272/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 1272/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1273/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 1273/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.520 total time=   0.5s\n",
            "[CV 2/5; 1273/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 1273/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.6s\n",
            "[CV 3/5; 1273/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 1273/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.5s\n",
            "[CV 4/5; 1273/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 1273/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.7s\n",
            "[CV 5/5; 1273/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 1273/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.8s\n",
            "[CV 1/5; 1274/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 1274/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.480 total time=   0.1s\n",
            "[CV 2/5; 1274/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 1274/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.1s\n",
            "[CV 3/5; 1274/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 1274/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.1s\n",
            "[CV 4/5; 1274/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 1274/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.1s\n",
            "[CV 5/5; 1274/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 1274/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.1s\n",
            "[CV 1/5; 1275/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 1275/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1275/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 1275/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1275/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 1275/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1275/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 1275/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1275/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 1275/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1276/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 1276/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1276/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 1276/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1276/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 1276/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1276/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 1276/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1276/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 1276/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1277/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 1277/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.488 total time=   0.5s\n",
            "[CV 2/5; 1277/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 1277/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.480 total time=   0.4s\n",
            "[CV 3/5; 1277/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 1277/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.500 total time=   0.4s\n",
            "[CV 4/5; 1277/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 1277/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.468 total time=   0.5s\n",
            "[CV 5/5; 1277/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 1277/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-06;, score=0.524 total time=   0.4s\n",
            "[CV 1/5; 1278/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 1278/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.544 total time=   0.5s\n",
            "[CV 2/5; 1278/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 1278/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.492 total time=   0.4s\n",
            "[CV 3/5; 1278/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 1278/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.552 total time=   0.3s\n",
            "[CV 4/5; 1278/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 1278/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.476 total time=   0.6s\n",
            "[CV 5/5; 1278/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 1278/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=1e-05;, score=0.424 total time=   0.6s\n",
            "[CV 1/5; 1279/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 1279/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1279/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 1279/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.532 total time=   0.1s\n",
            "[CV 3/5; 1279/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 1279/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.488 total time=   0.1s\n",
            "[CV 4/5; 1279/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 1279/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.468 total time=   0.1s\n",
            "[CV 5/5; 1279/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 1279/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.0001;, score=0.508 total time=   0.1s\n",
            "[CV 1/5; 1280/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 1/5; 1280/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.512 total time=   0.0s\n",
            "[CV 2/5; 1280/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 2/5; 1280/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 3/5; 1280/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 3/5; 1280/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.504 total time=   0.0s\n",
            "[CV 4/5; 1280/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 4/5; 1280/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.452 total time=   0.0s\n",
            "[CV 5/5; 1280/1344] START alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 5/5; 1280/1344] END alpha=100, loss=squared_hinge, max_iter=10000, penalty=None, tol=0.001;, score=0.560 total time=   0.0s\n",
            "[CV 1/5; 1281/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 1281/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.520 total time=   0.5s\n",
            "[CV 2/5; 1281/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 1281/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.4s\n",
            "[CV 3/5; 1281/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 1281/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.5s\n",
            "[CV 4/5; 1281/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 1281/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.3s\n",
            "[CV 5/5; 1281/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 1281/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.3s\n",
            "[CV 1/5; 1282/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 1282/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1282/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 1282/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1282/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 1282/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1282/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 1282/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1282/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 1282/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1283/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 1283/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1283/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 1283/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1283/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 1283/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1283/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 1283/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1283/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 1283/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1284/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 1284/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1284/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 1284/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1284/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 1284/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1284/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 1284/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1284/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 1284/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1285/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 1285/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.520 total time=   0.4s\n",
            "[CV 2/5; 1285/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 1285/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.5s\n",
            "[CV 3/5; 1285/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 1285/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.5s\n",
            "[CV 4/5; 1285/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 1285/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.6s\n",
            "[CV 5/5; 1285/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 1285/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.8s\n",
            "[CV 1/5; 1286/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 1286/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.480 total time=   0.1s\n",
            "[CV 2/5; 1286/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 1286/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.1s\n",
            "[CV 3/5; 1286/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 1286/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.1s\n",
            "[CV 4/5; 1286/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 1286/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.1s\n",
            "[CV 5/5; 1286/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 1286/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.1s\n",
            "[CV 1/5; 1287/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 1287/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1287/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 1287/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1287/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 1287/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1287/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 1287/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1287/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 1287/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1288/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 1288/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1288/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 1288/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1288/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 1288/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1288/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 1288/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1288/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 1288/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1289/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 1289/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.520 total time=   0.5s\n",
            "[CV 2/5; 1289/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 1289/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.6s\n",
            "[CV 3/5; 1289/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 1289/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.5s\n",
            "[CV 4/5; 1289/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 1289/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.6s\n",
            "[CV 5/5; 1289/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 1289/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.7s\n",
            "[CV 1/5; 1290/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 1290/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.480 total time=   0.1s\n",
            "[CV 2/5; 1290/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 1290/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.1s\n",
            "[CV 3/5; 1290/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 1290/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.1s\n",
            "[CV 4/5; 1290/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 1290/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.1s\n",
            "[CV 5/5; 1290/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 1290/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.1s\n",
            "[CV 1/5; 1291/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 1291/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1291/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 1291/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1291/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 1291/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1291/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 1291/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1291/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 1291/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1292/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 1292/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1292/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 1292/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1292/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 1292/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1292/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 1292/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1292/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 1292/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1293/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 1293/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.540 total time=   5.0s\n",
            "[CV 2/5; 1293/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 1293/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.528 total time=   1.6s\n",
            "[CV 3/5; 1293/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 1293/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.460 total time=   4.3s\n",
            "[CV 4/5; 1293/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 1293/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.528 total time=   5.0s\n",
            "[CV 5/5; 1293/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 1293/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-06;, score=0.584 total time=   3.7s\n",
            "[CV 1/5; 1294/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 1294/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.532 total time=   0.4s\n",
            "[CV 2/5; 1294/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 1294/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.492 total time=   0.9s\n",
            "[CV 3/5; 1294/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 1294/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.476 total time=   0.3s\n",
            "[CV 4/5; 1294/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 1294/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.508 total time=   1.0s\n",
            "[CV 5/5; 1294/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 1294/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=1e-05;, score=0.528 total time=   0.1s\n",
            "[CV 1/5; 1295/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 1295/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.440 total time=   0.0s\n",
            "[CV 2/5; 1295/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 1295/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.512 total time=   0.1s\n",
            "[CV 3/5; 1295/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 1295/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.452 total time=   0.2s\n",
            "[CV 4/5; 1295/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 1295/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.536 total time=   0.0s\n",
            "[CV 5/5; 1295/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 1295/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.0001;, score=0.552 total time=   0.1s\n",
            "[CV 1/5; 1296/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 1/5; 1296/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.544 total time=   0.0s\n",
            "[CV 2/5; 1296/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 2/5; 1296/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.504 total time=   0.0s\n",
            "[CV 3/5; 1296/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 3/5; 1296/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.512 total time=   0.0s\n",
            "[CV 4/5; 1296/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 4/5; 1296/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.528 total time=   0.0s\n",
            "[CV 5/5; 1296/1344] START alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 5/5; 1296/1344] END alpha=100, loss=squared_hinge, max_iter=100000, penalty=None, tol=0.001;, score=0.572 total time=   0.0s\n",
            "[CV 1/5; 1297/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 1297/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.480 total time=   0.1s\n",
            "[CV 2/5; 1297/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 1297/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1297/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 1297/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1297/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 1297/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1297/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 1297/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 1/5; 1298/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 1298/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1298/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 1298/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1298/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 1298/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1298/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 1298/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1298/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 1298/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1299/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 1299/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1299/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 1299/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1299/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 1299/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1299/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 1299/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1299/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 1299/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1300/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 1300/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1300/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 1300/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1300/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 1300/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1300/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 1300/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1300/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 1300/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1301/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 1301/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.520 total time=   0.1s\n",
            "[CV 2/5; 1301/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 1301/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 3/5; 1301/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 1301/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 4/5; 1301/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 1301/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 5/5; 1301/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 1301/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 1/5; 1302/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 1302/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1302/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 1302/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1302/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 1302/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1302/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 1302/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1302/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 1302/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1303/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 1303/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1303/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 1303/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1303/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 1303/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1303/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 1303/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1303/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 1303/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1304/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 1304/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1304/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 1304/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1304/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 1304/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1304/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 1304/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1304/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 1304/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1305/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 1305/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.480 total time=   0.1s\n",
            "[CV 2/5; 1305/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 1305/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 3/5; 1305/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 1305/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 4/5; 1305/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 1305/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.1s\n",
            "[CV 5/5; 1305/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 1305/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.1s\n",
            "[CV 1/5; 1306/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 1306/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1306/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 1306/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1306/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 1306/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1306/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 1306/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1306/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 1306/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1307/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 1307/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1307/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 1307/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1307/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 1307/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1307/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 1307/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1307/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 1307/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1308/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 1308/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1308/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 1308/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1308/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 1308/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1308/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 1308/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1308/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 1308/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1309/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 1309/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 2/5; 1309/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 1309/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1309/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 1309/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.540 total time=   0.0s\n",
            "[CV 4/5; 1309/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 1309/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.528 total time=   0.0s\n",
            "[CV 5/5; 1309/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 1309/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=1e-06;, score=0.468 total time=   0.0s\n",
            "[CV 1/5; 1310/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 1310/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.488 total time=   0.1s\n",
            "[CV 2/5; 1310/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 1310/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 3/5; 1310/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 1310/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.440 total time=   0.0s\n",
            "[CV 4/5; 1310/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 1310/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.504 total time=   0.1s\n",
            "[CV 5/5; 1310/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 1310/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=1e-05;, score=0.596 total time=   0.0s\n",
            "[CV 1/5; 1311/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 1311/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.544 total time=   0.0s\n",
            "[CV 2/5; 1311/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 1311/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.484 total time=   0.0s\n",
            "[CV 3/5; 1311/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 1311/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.532 total time=   0.0s\n",
            "[CV 4/5; 1311/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 1311/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.472 total time=   0.0s\n",
            "[CV 5/5; 1311/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 1311/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=0.0001;, score=0.560 total time=   0.0s\n",
            "[CV 1/5; 1312/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 1/5; 1312/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.492 total time=   0.0s\n",
            "[CV 2/5; 1312/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 2/5; 1312/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 3/5; 1312/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 3/5; 1312/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1312/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 4/5; 1312/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.500 total time=   0.0s\n",
            "[CV 5/5; 1312/1344] START alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=0.001\n",
            "[CV 5/5; 1312/1344] END alpha=100, loss=perceptron, max_iter=1000, penalty=None, tol=0.001;, score=0.448 total time=   0.0s\n",
            "[CV 1/5; 1313/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 1313/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.480 total time=   0.2s\n",
            "[CV 2/5; 1313/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 1313/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 3/5; 1313/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 1313/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 4/5; 1313/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 1313/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.1s\n",
            "[CV 5/5; 1313/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 1313/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.1s\n",
            "[CV 1/5; 1314/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 1314/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1314/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 1314/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1314/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 1314/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1314/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 1314/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1314/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 1314/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1315/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 1315/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1315/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 1315/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1315/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 1315/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1315/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 1315/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1315/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 1315/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1316/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 1316/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1316/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 1316/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1316/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 1316/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1316/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 1316/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1316/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 1316/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1317/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 1317/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.480 total time=   0.2s\n",
            "[CV 2/5; 1317/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 1317/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.2s\n",
            "[CV 3/5; 1317/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 1317/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.2s\n",
            "[CV 4/5; 1317/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 1317/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.3s\n",
            "[CV 5/5; 1317/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 1317/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-06;, score=0.524 total time=   0.2s\n",
            "[CV 1/5; 1318/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 1318/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1318/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 1318/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1318/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 1318/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1318/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 1318/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1318/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 1318/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1319/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 1319/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1319/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 1319/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1319/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 1319/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1319/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 1319/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1319/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 1319/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1320/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 1320/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1320/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 1320/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1320/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 1320/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1320/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 1320/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1320/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 1320/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1321/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 1321/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.520 total time=   0.2s\n",
            "[CV 2/5; 1321/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 1321/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.3s\n",
            "[CV 3/5; 1321/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 1321/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.3s\n",
            "[CV 4/5; 1321/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 1321/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.2s\n",
            "[CV 5/5; 1321/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 1321/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.3s\n",
            "[CV 1/5; 1322/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 1322/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1322/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 1322/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1322/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 1322/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1322/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 1322/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1322/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 1322/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1323/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 1323/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1323/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 1323/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1323/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 1323/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1323/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 1323/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1323/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 1323/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1324/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 1324/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1324/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 1324/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1324/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 1324/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1324/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 1324/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1324/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 1324/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1325/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 1325/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.460 total time=   0.4s\n",
            "[CV 2/5; 1325/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 1325/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.476 total time=   0.4s\n",
            "[CV 3/5; 1325/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 1325/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.512 total time=   0.4s\n",
            "[CV 4/5; 1325/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 1325/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.496 total time=   0.4s\n",
            "[CV 5/5; 1325/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 1325/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=1e-06;, score=0.440 total time=   0.4s\n",
            "[CV 1/5; 1326/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 1326/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.452 total time=   0.0s\n",
            "[CV 2/5; 1326/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 1326/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.512 total time=   0.0s\n",
            "[CV 3/5; 1326/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 1326/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.500 total time=   0.0s\n",
            "[CV 4/5; 1326/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 1326/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.484 total time=   0.0s\n",
            "[CV 5/5; 1326/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 1326/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=1e-05;, score=0.436 total time=   0.1s\n",
            "[CV 1/5; 1327/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 1327/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.540 total time=   0.0s\n",
            "[CV 2/5; 1327/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 1327/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.520 total time=   0.0s\n",
            "[CV 3/5; 1327/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 1327/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.496 total time=   0.0s\n",
            "[CV 4/5; 1327/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 1327/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.472 total time=   0.0s\n",
            "[CV 5/5; 1327/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 1327/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=0.0001;, score=0.556 total time=   0.0s\n",
            "[CV 1/5; 1328/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 1/5; 1328/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.528 total time=   0.0s\n",
            "[CV 2/5; 1328/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 2/5; 1328/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.488 total time=   0.0s\n",
            "[CV 3/5; 1328/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 3/5; 1328/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.460 total time=   0.0s\n",
            "[CV 4/5; 1328/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 4/5; 1328/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.468 total time=   0.0s\n",
            "[CV 5/5; 1328/1344] START alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=0.001\n",
            "[CV 5/5; 1328/1344] END alpha=100, loss=perceptron, max_iter=10000, penalty=None, tol=0.001;, score=0.604 total time=   0.0s\n",
            "[CV 1/5; 1329/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 1329/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.480 total time=   0.1s\n",
            "[CV 2/5; 1329/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 1329/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.1s\n",
            "[CV 3/5; 1329/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 1329/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 4/5; 1329/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 1329/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.524 total time=   0.1s\n",
            "[CV 5/5; 1329/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 1329/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-06;, score=0.476 total time=   0.1s\n",
            "[CV 1/5; 1330/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 1330/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1330/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 1330/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1330/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 1330/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1330/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 1330/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1330/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 1330/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1331/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 1331/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1331/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 1331/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1331/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 1331/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1331/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 1331/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1331/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 1331/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1332/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 1/5; 1332/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1332/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 2/5; 1332/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1332/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 3/5; 1332/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1332/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 4/5; 1332/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1332/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001\n",
            "[CV 5/5; 1332/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l2, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1333/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 1333/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.480 total time=   0.2s\n",
            "[CV 2/5; 1333/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 1333/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.2s\n",
            "[CV 3/5; 1333/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 1333/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.2s\n",
            "[CV 4/5; 1333/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 1333/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.2s\n",
            "[CV 5/5; 1333/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 1333/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-06;, score=0.476 total time=   0.2s\n",
            "[CV 1/5; 1334/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 1334/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1334/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 1334/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1334/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 1334/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1334/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 1334/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1334/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 1334/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1335/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 1335/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1335/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 1335/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1335/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 1335/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 4/5; 1335/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 1335/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1335/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 1335/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 1336/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 1/5; 1336/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1336/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 2/5; 1336/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 3/5; 1336/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 3/5; 1336/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1336/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 4/5; 1336/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1336/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001\n",
            "[CV 5/5; 1336/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=l1, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1337/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 1337/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.480 total time=   0.2s\n",
            "[CV 2/5; 1337/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 1337/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.2s\n",
            "[CV 3/5; 1337/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 1337/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.2s\n",
            "[CV 4/5; 1337/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 1337/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.2s\n",
            "[CV 5/5; 1337/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 1337/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-06;, score=0.476 total time=   0.2s\n",
            "[CV 1/5; 1338/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 1338/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1338/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 1338/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1338/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 1338/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1338/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 1338/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 5/5; 1338/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 1338/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=1e-05;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1339/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 1339/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.480 total time=   0.0s\n",
            "[CV 2/5; 1339/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 1339/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1339/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 1339/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1339/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 1339/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1339/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 1339/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.0001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1340/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 1/5; 1340/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 1340/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 2/5; 1340/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 1340/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 3/5; 1340/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 4/5; 1340/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 4/5; 1340/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1340/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001\n",
            "[CV 5/5; 1340/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=elasticnet, tol=0.001;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 1341/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 1341/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.448 total time=   0.4s\n",
            "[CV 2/5; 1341/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 1341/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.564 total time=   0.1s\n",
            "[CV 3/5; 1341/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 1341/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.492 total time=   0.4s\n",
            "[CV 4/5; 1341/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 1341/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.472 total time=   0.4s\n",
            "[CV 5/5; 1341/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 1341/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=1e-06;, score=0.548 total time=   0.4s\n",
            "[CV 1/5; 1342/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 1342/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.456 total time=   0.1s\n",
            "[CV 2/5; 1342/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 1342/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.464 total time=   0.1s\n",
            "[CV 3/5; 1342/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 1342/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.484 total time=   0.0s\n",
            "[CV 4/5; 1342/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 1342/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.460 total time=   0.0s\n",
            "[CV 5/5; 1342/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 1342/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=1e-05;, score=0.556 total time=   0.1s\n",
            "[CV 1/5; 1343/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 1343/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.528 total time=   0.0s\n",
            "[CV 2/5; 1343/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 1343/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.528 total time=   0.0s\n",
            "[CV 3/5; 1343/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 1343/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.500 total time=   0.0s\n",
            "[CV 4/5; 1343/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 1343/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.472 total time=   0.0s\n",
            "[CV 5/5; 1343/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 1343/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=0.0001;, score=0.576 total time=   0.0s\n",
            "[CV 1/5; 1344/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 1/5; 1344/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.540 total time=   0.0s\n",
            "[CV 2/5; 1344/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 2/5; 1344/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.484 total time=   0.0s\n",
            "[CV 3/5; 1344/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 3/5; 1344/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.528 total time=   0.0s\n",
            "[CV 4/5; 1344/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 4/5; 1344/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 1344/1344] START alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=0.001\n",
            "[CV 5/5; 1344/1344] END alpha=100, loss=perceptron, max_iter=100000, penalty=None, tol=0.001;, score=0.456 total time=   0.0s\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;sgdc&#x27;,\n",
              "                 GridSearchCV(cv=5, estimator=SGDClassifier(),\n",
              "                              param_grid={&#x27;alpha&#x27;: [1e-06, 1e-05, 0.0001, 0.01,\n",
              "                                                    1, 10, 100],\n",
              "                                          &#x27;loss&#x27;: [&#x27;hinge&#x27;, &#x27;log_loss&#x27;,\n",
              "                                                   &#x27;squared_hinge&#x27;,\n",
              "                                                   &#x27;perceptron&#x27;],\n",
              "                                          &#x27;max_iter&#x27;: [1000, 10000, 100000],\n",
              "                                          &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;,\n",
              "                                                      None],\n",
              "                                          &#x27;tol&#x27;: [1e-06, 1e-05, 0.0001, 0.001]},\n",
              "                              verbose=10))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;sgdc&#x27;,\n",
              "                 GridSearchCV(cv=5, estimator=SGDClassifier(),\n",
              "                              param_grid={&#x27;alpha&#x27;: [1e-06, 1e-05, 0.0001, 0.01,\n",
              "                                                    1, 10, 100],\n",
              "                                          &#x27;loss&#x27;: [&#x27;hinge&#x27;, &#x27;log_loss&#x27;,\n",
              "                                                   &#x27;squared_hinge&#x27;,\n",
              "                                                   &#x27;perceptron&#x27;],\n",
              "                                          &#x27;max_iter&#x27;: [1000, 10000, 100000],\n",
              "                                          &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;,\n",
              "                                                      None],\n",
              "                                          &#x27;tol&#x27;: [1e-06, 1e-05, 0.0001, 0.001]},\n",
              "                              verbose=10))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">sgdc: GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SGDClassifier(),\n",
              "             param_grid={&#x27;alpha&#x27;: [1e-06, 1e-05, 0.0001, 0.01, 1, 10, 100],\n",
              "                         &#x27;loss&#x27;: [&#x27;hinge&#x27;, &#x27;log_loss&#x27;, &#x27;squared_hinge&#x27;,\n",
              "                                  &#x27;perceptron&#x27;],\n",
              "                         &#x27;max_iter&#x27;: [1000, 10000, 100000],\n",
              "                         &#x27;penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;, None],\n",
              "                         &#x27;tol&#x27;: [1e-06, 1e-05, 0.0001, 0.001]},\n",
              "             verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                ('sgdc',\n",
              "                 GridSearchCV(cv=5, estimator=SGDClassifier(),\n",
              "                              param_grid={'alpha': [1e-06, 1e-05, 0.0001, 0.01,\n",
              "                                                    1, 10, 100],\n",
              "                                          'loss': ['hinge', 'log_loss',\n",
              "                                                   'squared_hinge',\n",
              "                                                   'perceptron'],\n",
              "                                          'max_iter': [1000, 10000, 100000],\n",
              "                                          'penalty': ['l2', 'l1', 'elasticnet',\n",
              "                                                      None],\n",
              "                                          'tol': [1e-06, 1e-05, 0.0001, 0.001]},\n",
              "                              verbose=10))])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "param_grid={\"loss\": [\"hinge\", \"log_loss\", \"squared_hinge\", \"perceptron\"],\n",
        "            \"penalty\": [\"l2\", \"l1\", \"elasticnet\", None],\n",
        "            \"alpha\": [1e-6, 1e-5, 1e-4, 1e-2, 1, 10, 100],\n",
        "            \"max_iter\":[1000, 10000, 100000],\n",
        "            \"tol\":[1e-6, 1e-5, 1e-4, 1e-3]}\n",
        "\n",
        "clf = Pipeline([(\"scaler\", StandardScaler()),\n",
        "                (\"sgdc\", GridSearchCV(SGDClassifier(),\n",
        "                              param_grid=param_grid,\n",
        "                              cv=5,\n",
        "                              refit=True,\n",
        "                              verbose=10))])\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "5FMKB5upGH5y",
        "outputId": "5c55a05f-46ad-4d98-9878-4d6de37e3857"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(loss=&#x27;log_loss&#x27;, max_iter=100000, penalty=&#x27;l1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(loss=&#x27;log_loss&#x27;, max_iter=100000, penalty=&#x27;l1&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "SGDClassifier(loss='log_loss', max_iter=100000, penalty='l1')"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf[\"sgdc\"].best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAOzOCc-IALH",
        "outputId": "06a3e595-3862-4a4a-c0bb-63ce9ca2a722"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9768000000000001"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf[\"sgdc\"].best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo4FCpPtNC5W"
      },
      "source": [
        "#### Evaluating Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVWGusCbAyh6"
      },
      "outputs": [],
      "source": [
        "y_valid_pred = clf.predict(X_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlJc1sfJBMnC",
        "outputId": "5615ee67-93e1-4340-fb82-72f0c238744a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9761467889908256"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_valid, y_valid_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZF3yXnEqBWD6"
      },
      "outputs": [],
      "source": [
        "# Combination of Classification and Regression?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIiTAgrXBqnS",
        "outputId": "fede2b49-ef4c-4f2a-db3f-4d896bae93f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9828009828009828"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = clf.predict(X_test)\n",
        "f1_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhzT0jqSB8kj"
      },
      "source": [
        "### Support Vector Machines\n",
        "\n",
        "Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDtaQYinNbMw"
      },
      "source": [
        "#### Training Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "03olkoPsNeTD",
        "outputId": "f731be7d-bf69-475d-9425-c63ea21e87d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 63 candidates, totalling 315 fits\n",
            "[CV 1/5; 1/63] START C=0.001, kernel=linear, tol=0.001..........................\n",
            "[CV 1/5; 1/63] END C=0.001, kernel=linear, tol=0.001;, score=0.512 total time=   0.0s\n",
            "[CV 2/5; 1/63] START C=0.001, kernel=linear, tol=0.001..........................\n",
            "[CV 2/5; 1/63] END C=0.001, kernel=linear, tol=0.001;, score=0.512 total time=   0.0s\n",
            "[CV 3/5; 1/63] START C=0.001, kernel=linear, tol=0.001..........................\n",
            "[CV 3/5; 1/63] END C=0.001, kernel=linear, tol=0.001;, score=0.512 total time=   0.0s\n",
            "[CV 4/5; 1/63] START C=0.001, kernel=linear, tol=0.001..........................\n",
            "[CV 4/5; 1/63] END C=0.001, kernel=linear, tol=0.001;, score=0.509 total time=   0.0s\n",
            "[CV 5/5; 1/63] START C=0.001, kernel=linear, tol=0.001..........................\n",
            "[CV 5/5; 1/63] END C=0.001, kernel=linear, tol=0.001;, score=0.509 total time=   0.0s\n",
            "[CV 1/5; 2/63] START C=0.001, kernel=linear, tol=0.0001.........................\n",
            "[CV 1/5; 2/63] END C=0.001, kernel=linear, tol=0.0001;, score=0.512 total time=   0.0s\n",
            "[CV 2/5; 2/63] START C=0.001, kernel=linear, tol=0.0001.........................\n",
            "[CV 2/5; 2/63] END C=0.001, kernel=linear, tol=0.0001;, score=0.512 total time=   0.0s\n",
            "[CV 3/5; 2/63] START C=0.001, kernel=linear, tol=0.0001.........................\n",
            "[CV 3/5; 2/63] END C=0.001, kernel=linear, tol=0.0001;, score=0.512 total time=   0.0s\n",
            "[CV 4/5; 2/63] START C=0.001, kernel=linear, tol=0.0001.........................\n",
            "[CV 4/5; 2/63] END C=0.001, kernel=linear, tol=0.0001;, score=0.509 total time=   0.0s\n",
            "[CV 5/5; 2/63] START C=0.001, kernel=linear, tol=0.0001.........................\n",
            "[CV 5/5; 2/63] END C=0.001, kernel=linear, tol=0.0001;, score=0.509 total time=   0.0s\n",
            "[CV 1/5; 3/63] START C=0.001, kernel=linear, tol=1e-05..........................\n",
            "[CV 1/5; 3/63] END C=0.001, kernel=linear, tol=1e-05;, score=0.512 total time=   0.0s\n",
            "[CV 2/5; 3/63] START C=0.001, kernel=linear, tol=1e-05..........................\n",
            "[CV 2/5; 3/63] END C=0.001, kernel=linear, tol=1e-05;, score=0.512 total time=   0.0s\n",
            "[CV 3/5; 3/63] START C=0.001, kernel=linear, tol=1e-05..........................\n",
            "[CV 3/5; 3/63] END C=0.001, kernel=linear, tol=1e-05;, score=0.512 total time=   0.0s\n",
            "[CV 4/5; 3/63] START C=0.001, kernel=linear, tol=1e-05..........................\n",
            "[CV 4/5; 3/63] END C=0.001, kernel=linear, tol=1e-05;, score=0.509 total time=   0.0s\n",
            "[CV 5/5; 3/63] START C=0.001, kernel=linear, tol=1e-05..........................\n",
            "[CV 5/5; 3/63] END C=0.001, kernel=linear, tol=1e-05;, score=0.509 total time=   0.0s\n",
            "[CV 1/5; 4/63] START C=0.01, kernel=linear, tol=0.001...........................\n",
            "[CV 1/5; 4/63] END C=0.01, kernel=linear, tol=0.001;, score=0.547 total time=   0.0s\n",
            "[CV 2/5; 4/63] START C=0.01, kernel=linear, tol=0.001...........................\n",
            "[CV 2/5; 4/63] END C=0.01, kernel=linear, tol=0.001;, score=0.512 total time=   0.0s\n",
            "[CV 3/5; 4/63] START C=0.01, kernel=linear, tol=0.001...........................\n",
            "[CV 3/5; 4/63] END C=0.01, kernel=linear, tol=0.001;, score=0.547 total time=   0.0s\n",
            "[CV 4/5; 4/63] START C=0.01, kernel=linear, tol=0.001...........................\n",
            "[CV 4/5; 4/63] END C=0.01, kernel=linear, tol=0.001;, score=0.509 total time=   0.0s\n",
            "[CV 5/5; 4/63] START C=0.01, kernel=linear, tol=0.001...........................\n",
            "[CV 5/5; 4/63] END C=0.01, kernel=linear, tol=0.001;, score=0.509 total time=   0.0s\n",
            "[CV 1/5; 5/63] START C=0.01, kernel=linear, tol=0.0001..........................\n",
            "[CV 1/5; 5/63] END C=0.01, kernel=linear, tol=0.0001;, score=0.547 total time=   0.0s\n",
            "[CV 2/5; 5/63] START C=0.01, kernel=linear, tol=0.0001..........................\n",
            "[CV 2/5; 5/63] END C=0.01, kernel=linear, tol=0.0001;, score=0.512 total time=   0.0s\n",
            "[CV 3/5; 5/63] START C=0.01, kernel=linear, tol=0.0001..........................\n",
            "[CV 3/5; 5/63] END C=0.01, kernel=linear, tol=0.0001;, score=0.547 total time=   0.0s\n",
            "[CV 4/5; 5/63] START C=0.01, kernel=linear, tol=0.0001..........................\n",
            "[CV 4/5; 5/63] END C=0.01, kernel=linear, tol=0.0001;, score=0.509 total time=   0.0s\n",
            "[CV 5/5; 5/63] START C=0.01, kernel=linear, tol=0.0001..........................\n",
            "[CV 5/5; 5/63] END C=0.01, kernel=linear, tol=0.0001;, score=0.509 total time=   0.0s\n",
            "[CV 1/5; 6/63] START C=0.01, kernel=linear, tol=1e-05...........................\n",
            "[CV 1/5; 6/63] END C=0.01, kernel=linear, tol=1e-05;, score=0.547 total time=   0.0s\n",
            "[CV 2/5; 6/63] START C=0.01, kernel=linear, tol=1e-05...........................\n",
            "[CV 2/5; 6/63] END C=0.01, kernel=linear, tol=1e-05;, score=0.512 total time=   0.0s\n",
            "[CV 3/5; 6/63] START C=0.01, kernel=linear, tol=1e-05...........................\n",
            "[CV 3/5; 6/63] END C=0.01, kernel=linear, tol=1e-05;, score=0.547 total time=   0.0s\n",
            "[CV 4/5; 6/63] START C=0.01, kernel=linear, tol=1e-05...........................\n",
            "[CV 4/5; 6/63] END C=0.01, kernel=linear, tol=1e-05;, score=0.509 total time=   0.0s\n",
            "[CV 5/5; 6/63] START C=0.01, kernel=linear, tol=1e-05...........................\n",
            "[CV 5/5; 6/63] END C=0.01, kernel=linear, tol=1e-05;, score=0.509 total time=   0.0s\n",
            "[CV 1/5; 7/63] START C=0.1, kernel=linear, tol=0.001............................\n",
            "[CV 1/5; 7/63] END C=0.1, kernel=linear, tol=0.001;, score=0.669 total time=   0.0s\n",
            "[CV 2/5; 7/63] START C=0.1, kernel=linear, tol=0.001............................\n",
            "[CV 2/5; 7/63] END C=0.1, kernel=linear, tol=0.001;, score=0.698 total time=   0.0s\n",
            "[CV 3/5; 7/63] START C=0.1, kernel=linear, tol=0.001............................\n",
            "[CV 3/5; 7/63] END C=0.1, kernel=linear, tol=0.001;, score=0.581 total time=   0.0s\n",
            "[CV 4/5; 7/63] START C=0.1, kernel=linear, tol=0.001............................\n",
            "[CV 4/5; 7/63] END C=0.1, kernel=linear, tol=0.001;, score=0.632 total time=   0.0s\n",
            "[CV 5/5; 7/63] START C=0.1, kernel=linear, tol=0.001............................\n",
            "[CV 5/5; 7/63] END C=0.1, kernel=linear, tol=0.001;, score=0.614 total time=   0.0s\n",
            "[CV 1/5; 8/63] START C=0.1, kernel=linear, tol=0.0001...........................\n",
            "[CV 1/5; 8/63] END C=0.1, kernel=linear, tol=0.0001;, score=0.669 total time=   0.0s\n",
            "[CV 2/5; 8/63] START C=0.1, kernel=linear, tol=0.0001...........................\n",
            "[CV 2/5; 8/63] END C=0.1, kernel=linear, tol=0.0001;, score=0.698 total time=   0.0s\n",
            "[CV 3/5; 8/63] START C=0.1, kernel=linear, tol=0.0001...........................\n",
            "[CV 3/5; 8/63] END C=0.1, kernel=linear, tol=0.0001;, score=0.581 total time=   0.0s\n",
            "[CV 4/5; 8/63] START C=0.1, kernel=linear, tol=0.0001...........................\n",
            "[CV 4/5; 8/63] END C=0.1, kernel=linear, tol=0.0001;, score=0.632 total time=   0.0s\n",
            "[CV 5/5; 8/63] START C=0.1, kernel=linear, tol=0.0001...........................\n",
            "[CV 5/5; 8/63] END C=0.1, kernel=linear, tol=0.0001;, score=0.614 total time=   0.0s\n",
            "[CV 1/5; 9/63] START C=0.1, kernel=linear, tol=1e-05............................\n",
            "[CV 1/5; 9/63] END C=0.1, kernel=linear, tol=1e-05;, score=0.669 total time=   0.0s\n",
            "[CV 2/5; 9/63] START C=0.1, kernel=linear, tol=1e-05............................\n",
            "[CV 2/5; 9/63] END C=0.1, kernel=linear, tol=1e-05;, score=0.698 total time=   0.0s\n",
            "[CV 3/5; 9/63] START C=0.1, kernel=linear, tol=1e-05............................\n",
            "[CV 3/5; 9/63] END C=0.1, kernel=linear, tol=1e-05;, score=0.581 total time=   0.0s\n",
            "[CV 4/5; 9/63] START C=0.1, kernel=linear, tol=1e-05............................\n",
            "[CV 4/5; 9/63] END C=0.1, kernel=linear, tol=1e-05;, score=0.632 total time=   0.0s\n",
            "[CV 5/5; 9/63] START C=0.1, kernel=linear, tol=1e-05............................\n",
            "[CV 5/5; 9/63] END C=0.1, kernel=linear, tol=1e-05;, score=0.614 total time=   0.0s\n",
            "[CV 1/5; 10/63] START C=1, kernel=linear, tol=0.001.............................\n",
            "[CV 1/5; 10/63] END C=1, kernel=linear, tol=0.001;, score=0.820 total time=   0.0s\n",
            "[CV 2/5; 10/63] START C=1, kernel=linear, tol=0.001.............................\n",
            "[CV 2/5; 10/63] END C=1, kernel=linear, tol=0.001;, score=0.826 total time=   0.0s\n",
            "[CV 3/5; 10/63] START C=1, kernel=linear, tol=0.001.............................\n",
            "[CV 3/5; 10/63] END C=1, kernel=linear, tol=0.001;, score=0.890 total time=   0.0s\n",
            "[CV 4/5; 10/63] START C=1, kernel=linear, tol=0.001.............................\n",
            "[CV 4/5; 10/63] END C=1, kernel=linear, tol=0.001;, score=0.813 total time=   0.0s\n",
            "[CV 5/5; 10/63] START C=1, kernel=linear, tol=0.001.............................\n",
            "[CV 5/5; 10/63] END C=1, kernel=linear, tol=0.001;, score=0.836 total time=   0.0s\n",
            "[CV 1/5; 11/63] START C=1, kernel=linear, tol=0.0001............................\n",
            "[CV 1/5; 11/63] END C=1, kernel=linear, tol=0.0001;, score=0.820 total time=   0.0s\n",
            "[CV 2/5; 11/63] START C=1, kernel=linear, tol=0.0001............................\n",
            "[CV 2/5; 11/63] END C=1, kernel=linear, tol=0.0001;, score=0.826 total time=   0.0s\n",
            "[CV 3/5; 11/63] START C=1, kernel=linear, tol=0.0001............................\n",
            "[CV 3/5; 11/63] END C=1, kernel=linear, tol=0.0001;, score=0.890 total time=   0.0s\n",
            "[CV 4/5; 11/63] START C=1, kernel=linear, tol=0.0001............................\n",
            "[CV 4/5; 11/63] END C=1, kernel=linear, tol=0.0001;, score=0.813 total time=   0.0s\n",
            "[CV 5/5; 11/63] START C=1, kernel=linear, tol=0.0001............................\n",
            "[CV 5/5; 11/63] END C=1, kernel=linear, tol=0.0001;, score=0.836 total time=   0.0s\n",
            "[CV 1/5; 12/63] START C=1, kernel=linear, tol=1e-05.............................\n",
            "[CV 1/5; 12/63] END C=1, kernel=linear, tol=1e-05;, score=0.820 total time=   0.0s\n",
            "[CV 2/5; 12/63] START C=1, kernel=linear, tol=1e-05.............................\n",
            "[CV 2/5; 12/63] END C=1, kernel=linear, tol=1e-05;, score=0.826 total time=   0.0s\n",
            "[CV 3/5; 12/63] START C=1, kernel=linear, tol=1e-05.............................\n",
            "[CV 3/5; 12/63] END C=1, kernel=linear, tol=1e-05;, score=0.890 total time=   0.0s\n",
            "[CV 4/5; 12/63] START C=1, kernel=linear, tol=1e-05.............................\n",
            "[CV 4/5; 12/63] END C=1, kernel=linear, tol=1e-05;, score=0.813 total time=   0.0s\n",
            "[CV 5/5; 12/63] START C=1, kernel=linear, tol=1e-05.............................\n",
            "[CV 5/5; 12/63] END C=1, kernel=linear, tol=1e-05;, score=0.836 total time=   0.0s\n",
            "[CV 1/5; 13/63] START C=10, kernel=linear, tol=0.001............................\n",
            "[CV 1/5; 13/63] END C=10, kernel=linear, tol=0.001;, score=0.913 total time=   0.0s\n",
            "[CV 2/5; 13/63] START C=10, kernel=linear, tol=0.001............................\n",
            "[CV 2/5; 13/63] END C=10, kernel=linear, tol=0.001;, score=0.942 total time=   0.0s\n",
            "[CV 3/5; 13/63] START C=10, kernel=linear, tol=0.001............................\n",
            "[CV 3/5; 13/63] END C=10, kernel=linear, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 13/63] START C=10, kernel=linear, tol=0.001............................\n",
            "[CV 4/5; 13/63] END C=10, kernel=linear, tol=0.001;, score=0.959 total time=   0.1s\n",
            "[CV 5/5; 13/63] START C=10, kernel=linear, tol=0.001............................\n",
            "[CV 5/5; 13/63] END C=10, kernel=linear, tol=0.001;, score=0.947 total time=   0.1s\n",
            "[CV 1/5; 14/63] START C=10, kernel=linear, tol=0.0001...........................\n",
            "[CV 1/5; 14/63] END C=10, kernel=linear, tol=0.0001;, score=0.913 total time=   0.1s\n",
            "[CV 2/5; 14/63] START C=10, kernel=linear, tol=0.0001...........................\n",
            "[CV 2/5; 14/63] END C=10, kernel=linear, tol=0.0001;, score=0.942 total time=   0.1s\n",
            "[CV 3/5; 14/63] START C=10, kernel=linear, tol=0.0001...........................\n",
            "[CV 3/5; 14/63] END C=10, kernel=linear, tol=0.0001;, score=0.948 total time=   0.1s\n",
            "[CV 4/5; 14/63] START C=10, kernel=linear, tol=0.0001...........................\n",
            "[CV 4/5; 14/63] END C=10, kernel=linear, tol=0.0001;, score=0.959 total time=   0.1s\n",
            "[CV 5/5; 14/63] START C=10, kernel=linear, tol=0.0001...........................\n",
            "[CV 5/5; 14/63] END C=10, kernel=linear, tol=0.0001;, score=0.947 total time=   0.1s\n",
            "[CV 1/5; 15/63] START C=10, kernel=linear, tol=1e-05............................\n",
            "[CV 1/5; 15/63] END C=10, kernel=linear, tol=1e-05;, score=0.913 total time=   0.1s\n",
            "[CV 2/5; 15/63] START C=10, kernel=linear, tol=1e-05............................\n",
            "[CV 2/5; 15/63] END C=10, kernel=linear, tol=1e-05;, score=0.942 total time=   0.1s\n",
            "[CV 3/5; 15/63] START C=10, kernel=linear, tol=1e-05............................\n",
            "[CV 3/5; 15/63] END C=10, kernel=linear, tol=1e-05;, score=0.948 total time=   0.1s\n",
            "[CV 4/5; 15/63] START C=10, kernel=linear, tol=1e-05............................\n",
            "[CV 4/5; 15/63] END C=10, kernel=linear, tol=1e-05;, score=0.959 total time=   0.2s\n",
            "[CV 5/5; 15/63] START C=10, kernel=linear, tol=1e-05............................\n",
            "[CV 5/5; 15/63] END C=10, kernel=linear, tol=1e-05;, score=0.947 total time=   0.1s\n",
            "[CV 1/5; 16/63] START C=100.0, kernel=linear, tol=0.001.........................\n",
            "[CV 1/5; 16/63] END C=100.0, kernel=linear, tol=0.001;, score=0.930 total time=   0.4s\n",
            "[CV 2/5; 16/63] START C=100.0, kernel=linear, tol=0.001.........................\n",
            "[CV 2/5; 16/63] END C=100.0, kernel=linear, tol=0.001;, score=0.959 total time=   0.3s\n",
            "[CV 3/5; 16/63] START C=100.0, kernel=linear, tol=0.001.........................\n",
            "[CV 3/5; 16/63] END C=100.0, kernel=linear, tol=0.001;, score=0.977 total time=   0.3s\n",
            "[CV 4/5; 16/63] START C=100.0, kernel=linear, tol=0.001.........................\n",
            "[CV 4/5; 16/63] END C=100.0, kernel=linear, tol=0.001;, score=0.971 total time=   0.2s\n",
            "[CV 5/5; 16/63] START C=100.0, kernel=linear, tol=0.001.........................\n",
            "[CV 5/5; 16/63] END C=100.0, kernel=linear, tol=0.001;, score=0.959 total time=   0.1s\n",
            "[CV 1/5; 17/63] START C=100.0, kernel=linear, tol=0.0001........................\n",
            "[CV 1/5; 17/63] END C=100.0, kernel=linear, tol=0.0001;, score=0.930 total time=   1.0s\n",
            "[CV 2/5; 17/63] START C=100.0, kernel=linear, tol=0.0001........................\n",
            "[CV 2/5; 17/63] END C=100.0, kernel=linear, tol=0.0001;, score=0.959 total time=   0.3s\n",
            "[CV 3/5; 17/63] START C=100.0, kernel=linear, tol=0.0001........................\n",
            "[CV 3/5; 17/63] END C=100.0, kernel=linear, tol=0.0001;, score=0.977 total time=   0.2s\n",
            "[CV 4/5; 17/63] START C=100.0, kernel=linear, tol=0.0001........................\n",
            "[CV 4/5; 17/63] END C=100.0, kernel=linear, tol=0.0001;, score=0.971 total time=   0.3s\n",
            "[CV 5/5; 17/63] START C=100.0, kernel=linear, tol=0.0001........................\n",
            "[CV 5/5; 17/63] END C=100.0, kernel=linear, tol=0.0001;, score=0.959 total time=   0.2s\n",
            "[CV 1/5; 18/63] START C=100.0, kernel=linear, tol=1e-05.........................\n",
            "[CV 1/5; 18/63] END C=100.0, kernel=linear, tol=1e-05;, score=0.930 total time=   1.8s\n",
            "[CV 2/5; 18/63] START C=100.0, kernel=linear, tol=1e-05.........................\n",
            "[CV 2/5; 18/63] END C=100.0, kernel=linear, tol=1e-05;, score=0.959 total time=   0.3s\n",
            "[CV 3/5; 18/63] START C=100.0, kernel=linear, tol=1e-05.........................\n",
            "[CV 3/5; 18/63] END C=100.0, kernel=linear, tol=1e-05;, score=0.977 total time=   0.4s\n",
            "[CV 4/5; 18/63] START C=100.0, kernel=linear, tol=1e-05.........................\n",
            "[CV 4/5; 18/63] END C=100.0, kernel=linear, tol=1e-05;, score=0.971 total time=   0.4s\n",
            "[CV 5/5; 18/63] START C=100.0, kernel=linear, tol=1e-05.........................\n",
            "[CV 5/5; 18/63] END C=100.0, kernel=linear, tol=1e-05;, score=0.959 total time=   0.2s\n",
            "[CV 1/5; 19/63] START C=1000.0, kernel=linear, tol=0.001........................\n",
            "[CV 1/5; 19/63] END C=1000.0, kernel=linear, tol=0.001;, score=0.948 total time=   1.3s\n",
            "[CV 2/5; 19/63] START C=1000.0, kernel=linear, tol=0.001........................\n",
            "[CV 2/5; 19/63] END C=1000.0, kernel=linear, tol=0.001;, score=0.965 total time=   0.7s\n",
            "[CV 3/5; 19/63] START C=1000.0, kernel=linear, tol=0.001........................\n",
            "[CV 3/5; 19/63] END C=1000.0, kernel=linear, tol=0.001;, score=0.977 total time=   0.4s\n",
            "[CV 4/5; 19/63] START C=1000.0, kernel=linear, tol=0.001........................\n",
            "[CV 4/5; 19/63] END C=1000.0, kernel=linear, tol=0.001;, score=0.971 total time=   1.2s\n",
            "[CV 5/5; 19/63] START C=1000.0, kernel=linear, tol=0.001........................\n",
            "[CV 5/5; 19/63] END C=1000.0, kernel=linear, tol=0.001;, score=0.959 total time=   0.7s\n",
            "[CV 1/5; 20/63] START C=1000.0, kernel=linear, tol=0.0001.......................\n",
            "[CV 1/5; 20/63] END C=1000.0, kernel=linear, tol=0.0001;, score=0.948 total time=   1.6s\n",
            "[CV 2/5; 20/63] START C=1000.0, kernel=linear, tol=0.0001.......................\n",
            "[CV 2/5; 20/63] END C=1000.0, kernel=linear, tol=0.0001;, score=0.965 total time=   1.2s\n",
            "[CV 3/5; 20/63] START C=1000.0, kernel=linear, tol=0.0001.......................\n",
            "[CV 3/5; 20/63] END C=1000.0, kernel=linear, tol=0.0001;, score=0.977 total time=   0.5s\n",
            "[CV 4/5; 20/63] START C=1000.0, kernel=linear, tol=0.0001.......................\n",
            "[CV 4/5; 20/63] END C=1000.0, kernel=linear, tol=0.0001;, score=0.971 total time=   2.5s\n",
            "[CV 5/5; 20/63] START C=1000.0, kernel=linear, tol=0.0001.......................\n",
            "[CV 5/5; 20/63] END C=1000.0, kernel=linear, tol=0.0001;, score=0.959 total time=   0.9s\n",
            "[CV 1/5; 21/63] START C=1000.0, kernel=linear, tol=1e-05........................\n",
            "[CV 1/5; 21/63] END C=1000.0, kernel=linear, tol=1e-05;, score=0.948 total time=   1.2s\n",
            "[CV 2/5; 21/63] START C=1000.0, kernel=linear, tol=1e-05........................\n",
            "[CV 2/5; 21/63] END C=1000.0, kernel=linear, tol=1e-05;, score=0.965 total time=   1.3s\n",
            "[CV 3/5; 21/63] START C=1000.0, kernel=linear, tol=1e-05........................\n",
            "[CV 3/5; 21/63] END C=1000.0, kernel=linear, tol=1e-05;, score=0.977 total time=   0.8s\n",
            "[CV 4/5; 21/63] START C=1000.0, kernel=linear, tol=1e-05........................\n",
            "[CV 4/5; 21/63] END C=1000.0, kernel=linear, tol=1e-05;, score=0.971 total time=   4.1s\n",
            "[CV 5/5; 21/63] START C=1000.0, kernel=linear, tol=1e-05........................\n",
            "[CV 5/5; 21/63] END C=1000.0, kernel=linear, tol=1e-05;, score=0.959 total time=   0.9s\n",
            "[CV 1/5; 22/63] START C=10000.0, kernel=linear, tol=0.001.......................\n",
            "[CV 1/5; 22/63] END C=10000.0, kernel=linear, tol=0.001;, score=0.953 total time=   6.5s\n",
            "[CV 2/5; 22/63] START C=10000.0, kernel=linear, tol=0.001.......................\n",
            "[CV 2/5; 22/63] END C=10000.0, kernel=linear, tol=0.001;, score=0.971 total time=   1.5s\n",
            "[CV 3/5; 22/63] START C=10000.0, kernel=linear, tol=0.001.......................\n",
            "[CV 3/5; 22/63] END C=10000.0, kernel=linear, tol=0.001;, score=0.983 total time=   4.2s\n",
            "[CV 4/5; 22/63] START C=10000.0, kernel=linear, tol=0.001.......................\n",
            "[CV 4/5; 22/63] END C=10000.0, kernel=linear, tol=0.001;, score=0.977 total time=  14.7s\n",
            "[CV 5/5; 22/63] START C=10000.0, kernel=linear, tol=0.001.......................\n",
            "[CV 5/5; 22/63] END C=10000.0, kernel=linear, tol=0.001;, score=0.971 total time=   5.4s\n",
            "[CV 1/5; 23/63] START C=10000.0, kernel=linear, tol=0.0001......................\n",
            "[CV 1/5; 23/63] END C=10000.0, kernel=linear, tol=0.0001;, score=0.953 total time=  11.3s\n",
            "[CV 2/5; 23/63] START C=10000.0, kernel=linear, tol=0.0001......................\n",
            "[CV 2/5; 23/63] END C=10000.0, kernel=linear, tol=0.0001;, score=0.971 total time=   2.0s\n",
            "[CV 3/5; 23/63] START C=10000.0, kernel=linear, tol=0.0001......................\n",
            "[CV 3/5; 23/63] END C=10000.0, kernel=linear, tol=0.0001;, score=0.983 total time=   3.8s\n",
            "[CV 4/5; 23/63] START C=10000.0, kernel=linear, tol=0.0001......................\n",
            "[CV 4/5; 23/63] END C=10000.0, kernel=linear, tol=0.0001;, score=0.977 total time=  17.3s\n",
            "[CV 5/5; 23/63] START C=10000.0, kernel=linear, tol=0.0001......................\n",
            "[CV 5/5; 23/63] END C=10000.0, kernel=linear, tol=0.0001;, score=0.971 total time=  22.2s\n",
            "[CV 1/5; 24/63] START C=10000.0, kernel=linear, tol=1e-05.......................\n",
            "[CV 1/5; 24/63] END C=10000.0, kernel=linear, tol=1e-05;, score=0.953 total time=  12.7s\n",
            "[CV 2/5; 24/63] START C=10000.0, kernel=linear, tol=1e-05.......................\n",
            "[CV 2/5; 24/63] END C=10000.0, kernel=linear, tol=1e-05;, score=0.971 total time=   2.0s\n",
            "[CV 3/5; 24/63] START C=10000.0, kernel=linear, tol=1e-05.......................\n",
            "[CV 3/5; 24/63] END C=10000.0, kernel=linear, tol=1e-05;, score=0.983 total time=   4.5s\n",
            "[CV 4/5; 24/63] START C=10000.0, kernel=linear, tol=1e-05.......................\n",
            "[CV 4/5; 24/63] END C=10000.0, kernel=linear, tol=1e-05;, score=0.977 total time=  16.6s\n",
            "[CV 5/5; 24/63] START C=10000.0, kernel=linear, tol=1e-05.......................\n",
            "[CV 5/5; 24/63] END C=10000.0, kernel=linear, tol=1e-05;, score=0.971 total time=  30.8s\n",
            "[CV 1/5; 25/63] START C=100000.0, kernel=linear, tol=0.001......................\n",
            "[CV 1/5; 25/63] END C=100000.0, kernel=linear, tol=0.001;, score=0.971 total time=  38.6s\n",
            "[CV 2/5; 25/63] START C=100000.0, kernel=linear, tol=0.001......................\n",
            "[CV 2/5; 25/63] END C=100000.0, kernel=linear, tol=0.001;, score=0.977 total time=  28.1s\n",
            "[CV 3/5; 25/63] START C=100000.0, kernel=linear, tol=0.001......................\n",
            "[CV 3/5; 25/63] END C=100000.0, kernel=linear, tol=0.001;, score=0.983 total time=  30.0s\n",
            "[CV 4/5; 25/63] START C=100000.0, kernel=linear, tol=0.001......................\n",
            "[CV 4/5; 25/63] END C=100000.0, kernel=linear, tol=0.001;, score=0.971 total time= 1.5min\n",
            "[CV 5/5; 25/63] START C=100000.0, kernel=linear, tol=0.001......................\n",
            "[CV 5/5; 25/63] END C=100000.0, kernel=linear, tol=0.001;, score=0.953 total time=  42.0s\n",
            "[CV 1/5; 26/63] START C=100000.0, kernel=linear, tol=0.0001.....................\n",
            "[CV 1/5; 26/63] END C=100000.0, kernel=linear, tol=0.0001;, score=0.971 total time= 1.0min\n",
            "[CV 2/5; 26/63] START C=100000.0, kernel=linear, tol=0.0001.....................\n",
            "[CV 2/5; 26/63] END C=100000.0, kernel=linear, tol=0.0001;, score=0.977 total time=  27.1s\n",
            "[CV 3/5; 26/63] START C=100000.0, kernel=linear, tol=0.0001.....................\n",
            "[CV 3/5; 26/63] END C=100000.0, kernel=linear, tol=0.0001;, score=0.983 total time=  35.6s\n",
            "[CV 4/5; 26/63] START C=100000.0, kernel=linear, tol=0.0001.....................\n",
            "[CV 4/5; 26/63] END C=100000.0, kernel=linear, tol=0.0001;, score=0.977 total time= 1.8min\n",
            "[CV 5/5; 26/63] START C=100000.0, kernel=linear, tol=0.0001.....................\n",
            "[CV 5/5; 26/63] END C=100000.0, kernel=linear, tol=0.0001;, score=0.953 total time= 1.9min\n",
            "[CV 1/5; 27/63] START C=100000.0, kernel=linear, tol=1e-05......................\n",
            "[CV 1/5; 27/63] END C=100000.0, kernel=linear, tol=1e-05;, score=0.971 total time= 1.7min\n",
            "[CV 2/5; 27/63] START C=100000.0, kernel=linear, tol=1e-05......................\n",
            "[CV 2/5; 27/63] END C=100000.0, kernel=linear, tol=1e-05;, score=0.977 total time=  36.2s\n",
            "[CV 3/5; 27/63] START C=100000.0, kernel=linear, tol=1e-05......................\n",
            "[CV 3/5; 27/63] END C=100000.0, kernel=linear, tol=1e-05;, score=0.983 total time=  55.5s\n",
            "[CV 4/5; 27/63] START C=100000.0, kernel=linear, tol=1e-05......................\n",
            "[CV 4/5; 27/63] END C=100000.0, kernel=linear, tol=1e-05;, score=0.977 total time= 3.2min\n",
            "[CV 5/5; 27/63] START C=100000.0, kernel=linear, tol=1e-05......................\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-c986bfcd3432>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                               verbose=10))])\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_status_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibsvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = [\n",
        " {'kernel': ['linear'], 'C': [1e-3, 1e-2, 1e-1, 1, 10, 1e2, 1e3, 1e4, 1e5], 'tol':[1e-3, 1e-4, 1e-5]},\n",
        " {'kernel': ['rbf'], 'C': [1, 10, 1e2, 1e3, 1e4, 1e5], 'gamma': [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 'scale']},\n",
        "#  {'kernel': ['poly'], 'C': [1, 10, 1e2, 1e3, 1e4, 1e5], 'gamma': [1e-1, 1e-2, 'scale'], 'degree': [2, 3, 4, 5]},\n",
        "#  {'kernel': ['sigmoid'], 'C': [1, 10, 1e2, 1e3, 1e4, 1e5], 'gamma': [1e-3, 1e-4, 1e-5, 'scale']},\n",
        "]\n",
        "\n",
        "clf = Pipeline([('scaler', StandardScaler()),\n",
        "                ('svc', GridSearchCV(SVC(),\n",
        "                              param_grid=param_grid,\n",
        "                              cv=5,\n",
        "                              refit=True,\n",
        "                              verbose=10))])\n",
        "\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "W_3DfB86QFYM",
        "outputId": "5b0cd7b3-29ed-4517-d91b-aeb827739c76"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10000.0, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-51\" type=\"checkbox\" checked><label for=\"sk-estimator-id-51\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10000.0, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "SVC(C=10000.0, kernel='linear')"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf[\"svc\"].best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXwtblANQbqi",
        "outputId": "b7451d52-9c15-4abe-a0dc-93a9dc150a73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9864"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf[\"svc\"].best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43M6ChvVQrOL"
      },
      "source": [
        "#### Evaluating Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoM3BEnRrHGT",
        "outputId": "324a5154-416f-4a9f-efb5-7bbaed13d00c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation f1 Score:  0.9945355191256832\n",
            "Test f1 Score:  0.9828009828009828\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "y_valid_pred = clf.predict(X_valid)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Validation f1 Score: \", f1_score(y_valid, y_valid_pred))\n",
        "print(\"Test f1 Score: \", f1_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNYzyI1Biki9"
      },
      "source": [
        "### Nearest Neighbors Classification\n",
        "\n",
        "Neighbors-based classification is a type of instance-based learning or non-generalizing learning: it does not attempt to construct a general internal model, but simply stores instances of the training data. Classification is computed from a simple majority vote of the nearest neighbors of each point: a query point is assigned the data class which has the most representatives within the nearest neighbors of the point."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THpzOdgHlsvP"
      },
      "source": [
        "#### Training Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RH8hq3kzjLFG",
        "outputId": "5344a17c-0139-40e9-b927-35192b53864c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
            "[CV 1/5; 1/80] START leaf_size=15, n_neighbors=3, p=1, weights=uniform..........\n",
            "[CV 1/5; 1/80] END leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.648 total time=   0.0s\n",
            "[CV 2/5; 1/80] START leaf_size=15, n_neighbors=3, p=1, weights=uniform..........\n",
            "[CV 2/5; 1/80] END leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.632 total time=   0.0s\n",
            "[CV 3/5; 1/80] START leaf_size=15, n_neighbors=3, p=1, weights=uniform..........\n",
            "[CV 3/5; 1/80] END leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.628 total time=   0.0s\n",
            "[CV 4/5; 1/80] START leaf_size=15, n_neighbors=3, p=1, weights=uniform..........\n",
            "[CV 4/5; 1/80] END leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.660 total time=   0.0s\n",
            "[CV 5/5; 1/80] START leaf_size=15, n_neighbors=3, p=1, weights=uniform..........\n",
            "[CV 5/5; 1/80] END leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.652 total time=   0.0s\n",
            "[CV 1/5; 2/80] START leaf_size=15, n_neighbors=3, p=1, weights=distanc..........\n",
            "[CV 1/5; 2/80] END leaf_size=15, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 2/80] START leaf_size=15, n_neighbors=3, p=1, weights=distanc..........\n",
            "[CV 2/5; 2/80] END leaf_size=15, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 2/80] START leaf_size=15, n_neighbors=3, p=1, weights=distanc..........\n",
            "[CV 3/5; 2/80] END leaf_size=15, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 2/80] START leaf_size=15, n_neighbors=3, p=1, weights=distanc..........\n",
            "[CV 4/5; 2/80] END leaf_size=15, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 2/80] START leaf_size=15, n_neighbors=3, p=1, weights=distanc..........\n",
            "[CV 5/5; 2/80] END leaf_size=15, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 3/80] START leaf_size=15, n_neighbors=3, p=2, weights=uniform..........\n",
            "[CV 1/5; 3/80] END leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.616 total time=   0.0s\n",
            "[CV 2/5; 3/80] START leaf_size=15, n_neighbors=3, p=2, weights=uniform..........\n",
            "[CV 2/5; 3/80] END leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.652 total time=   0.0s\n",
            "[CV 3/5; 3/80] START leaf_size=15, n_neighbors=3, p=2, weights=uniform..........\n",
            "[CV 3/5; 3/80] END leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.640 total time=   0.0s\n",
            "[CV 4/5; 3/80] START leaf_size=15, n_neighbors=3, p=2, weights=uniform..........\n",
            "[CV 4/5; 3/80] END leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.652 total time=   0.0s\n",
            "[CV 5/5; 3/80] START leaf_size=15, n_neighbors=3, p=2, weights=uniform..........\n",
            "[CV 5/5; 3/80] END leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.676 total time=   0.0s\n",
            "[CV 1/5; 4/80] START leaf_size=15, n_neighbors=3, p=2, weights=distanc..........\n",
            "[CV 1/5; 4/80] END leaf_size=15, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 4/80] START leaf_size=15, n_neighbors=3, p=2, weights=distanc..........\n",
            "[CV 2/5; 4/80] END leaf_size=15, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 4/80] START leaf_size=15, n_neighbors=3, p=2, weights=distanc..........\n",
            "[CV 3/5; 4/80] END leaf_size=15, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 4/80] START leaf_size=15, n_neighbors=3, p=2, weights=distanc..........\n",
            "[CV 4/5; 4/80] END leaf_size=15, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 4/80] START leaf_size=15, n_neighbors=3, p=2, weights=distanc..........\n",
            "[CV 5/5; 4/80] END leaf_size=15, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 5/80] START leaf_size=15, n_neighbors=4, p=1, weights=uniform..........\n",
            "[CV 1/5; 5/80] END leaf_size=15, n_neighbors=4, p=1, weights=uniform;, score=0.632 total time=   0.0s\n",
            "[CV 2/5; 5/80] START leaf_size=15, n_neighbors=4, p=1, weights=uniform..........\n",
            "[CV 2/5; 5/80] END leaf_size=15, n_neighbors=4, p=1, weights=uniform;, score=0.608 total time=   0.0s\n",
            "[CV 3/5; 5/80] START leaf_size=15, n_neighbors=4, p=1, weights=uniform..........\n",
            "[CV 3/5; 5/80] END leaf_size=15, n_neighbors=4, p=1, weights=uniform;, score=0.592 total time=   0.0s\n",
            "[CV 4/5; 5/80] START leaf_size=15, n_neighbors=4, p=1, weights=uniform..........\n",
            "[CV 4/5; 5/80] END leaf_size=15, n_neighbors=4, p=1, weights=uniform;, score=0.624 total time=   0.0s\n",
            "[CV 5/5; 5/80] START leaf_size=15, n_neighbors=4, p=1, weights=uniform..........\n",
            "[CV 5/5; 5/80] END leaf_size=15, n_neighbors=4, p=1, weights=uniform;, score=0.652 total time=   0.0s\n",
            "[CV 1/5; 6/80] START leaf_size=15, n_neighbors=4, p=1, weights=distanc..........\n",
            "[CV 1/5; 6/80] END leaf_size=15, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 6/80] START leaf_size=15, n_neighbors=4, p=1, weights=distanc..........\n",
            "[CV 2/5; 6/80] END leaf_size=15, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 6/80] START leaf_size=15, n_neighbors=4, p=1, weights=distanc..........\n",
            "[CV 3/5; 6/80] END leaf_size=15, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 6/80] START leaf_size=15, n_neighbors=4, p=1, weights=distanc..........\n",
            "[CV 4/5; 6/80] END leaf_size=15, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 6/80] START leaf_size=15, n_neighbors=4, p=1, weights=distanc..........\n",
            "[CV 5/5; 6/80] END leaf_size=15, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 7/80] START leaf_size=15, n_neighbors=4, p=2, weights=uniform..........\n",
            "[CV 1/5; 7/80] END leaf_size=15, n_neighbors=4, p=2, weights=uniform;, score=0.588 total time=   0.0s\n",
            "[CV 2/5; 7/80] START leaf_size=15, n_neighbors=4, p=2, weights=uniform..........\n",
            "[CV 2/5; 7/80] END leaf_size=15, n_neighbors=4, p=2, weights=uniform;, score=0.612 total time=   0.0s\n",
            "[CV 3/5; 7/80] START leaf_size=15, n_neighbors=4, p=2, weights=uniform..........\n",
            "[CV 3/5; 7/80] END leaf_size=15, n_neighbors=4, p=2, weights=uniform;, score=0.596 total time=   0.0s\n",
            "[CV 4/5; 7/80] START leaf_size=15, n_neighbors=4, p=2, weights=uniform..........\n",
            "[CV 4/5; 7/80] END leaf_size=15, n_neighbors=4, p=2, weights=uniform;, score=0.580 total time=   0.0s\n",
            "[CV 5/5; 7/80] START leaf_size=15, n_neighbors=4, p=2, weights=uniform..........\n",
            "[CV 5/5; 7/80] END leaf_size=15, n_neighbors=4, p=2, weights=uniform;, score=0.668 total time=   0.0s\n",
            "[CV 1/5; 8/80] START leaf_size=15, n_neighbors=4, p=2, weights=distanc..........\n",
            "[CV 1/5; 8/80] END leaf_size=15, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 8/80] START leaf_size=15, n_neighbors=4, p=2, weights=distanc..........\n",
            "[CV 2/5; 8/80] END leaf_size=15, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 8/80] START leaf_size=15, n_neighbors=4, p=2, weights=distanc..........\n",
            "[CV 3/5; 8/80] END leaf_size=15, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 8/80] START leaf_size=15, n_neighbors=4, p=2, weights=distanc..........\n",
            "[CV 4/5; 8/80] END leaf_size=15, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 8/80] START leaf_size=15, n_neighbors=4, p=2, weights=distanc..........\n",
            "[CV 5/5; 8/80] END leaf_size=15, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 9/80] START leaf_size=15, n_neighbors=5, p=1, weights=uniform..........\n",
            "[CV 1/5; 9/80] END leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.620 total time=   0.0s\n",
            "[CV 2/5; 9/80] START leaf_size=15, n_neighbors=5, p=1, weights=uniform..........\n",
            "[CV 2/5; 9/80] END leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.644 total time=   0.0s\n",
            "[CV 3/5; 9/80] START leaf_size=15, n_neighbors=5, p=1, weights=uniform..........\n",
            "[CV 3/5; 9/80] END leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.584 total time=   0.0s\n",
            "[CV 4/5; 9/80] START leaf_size=15, n_neighbors=5, p=1, weights=uniform..........\n",
            "[CV 4/5; 9/80] END leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.640 total time=   0.0s\n",
            "[CV 5/5; 9/80] START leaf_size=15, n_neighbors=5, p=1, weights=uniform..........\n",
            "[CV 5/5; 9/80] END leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.676 total time=   0.0s\n",
            "[CV 1/5; 10/80] START leaf_size=15, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 1/5; 10/80] END leaf_size=15, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 10/80] START leaf_size=15, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 2/5; 10/80] END leaf_size=15, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 10/80] START leaf_size=15, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 3/5; 10/80] END leaf_size=15, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 10/80] START leaf_size=15, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 4/5; 10/80] END leaf_size=15, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 10/80] START leaf_size=15, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 5/5; 10/80] END leaf_size=15, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 11/80] START leaf_size=15, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 1/5; 11/80] END leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.612 total time=   0.0s\n",
            "[CV 2/5; 11/80] START leaf_size=15, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 2/5; 11/80] END leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.664 total time=   0.0s\n",
            "[CV 3/5; 11/80] START leaf_size=15, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 3/5; 11/80] END leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.588 total time=   0.0s\n",
            "[CV 4/5; 11/80] START leaf_size=15, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 4/5; 11/80] END leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.616 total time=   0.0s\n",
            "[CV 5/5; 11/80] START leaf_size=15, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 5/5; 11/80] END leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.700 total time=   0.0s\n",
            "[CV 1/5; 12/80] START leaf_size=15, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 1/5; 12/80] END leaf_size=15, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 12/80] START leaf_size=15, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 2/5; 12/80] END leaf_size=15, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 12/80] START leaf_size=15, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 3/5; 12/80] END leaf_size=15, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 12/80] START leaf_size=15, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 4/5; 12/80] END leaf_size=15, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 12/80] START leaf_size=15, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 5/5; 12/80] END leaf_size=15, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 13/80] START leaf_size=15, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 1/5; 13/80] END leaf_size=15, n_neighbors=6, p=1, weights=uniform;, score=0.616 total time=   0.0s\n",
            "[CV 2/5; 13/80] START leaf_size=15, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 2/5; 13/80] END leaf_size=15, n_neighbors=6, p=1, weights=uniform;, score=0.584 total time=   0.0s\n",
            "[CV 3/5; 13/80] START leaf_size=15, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 3/5; 13/80] END leaf_size=15, n_neighbors=6, p=1, weights=uniform;, score=0.580 total time=   0.0s\n",
            "[CV 4/5; 13/80] START leaf_size=15, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 4/5; 13/80] END leaf_size=15, n_neighbors=6, p=1, weights=uniform;, score=0.628 total time=   0.0s\n",
            "[CV 5/5; 13/80] START leaf_size=15, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 5/5; 13/80] END leaf_size=15, n_neighbors=6, p=1, weights=uniform;, score=0.648 total time=   0.0s\n",
            "[CV 1/5; 14/80] START leaf_size=15, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 1/5; 14/80] END leaf_size=15, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 14/80] START leaf_size=15, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 2/5; 14/80] END leaf_size=15, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 14/80] START leaf_size=15, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 3/5; 14/80] END leaf_size=15, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 14/80] START leaf_size=15, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 4/5; 14/80] END leaf_size=15, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 14/80] START leaf_size=15, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 5/5; 14/80] END leaf_size=15, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 15/80] START leaf_size=15, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 1/5; 15/80] END leaf_size=15, n_neighbors=6, p=2, weights=uniform;, score=0.608 total time=   0.0s\n",
            "[CV 2/5; 15/80] START leaf_size=15, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 2/5; 15/80] END leaf_size=15, n_neighbors=6, p=2, weights=uniform;, score=0.584 total time=   0.0s\n",
            "[CV 3/5; 15/80] START leaf_size=15, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 3/5; 15/80] END leaf_size=15, n_neighbors=6, p=2, weights=uniform;, score=0.588 total time=   0.0s\n",
            "[CV 4/5; 15/80] START leaf_size=15, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 4/5; 15/80] END leaf_size=15, n_neighbors=6, p=2, weights=uniform;, score=0.632 total time=   0.0s\n",
            "[CV 5/5; 15/80] START leaf_size=15, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 5/5; 15/80] END leaf_size=15, n_neighbors=6, p=2, weights=uniform;, score=0.684 total time=   0.0s\n",
            "[CV 1/5; 16/80] START leaf_size=15, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 1/5; 16/80] END leaf_size=15, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 16/80] START leaf_size=15, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 2/5; 16/80] END leaf_size=15, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 16/80] START leaf_size=15, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 3/5; 16/80] END leaf_size=15, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 16/80] START leaf_size=15, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 4/5; 16/80] END leaf_size=15, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 16/80] START leaf_size=15, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 5/5; 16/80] END leaf_size=15, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 17/80] START leaf_size=15, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 1/5; 17/80] END leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.600 total time=   0.0s\n",
            "[CV 2/5; 17/80] START leaf_size=15, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 2/5; 17/80] END leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.588 total time=   0.0s\n",
            "[CV 3/5; 17/80] START leaf_size=15, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 3/5; 17/80] END leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.572 total time=   0.0s\n",
            "[CV 4/5; 17/80] START leaf_size=15, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 4/5; 17/80] END leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.580 total time=   0.0s\n",
            "[CV 5/5; 17/80] START leaf_size=15, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 5/5; 17/80] END leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.688 total time=   0.0s\n",
            "[CV 1/5; 18/80] START leaf_size=15, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 1/5; 18/80] END leaf_size=15, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 18/80] START leaf_size=15, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 2/5; 18/80] END leaf_size=15, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 18/80] START leaf_size=15, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 3/5; 18/80] END leaf_size=15, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 18/80] START leaf_size=15, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 4/5; 18/80] END leaf_size=15, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 18/80] START leaf_size=15, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 5/5; 18/80] END leaf_size=15, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 19/80] START leaf_size=15, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 1/5; 19/80] END leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.608 total time=   0.0s\n",
            "[CV 2/5; 19/80] START leaf_size=15, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 2/5; 19/80] END leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.584 total time=   0.0s\n",
            "[CV 3/5; 19/80] START leaf_size=15, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 3/5; 19/80] END leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.560 total time=   0.0s\n",
            "[CV 4/5; 19/80] START leaf_size=15, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 4/5; 19/80] END leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.604 total time=   0.0s\n",
            "[CV 5/5; 19/80] START leaf_size=15, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 5/5; 19/80] END leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.680 total time=   0.0s\n",
            "[CV 1/5; 20/80] START leaf_size=15, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 1/5; 20/80] END leaf_size=15, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 20/80] START leaf_size=15, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 2/5; 20/80] END leaf_size=15, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 20/80] START leaf_size=15, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 3/5; 20/80] END leaf_size=15, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 20/80] START leaf_size=15, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 4/5; 20/80] END leaf_size=15, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 20/80] START leaf_size=15, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 5/5; 20/80] END leaf_size=15, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 21/80] START leaf_size=30, n_neighbors=3, p=1, weights=uniform.........\n",
            "[CV 1/5; 21/80] END leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.648 total time=   0.0s\n",
            "[CV 2/5; 21/80] START leaf_size=30, n_neighbors=3, p=1, weights=uniform.........\n",
            "[CV 2/5; 21/80] END leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.632 total time=   0.0s\n",
            "[CV 3/5; 21/80] START leaf_size=30, n_neighbors=3, p=1, weights=uniform.........\n",
            "[CV 3/5; 21/80] END leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.628 total time=   0.0s\n",
            "[CV 4/5; 21/80] START leaf_size=30, n_neighbors=3, p=1, weights=uniform.........\n",
            "[CV 4/5; 21/80] END leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.660 total time=   0.0s\n",
            "[CV 5/5; 21/80] START leaf_size=30, n_neighbors=3, p=1, weights=uniform.........\n",
            "[CV 5/5; 21/80] END leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.652 total time=   0.0s\n",
            "[CV 1/5; 22/80] START leaf_size=30, n_neighbors=3, p=1, weights=distanc.........\n",
            "[CV 1/5; 22/80] END leaf_size=30, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 22/80] START leaf_size=30, n_neighbors=3, p=1, weights=distanc.........\n",
            "[CV 2/5; 22/80] END leaf_size=30, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 22/80] START leaf_size=30, n_neighbors=3, p=1, weights=distanc.........\n",
            "[CV 3/5; 22/80] END leaf_size=30, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 22/80] START leaf_size=30, n_neighbors=3, p=1, weights=distanc.........\n",
            "[CV 4/5; 22/80] END leaf_size=30, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 22/80] START leaf_size=30, n_neighbors=3, p=1, weights=distanc.........\n",
            "[CV 5/5; 22/80] END leaf_size=30, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 23/80] START leaf_size=30, n_neighbors=3, p=2, weights=uniform.........\n",
            "[CV 1/5; 23/80] END leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.616 total time=   0.0s\n",
            "[CV 2/5; 23/80] START leaf_size=30, n_neighbors=3, p=2, weights=uniform.........\n",
            "[CV 2/5; 23/80] END leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.652 total time=   0.0s\n",
            "[CV 3/5; 23/80] START leaf_size=30, n_neighbors=3, p=2, weights=uniform.........\n",
            "[CV 3/5; 23/80] END leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.640 total time=   0.0s\n",
            "[CV 4/5; 23/80] START leaf_size=30, n_neighbors=3, p=2, weights=uniform.........\n",
            "[CV 4/5; 23/80] END leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.652 total time=   0.0s\n",
            "[CV 5/5; 23/80] START leaf_size=30, n_neighbors=3, p=2, weights=uniform.........\n",
            "[CV 5/5; 23/80] END leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.676 total time=   0.0s\n",
            "[CV 1/5; 24/80] START leaf_size=30, n_neighbors=3, p=2, weights=distanc.........\n",
            "[CV 1/5; 24/80] END leaf_size=30, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 24/80] START leaf_size=30, n_neighbors=3, p=2, weights=distanc.........\n",
            "[CV 2/5; 24/80] END leaf_size=30, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 24/80] START leaf_size=30, n_neighbors=3, p=2, weights=distanc.........\n",
            "[CV 3/5; 24/80] END leaf_size=30, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 24/80] START leaf_size=30, n_neighbors=3, p=2, weights=distanc.........\n",
            "[CV 4/5; 24/80] END leaf_size=30, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 24/80] START leaf_size=30, n_neighbors=3, p=2, weights=distanc.........\n",
            "[CV 5/5; 24/80] END leaf_size=30, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 25/80] START leaf_size=30, n_neighbors=4, p=1, weights=uniform.........\n",
            "[CV 1/5; 25/80] END leaf_size=30, n_neighbors=4, p=1, weights=uniform;, score=0.632 total time=   0.0s\n",
            "[CV 2/5; 25/80] START leaf_size=30, n_neighbors=4, p=1, weights=uniform.........\n",
            "[CV 2/5; 25/80] END leaf_size=30, n_neighbors=4, p=1, weights=uniform;, score=0.608 total time=   0.0s\n",
            "[CV 3/5; 25/80] START leaf_size=30, n_neighbors=4, p=1, weights=uniform.........\n",
            "[CV 3/5; 25/80] END leaf_size=30, n_neighbors=4, p=1, weights=uniform;, score=0.592 total time=   0.0s\n",
            "[CV 4/5; 25/80] START leaf_size=30, n_neighbors=4, p=1, weights=uniform.........\n",
            "[CV 4/5; 25/80] END leaf_size=30, n_neighbors=4, p=1, weights=uniform;, score=0.624 total time=   0.0s\n",
            "[CV 5/5; 25/80] START leaf_size=30, n_neighbors=4, p=1, weights=uniform.........\n",
            "[CV 5/5; 25/80] END leaf_size=30, n_neighbors=4, p=1, weights=uniform;, score=0.652 total time=   0.0s\n",
            "[CV 1/5; 26/80] START leaf_size=30, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 1/5; 26/80] END leaf_size=30, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 26/80] START leaf_size=30, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 2/5; 26/80] END leaf_size=30, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 26/80] START leaf_size=30, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 3/5; 26/80] END leaf_size=30, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 26/80] START leaf_size=30, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 4/5; 26/80] END leaf_size=30, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 26/80] START leaf_size=30, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 5/5; 26/80] END leaf_size=30, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 27/80] START leaf_size=30, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 1/5; 27/80] END leaf_size=30, n_neighbors=4, p=2, weights=uniform;, score=0.588 total time=   0.0s\n",
            "[CV 2/5; 27/80] START leaf_size=30, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 2/5; 27/80] END leaf_size=30, n_neighbors=4, p=2, weights=uniform;, score=0.612 total time=   0.0s\n",
            "[CV 3/5; 27/80] START leaf_size=30, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 3/5; 27/80] END leaf_size=30, n_neighbors=4, p=2, weights=uniform;, score=0.596 total time=   0.0s\n",
            "[CV 4/5; 27/80] START leaf_size=30, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 4/5; 27/80] END leaf_size=30, n_neighbors=4, p=2, weights=uniform;, score=0.580 total time=   0.0s\n",
            "[CV 5/5; 27/80] START leaf_size=30, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 5/5; 27/80] END leaf_size=30, n_neighbors=4, p=2, weights=uniform;, score=0.668 total time=   0.0s\n",
            "[CV 1/5; 28/80] START leaf_size=30, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 1/5; 28/80] END leaf_size=30, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 28/80] START leaf_size=30, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 2/5; 28/80] END leaf_size=30, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 28/80] START leaf_size=30, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 3/5; 28/80] END leaf_size=30, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 28/80] START leaf_size=30, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 4/5; 28/80] END leaf_size=30, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 28/80] START leaf_size=30, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 5/5; 28/80] END leaf_size=30, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 29/80] START leaf_size=30, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 1/5; 29/80] END leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.620 total time=   0.0s\n",
            "[CV 2/5; 29/80] START leaf_size=30, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 2/5; 29/80] END leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.644 total time=   0.0s\n",
            "[CV 3/5; 29/80] START leaf_size=30, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 3/5; 29/80] END leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.584 total time=   0.0s\n",
            "[CV 4/5; 29/80] START leaf_size=30, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 4/5; 29/80] END leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.640 total time=   0.0s\n",
            "[CV 5/5; 29/80] START leaf_size=30, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 5/5; 29/80] END leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.676 total time=   0.0s\n",
            "[CV 1/5; 30/80] START leaf_size=30, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 1/5; 30/80] END leaf_size=30, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 30/80] START leaf_size=30, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 2/5; 30/80] END leaf_size=30, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 30/80] START leaf_size=30, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 3/5; 30/80] END leaf_size=30, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 30/80] START leaf_size=30, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 4/5; 30/80] END leaf_size=30, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 30/80] START leaf_size=30, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 5/5; 30/80] END leaf_size=30, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 31/80] START leaf_size=30, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 1/5; 31/80] END leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.612 total time=   0.0s\n",
            "[CV 2/5; 31/80] START leaf_size=30, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 2/5; 31/80] END leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.664 total time=   0.0s\n",
            "[CV 3/5; 31/80] START leaf_size=30, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 3/5; 31/80] END leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.588 total time=   0.0s\n",
            "[CV 4/5; 31/80] START leaf_size=30, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 4/5; 31/80] END leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.616 total time=   0.0s\n",
            "[CV 5/5; 31/80] START leaf_size=30, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 5/5; 31/80] END leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.700 total time=   0.0s\n",
            "[CV 1/5; 32/80] START leaf_size=30, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 1/5; 32/80] END leaf_size=30, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 32/80] START leaf_size=30, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 2/5; 32/80] END leaf_size=30, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 32/80] START leaf_size=30, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 3/5; 32/80] END leaf_size=30, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 32/80] START leaf_size=30, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 4/5; 32/80] END leaf_size=30, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 32/80] START leaf_size=30, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 5/5; 32/80] END leaf_size=30, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 33/80] START leaf_size=30, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 1/5; 33/80] END leaf_size=30, n_neighbors=6, p=1, weights=uniform;, score=0.616 total time=   0.0s\n",
            "[CV 2/5; 33/80] START leaf_size=30, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 2/5; 33/80] END leaf_size=30, n_neighbors=6, p=1, weights=uniform;, score=0.584 total time=   0.0s\n",
            "[CV 3/5; 33/80] START leaf_size=30, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 3/5; 33/80] END leaf_size=30, n_neighbors=6, p=1, weights=uniform;, score=0.580 total time=   0.0s\n",
            "[CV 4/5; 33/80] START leaf_size=30, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 4/5; 33/80] END leaf_size=30, n_neighbors=6, p=1, weights=uniform;, score=0.628 total time=   0.0s\n",
            "[CV 5/5; 33/80] START leaf_size=30, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 5/5; 33/80] END leaf_size=30, n_neighbors=6, p=1, weights=uniform;, score=0.648 total time=   0.0s\n",
            "[CV 1/5; 34/80] START leaf_size=30, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 1/5; 34/80] END leaf_size=30, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 34/80] START leaf_size=30, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 2/5; 34/80] END leaf_size=30, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 34/80] START leaf_size=30, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 3/5; 34/80] END leaf_size=30, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 34/80] START leaf_size=30, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 4/5; 34/80] END leaf_size=30, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 34/80] START leaf_size=30, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 5/5; 34/80] END leaf_size=30, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 35/80] START leaf_size=30, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 1/5; 35/80] END leaf_size=30, n_neighbors=6, p=2, weights=uniform;, score=0.608 total time=   0.0s\n",
            "[CV 2/5; 35/80] START leaf_size=30, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 2/5; 35/80] END leaf_size=30, n_neighbors=6, p=2, weights=uniform;, score=0.584 total time=   0.0s\n",
            "[CV 3/5; 35/80] START leaf_size=30, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 3/5; 35/80] END leaf_size=30, n_neighbors=6, p=2, weights=uniform;, score=0.588 total time=   0.0s\n",
            "[CV 4/5; 35/80] START leaf_size=30, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 4/5; 35/80] END leaf_size=30, n_neighbors=6, p=2, weights=uniform;, score=0.632 total time=   0.0s\n",
            "[CV 5/5; 35/80] START leaf_size=30, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 5/5; 35/80] END leaf_size=30, n_neighbors=6, p=2, weights=uniform;, score=0.684 total time=   0.1s\n",
            "[CV 1/5; 36/80] START leaf_size=30, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 1/5; 36/80] END leaf_size=30, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 36/80] START leaf_size=30, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 2/5; 36/80] END leaf_size=30, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 36/80] START leaf_size=30, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 3/5; 36/80] END leaf_size=30, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 36/80] START leaf_size=30, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 4/5; 36/80] END leaf_size=30, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 36/80] START leaf_size=30, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 5/5; 36/80] END leaf_size=30, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 37/80] START leaf_size=30, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 1/5; 37/80] END leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.600 total time=   0.0s\n",
            "[CV 2/5; 37/80] START leaf_size=30, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 2/5; 37/80] END leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.588 total time=   0.0s\n",
            "[CV 3/5; 37/80] START leaf_size=30, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 3/5; 37/80] END leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.572 total time=   0.0s\n",
            "[CV 4/5; 37/80] START leaf_size=30, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 4/5; 37/80] END leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.580 total time=   0.0s\n",
            "[CV 5/5; 37/80] START leaf_size=30, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 5/5; 37/80] END leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.688 total time=   0.0s\n",
            "[CV 1/5; 38/80] START leaf_size=30, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 1/5; 38/80] END leaf_size=30, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 38/80] START leaf_size=30, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 2/5; 38/80] END leaf_size=30, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 38/80] START leaf_size=30, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 3/5; 38/80] END leaf_size=30, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 38/80] START leaf_size=30, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 4/5; 38/80] END leaf_size=30, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 38/80] START leaf_size=30, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 5/5; 38/80] END leaf_size=30, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 39/80] START leaf_size=30, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 1/5; 39/80] END leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.608 total time=   0.0s\n",
            "[CV 2/5; 39/80] START leaf_size=30, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 2/5; 39/80] END leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.584 total time=   0.0s\n",
            "[CV 3/5; 39/80] START leaf_size=30, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 3/5; 39/80] END leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.560 total time=   0.0s\n",
            "[CV 4/5; 39/80] START leaf_size=30, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 4/5; 39/80] END leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.604 total time=   0.0s\n",
            "[CV 5/5; 39/80] START leaf_size=30, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 5/5; 39/80] END leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.680 total time=   0.0s\n",
            "[CV 1/5; 40/80] START leaf_size=30, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 1/5; 40/80] END leaf_size=30, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 40/80] START leaf_size=30, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 2/5; 40/80] END leaf_size=30, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 40/80] START leaf_size=30, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 3/5; 40/80] END leaf_size=30, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 40/80] START leaf_size=30, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 4/5; 40/80] END leaf_size=30, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 40/80] START leaf_size=30, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 5/5; 40/80] END leaf_size=30, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 41/80] START leaf_size=45, n_neighbors=3, p=1, weights=uniform.........\n",
            "[CV 1/5; 41/80] END leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.648 total time=   0.0s\n",
            "[CV 2/5; 41/80] START leaf_size=45, n_neighbors=3, p=1, weights=uniform.........\n",
            "[CV 2/5; 41/80] END leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.632 total time=   0.0s\n",
            "[CV 3/5; 41/80] START leaf_size=45, n_neighbors=3, p=1, weights=uniform.........\n",
            "[CV 3/5; 41/80] END leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.628 total time=   0.0s\n",
            "[CV 4/5; 41/80] START leaf_size=45, n_neighbors=3, p=1, weights=uniform.........\n",
            "[CV 4/5; 41/80] END leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.660 total time=   0.0s\n",
            "[CV 5/5; 41/80] START leaf_size=45, n_neighbors=3, p=1, weights=uniform.........\n",
            "[CV 5/5; 41/80] END leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.652 total time=   0.0s\n",
            "[CV 1/5; 42/80] START leaf_size=45, n_neighbors=3, p=1, weights=distanc.........\n",
            "[CV 1/5; 42/80] END leaf_size=45, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 42/80] START leaf_size=45, n_neighbors=3, p=1, weights=distanc.........\n",
            "[CV 2/5; 42/80] END leaf_size=45, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 42/80] START leaf_size=45, n_neighbors=3, p=1, weights=distanc.........\n",
            "[CV 3/5; 42/80] END leaf_size=45, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 42/80] START leaf_size=45, n_neighbors=3, p=1, weights=distanc.........\n",
            "[CV 4/5; 42/80] END leaf_size=45, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 42/80] START leaf_size=45, n_neighbors=3, p=1, weights=distanc.........\n",
            "[CV 5/5; 42/80] END leaf_size=45, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 43/80] START leaf_size=45, n_neighbors=3, p=2, weights=uniform.........\n",
            "[CV 1/5; 43/80] END leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.616 total time=   0.0s\n",
            "[CV 2/5; 43/80] START leaf_size=45, n_neighbors=3, p=2, weights=uniform.........\n",
            "[CV 2/5; 43/80] END leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.652 total time=   0.0s\n",
            "[CV 3/5; 43/80] START leaf_size=45, n_neighbors=3, p=2, weights=uniform.........\n",
            "[CV 3/5; 43/80] END leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.640 total time=   0.0s\n",
            "[CV 4/5; 43/80] START leaf_size=45, n_neighbors=3, p=2, weights=uniform.........\n",
            "[CV 4/5; 43/80] END leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.652 total time=   0.0s\n",
            "[CV 5/5; 43/80] START leaf_size=45, n_neighbors=3, p=2, weights=uniform.........\n",
            "[CV 5/5; 43/80] END leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.676 total time=   0.0s\n",
            "[CV 1/5; 44/80] START leaf_size=45, n_neighbors=3, p=2, weights=distanc.........\n",
            "[CV 1/5; 44/80] END leaf_size=45, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 44/80] START leaf_size=45, n_neighbors=3, p=2, weights=distanc.........\n",
            "[CV 2/5; 44/80] END leaf_size=45, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 44/80] START leaf_size=45, n_neighbors=3, p=2, weights=distanc.........\n",
            "[CV 3/5; 44/80] END leaf_size=45, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 44/80] START leaf_size=45, n_neighbors=3, p=2, weights=distanc.........\n",
            "[CV 4/5; 44/80] END leaf_size=45, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 44/80] START leaf_size=45, n_neighbors=3, p=2, weights=distanc.........\n",
            "[CV 5/5; 44/80] END leaf_size=45, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 45/80] START leaf_size=45, n_neighbors=4, p=1, weights=uniform.........\n",
            "[CV 1/5; 45/80] END leaf_size=45, n_neighbors=4, p=1, weights=uniform;, score=0.632 total time=   0.0s\n",
            "[CV 2/5; 45/80] START leaf_size=45, n_neighbors=4, p=1, weights=uniform.........\n",
            "[CV 2/5; 45/80] END leaf_size=45, n_neighbors=4, p=1, weights=uniform;, score=0.608 total time=   0.0s\n",
            "[CV 3/5; 45/80] START leaf_size=45, n_neighbors=4, p=1, weights=uniform.........\n",
            "[CV 3/5; 45/80] END leaf_size=45, n_neighbors=4, p=1, weights=uniform;, score=0.592 total time=   0.0s\n",
            "[CV 4/5; 45/80] START leaf_size=45, n_neighbors=4, p=1, weights=uniform.........\n",
            "[CV 4/5; 45/80] END leaf_size=45, n_neighbors=4, p=1, weights=uniform;, score=0.624 total time=   0.0s\n",
            "[CV 5/5; 45/80] START leaf_size=45, n_neighbors=4, p=1, weights=uniform.........\n",
            "[CV 5/5; 45/80] END leaf_size=45, n_neighbors=4, p=1, weights=uniform;, score=0.652 total time=   0.0s\n",
            "[CV 1/5; 46/80] START leaf_size=45, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 1/5; 46/80] END leaf_size=45, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 46/80] START leaf_size=45, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 2/5; 46/80] END leaf_size=45, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 46/80] START leaf_size=45, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 3/5; 46/80] END leaf_size=45, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 46/80] START leaf_size=45, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 4/5; 46/80] END leaf_size=45, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 46/80] START leaf_size=45, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 5/5; 46/80] END leaf_size=45, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 47/80] START leaf_size=45, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 1/5; 47/80] END leaf_size=45, n_neighbors=4, p=2, weights=uniform;, score=0.588 total time=   0.0s\n",
            "[CV 2/5; 47/80] START leaf_size=45, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 2/5; 47/80] END leaf_size=45, n_neighbors=4, p=2, weights=uniform;, score=0.612 total time=   0.0s\n",
            "[CV 3/5; 47/80] START leaf_size=45, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 3/5; 47/80] END leaf_size=45, n_neighbors=4, p=2, weights=uniform;, score=0.596 total time=   0.0s\n",
            "[CV 4/5; 47/80] START leaf_size=45, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 4/5; 47/80] END leaf_size=45, n_neighbors=4, p=2, weights=uniform;, score=0.580 total time=   0.0s\n",
            "[CV 5/5; 47/80] START leaf_size=45, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 5/5; 47/80] END leaf_size=45, n_neighbors=4, p=2, weights=uniform;, score=0.668 total time=   0.0s\n",
            "[CV 1/5; 48/80] START leaf_size=45, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 1/5; 48/80] END leaf_size=45, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 48/80] START leaf_size=45, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 2/5; 48/80] END leaf_size=45, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 48/80] START leaf_size=45, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 3/5; 48/80] END leaf_size=45, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 48/80] START leaf_size=45, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 4/5; 48/80] END leaf_size=45, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 48/80] START leaf_size=45, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 5/5; 48/80] END leaf_size=45, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 49/80] START leaf_size=45, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 1/5; 49/80] END leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.620 total time=   0.0s\n",
            "[CV 2/5; 49/80] START leaf_size=45, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 2/5; 49/80] END leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.644 total time=   0.0s\n",
            "[CV 3/5; 49/80] START leaf_size=45, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 3/5; 49/80] END leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.584 total time=   0.0s\n",
            "[CV 4/5; 49/80] START leaf_size=45, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 4/5; 49/80] END leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.640 total time=   0.0s\n",
            "[CV 5/5; 49/80] START leaf_size=45, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 5/5; 49/80] END leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.676 total time=   0.0s\n",
            "[CV 1/5; 50/80] START leaf_size=45, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 1/5; 50/80] END leaf_size=45, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 50/80] START leaf_size=45, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 2/5; 50/80] END leaf_size=45, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 50/80] START leaf_size=45, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 3/5; 50/80] END leaf_size=45, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 50/80] START leaf_size=45, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 4/5; 50/80] END leaf_size=45, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 50/80] START leaf_size=45, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 5/5; 50/80] END leaf_size=45, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 51/80] START leaf_size=45, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 1/5; 51/80] END leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.612 total time=   0.0s\n",
            "[CV 2/5; 51/80] START leaf_size=45, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 2/5; 51/80] END leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.664 total time=   0.0s\n",
            "[CV 3/5; 51/80] START leaf_size=45, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 3/5; 51/80] END leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.588 total time=   0.0s\n",
            "[CV 4/5; 51/80] START leaf_size=45, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 4/5; 51/80] END leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.616 total time=   0.0s\n",
            "[CV 5/5; 51/80] START leaf_size=45, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 5/5; 51/80] END leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.700 total time=   0.0s\n",
            "[CV 1/5; 52/80] START leaf_size=45, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 1/5; 52/80] END leaf_size=45, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 52/80] START leaf_size=45, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 2/5; 52/80] END leaf_size=45, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 52/80] START leaf_size=45, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 3/5; 52/80] END leaf_size=45, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 52/80] START leaf_size=45, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 4/5; 52/80] END leaf_size=45, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 52/80] START leaf_size=45, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 5/5; 52/80] END leaf_size=45, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 53/80] START leaf_size=45, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 1/5; 53/80] END leaf_size=45, n_neighbors=6, p=1, weights=uniform;, score=0.616 total time=   0.0s\n",
            "[CV 2/5; 53/80] START leaf_size=45, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 2/5; 53/80] END leaf_size=45, n_neighbors=6, p=1, weights=uniform;, score=0.584 total time=   0.0s\n",
            "[CV 3/5; 53/80] START leaf_size=45, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 3/5; 53/80] END leaf_size=45, n_neighbors=6, p=1, weights=uniform;, score=0.580 total time=   0.0s\n",
            "[CV 4/5; 53/80] START leaf_size=45, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 4/5; 53/80] END leaf_size=45, n_neighbors=6, p=1, weights=uniform;, score=0.628 total time=   0.0s\n",
            "[CV 5/5; 53/80] START leaf_size=45, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 5/5; 53/80] END leaf_size=45, n_neighbors=6, p=1, weights=uniform;, score=0.648 total time=   0.0s\n",
            "[CV 1/5; 54/80] START leaf_size=45, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 1/5; 54/80] END leaf_size=45, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 54/80] START leaf_size=45, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 2/5; 54/80] END leaf_size=45, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 54/80] START leaf_size=45, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 3/5; 54/80] END leaf_size=45, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 54/80] START leaf_size=45, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 4/5; 54/80] END leaf_size=45, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 54/80] START leaf_size=45, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 5/5; 54/80] END leaf_size=45, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 55/80] START leaf_size=45, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 1/5; 55/80] END leaf_size=45, n_neighbors=6, p=2, weights=uniform;, score=0.608 total time=   0.1s\n",
            "[CV 2/5; 55/80] START leaf_size=45, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 2/5; 55/80] END leaf_size=45, n_neighbors=6, p=2, weights=uniform;, score=0.584 total time=   0.0s\n",
            "[CV 3/5; 55/80] START leaf_size=45, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 3/5; 55/80] END leaf_size=45, n_neighbors=6, p=2, weights=uniform;, score=0.588 total time=   0.0s\n",
            "[CV 4/5; 55/80] START leaf_size=45, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 4/5; 55/80] END leaf_size=45, n_neighbors=6, p=2, weights=uniform;, score=0.632 total time=   0.0s\n",
            "[CV 5/5; 55/80] START leaf_size=45, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 5/5; 55/80] END leaf_size=45, n_neighbors=6, p=2, weights=uniform;, score=0.684 total time=   0.1s\n",
            "[CV 1/5; 56/80] START leaf_size=45, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 1/5; 56/80] END leaf_size=45, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 56/80] START leaf_size=45, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 2/5; 56/80] END leaf_size=45, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 56/80] START leaf_size=45, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 3/5; 56/80] END leaf_size=45, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 56/80] START leaf_size=45, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 4/5; 56/80] END leaf_size=45, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 56/80] START leaf_size=45, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 5/5; 56/80] END leaf_size=45, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 57/80] START leaf_size=45, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 1/5; 57/80] END leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.600 total time=   0.0s\n",
            "[CV 2/5; 57/80] START leaf_size=45, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 2/5; 57/80] END leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.588 total time=   0.0s\n",
            "[CV 3/5; 57/80] START leaf_size=45, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 3/5; 57/80] END leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.572 total time=   0.0s\n",
            "[CV 4/5; 57/80] START leaf_size=45, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 4/5; 57/80] END leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.580 total time=   0.0s\n",
            "[CV 5/5; 57/80] START leaf_size=45, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 5/5; 57/80] END leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.688 total time=   0.0s\n",
            "[CV 1/5; 58/80] START leaf_size=45, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 1/5; 58/80] END leaf_size=45, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 58/80] START leaf_size=45, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 2/5; 58/80] END leaf_size=45, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 58/80] START leaf_size=45, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 3/5; 58/80] END leaf_size=45, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 58/80] START leaf_size=45, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 4/5; 58/80] END leaf_size=45, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 58/80] START leaf_size=45, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 5/5; 58/80] END leaf_size=45, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 59/80] START leaf_size=45, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 1/5; 59/80] END leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.608 total time=   0.0s\n",
            "[CV 2/5; 59/80] START leaf_size=45, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 2/5; 59/80] END leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.584 total time=   0.0s\n",
            "[CV 3/5; 59/80] START leaf_size=45, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 3/5; 59/80] END leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.560 total time=   0.0s\n",
            "[CV 4/5; 59/80] START leaf_size=45, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 4/5; 59/80] END leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.604 total time=   0.0s\n",
            "[CV 5/5; 59/80] START leaf_size=45, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 5/5; 59/80] END leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.680 total time=   0.0s\n",
            "[CV 1/5; 60/80] START leaf_size=45, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 1/5; 60/80] END leaf_size=45, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 60/80] START leaf_size=45, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 2/5; 60/80] END leaf_size=45, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 60/80] START leaf_size=45, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 3/5; 60/80] END leaf_size=45, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 60/80] START leaf_size=45, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 4/5; 60/80] END leaf_size=45, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 60/80] START leaf_size=45, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 5/5; 60/80] END leaf_size=45, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 61/80] START leaf_size=60, n_neighbors=3, p=1, weights=uniform.........\n",
            "[CV 1/5; 61/80] END leaf_size=60, n_neighbors=3, p=1, weights=uniform;, score=0.648 total time=   0.0s\n",
            "[CV 2/5; 61/80] START leaf_size=60, n_neighbors=3, p=1, weights=uniform.........\n",
            "[CV 2/5; 61/80] END leaf_size=60, n_neighbors=3, p=1, weights=uniform;, score=0.632 total time=   0.0s\n",
            "[CV 3/5; 61/80] START leaf_size=60, n_neighbors=3, p=1, weights=uniform.........\n",
            "[CV 3/5; 61/80] END leaf_size=60, n_neighbors=3, p=1, weights=uniform;, score=0.628 total time=   0.0s\n",
            "[CV 4/5; 61/80] START leaf_size=60, n_neighbors=3, p=1, weights=uniform.........\n",
            "[CV 4/5; 61/80] END leaf_size=60, n_neighbors=3, p=1, weights=uniform;, score=0.660 total time=   0.0s\n",
            "[CV 5/5; 61/80] START leaf_size=60, n_neighbors=3, p=1, weights=uniform.........\n",
            "[CV 5/5; 61/80] END leaf_size=60, n_neighbors=3, p=1, weights=uniform;, score=0.652 total time=   0.0s\n",
            "[CV 1/5; 62/80] START leaf_size=60, n_neighbors=3, p=1, weights=distanc.........\n",
            "[CV 1/5; 62/80] END leaf_size=60, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 62/80] START leaf_size=60, n_neighbors=3, p=1, weights=distanc.........\n",
            "[CV 2/5; 62/80] END leaf_size=60, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 62/80] START leaf_size=60, n_neighbors=3, p=1, weights=distanc.........\n",
            "[CV 3/5; 62/80] END leaf_size=60, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 62/80] START leaf_size=60, n_neighbors=3, p=1, weights=distanc.........\n",
            "[CV 4/5; 62/80] END leaf_size=60, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 62/80] START leaf_size=60, n_neighbors=3, p=1, weights=distanc.........\n",
            "[CV 5/5; 62/80] END leaf_size=60, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 63/80] START leaf_size=60, n_neighbors=3, p=2, weights=uniform.........\n",
            "[CV 1/5; 63/80] END leaf_size=60, n_neighbors=3, p=2, weights=uniform;, score=0.616 total time=   0.0s\n",
            "[CV 2/5; 63/80] START leaf_size=60, n_neighbors=3, p=2, weights=uniform.........\n",
            "[CV 2/5; 63/80] END leaf_size=60, n_neighbors=3, p=2, weights=uniform;, score=0.652 total time=   0.0s\n",
            "[CV 3/5; 63/80] START leaf_size=60, n_neighbors=3, p=2, weights=uniform.........\n",
            "[CV 3/5; 63/80] END leaf_size=60, n_neighbors=3, p=2, weights=uniform;, score=0.640 total time=   0.0s\n",
            "[CV 4/5; 63/80] START leaf_size=60, n_neighbors=3, p=2, weights=uniform.........\n",
            "[CV 4/5; 63/80] END leaf_size=60, n_neighbors=3, p=2, weights=uniform;, score=0.652 total time=   0.1s\n",
            "[CV 5/5; 63/80] START leaf_size=60, n_neighbors=3, p=2, weights=uniform.........\n",
            "[CV 5/5; 63/80] END leaf_size=60, n_neighbors=3, p=2, weights=uniform;, score=0.676 total time=   0.1s\n",
            "[CV 1/5; 64/80] START leaf_size=60, n_neighbors=3, p=2, weights=distanc.........\n",
            "[CV 1/5; 64/80] END leaf_size=60, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 64/80] START leaf_size=60, n_neighbors=3, p=2, weights=distanc.........\n",
            "[CV 2/5; 64/80] END leaf_size=60, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 64/80] START leaf_size=60, n_neighbors=3, p=2, weights=distanc.........\n",
            "[CV 3/5; 64/80] END leaf_size=60, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 64/80] START leaf_size=60, n_neighbors=3, p=2, weights=distanc.........\n",
            "[CV 4/5; 64/80] END leaf_size=60, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 64/80] START leaf_size=60, n_neighbors=3, p=2, weights=distanc.........\n",
            "[CV 5/5; 64/80] END leaf_size=60, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 65/80] START leaf_size=60, n_neighbors=4, p=1, weights=uniform.........\n",
            "[CV 1/5; 65/80] END leaf_size=60, n_neighbors=4, p=1, weights=uniform;, score=0.632 total time=   0.1s\n",
            "[CV 2/5; 65/80] START leaf_size=60, n_neighbors=4, p=1, weights=uniform.........\n",
            "[CV 2/5; 65/80] END leaf_size=60, n_neighbors=4, p=1, weights=uniform;, score=0.608 total time=   0.0s\n",
            "[CV 3/5; 65/80] START leaf_size=60, n_neighbors=4, p=1, weights=uniform.........\n",
            "[CV 3/5; 65/80] END leaf_size=60, n_neighbors=4, p=1, weights=uniform;, score=0.592 total time=   0.0s\n",
            "[CV 4/5; 65/80] START leaf_size=60, n_neighbors=4, p=1, weights=uniform.........\n",
            "[CV 4/5; 65/80] END leaf_size=60, n_neighbors=4, p=1, weights=uniform;, score=0.624 total time=   0.0s\n",
            "[CV 5/5; 65/80] START leaf_size=60, n_neighbors=4, p=1, weights=uniform.........\n",
            "[CV 5/5; 65/80] END leaf_size=60, n_neighbors=4, p=1, weights=uniform;, score=0.652 total time=   0.0s\n",
            "[CV 1/5; 66/80] START leaf_size=60, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 1/5; 66/80] END leaf_size=60, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 66/80] START leaf_size=60, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 2/5; 66/80] END leaf_size=60, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 66/80] START leaf_size=60, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 3/5; 66/80] END leaf_size=60, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 66/80] START leaf_size=60, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 4/5; 66/80] END leaf_size=60, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 66/80] START leaf_size=60, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 5/5; 66/80] END leaf_size=60, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 67/80] START leaf_size=60, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 1/5; 67/80] END leaf_size=60, n_neighbors=4, p=2, weights=uniform;, score=0.588 total time=   0.0s\n",
            "[CV 2/5; 67/80] START leaf_size=60, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 2/5; 67/80] END leaf_size=60, n_neighbors=4, p=2, weights=uniform;, score=0.612 total time=   0.0s\n",
            "[CV 3/5; 67/80] START leaf_size=60, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 3/5; 67/80] END leaf_size=60, n_neighbors=4, p=2, weights=uniform;, score=0.596 total time=   0.0s\n",
            "[CV 4/5; 67/80] START leaf_size=60, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 4/5; 67/80] END leaf_size=60, n_neighbors=4, p=2, weights=uniform;, score=0.580 total time=   0.0s\n",
            "[CV 5/5; 67/80] START leaf_size=60, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 5/5; 67/80] END leaf_size=60, n_neighbors=4, p=2, weights=uniform;, score=0.668 total time=   0.0s\n",
            "[CV 1/5; 68/80] START leaf_size=60, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 1/5; 68/80] END leaf_size=60, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 68/80] START leaf_size=60, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 2/5; 68/80] END leaf_size=60, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 68/80] START leaf_size=60, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 3/5; 68/80] END leaf_size=60, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 68/80] START leaf_size=60, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 4/5; 68/80] END leaf_size=60, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 68/80] START leaf_size=60, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 5/5; 68/80] END leaf_size=60, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 69/80] START leaf_size=60, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 1/5; 69/80] END leaf_size=60, n_neighbors=5, p=1, weights=uniform;, score=0.620 total time=   0.0s\n",
            "[CV 2/5; 69/80] START leaf_size=60, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 2/5; 69/80] END leaf_size=60, n_neighbors=5, p=1, weights=uniform;, score=0.644 total time=   0.0s\n",
            "[CV 3/5; 69/80] START leaf_size=60, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 3/5; 69/80] END leaf_size=60, n_neighbors=5, p=1, weights=uniform;, score=0.584 total time=   0.0s\n",
            "[CV 4/5; 69/80] START leaf_size=60, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 4/5; 69/80] END leaf_size=60, n_neighbors=5, p=1, weights=uniform;, score=0.640 total time=   0.1s\n",
            "[CV 5/5; 69/80] START leaf_size=60, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 5/5; 69/80] END leaf_size=60, n_neighbors=5, p=1, weights=uniform;, score=0.676 total time=   0.0s\n",
            "[CV 1/5; 70/80] START leaf_size=60, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 1/5; 70/80] END leaf_size=60, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 70/80] START leaf_size=60, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 2/5; 70/80] END leaf_size=60, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 70/80] START leaf_size=60, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 3/5; 70/80] END leaf_size=60, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 70/80] START leaf_size=60, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 4/5; 70/80] END leaf_size=60, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 70/80] START leaf_size=60, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 5/5; 70/80] END leaf_size=60, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 71/80] START leaf_size=60, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 1/5; 71/80] END leaf_size=60, n_neighbors=5, p=2, weights=uniform;, score=0.612 total time=   0.0s\n",
            "[CV 2/5; 71/80] START leaf_size=60, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 2/5; 71/80] END leaf_size=60, n_neighbors=5, p=2, weights=uniform;, score=0.664 total time=   0.0s\n",
            "[CV 3/5; 71/80] START leaf_size=60, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 3/5; 71/80] END leaf_size=60, n_neighbors=5, p=2, weights=uniform;, score=0.588 total time=   0.0s\n",
            "[CV 4/5; 71/80] START leaf_size=60, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 4/5; 71/80] END leaf_size=60, n_neighbors=5, p=2, weights=uniform;, score=0.616 total time=   0.0s\n",
            "[CV 5/5; 71/80] START leaf_size=60, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 5/5; 71/80] END leaf_size=60, n_neighbors=5, p=2, weights=uniform;, score=0.700 total time=   0.0s\n",
            "[CV 1/5; 72/80] START leaf_size=60, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 1/5; 72/80] END leaf_size=60, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 72/80] START leaf_size=60, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 2/5; 72/80] END leaf_size=60, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 72/80] START leaf_size=60, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 3/5; 72/80] END leaf_size=60, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 72/80] START leaf_size=60, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 4/5; 72/80] END leaf_size=60, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 72/80] START leaf_size=60, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 5/5; 72/80] END leaf_size=60, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 73/80] START leaf_size=60, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 1/5; 73/80] END leaf_size=60, n_neighbors=6, p=1, weights=uniform;, score=0.616 total time=   0.0s\n",
            "[CV 2/5; 73/80] START leaf_size=60, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 2/5; 73/80] END leaf_size=60, n_neighbors=6, p=1, weights=uniform;, score=0.584 total time=   0.0s\n",
            "[CV 3/5; 73/80] START leaf_size=60, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 3/5; 73/80] END leaf_size=60, n_neighbors=6, p=1, weights=uniform;, score=0.580 total time=   0.0s\n",
            "[CV 4/5; 73/80] START leaf_size=60, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 4/5; 73/80] END leaf_size=60, n_neighbors=6, p=1, weights=uniform;, score=0.628 total time=   0.1s\n",
            "[CV 5/5; 73/80] START leaf_size=60, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 5/5; 73/80] END leaf_size=60, n_neighbors=6, p=1, weights=uniform;, score=0.648 total time=   0.0s\n",
            "[CV 1/5; 74/80] START leaf_size=60, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 1/5; 74/80] END leaf_size=60, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 74/80] START leaf_size=60, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 2/5; 74/80] END leaf_size=60, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 74/80] START leaf_size=60, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 3/5; 74/80] END leaf_size=60, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 74/80] START leaf_size=60, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 4/5; 74/80] END leaf_size=60, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 74/80] START leaf_size=60, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 5/5; 74/80] END leaf_size=60, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 75/80] START leaf_size=60, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 1/5; 75/80] END leaf_size=60, n_neighbors=6, p=2, weights=uniform;, score=0.608 total time=   0.0s\n",
            "[CV 2/5; 75/80] START leaf_size=60, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 2/5; 75/80] END leaf_size=60, n_neighbors=6, p=2, weights=uniform;, score=0.584 total time=   0.0s\n",
            "[CV 3/5; 75/80] START leaf_size=60, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 3/5; 75/80] END leaf_size=60, n_neighbors=6, p=2, weights=uniform;, score=0.588 total time=   0.0s\n",
            "[CV 4/5; 75/80] START leaf_size=60, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 4/5; 75/80] END leaf_size=60, n_neighbors=6, p=2, weights=uniform;, score=0.632 total time=   0.0s\n",
            "[CV 5/5; 75/80] START leaf_size=60, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 5/5; 75/80] END leaf_size=60, n_neighbors=6, p=2, weights=uniform;, score=0.684 total time=   0.0s\n",
            "[CV 1/5; 76/80] START leaf_size=60, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 1/5; 76/80] END leaf_size=60, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 76/80] START leaf_size=60, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 2/5; 76/80] END leaf_size=60, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 76/80] START leaf_size=60, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 3/5; 76/80] END leaf_size=60, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 76/80] START leaf_size=60, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 4/5; 76/80] END leaf_size=60, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 76/80] START leaf_size=60, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 5/5; 76/80] END leaf_size=60, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 77/80] START leaf_size=60, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 1/5; 77/80] END leaf_size=60, n_neighbors=7, p=1, weights=uniform;, score=0.600 total time=   0.0s\n",
            "[CV 2/5; 77/80] START leaf_size=60, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 2/5; 77/80] END leaf_size=60, n_neighbors=7, p=1, weights=uniform;, score=0.588 total time=   0.1s\n",
            "[CV 3/5; 77/80] START leaf_size=60, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 3/5; 77/80] END leaf_size=60, n_neighbors=7, p=1, weights=uniform;, score=0.572 total time=   0.0s\n",
            "[CV 4/5; 77/80] START leaf_size=60, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 4/5; 77/80] END leaf_size=60, n_neighbors=7, p=1, weights=uniform;, score=0.580 total time=   0.0s\n",
            "[CV 5/5; 77/80] START leaf_size=60, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 5/5; 77/80] END leaf_size=60, n_neighbors=7, p=1, weights=uniform;, score=0.688 total time=   0.0s\n",
            "[CV 1/5; 78/80] START leaf_size=60, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 1/5; 78/80] END leaf_size=60, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 78/80] START leaf_size=60, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 2/5; 78/80] END leaf_size=60, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 78/80] START leaf_size=60, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 3/5; 78/80] END leaf_size=60, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 78/80] START leaf_size=60, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 4/5; 78/80] END leaf_size=60, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 78/80] START leaf_size=60, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 5/5; 78/80] END leaf_size=60, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 79/80] START leaf_size=60, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 1/5; 79/80] END leaf_size=60, n_neighbors=7, p=2, weights=uniform;, score=0.608 total time=   0.1s\n",
            "[CV 2/5; 79/80] START leaf_size=60, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 2/5; 79/80] END leaf_size=60, n_neighbors=7, p=2, weights=uniform;, score=0.584 total time=   0.0s\n",
            "[CV 3/5; 79/80] START leaf_size=60, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 3/5; 79/80] END leaf_size=60, n_neighbors=7, p=2, weights=uniform;, score=0.560 total time=   0.0s\n",
            "[CV 4/5; 79/80] START leaf_size=60, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 4/5; 79/80] END leaf_size=60, n_neighbors=7, p=2, weights=uniform;, score=0.604 total time=   0.0s\n",
            "[CV 5/5; 79/80] START leaf_size=60, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 5/5; 79/80] END leaf_size=60, n_neighbors=7, p=2, weights=uniform;, score=0.680 total time=   0.0s\n",
            "[CV 1/5; 80/80] START leaf_size=60, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 1/5; 80/80] END leaf_size=60, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 80/80] START leaf_size=60, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 2/5; 80/80] END leaf_size=60, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 80/80] START leaf_size=60, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 3/5; 80/80] END leaf_size=60, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 80/80] START leaf_size=60, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 4/5; 80/80] END leaf_size=60, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 80/80] START leaf_size=60, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 5/5; 80/80] END leaf_size=60, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "200 fits failed out of a total of 400.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "200 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py\", line 213, in fit\n",
            "    self._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 600, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'weights' parameter of KNeighborsClassifier must be a str among {'distance', 'uniform'}, a callable or None. Got 'distanc' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.644     nan 0.6472    nan 0.6216    nan 0.6088    nan 0.6328    nan\n",
            " 0.636     nan 0.6112    nan 0.6192    nan 0.6056    nan 0.6072    nan\n",
            " 0.644     nan 0.6472    nan 0.6216    nan 0.6088    nan 0.6328    nan\n",
            " 0.636     nan 0.6112    nan 0.6192    nan 0.6056    nan 0.6072    nan\n",
            " 0.644     nan 0.6472    nan 0.6216    nan 0.6088    nan 0.6328    nan\n",
            " 0.636     nan 0.6112    nan 0.6192    nan 0.6056    nan 0.6072    nan\n",
            " 0.644     nan 0.6472    nan 0.6216    nan 0.6088    nan 0.6328    nan\n",
            " 0.636     nan 0.6112    nan 0.6192    nan 0.6056    nan 0.6072    nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;knnc&#x27;,\n",
              "                 GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
              "                              param_grid=[{&#x27;leaf_size&#x27;: [15, 30, 45, 60],\n",
              "                                           &#x27;n_neighbors&#x27;: [3, 4, 5, 6, 7],\n",
              "                                           &#x27;p&#x27;: [1, 2],\n",
              "                                           &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distanc&#x27;]}],\n",
              "                              verbose=10))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;knnc&#x27;,\n",
              "                 GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
              "                              param_grid=[{&#x27;leaf_size&#x27;: [15, 30, 45, 60],\n",
              "                                           &#x27;n_neighbors&#x27;: [3, 4, 5, 6, 7],\n",
              "                                           &#x27;p&#x27;: [1, 2],\n",
              "                                           &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distanc&#x27;]}],\n",
              "                              verbose=10))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">knnc: GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
              "             param_grid=[{&#x27;leaf_size&#x27;: [15, 30, 45, 60],\n",
              "                          &#x27;n_neighbors&#x27;: [3, 4, 5, 6, 7], &#x27;p&#x27;: [1, 2],\n",
              "                          &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distanc&#x27;]}],\n",
              "             verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                ('knnc',\n",
              "                 GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
              "                              param_grid=[{'leaf_size': [15, 30, 45, 60],\n",
              "                                           'n_neighbors': [3, 4, 5, 6, 7],\n",
              "                                           'p': [1, 2],\n",
              "                                           'weights': ['uniform', 'distanc']}],\n",
              "                              verbose=10))])"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "param_grid = [{'n_neighbors': [3, 4, 5, 6, 7], 'weights':['uniform', 'distanc'], 'leaf_size': [15, 30, 45, 60], 'p': [1, 2]}]\n",
        "\n",
        "clf = Pipeline([('scaler', StandardScaler()),\n",
        "                ('knnc', GridSearchCV(KNeighborsClassifier(),\n",
        "                              param_grid=param_grid,\n",
        "                              cv=5,\n",
        "                              refit=True,\n",
        "                              verbose=10))])\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "e-Pj1xx6lOxU",
        "outputId": "dce1e72e-faf4-468d-ef9c-c096dc6bf244"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(leaf_size=15, n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" checked><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(leaf_size=15, n_neighbors=3)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KNeighborsClassifier(leaf_size=15, n_neighbors=3)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf['knnc'].best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Q7fw6dwlSy1",
        "outputId": "ac50255b-17c5-410e-ea15-079ff2edbbea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6472"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf['knnc'].best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-o_mXlfKlHq9"
      },
      "source": [
        "#### Evaluating Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgaQ1Sc5kuo9",
        "outputId": "1d7be28c-cd1f-468f-dea4-990a3c753ed0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation f1 Score:  0.6571936056838366\n",
            "Test f1 Score:  0.5831325301204819\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "y_valid_pred = clf.predict(X_valid)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Validation f1 Score: \", f1_score(y_valid, y_valid_pred))\n",
        "print(\"Test f1 Score: \", f1_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8UAlZ6qlFQk"
      },
      "source": [
        "### Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62JLdYYVl5b9"
      },
      "source": [
        "#### Training Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GwpKoUzXl1HE",
        "outputId": "eab23fdb-a97d-4f5a-b381-eddfdaf6a2fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
            "[CV 1/5; 1/216] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 1/216] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.608 total time=   0.0s\n",
            "[CV 2/5; 1/216] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 1/216] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.648 total time=   0.0s\n",
            "[CV 3/5; 1/216] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 1/216] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.712 total time=   0.0s\n",
            "[CV 4/5; 1/216] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 1/216] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.624 total time=   0.0s\n",
            "[CV 5/5; 1/216] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 1/216] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.688 total time=   0.0s\n",
            "[CV 1/5; 2/216] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 2/216] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.592 total time=   0.0s\n",
            "[CV 2/5; 2/216] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 2/216] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.664 total time=   0.0s\n",
            "[CV 3/5; 2/216] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 2/216] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.620 total time=   0.0s\n",
            "[CV 4/5; 2/216] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 2/216] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.560 total time=   0.0s\n",
            "[CV 5/5; 2/216] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 2/216] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.640 total time=   0.0s\n",
            "[CV 1/5; 3/216] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 3/216] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.588 total time=   0.0s\n",
            "[CV 2/5; 3/216] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 3/216] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.672 total time=   0.0s\n",
            "[CV 3/5; 3/216] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 3/216] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.656 total time=   0.0s\n",
            "[CV 4/5; 3/216] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 3/216] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.616 total time=   0.0s\n",
            "[CV 5/5; 3/216] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 3/216] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.656 total time=   0.0s\n",
            "[CV 1/5; 4/216] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 4/216] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.612 total time=   0.0s\n",
            "[CV 2/5; 4/216] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 4/216] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.600 total time=   0.0s\n",
            "[CV 3/5; 4/216] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 4/216] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.580 total time=   0.0s\n",
            "[CV 4/5; 4/216] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 4/216] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.548 total time=   0.0s\n",
            "[CV 5/5; 4/216] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 4/216] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.612 total time=   0.0s\n",
            "[CV 1/5; 5/216] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 5/216] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.664 total time=   0.0s\n",
            "[CV 2/5; 5/216] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 5/216] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.620 total time=   0.0s\n",
            "[CV 3/5; 5/216] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 5/216] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.656 total time=   0.0s\n",
            "[CV 4/5; 5/216] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 5/216] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.624 total time=   0.0s\n",
            "[CV 5/5; 5/216] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 5/216] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.700 total time=   0.0s\n",
            "[CV 1/5; 6/216] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 6/216] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.636 total time=   0.0s\n",
            "[CV 2/5; 6/216] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 6/216] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.692 total time=   0.0s\n",
            "[CV 3/5; 6/216] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 6/216] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.672 total time=   0.0s\n",
            "[CV 4/5; 6/216] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 6/216] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.572 total time=   0.0s\n",
            "[CV 5/5; 6/216] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 6/216] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.560 total time=   0.0s\n",
            "[CV 1/5; 7/216] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 7/216] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.640 total time=   0.0s\n",
            "[CV 2/5; 7/216] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 7/216] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.596 total time=   0.0s\n",
            "[CV 3/5; 7/216] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 7/216] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.588 total time=   0.0s\n",
            "[CV 4/5; 7/216] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 7/216] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.644 total time=   0.0s\n",
            "[CV 5/5; 7/216] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 7/216] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.660 total time=   0.0s\n",
            "[CV 1/5; 8/216] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 8/216] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.644 total time=   0.0s\n",
            "[CV 2/5; 8/216] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 8/216] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.608 total time=   0.0s\n",
            "[CV 3/5; 8/216] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 8/216] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.584 total time=   0.0s\n",
            "[CV 4/5; 8/216] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 8/216] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.596 total time=   0.0s\n",
            "[CV 5/5; 8/216] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 8/216] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.620 total time=   0.0s\n",
            "[CV 1/5; 9/216] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 9/216] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.712 total time=   0.0s\n",
            "[CV 2/5; 9/216] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 9/216] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.652 total time=   0.0s\n",
            "[CV 3/5; 9/216] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 9/216] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.660 total time=   0.0s\n",
            "[CV 4/5; 9/216] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 9/216] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.588 total time=   0.0s\n",
            "[CV 5/5; 9/216] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 9/216] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.660 total time=   0.0s\n",
            "[CV 1/5; 10/216] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 10/216] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.612 total time=   0.0s\n",
            "[CV 2/5; 10/216] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 10/216] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.548 total time=   0.0s\n",
            "[CV 3/5; 10/216] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 10/216] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.596 total time=   0.0s\n",
            "[CV 4/5; 10/216] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 10/216] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.572 total time=   0.0s\n",
            "[CV 5/5; 10/216] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 10/216] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.616 total time=   0.0s\n",
            "[CV 1/5; 11/216] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 11/216] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.664 total time=   0.0s\n",
            "[CV 2/5; 11/216] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 11/216] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.624 total time=   0.0s\n",
            "[CV 3/5; 11/216] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 11/216] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.616 total time=   0.0s\n",
            "[CV 4/5; 11/216] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 11/216] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.652 total time=   0.0s\n",
            "[CV 5/5; 11/216] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 11/216] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.712 total time=   0.0s\n",
            "[CV 1/5; 12/216] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 12/216] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.600 total time=   0.0s\n",
            "[CV 2/5; 12/216] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 12/216] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.516 total time=   0.0s\n",
            "[CV 3/5; 12/216] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 12/216] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.604 total time=   0.0s\n",
            "[CV 4/5; 12/216] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 12/216] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.616 total time=   0.0s\n",
            "[CV 5/5; 12/216] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 12/216] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.660 total time=   0.0s\n",
            "[CV 1/5; 13/216] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 13/216] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.600 total time=   0.0s\n",
            "[CV 2/5; 13/216] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 13/216] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.624 total time=   0.0s\n",
            "[CV 3/5; 13/216] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 13/216] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.684 total time=   0.0s\n",
            "[CV 4/5; 13/216] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 13/216] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.648 total time=   0.0s\n",
            "[CV 5/5; 13/216] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 13/216] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.688 total time=   0.0s\n",
            "[CV 1/5; 14/216] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 14/216] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.584 total time=   0.0s\n",
            "[CV 2/5; 14/216] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 14/216] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.560 total time=   0.0s\n",
            "[CV 3/5; 14/216] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 14/216] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.608 total time=   0.0s\n",
            "[CV 4/5; 14/216] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 14/216] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.536 total time=   0.0s\n",
            "[CV 5/5; 14/216] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 14/216] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.588 total time=   0.0s\n",
            "[CV 1/5; 15/216] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 15/216] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.632 total time=   0.0s\n",
            "[CV 2/5; 15/216] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 15/216] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.640 total time=   0.0s\n",
            "[CV 3/5; 15/216] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 15/216] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.596 total time=   0.0s\n",
            "[CV 4/5; 15/216] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 15/216] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.632 total time=   0.0s\n",
            "[CV 5/5; 15/216] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 15/216] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.684 total time=   0.0s\n",
            "[CV 1/5; 16/216] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 16/216] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.512 total time=   0.0s\n",
            "[CV 2/5; 16/216] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 16/216] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.528 total time=   0.0s\n",
            "[CV 3/5; 16/216] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 16/216] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.552 total time=   0.0s\n",
            "[CV 4/5; 16/216] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 16/216] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.588 total time=   0.0s\n",
            "[CV 5/5; 16/216] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 16/216] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.572 total time=   0.0s\n",
            "[CV 1/5; 17/216] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 17/216] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.676 total time=   0.0s\n",
            "[CV 2/5; 17/216] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 17/216] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.584 total time=   0.0s\n",
            "[CV 3/5; 17/216] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 17/216] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.612 total time=   0.0s\n",
            "[CV 4/5; 17/216] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 17/216] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.688 total time=   0.0s"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[CV 5/5; 17/216] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 17/216] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.660 total time=   0.0s\n",
            "[CV 1/5; 18/216] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 18/216] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.628 total time=   0.0s\n",
            "[CV 2/5; 18/216] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 18/216] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.572 total time=   0.0s\n",
            "[CV 3/5; 18/216] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 18/216] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.556 total time=   0.0s\n",
            "[CV 4/5; 18/216] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 18/216] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.580 total time=   0.0s\n",
            "[CV 5/5; 18/216] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 18/216] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.624 total time=   0.0s\n",
            "[CV 1/5; 19/216] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 19/216] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.680 total time=   0.0s\n",
            "[CV 2/5; 19/216] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 19/216] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.660 total time=   0.0s\n",
            "[CV 3/5; 19/216] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 19/216] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.640 total time=   0.0s\n",
            "[CV 4/5; 19/216] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 19/216] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.656 total time=   0.0s\n",
            "[CV 5/5; 19/216] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 19/216] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.708 total time=   0.0s\n",
            "[CV 1/5; 20/216] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 20/216] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.640 total time=   0.0s\n",
            "[CV 2/5; 20/216] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 20/216] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.588 total time=   0.0s\n",
            "[CV 3/5; 20/216] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 20/216] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.616 total time=   0.0s\n",
            "[CV 4/5; 20/216] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 20/216] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.672 total time=   0.0s\n",
            "[CV 5/5; 20/216] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 20/216] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.668 total time=   0.0s\n",
            "[CV 1/5; 21/216] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 21/216] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.688 total time=   0.0s\n",
            "[CV 2/5; 21/216] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 21/216] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.660 total time=   0.0s\n",
            "[CV 3/5; 21/216] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 21/216] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.636 total time=   0.0s\n",
            "[CV 4/5; 21/216] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 21/216] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.628 total time=   0.0s\n",
            "[CV 5/5; 21/216] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 21/216] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.720 total time=   0.0s\n",
            "[CV 1/5; 22/216] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 22/216] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.648 total time=   0.0s\n",
            "[CV 2/5; 22/216] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 22/216] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.664 total time=   0.0s\n",
            "[CV 3/5; 22/216] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 22/216] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.660 total time=   0.0s\n",
            "[CV 4/5; 22/216] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 22/216] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.632 total time=   0.0s\n",
            "[CV 5/5; 22/216] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 22/216] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.624 total time=   0.0s\n",
            "[CV 1/5; 23/216] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 23/216] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.620 total time=   0.0s\n",
            "[CV 2/5; 23/216] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 23/216] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.588 total time=   0.0s\n",
            "[CV 3/5; 23/216] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 23/216] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.624 total time=   0.0s\n",
            "[CV 4/5; 23/216] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 23/216] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.564 total time=   0.0s\n",
            "[CV 5/5; 23/216] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 23/216] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.644 total time=   0.0s\n",
            "[CV 1/5; 24/216] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 24/216] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.648 total time=   0.0s\n",
            "[CV 2/5; 24/216] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 24/216] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.572 total time=   0.0s\n",
            "[CV 3/5; 24/216] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 24/216] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.660 total time=   0.0s\n",
            "[CV 4/5; 24/216] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 24/216] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.656 total time=   0.0s\n",
            "[CV 5/5; 24/216] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 24/216] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.660 total time=   0.0s\n",
            "[CV 1/5; 25/216] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 25/216] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.660 total time=   0.0s\n",
            "[CV 2/5; 25/216] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 25/216] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.628 total time=   0.0s\n",
            "[CV 3/5; 25/216] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 25/216] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.652 total time=   0.0s\n",
            "[CV 4/5; 25/216] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 25/216] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.644 total time=   0.0s\n",
            "[CV 5/5; 25/216] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 25/216] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.672 total time=   0.0s\n",
            "[CV 1/5; 26/216] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 26/216] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.532 total time=   0.0s\n",
            "[CV 2/5; 26/216] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 26/216] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.576 total time=   0.0s\n",
            "[CV 3/5; 26/216] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 26/216] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.580 total time=   0.0s\n",
            "[CV 4/5; 26/216] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 26/216] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.560 total time=   0.0s\n",
            "[CV 5/5; 26/216] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 26/216] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.492 total time=   0.0s\n",
            "[CV 1/5; 27/216] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 27/216] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.628 total time=   0.0s\n",
            "[CV 2/5; 27/216] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 27/216] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.604 total time=   0.0s\n",
            "[CV 3/5; 27/216] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 27/216] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.604 total time=   0.0s\n",
            "[CV 4/5; 27/216] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 27/216] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.604 total time=   0.0s\n",
            "[CV 5/5; 27/216] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 27/216] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.676 total time=   0.0s\n",
            "[CV 1/5; 28/216] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 28/216] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.576 total time=   0.0s\n",
            "[CV 2/5; 28/216] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 28/216] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.548 total time=   0.0s\n",
            "[CV 3/5; 28/216] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 28/216] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.592 total time=   0.0s\n",
            "[CV 4/5; 28/216] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 28/216] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.536 total time=   0.0s\n",
            "[CV 5/5; 28/216] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 28/216] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.608 total time=   0.0s\n",
            "[CV 1/5; 29/216] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 29/216] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.616 total time=   0.0s\n",
            "[CV 2/5; 29/216] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 29/216] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.600 total time=   0.0s\n",
            "[CV 3/5; 29/216] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 29/216] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.504 total time=   0.0s\n",
            "[CV 4/5; 29/216] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 29/216] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.628 total time=   0.0s\n",
            "[CV 5/5; 29/216] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 29/216] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.668 total time=   0.0s\n",
            "[CV 1/5; 30/216] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 30/216] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.672 total time=   0.0s\n",
            "[CV 2/5; 30/216] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 30/216] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.564 total time=   0.0s\n",
            "[CV 3/5; 30/216] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 30/216] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.576 total time=   0.0s\n",
            "[CV 4/5; 30/216] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 30/216] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.604 total time=   0.0s\n",
            "[CV 5/5; 30/216] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 30/216] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.516 total time=   0.0s\n",
            "[CV 1/5; 31/216] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 31/216] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.740 total time=   0.0s\n",
            "[CV 2/5; 31/216] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 31/216] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.636 total time=   0.0s\n",
            "[CV 3/5; 31/216] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 31/216] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.708 total time=   0.0s\n",
            "[CV 4/5; 31/216] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 31/216] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.620 total time=   0.0s\n",
            "[CV 5/5; 31/216] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 31/216] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.684 total time=   0.0s\n",
            "[CV 1/5; 32/216] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 32/216] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.596 total time=   0.0s\n",
            "[CV 2/5; 32/216] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 32/216] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.568 total time=   0.0s\n",
            "[CV 3/5; 32/216] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 32/216] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.576 total time=   0.0s\n",
            "[CV 4/5; 32/216] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 32/216] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.532 total time=   0.0s\n",
            "[CV 5/5; 32/216] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 32/216] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.596 total time=   0.0s\n",
            "[CV 1/5; 33/216] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 33/216] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.688 total time=   0.0s\n",
            "[CV 2/5; 33/216] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 33/216] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.628 total time=   0.0s\n",
            "[CV 3/5; 33/216] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 33/216] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.612 total time=   0.0s\n",
            "[CV 4/5; 33/216] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 33/216] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.580 total time=   0.0s\n",
            "[CV 5/5; 33/216] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 33/216] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.696 total time=   0.0s\n",
            "[CV 1/5; 34/216] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 34/216] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.584 total time=   0.0s\n",
            "[CV 2/5; 34/216] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 34/216] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.620 total time=   0.0s\n",
            "[CV 3/5; 34/216] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 34/216] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.492 total time=   0.0s\n",
            "[CV 4/5; 34/216] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 34/216] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.572 total time=   0.0s\n",
            "[CV 5/5; 34/216] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 34/216] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.640 total time=   0.0s\n",
            "[CV 1/5; 35/216] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 35/216] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.668 total time=   0.0s\n",
            "[CV 2/5; 35/216] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 35/216] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 3/5; 35/216] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 35/216] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.644 total time=   0.0s\n",
            "[CV 4/5; 35/216] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 35/216] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.616 total time=   0.0s\n",
            "[CV 5/5; 35/216] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 35/216] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.684 total time=   0.0s\n",
            "[CV 1/5; 36/216] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 36/216] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.572 total time=   0.0s\n",
            "[CV 2/5; 36/216] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 36/216] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.548 total time=   0.0s\n",
            "[CV 3/5; 36/216] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 36/216] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.552 total time=   0.0s\n",
            "[CV 4/5; 36/216] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 36/216] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.544 total time=   0.0s\n",
            "[CV 5/5; 36/216] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 36/216] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.556 total time=   0.0s\n",
            "[CV 1/5; 37/216] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 37/216] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.684 total time=   0.0s\n",
            "[CV 2/5; 37/216] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 37/216] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.628 total time=   0.0s\n",
            "[CV 3/5; 37/216] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 37/216] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.664 total time=   0.0s\n",
            "[CV 4/5; 37/216] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 37/216] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.716 total time=   0.0s\n",
            "[CV 5/5; 37/216] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 37/216] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.744 total time=   0.0s\n",
            "[CV 1/5; 38/216] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 38/216] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.652 total time=   0.0s\n",
            "[CV 2/5; 38/216] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 38/216] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.676 total time=   0.0s\n",
            "[CV 3/5; 38/216] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 38/216] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.612 total time=   0.0s\n",
            "[CV 4/5; 38/216] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 38/216] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.628 total time=   0.0s\n",
            "[CV 5/5; 38/216] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 38/216] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.616 total time=   0.0s\n",
            "[CV 1/5; 39/216] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 39/216] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.676 total time=   0.0s\n",
            "[CV 2/5; 39/216] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 39/216] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.684 total time=   0.0s\n",
            "[CV 3/5; 39/216] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 39/216] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.704 total time=   0.0s\n",
            "[CV 4/5; 39/216] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 39/216] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.624 total time=   0.0s\n",
            "[CV 5/5; 39/216] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 39/216] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.632 total time=   0.0s\n",
            "[CV 1/5; 40/216] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 40/216] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.632 total time=   0.0s\n",
            "[CV 2/5; 40/216] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 40/216] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.584 total time=   0.0s\n",
            "[CV 3/5; 40/216] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 40/216] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.612 total time=   0.0s\n",
            "[CV 4/5; 40/216] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 40/216] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.632 total time=   0.0s\n",
            "[CV 5/5; 40/216] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 40/216] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.628 total time=   0.0s\n",
            "[CV 1/5; 41/216] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 41/216] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.708 total time=   0.0s\n",
            "[CV 2/5; 41/216] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 41/216] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.624 total time=   0.0s\n",
            "[CV 3/5; 41/216] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 41/216] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.636 total time=   0.0s\n",
            "[CV 4/5; 41/216] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 41/216] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.692 total time=   0.0s\n",
            "[CV 5/5; 41/216] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 41/216] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.720 total time=   0.0s\n",
            "[CV 1/5; 42/216] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 42/216] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.644 total time=   0.0s\n",
            "[CV 2/5; 42/216] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 42/216] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.596 total time=   0.0s\n",
            "[CV 3/5; 42/216] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 42/216] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.664 total time=   0.0s\n",
            "[CV 4/5; 42/216] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 42/216] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.572 total time=   0.0s\n",
            "[CV 5/5; 42/216] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 42/216] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.620 total time=   0.0s\n",
            "[CV 1/5; 43/216] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 43/216] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.656 total time=   0.0s\n",
            "[CV 2/5; 43/216] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 43/216] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.648 total time=   0.0s\n",
            "[CV 3/5; 43/216] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 43/216] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.664 total time=   0.0s\n",
            "[CV 4/5; 43/216] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 43/216] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.636 total time=   0.0s\n",
            "[CV 5/5; 43/216] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 43/216] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.668 total time=   0.0s\n",
            "[CV 1/5; 44/216] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 44/216] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.680 total time=   0.0s\n",
            "[CV 2/5; 44/216] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 44/216] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.568 total time=   0.0s\n",
            "[CV 3/5; 44/216] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 44/216] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.632 total time=   0.0s\n",
            "[CV 4/5; 44/216] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 44/216] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.636 total time=   0.0s\n",
            "[CV 5/5; 44/216] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 44/216] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.628 total time=   0.0s\n",
            "[CV 1/5; 45/216] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 45/216] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.676 total time=   0.0s\n",
            "[CV 2/5; 45/216] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 45/216] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.624 total time=   0.0s\n",
            "[CV 3/5; 45/216] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 45/216] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.680 total time=   0.0s\n",
            "[CV 4/5; 45/216] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 45/216] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.668 total time=   0.0s\n",
            "[CV 5/5; 45/216] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 45/216] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.692 total time=   0.0s\n",
            "[CV 1/5; 46/216] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 46/216] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.680 total time=   0.0s\n",
            "[CV 2/5; 46/216] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 46/216] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.624 total time=   0.0s\n",
            "[CV 3/5; 46/216] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 46/216] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.576 total time=   0.0s\n",
            "[CV 4/5; 46/216] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 46/216] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.620 total time=   0.0s\n",
            "[CV 5/5; 46/216] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 46/216] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.580 total time=   0.0s\n",
            "[CV 1/5; 47/216] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 47/216] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.672 total time=   0.0s\n",
            "[CV 2/5; 47/216] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 47/216] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.676 total time=   0.0s\n",
            "[CV 3/5; 47/216] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 47/216] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.648 total time=   0.0s\n",
            "[CV 4/5; 47/216] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 47/216] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.676 total time=   0.0s\n",
            "[CV 5/5; 47/216] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 47/216] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.652 total time=   0.0s\n",
            "[CV 1/5; 48/216] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 48/216] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.628 total time=   0.0s\n",
            "[CV 2/5; 48/216] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 48/216] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.560 total time=   0.0s\n",
            "[CV 3/5; 48/216] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 48/216] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.612 total time=   0.0s\n",
            "[CV 4/5; 48/216] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 48/216] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.652 total time=   0.0s\n",
            "[CV 5/5; 48/216] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 48/216] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.592 total time=   0.0s\n",
            "[CV 1/5; 49/216] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 49/216] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.672 total time=   0.0s\n",
            "[CV 2/5; 49/216] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 49/216] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.656 total time=   0.0s\n",
            "[CV 3/5; 49/216] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 49/216] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.644 total time=   0.0s\n",
            "[CV 4/5; 49/216] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 49/216] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.668 total time=   0.0s\n",
            "[CV 5/5; 49/216] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 49/216] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.652 total time=   0.0s\n",
            "[CV 1/5; 50/216] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 50/216] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.592 total time=   0.0s\n",
            "[CV 2/5; 50/216] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 50/216] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.616 total time=   0.0s\n",
            "[CV 3/5; 50/216] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 50/216] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.624 total time=   0.0s\n",
            "[CV 4/5; 50/216] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 50/216] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.624 total time=   0.0s\n",
            "[CV 5/5; 50/216] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 50/216] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.632 total time=   0.0s\n",
            "[CV 1/5; 51/216] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 51/216] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.672 total time=   0.0s\n",
            "[CV 2/5; 51/216] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 51/216] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.692 total time=   0.0s\n",
            "[CV 3/5; 51/216] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 51/216] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.620 total time=   0.0s\n",
            "[CV 4/5; 51/216] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 51/216] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.676 total time=   0.0s\n",
            "[CV 5/5; 51/216] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 51/216] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.712 total time=   0.0s\n",
            "[CV 1/5; 52/216] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 52/216] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.664 total time=   0.0s\n",
            "[CV 2/5; 52/216] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 52/216] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.580 total time=   0.0s\n",
            "[CV 3/5; 52/216] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 52/216] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.596 total time=   0.0s\n",
            "[CV 4/5; 52/216] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 52/216] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.596 total time=   0.0s\n",
            "[CV 5/5; 52/216] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 52/216] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.620 total time=   0.0s\n",
            "[CV 1/5; 53/216] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 53/216] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.700 total time=   0.0s\n",
            "[CV 2/5; 53/216] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 53/216] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.652 total time=   0.0s\n",
            "[CV 3/5; 53/216] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 53/216] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.720 total time=   0.0s\n",
            "[CV 4/5; 53/216] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 53/216] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.660 total time=   0.0s\n",
            "[CV 5/5; 53/216] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 53/216] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.688 total time=   0.0s\n",
            "[CV 1/5; 54/216] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 54/216] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.528 total time=   0.0s\n",
            "[CV 2/5; 54/216] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 54/216] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.580 total time=   0.0s\n",
            "[CV 3/5; 54/216] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 54/216] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.616 total time=   0.0s\n",
            "[CV 4/5; 54/216] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 54/216] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.504 total time=   0.0s\n",
            "[CV 5/5; 54/216] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 54/216] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.568 total time=   0.0s\n",
            "[CV 1/5; 55/216] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 55/216] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.780 total time=   0.0s\n",
            "[CV 2/5; 55/216] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 55/216] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.684 total time=   0.0s\n",
            "[CV 3/5; 55/216] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 55/216] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.832 total time=   0.0s\n",
            "[CV 4/5; 55/216] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 55/216] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.788 total time=   0.0s\n",
            "[CV 5/5; 55/216] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 55/216] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.792 total time=   0.0s\n",
            "[CV 1/5; 56/216] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 56/216] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.724 total time=   0.0s\n",
            "[CV 2/5; 56/216] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 56/216] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.648 total time=   0.0s\n",
            "[CV 3/5; 56/216] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 56/216] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.712 total time=   0.0s\n",
            "[CV 4/5; 56/216] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 56/216] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.692 total time=   0.0s\n",
            "[CV 5/5; 56/216] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 56/216] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.684 total time=   0.0s\n",
            "[CV 1/5; 57/216] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 57/216] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.748 total time=   0.0s\n",
            "[CV 2/5; 57/216] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 57/216] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.672 total time=   0.0s\n",
            "[CV 3/5; 57/216] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 57/216] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.848 total time=   0.0s\n",
            "[CV 4/5; 57/216] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 57/216] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.776 total time=   0.0s\n",
            "[CV 5/5; 57/216] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 57/216] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.800 total time=   0.0s\n",
            "[CV 1/5; 58/216] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 58/216] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.656 total time=   0.0s\n",
            "[CV 2/5; 58/216] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 58/216] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.740 total time=   0.0s\n",
            "[CV 3/5; 58/216] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 58/216] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.648 total time=   0.0s\n",
            "[CV 4/5; 58/216] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 58/216] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.720 total time=   0.0s\n",
            "[CV 5/5; 58/216] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 58/216] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.664 total time=   0.0s\n",
            "[CV 1/5; 59/216] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 59/216] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.752 total time=   0.0s\n",
            "[CV 2/5; 59/216] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 59/216] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.668 total time=   0.0s\n",
            "[CV 3/5; 59/216] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 59/216] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.836 total time=   0.0s\n",
            "[CV 4/5; 59/216] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 59/216] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.804 total time=   0.0s\n",
            "[CV 5/5; 59/216] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 59/216] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.780 total time=   0.0s\n",
            "[CV 1/5; 60/216] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 60/216] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.700 total time=   0.0s\n",
            "[CV 2/5; 60/216] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 60/216] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.748 total time=   0.0s\n",
            "[CV 3/5; 60/216] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 60/216] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.712 total time=   0.0s\n",
            "[CV 4/5; 60/216] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 60/216] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.652 total time=   0.0s\n",
            "[CV 5/5; 60/216] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 60/216] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.644 total time=   0.0s\n",
            "[CV 1/5; 61/216] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 61/216] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.752 total time=   0.0s\n",
            "[CV 2/5; 61/216] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 61/216] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.708 total time=   0.0s\n",
            "[CV 3/5; 61/216] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 61/216] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.840 total time=   0.0s\n",
            "[CV 4/5; 61/216] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 61/216] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.800 total time=   0.0s\n",
            "[CV 5/5; 61/216] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 61/216] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.792 total time=   0.0s\n",
            "[CV 1/5; 62/216] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 62/216] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.708 total time=   0.0s\n",
            "[CV 2/5; 62/216] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 62/216] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.688 total time=   0.0s\n",
            "[CV 3/5; 62/216] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 62/216] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.660 total time=   0.0s\n",
            "[CV 4/5; 62/216] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 62/216] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.672 total time=   0.0s\n",
            "[CV 5/5; 62/216] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 62/216] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.644 total time=   0.0s\n",
            "[CV 1/5; 63/216] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 63/216] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.768 total time=   0.0s\n",
            "[CV 2/5; 63/216] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 63/216] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.692 total time=   0.0s\n",
            "[CV 3/5; 63/216] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 63/216] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.840 total time=   0.0s\n",
            "[CV 4/5; 63/216] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 63/216] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.792 total time=   0.0s\n",
            "[CV 5/5; 63/216] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 63/216] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.788 total time=   0.1s\n",
            "[CV 1/5; 64/216] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 64/216] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.680 total time=   0.0s\n",
            "[CV 2/5; 64/216] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 64/216] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.700 total time=   0.0s\n",
            "[CV 3/5; 64/216] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 64/216] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.600 total time=   0.0s\n",
            "[CV 4/5; 64/216] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 64/216] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.624 total time=   0.0s\n",
            "[CV 5/5; 64/216] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 64/216] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.668 total time=   0.0s\n",
            "[CV 1/5; 65/216] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 65/216] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.756 total time=   0.0s\n",
            "[CV 2/5; 65/216] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 65/216] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.688 total time=   0.0s\n",
            "[CV 3/5; 65/216] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 65/216] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.852 total time=   0.0s\n",
            "[CV 4/5; 65/216] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 65/216] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.792 total time=   0.1s\n",
            "[CV 5/5; 65/216] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 65/216] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.776 total time=   0.1s\n",
            "[CV 1/5; 66/216] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 66/216] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.700 total time=   0.0s\n",
            "[CV 2/5; 66/216] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 66/216] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.596 total time=   0.0s\n",
            "[CV 3/5; 66/216] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 66/216] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.696 total time=   0.0s\n",
            "[CV 4/5; 66/216] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 66/216] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.740 total time=   0.0s\n",
            "[CV 5/5; 66/216] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 66/216] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.704 total time=   0.0s\n",
            "[CV 1/5; 67/216] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 67/216] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.752 total time=   0.0s\n",
            "[CV 2/5; 67/216] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 67/216] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.704 total time=   0.0s\n",
            "[CV 3/5; 67/216] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 67/216] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.852 total time=   0.0s\n",
            "[CV 4/5; 67/216] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 67/216] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.764 total time=   0.0s\n",
            "[CV 5/5; 67/216] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 67/216] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.812 total time=   0.1s\n",
            "[CV 1/5; 68/216] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 68/216] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.684 total time=   0.0s\n",
            "[CV 2/5; 68/216] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 68/216] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.616 total time=   0.0s\n",
            "[CV 3/5; 68/216] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 68/216] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.716 total time=   0.0s\n",
            "[CV 4/5; 68/216] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 68/216] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.648 total time=   0.0s\n",
            "[CV 5/5; 68/216] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 68/216] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.692 total time=   0.0s\n",
            "[CV 1/5; 69/216] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 69/216] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.760 total time=   0.0s\n",
            "[CV 2/5; 69/216] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 69/216] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.688 total time=   0.0s\n",
            "[CV 3/5; 69/216] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 69/216] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.852 total time=   0.0s\n",
            "[CV 4/5; 69/216] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 69/216] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.756 total time=   0.0s\n",
            "[CV 5/5; 69/216] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 69/216] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.800 total time=   0.0s\n",
            "[CV 1/5; 70/216] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 70/216] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.544 total time=   0.0s\n",
            "[CV 2/5; 70/216] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 70/216] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.624 total time=   0.0s\n",
            "[CV 3/5; 70/216] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 70/216] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.656 total time=   0.0s\n",
            "[CV 4/5; 70/216] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 70/216] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.692 total time=   0.0s\n",
            "[CV 5/5; 70/216] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 70/216] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.744 total time=   0.0s\n",
            "[CV 1/5; 71/216] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 71/216] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.768 total time=   0.0s\n",
            "[CV 2/5; 71/216] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 71/216] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.676 total time=   0.0s\n",
            "[CV 3/5; 71/216] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 71/216] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.864 total time=   0.0s\n",
            "[CV 4/5; 71/216] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 71/216] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.776 total time=   0.0s\n",
            "[CV 5/5; 71/216] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 71/216] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.800 total time=   0.0s\n",
            "[CV 1/5; 72/216] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 72/216] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.572 total time=   0.0s\n",
            "[CV 2/5; 72/216] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 72/216] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.696 total time=   0.0s\n",
            "[CV 3/5; 72/216] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 72/216] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.668 total time=   0.0s\n",
            "[CV 4/5; 72/216] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 72/216] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.656 total time=   0.0s\n",
            "[CV 5/5; 72/216] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 72/216] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.680 total time=   0.0s\n",
            "[CV 1/5; 73/216] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 73/216] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.624 total time=   0.0s\n",
            "[CV 2/5; 73/216] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 73/216] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.644 total time=   0.0s\n",
            "[CV 3/5; 73/216] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 73/216] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.632 total time=   0.0s\n",
            "[CV 4/5; 73/216] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 73/216] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.600 total time=   0.0s\n",
            "[CV 5/5; 73/216] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 73/216] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.648 total time=   0.0s\n",
            "[CV 1/5; 74/216] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 74/216] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.632 total time=   0.0s\n",
            "[CV 2/5; 74/216] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 74/216] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.640 total time=   0.0s\n",
            "[CV 3/5; 74/216] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 74/216] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.632 total time=   0.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 74/216] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 74/216] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.620 total time=   0.0s\n",
            "[CV 5/5; 74/216] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 74/216] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.616 total time=   0.0s\n",
            "[CV 1/5; 75/216] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 75/216] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.664 total time=   0.0s\n",
            "[CV 2/5; 75/216] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 75/216] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.616 total time=   0.0s\n",
            "[CV 3/5; 75/216] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 75/216] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.636 total time=   0.0s\n",
            "[CV 4/5; 75/216] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 75/216] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.648 total time=   0.0s\n",
            "[CV 5/5; 75/216] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 75/216] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.680 total time=   0.0s\n",
            "[CV 1/5; 76/216] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 76/216] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.680 total time=   0.0s\n",
            "[CV 2/5; 76/216] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 76/216] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.512 total time=   0.0s\n",
            "[CV 3/5; 76/216] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 76/216] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.600 total time=   0.0s\n",
            "[CV 4/5; 76/216] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 76/216] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.556 total time=   0.0s\n",
            "[CV 5/5; 76/216] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 76/216] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.708 total time=   0.0s\n",
            "[CV 1/5; 77/216] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 77/216] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.676 total time=   0.0s\n",
            "[CV 2/5; 77/216] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 77/216] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.648 total time=   0.0s\n",
            "[CV 3/5; 77/216] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 77/216] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.600 total time=   0.0s\n",
            "[CV 4/5; 77/216] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 77/216] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.632 total time=   0.0s\n",
            "[CV 5/5; 77/216] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 77/216] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.644 total time=   0.0s\n",
            "[CV 1/5; 78/216] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 78/216] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.600 total time=   0.0s\n",
            "[CV 2/5; 78/216] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 78/216] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.548 total time=   0.0s\n",
            "[CV 3/5; 78/216] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 78/216] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.656 total time=   0.0s\n",
            "[CV 4/5; 78/216] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 78/216] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.696 total time=   0.0s\n",
            "[CV 5/5; 78/216] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 78/216] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.664 total time=   0.0s\n",
            "[CV 1/5; 79/216] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 79/216] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.696 total time=   0.0s\n",
            "[CV 2/5; 79/216] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 79/216] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.616 total time=   0.0s\n",
            "[CV 3/5; 79/216] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 79/216] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.636 total time=   0.0s\n",
            "[CV 4/5; 79/216] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 79/216] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.672 total time=   0.0s\n",
            "[CV 5/5; 79/216] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 79/216] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.692 total time=   0.0s\n",
            "[CV 1/5; 80/216] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 80/216] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.624 total time=   0.0s\n",
            "[CV 2/5; 80/216] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 80/216] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.608 total time=   0.0s\n",
            "[CV 3/5; 80/216] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 80/216] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.644 total time=   0.0s\n",
            "[CV 4/5; 80/216] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 80/216] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.592 total time=   0.0s\n",
            "[CV 5/5; 80/216] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 80/216] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.592 total time=   0.0s\n",
            "[CV 1/5; 81/216] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 81/216] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.660 total time=   0.0s\n",
            "[CV 2/5; 81/216] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 81/216] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.652 total time=   0.0s\n",
            "[CV 3/5; 81/216] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 81/216] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.660 total time=   0.0s\n",
            "[CV 4/5; 81/216] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 81/216] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.652 total time=   0.0s\n",
            "[CV 5/5; 81/216] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 81/216] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.656 total time=   0.0s\n",
            "[CV 1/5; 82/216] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 82/216] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.616 total time=   0.0s\n",
            "[CV 2/5; 82/216] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 82/216] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.580 total time=   0.0s\n",
            "[CV 3/5; 82/216] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 82/216] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.500 total time=   0.0s\n",
            "[CV 4/5; 82/216] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 82/216] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.552 total time=   0.0s\n",
            "[CV 5/5; 82/216] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 82/216] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.628 total time=   0.0s\n",
            "[CV 1/5; 83/216] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 83/216] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.660 total time=   0.0s\n",
            "[CV 2/5; 83/216] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 83/216] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.644 total time=   0.0s\n",
            "[CV 3/5; 83/216] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 83/216] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.644 total time=   0.0s\n",
            "[CV 4/5; 83/216] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 83/216] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.604 total time=   0.0s\n",
            "[CV 5/5; 83/216] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 83/216] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.672 total time=   0.0s\n",
            "[CV 1/5; 84/216] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 84/216] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.568 total time=   0.0s\n",
            "[CV 2/5; 84/216] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 84/216] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.500 total time=   0.0s\n",
            "[CV 3/5; 84/216] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 84/216] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.596 total time=   0.0s\n",
            "[CV 4/5; 84/216] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 84/216] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.564 total time=   0.0s\n",
            "[CV 5/5; 84/216] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 84/216] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.680 total time=   0.0s\n",
            "[CV 1/5; 85/216] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 85/216] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.624 total time=   0.0s\n",
            "[CV 2/5; 85/216] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 85/216] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.608 total time=   0.0s\n",
            "[CV 3/5; 85/216] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 85/216] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.640 total time=   0.0s\n",
            "[CV 4/5; 85/216] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 85/216] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.612 total time=   0.0s\n",
            "[CV 5/5; 85/216] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 85/216] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.672 total time=   0.0s\n",
            "[CV 1/5; 86/216] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 86/216] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.608 total time=   0.0s\n",
            "[CV 2/5; 86/216] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 86/216] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.504 total time=   0.0s\n",
            "[CV 3/5; 86/216] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 86/216] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.588 total time=   0.0s\n",
            "[CV 4/5; 86/216] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 86/216] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.576 total time=   0.0s\n",
            "[CV 5/5; 86/216] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 86/216] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.572 total time=   0.0s\n",
            "[CV 1/5; 87/216] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 87/216] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.664 total time=   0.0s\n",
            "[CV 2/5; 87/216] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 87/216] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.636 total time=   0.0s\n",
            "[CV 3/5; 87/216] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 87/216] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.620 total time=   0.0s\n",
            "[CV 4/5; 87/216] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 87/216] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.604 total time=   0.0s\n",
            "[CV 5/5; 87/216] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 87/216] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.668 total time=   0.0s\n",
            "[CV 1/5; 88/216] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 88/216] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.612 total time=   0.0s\n",
            "[CV 2/5; 88/216] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 88/216] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.544 total time=   0.0s\n",
            "[CV 3/5; 88/216] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 88/216] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.556 total time=   0.0s\n",
            "[CV 4/5; 88/216] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 88/216] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.540 total time=   0.0s\n",
            "[CV 5/5; 88/216] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 88/216] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.556 total time=   0.0s\n",
            "[CV 1/5; 89/216] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 89/216] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.616 total time=   0.0s\n",
            "[CV 2/5; 89/216] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 89/216] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.580 total time=   0.0s\n",
            "[CV 3/5; 89/216] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 89/216] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.660 total time=   0.0s\n",
            "[CV 4/5; 89/216] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 89/216] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.628 total time=   0.0s\n",
            "[CV 5/5; 89/216] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 89/216] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.636 total time=   0.0s\n",
            "[CV 1/5; 90/216] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 90/216] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 90/216] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 90/216] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.468 total time=   0.0s\n",
            "[CV 3/5; 90/216] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 90/216] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.544 total time=   0.0s\n",
            "[CV 4/5; 90/216] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 90/216] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.556 total time=   0.0s\n",
            "[CV 5/5; 90/216] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 90/216] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.588 total time=   0.0s\n",
            "[CV 1/5; 91/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 91/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.552 total time=   0.0s\n",
            "[CV 2/5; 91/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 91/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.592 total time=   0.0s\n",
            "[CV 3/5; 91/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 91/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.652 total time=   0.0s\n",
            "[CV 4/5; 91/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 91/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.656 total time=   0.0s\n",
            "[CV 5/5; 91/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 91/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.704 total time=   0.0s\n",
            "[CV 1/5; 92/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 92/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.640 total time=   0.0s\n",
            "[CV 2/5; 92/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 92/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.620 total time=   0.0s\n",
            "[CV 3/5; 92/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 92/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.576 total time=   0.0s\n",
            "[CV 4/5; 92/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 92/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.664 total time=   0.0s\n",
            "[CV 5/5; 92/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 92/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.696 total time=   0.0s\n",
            "[CV 1/5; 93/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 93/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.628 total time=   0.0s\n",
            "[CV 2/5; 93/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 93/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.656 total time=   0.0s\n",
            "[CV 3/5; 93/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 93/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.628 total time=   0.0s\n",
            "[CV 4/5; 93/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 93/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.636 total time=   0.0s\n",
            "[CV 5/5; 93/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 93/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.668 total time=   0.0s\n",
            "[CV 1/5; 94/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 94/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.628 total time=   0.0s\n",
            "[CV 2/5; 94/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 94/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.616 total time=   0.0s\n",
            "[CV 3/5; 94/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 94/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.628 total time=   0.0s\n",
            "[CV 4/5; 94/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 94/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.580 total time=   0.0s\n",
            "[CV 5/5; 94/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 94/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.636 total time=   0.0s\n",
            "[CV 1/5; 95/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 95/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.616 total time=   0.0s\n",
            "[CV 2/5; 95/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 95/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.632 total time=   0.0s\n",
            "[CV 3/5; 95/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 95/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.708 total time=   0.0s\n",
            "[CV 4/5; 95/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 95/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.636 total time=   0.0s\n",
            "[CV 5/5; 95/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 95/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.744 total time=   0.0s\n",
            "[CV 1/5; 96/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 96/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.616 total time=   0.0s\n",
            "[CV 2/5; 96/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 96/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.596 total time=   0.0s\n",
            "[CV 3/5; 96/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 96/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.552 total time=   0.0s\n",
            "[CV 4/5; 96/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 96/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.628 total time=   0.0s\n",
            "[CV 5/5; 96/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 96/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.672 total time=   0.0s\n",
            "[CV 1/5; 97/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 97/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.652 total time=   0.0s\n",
            "[CV 2/5; 97/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 97/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.620 total time=   0.0s\n",
            "[CV 3/5; 97/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 97/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.596 total time=   0.0s\n",
            "[CV 4/5; 97/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 97/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.624 total time=   0.0s\n",
            "[CV 5/5; 97/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 97/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.708 total time=   0.0s\n",
            "[CV 1/5; 98/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 98/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.540 total time=   0.0s\n",
            "[CV 2/5; 98/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 98/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.640 total time=   0.0s\n",
            "[CV 3/5; 98/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 98/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.648 total time=   0.0s\n",
            "[CV 4/5; 98/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 98/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.628 total time=   0.0s\n",
            "[CV 5/5; 98/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 98/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.552 total time=   0.0s\n",
            "[CV 1/5; 99/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 99/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.632 total time=   0.0s\n",
            "[CV 2/5; 99/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 99/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.696 total time=   0.0s\n",
            "[CV 3/5; 99/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 99/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.612 total time=   0.0s\n",
            "[CV 4/5; 99/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 99/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.640 total time=   0.0s\n",
            "[CV 5/5; 99/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 99/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.660 total time=   0.0s\n",
            "[CV 1/5; 100/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 100/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.628 total time=   0.0s\n",
            "[CV 2/5; 100/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 100/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.504 total time=   0.0s\n",
            "[CV 3/5; 100/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 100/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.560 total time=   0.0s\n",
            "[CV 4/5; 100/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 100/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.524 total time=   0.0s\n",
            "[CV 5/5; 100/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 100/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.636 total time=   0.0s\n",
            "[CV 1/5; 101/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 101/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.616 total time=   0.0s\n",
            "[CV 2/5; 101/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 101/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.568 total time=   0.0s\n",
            "[CV 3/5; 101/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 101/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.656 total time=   0.0s\n",
            "[CV 4/5; 101/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 101/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.688 total time=   0.0s\n",
            "[CV 5/5; 101/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 101/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.652 total time=   0.0s\n",
            "[CV 1/5; 102/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 102/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.564 total time=   0.0s\n",
            "[CV 2/5; 102/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 102/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.560 total time=   0.0s\n",
            "[CV 3/5; 102/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 102/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.608 total time=   0.0s\n",
            "[CV 4/5; 102/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 102/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.568 total time=   0.0s\n",
            "[CV 5/5; 102/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 102/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.648 total time=   0.0s\n",
            "[CV 1/5; 103/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 103/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.704 total time=   0.0s\n",
            "[CV 2/5; 103/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 103/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.572 total time=   0.0s\n",
            "[CV 3/5; 103/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 103/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.676 total time=   0.0s\n",
            "[CV 4/5; 103/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 103/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.624 total time=   0.0s\n",
            "[CV 5/5; 103/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 103/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.744 total time=   0.0s\n",
            "[CV 1/5; 104/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 104/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.588 total time=   0.0s\n",
            "[CV 2/5; 104/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 104/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.616 total time=   0.0s\n",
            "[CV 3/5; 104/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 104/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.552 total time=   0.0s\n",
            "[CV 4/5; 104/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 104/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.560 total time=   0.0s\n",
            "[CV 5/5; 104/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 104/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.612 total time=   0.0s\n",
            "[CV 1/5; 105/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 105/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.636 total time=   0.0s\n",
            "[CV 2/5; 105/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 105/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.580 total time=   0.0s\n",
            "[CV 3/5; 105/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 105/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.632 total time=   0.0s\n",
            "[CV 4/5; 105/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 105/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.612 total time=   0.0s\n",
            "[CV 5/5; 105/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 105/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.660 total time=   0.0s\n",
            "[CV 1/5; 106/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 106/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.668 total time=   0.0s\n",
            "[CV 2/5; 106/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 106/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.604 total time=   0.0s\n",
            "[CV 3/5; 106/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 106/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.612 total time=   0.0s\n",
            "[CV 4/5; 106/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 106/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.520 total time=   0.0s\n",
            "[CV 5/5; 106/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 106/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.628 total time=   0.0s\n",
            "[CV 1/5; 107/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 107/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.672 total time=   0.0s\n",
            "[CV 2/5; 107/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 107/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.676 total time=   0.0s\n",
            "[CV 3/5; 107/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 107/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.716 total time=   0.0s\n",
            "[CV 4/5; 107/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 107/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.628 total time=   0.0s\n",
            "[CV 5/5; 107/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 107/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.704 total time=   0.0s\n",
            "[CV 1/5; 108/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 108/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.596 total time=   0.0s\n",
            "[CV 2/5; 108/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 108/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.560 total time=   0.0s\n",
            "[CV 3/5; 108/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 108/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.568 total time=   0.0s\n",
            "[CV 4/5; 108/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 108/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.612 total time=   0.0s\n",
            "[CV 5/5; 108/216] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 108/216] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.576 total time=   0.0s\n",
            "[CV 1/5; 109/216] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 109/216] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.708 total time=   0.0s\n",
            "[CV 2/5; 109/216] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 109/216] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.716 total time=   0.0s\n",
            "[CV 3/5; 109/216] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 109/216] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.688 total time=   0.0s\n",
            "[CV 4/5; 109/216] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 109/216] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.684 total time=   0.0s\n",
            "[CV 5/5; 109/216] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 109/216] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.680 total time=   0.0s\n",
            "[CV 1/5; 110/216] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 110/216] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.668 total time=   0.0s\n",
            "[CV 2/5; 110/216] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 110/216] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.648 total time=   0.0s\n",
            "[CV 3/5; 110/216] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 110/216] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.640 total time=   0.0s\n",
            "[CV 4/5; 110/216] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 110/216] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.636 total time=   0.0s\n",
            "[CV 5/5; 110/216] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 110/216] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.656 total time=   0.0s\n",
            "[CV 1/5; 111/216] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 111/216] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.732 total time=   0.0s\n",
            "[CV 2/5; 111/216] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 111/216] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.740 total time=   0.0s\n",
            "[CV 3/5; 111/216] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 111/216] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.672 total time=   0.0s\n",
            "[CV 4/5; 111/216] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 111/216] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.664 total time=   0.0s\n",
            "[CV 5/5; 111/216] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 111/216] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.688 total time=   0.0s\n",
            "[CV 1/5; 112/216] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 112/216] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.628 total time=   0.0s\n",
            "[CV 2/5; 112/216] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 112/216] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.636 total time=   0.0s\n",
            "[CV 3/5; 112/216] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 112/216] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.660 total time=   0.0s\n",
            "[CV 4/5; 112/216] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 112/216] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.636 total time=   0.0s\n",
            "[CV 5/5; 112/216] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 112/216] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.632 total time=   0.0s\n",
            "[CV 1/5; 113/216] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 113/216] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.712 total time=   0.0s\n",
            "[CV 2/5; 113/216] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 113/216] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.708 total time=   0.0s\n",
            "[CV 3/5; 113/216] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 113/216] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.700 total time=   0.0s\n",
            "[CV 4/5; 113/216] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 113/216] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.704 total time=   0.0s\n",
            "[CV 5/5; 113/216] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 113/216] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.672 total time=   0.0s\n",
            "[CV 1/5; 114/216] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 114/216] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.692 total time=   0.0s\n",
            "[CV 2/5; 114/216] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 114/216] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.588 total time=   0.0s\n",
            "[CV 3/5; 114/216] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 114/216] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.688 total time=   0.0s\n",
            "[CV 4/5; 114/216] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 114/216] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.620 total time=   0.0s\n",
            "[CV 5/5; 114/216] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 114/216] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.636 total time=   0.0s\n",
            "[CV 1/5; 115/216] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 115/216] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.652 total time=   0.0s\n",
            "[CV 2/5; 115/216] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 115/216] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.660 total time=   0.0s\n",
            "[CV 3/5; 115/216] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 115/216] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.656 total time=   0.0s\n",
            "[CV 4/5; 115/216] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 115/216] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.636 total time=   0.0s\n",
            "[CV 5/5; 115/216] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 115/216] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.756 total time=   0.0s\n",
            "[CV 1/5; 116/216] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 116/216] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.620 total time=   0.0s\n",
            "[CV 2/5; 116/216] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 116/216] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.648 total time=   0.0s\n",
            "[CV 3/5; 116/216] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 116/216] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.604 total time=   0.0s\n",
            "[CV 4/5; 116/216] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 116/216] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.604 total time=   0.0s\n",
            "[CV 5/5; 116/216] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 116/216] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.660 total time=   0.0s\n",
            "[CV 1/5; 117/216] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 117/216] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.708 total time=   0.0s\n",
            "[CV 2/5; 117/216] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 117/216] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.704 total time=   0.0s\n",
            "[CV 3/5; 117/216] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 117/216] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.708 total time=   0.0s\n",
            "[CV 4/5; 117/216] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 117/216] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.688 total time=   0.0s\n",
            "[CV 5/5; 117/216] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 117/216] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.700 total time=   0.0s\n",
            "[CV 1/5; 118/216] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 118/216] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.644 total time=   0.0s\n",
            "[CV 2/5; 118/216] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 118/216] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.652 total time=   0.0s\n",
            "[CV 3/5; 118/216] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 118/216] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.652 total time=   0.0s\n",
            "[CV 4/5; 118/216] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 118/216] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.600 total time=   0.0s\n",
            "[CV 5/5; 118/216] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 118/216] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.576 total time=   0.0s\n",
            "[CV 1/5; 119/216] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 119/216] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.636 total time=   0.0s\n",
            "[CV 2/5; 119/216] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 119/216] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.676 total time=   0.0s\n",
            "[CV 3/5; 119/216] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 119/216] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.616 total time=   0.0s\n",
            "[CV 4/5; 119/216] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 119/216] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.640 total time=   0.0s\n",
            "[CV 5/5; 119/216] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 119/216] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.744 total time=   0.0s\n",
            "[CV 1/5; 120/216] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 120/216] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.588 total time=   0.0s\n",
            "[CV 2/5; 120/216] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 120/216] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.584 total time=   0.0s\n",
            "[CV 3/5; 120/216] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 120/216] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.560 total time=   0.0s\n",
            "[CV 4/5; 120/216] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 120/216] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.612 total time=   0.0s\n",
            "[CV 5/5; 120/216] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 120/216] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.704 total time=   0.0s\n",
            "[CV 1/5; 121/216] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 121/216] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.680 total time=   0.0s\n",
            "[CV 2/5; 121/216] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 121/216] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.672 total time=   0.0s\n",
            "[CV 3/5; 121/216] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 121/216] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.688 total time=   0.0s\n",
            "[CV 4/5; 121/216] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 121/216] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.700 total time=   0.0s\n",
            "[CV 5/5; 121/216] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 121/216] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.680 total time=   0.0s\n",
            "[CV 1/5; 122/216] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 122/216] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.664 total time=   0.0s\n",
            "[CV 2/5; 122/216] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 122/216] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.548 total time=   0.0s\n",
            "[CV 3/5; 122/216] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 122/216] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.576 total time=   0.0s\n",
            "[CV 4/5; 122/216] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 122/216] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.544 total time=   0.0s\n",
            "[CV 5/5; 122/216] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 122/216] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.616 total time=   0.0s\n",
            "[CV 1/5; 123/216] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 123/216] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.704 total time=   0.0s\n",
            "[CV 2/5; 123/216] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 123/216] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.600 total time=   0.0s\n",
            "[CV 3/5; 123/216] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 123/216] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.676 total time=   0.0s\n",
            "[CV 4/5; 123/216] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 123/216] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.696 total time=   0.0s\n",
            "[CV 5/5; 123/216] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 123/216] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.744 total time=   0.0s\n",
            "[CV 1/5; 124/216] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 124/216] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.620 total time=   0.0s\n",
            "[CV 2/5; 124/216] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 124/216] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.620 total time=   0.0s\n",
            "[CV 3/5; 124/216] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 124/216] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.640 total time=   0.0s\n",
            "[CV 4/5; 124/216] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 124/216] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.592 total time=   0.0s\n",
            "[CV 5/5; 124/216] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 124/216] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.664 total time=   0.0s\n",
            "[CV 1/5; 125/216] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 125/216] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.672 total time=   0.0s\n",
            "[CV 2/5; 125/216] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 125/216] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.684 total time=   0.0s\n",
            "[CV 3/5; 125/216] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 125/216] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.692 total time=   0.0s\n",
            "[CV 4/5; 125/216] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 125/216] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.684 total time=   0.0s\n",
            "[CV 5/5; 125/216] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 125/216] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.716 total time=   0.0s\n",
            "[CV 1/5; 126/216] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 126/216] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.568 total time=   0.0s\n",
            "[CV 2/5; 126/216] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 126/216] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.624 total time=   0.0s\n",
            "[CV 3/5; 126/216] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 126/216] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.528 total time=   0.0s\n",
            "[CV 4/5; 126/216] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 126/216] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.568 total time=   0.0s\n",
            "[CV 5/5; 126/216] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 126/216] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.636 total time=   0.0s\n",
            "[CV 1/5; 127/216] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 127/216] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.736 total time=   0.0s\n",
            "[CV 2/5; 127/216] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 127/216] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.776 total time=   0.0s\n",
            "[CV 3/5; 127/216] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 127/216] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.852 total time=   0.0s\n",
            "[CV 4/5; 127/216] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 127/216] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.792 total time=   0.0s\n",
            "[CV 5/5; 127/216] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 127/216] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.808 total time=   0.0s\n",
            "[CV 1/5; 128/216] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 128/216] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.708 total time=   0.0s\n",
            "[CV 2/5; 128/216] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 128/216] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.748 total time=   0.0s\n",
            "[CV 3/5; 128/216] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 128/216] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.672 total time=   0.0s\n",
            "[CV 4/5; 128/216] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 128/216] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.776 total time=   0.0s\n",
            "[CV 5/5; 128/216] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 128/216] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.780 total time=   0.0s\n",
            "[CV 1/5; 129/216] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 129/216] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.748 total time=   0.0s\n",
            "[CV 2/5; 129/216] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 129/216] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.784 total time=   0.0s\n",
            "[CV 3/5; 129/216] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 129/216] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.848 total time=   0.0s\n",
            "[CV 4/5; 129/216] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 129/216] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.776 total time=   0.0s\n",
            "[CV 5/5; 129/216] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 129/216] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.812 total time=   0.0s\n",
            "[CV 1/5; 130/216] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 130/216] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.764 total time=   0.0s\n",
            "[CV 2/5; 130/216] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 130/216] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.744 total time=   0.0s\n",
            "[CV 3/5; 130/216] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 130/216] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.672 total time=   0.0s\n",
            "[CV 4/5; 130/216] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 130/216] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.652 total time=   0.0s\n",
            "[CV 5/5; 130/216] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 130/216] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.672 total time=   0.0s\n",
            "[CV 1/5; 131/216] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 131/216] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.736 total time=   0.0s\n",
            "[CV 2/5; 131/216] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 131/216] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.760 total time=   0.0s\n",
            "[CV 3/5; 131/216] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 131/216] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.844 total time=   0.0s\n",
            "[CV 4/5; 131/216] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 131/216] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.796 total time=   0.0s\n",
            "[CV 5/5; 131/216] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 131/216] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.800 total time=   0.0s\n",
            "[CV 1/5; 132/216] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 132/216] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.672 total time=   0.0s\n",
            "[CV 2/5; 132/216] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 132/216] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.660 total time=   0.0s\n",
            "[CV 3/5; 132/216] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 132/216] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.648 total time=   0.0s\n",
            "[CV 4/5; 132/216] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 132/216] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.784 total time=   0.0s\n",
            "[CV 5/5; 132/216] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 132/216] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.720 total time=   0.0s\n",
            "[CV 1/5; 133/216] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 133/216] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.740 total time=   0.0s\n",
            "[CV 2/5; 133/216] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 133/216] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.760 total time=   0.0s\n",
            "[CV 3/5; 133/216] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 133/216] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.848 total time=   0.0s\n",
            "[CV 4/5; 133/216] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 133/216] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.808 total time=   0.0s\n",
            "[CV 5/5; 133/216] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 133/216] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.784 total time=   0.0s\n",
            "[CV 1/5; 134/216] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 134/216] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.696 total time=   0.0s\n",
            "[CV 2/5; 134/216] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 134/216] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.628 total time=   0.0s\n",
            "[CV 3/5; 134/216] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 134/216] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.756 total time=   0.0s\n",
            "[CV 4/5; 134/216] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 134/216] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.620 total time=   0.0s\n",
            "[CV 5/5; 134/216] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 134/216] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.720 total time=   0.0s\n",
            "[CV 1/5; 135/216] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 135/216] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.752 total time=   0.0s\n",
            "[CV 2/5; 135/216] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 135/216] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.764 total time=   0.0s\n",
            "[CV 3/5; 135/216] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 135/216] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.844 total time=   0.0s\n",
            "[CV 4/5; 135/216] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 135/216] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.792 total time=   0.0s\n",
            "[CV 5/5; 135/216] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 135/216] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.816 total time=   0.0s\n",
            "[CV 1/5; 136/216] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 136/216] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.704 total time=   0.0s\n",
            "[CV 2/5; 136/216] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 136/216] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.684 total time=   0.0s\n",
            "[CV 3/5; 136/216] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 136/216] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.720 total time=   0.0s\n",
            "[CV 4/5; 136/216] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 136/216] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.640 total time=   0.0s\n",
            "[CV 5/5; 136/216] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 136/216] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.716 total time=   0.0s\n",
            "[CV 1/5; 137/216] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 137/216] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.740 total time=   0.0s\n",
            "[CV 2/5; 137/216] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 137/216] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.748 total time=   0.0s\n",
            "[CV 3/5; 137/216] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 137/216] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.852 total time=   0.0s\n",
            "[CV 4/5; 137/216] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 137/216] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.800 total time=   0.0s\n",
            "[CV 5/5; 137/216] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 137/216] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.796 total time=   0.0s\n",
            "[CV 1/5; 138/216] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 138/216] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.620 total time=   0.0s\n",
            "[CV 2/5; 138/216] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 138/216] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.708 total time=   0.0s\n",
            "[CV 3/5; 138/216] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 138/216] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.688 total time=   0.0s\n",
            "[CV 4/5; 138/216] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 138/216] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.672 total time=   0.0s\n",
            "[CV 5/5; 138/216] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 138/216] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.616 total time=   0.0s\n",
            "[CV 1/5; 139/216] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 139/216] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.744 total time=   0.1s\n",
            "[CV 2/5; 139/216] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 139/216] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.768 total time=   0.0s\n",
            "[CV 3/5; 139/216] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 139/216] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.844 total time=   0.1s\n",
            "[CV 4/5; 139/216] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 139/216] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.792 total time=   0.0s\n",
            "[CV 5/5; 139/216] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 139/216] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.804 total time=   0.0s\n",
            "[CV 1/5; 140/216] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 140/216] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.616 total time=   0.0s\n",
            "[CV 2/5; 140/216] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 140/216] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.748 total time=   0.0s\n",
            "[CV 3/5; 140/216] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 140/216] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.732 total time=   0.0s\n",
            "[CV 4/5; 140/216] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 140/216] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.664 total time=   0.0s\n",
            "[CV 5/5; 140/216] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 140/216] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.668 total time=   0.0s\n",
            "[CV 1/5; 141/216] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 141/216] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.748 total time=   0.0s\n",
            "[CV 2/5; 141/216] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 141/216] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.772 total time=   0.0s\n",
            "[CV 3/5; 141/216] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 141/216] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.844 total time=   0.0s\n",
            "[CV 4/5; 141/216] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 141/216] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.776 total time=   0.0s\n",
            "[CV 5/5; 141/216] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 141/216] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.796 total time=   0.0s\n",
            "[CV 1/5; 142/216] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 142/216] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.664 total time=   0.0s\n",
            "[CV 2/5; 142/216] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 142/216] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.700 total time=   0.0s\n",
            "[CV 3/5; 142/216] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 142/216] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.672 total time=   0.0s\n",
            "[CV 4/5; 142/216] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 142/216] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.688 total time=   0.0s\n",
            "[CV 5/5; 142/216] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 142/216] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.692 total time=   0.0s\n",
            "[CV 1/5; 143/216] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 143/216] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.748 total time=   0.0s\n",
            "[CV 2/5; 143/216] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 143/216] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.756 total time=   0.0s\n",
            "[CV 3/5; 143/216] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 143/216] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.844 total time=   0.0s\n",
            "[CV 4/5; 143/216] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 143/216] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.776 total time=   0.0s\n",
            "[CV 5/5; 143/216] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 143/216] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.800 total time=   0.0s\n",
            "[CV 1/5; 144/216] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 144/216] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.604 total time=   0.0s\n",
            "[CV 2/5; 144/216] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 144/216] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.552 total time=   0.0s\n",
            "[CV 3/5; 144/216] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 144/216] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.608 total time=   0.0s\n",
            "[CV 4/5; 144/216] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 144/216] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.636 total time=   0.0s\n",
            "[CV 5/5; 144/216] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 144/216] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.712 total time=   0.0s\n",
            "[CV 1/5; 145/216] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 145/216] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.620 total time=   0.0s\n",
            "[CV 2/5; 145/216] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 145/216] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.648 total time=   0.0s\n",
            "[CV 3/5; 145/216] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 145/216] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.652 total time=   0.0s\n",
            "[CV 4/5; 145/216] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 145/216] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.624 total time=   0.0s\n",
            "[CV 5/5; 145/216] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 145/216] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.708 total time=   0.0s\n",
            "[CV 1/5; 146/216] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 146/216] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.716 total time=   0.0s\n",
            "[CV 2/5; 146/216] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 146/216] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.580 total time=   0.0s\n",
            "[CV 3/5; 146/216] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 146/216] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.672 total time=   0.0s\n",
            "[CV 4/5; 146/216] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 146/216] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.600 total time=   0.0s\n",
            "[CV 5/5; 146/216] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 146/216] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.648 total time=   0.0s"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[CV 1/5; 147/216] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 147/216] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.680 total time=   0.0s\n",
            "[CV 2/5; 147/216] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 147/216] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.624 total time=   0.0s\n",
            "[CV 3/5; 147/216] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 147/216] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.656 total time=   0.0s\n",
            "[CV 4/5; 147/216] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 147/216] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.660 total time=   0.0s\n",
            "[CV 5/5; 147/216] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 147/216] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.644 total time=   0.0s\n",
            "[CV 1/5; 148/216] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 148/216] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.580 total time=   0.0s\n",
            "[CV 2/5; 148/216] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 148/216] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.624 total time=   0.0s\n",
            "[CV 3/5; 148/216] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 148/216] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.652 total time=   0.0s\n",
            "[CV 4/5; 148/216] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 148/216] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.636 total time=   0.0s\n",
            "[CV 5/5; 148/216] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 148/216] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.624 total time=   0.0s\n",
            "[CV 1/5; 149/216] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 149/216] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.656 total time=   0.0s\n",
            "[CV 2/5; 149/216] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 149/216] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.636 total time=   0.0s\n",
            "[CV 3/5; 149/216] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 149/216] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.620 total time=   0.0s\n",
            "[CV 4/5; 149/216] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 149/216] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.676 total time=   0.0s\n",
            "[CV 5/5; 149/216] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 149/216] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.664 total time=   0.0s\n",
            "[CV 1/5; 150/216] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 150/216] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.632 total time=   0.0s\n",
            "[CV 2/5; 150/216] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 150/216] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.616 total time=   0.0s\n",
            "[CV 3/5; 150/216] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 150/216] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.632 total time=   0.0s\n",
            "[CV 4/5; 150/216] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 150/216] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.616 total time=   0.0s\n",
            "[CV 5/5; 150/216] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 150/216] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.636 total time=   0.0s\n",
            "[CV 1/5; 151/216] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 151/216] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.644 total time=   0.0s\n",
            "[CV 2/5; 151/216] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 151/216] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.632 total time=   0.0s\n",
            "[CV 3/5; 151/216] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 151/216] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.656 total time=   0.0s\n",
            "[CV 4/5; 151/216] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 151/216] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.636 total time=   0.0s\n",
            "[CV 5/5; 151/216] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 151/216] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.664 total time=   0.0s\n",
            "[CV 1/5; 152/216] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 152/216] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.604 total time=   0.0s\n",
            "[CV 2/5; 152/216] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 152/216] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.600 total time=   0.0s\n",
            "[CV 3/5; 152/216] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 152/216] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.604 total time=   0.0s\n",
            "[CV 4/5; 152/216] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 152/216] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.616 total time=   0.0s\n",
            "[CV 5/5; 152/216] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 152/216] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.612 total time=   0.0s\n",
            "[CV 1/5; 153/216] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 153/216] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.596 total time=   0.0s\n",
            "[CV 2/5; 153/216] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 153/216] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.632 total time=   0.0s\n",
            "[CV 3/5; 153/216] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 153/216] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.612 total time=   0.0s\n",
            "[CV 4/5; 153/216] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 153/216] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.728 total time=   0.0s\n",
            "[CV 5/5; 153/216] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 153/216] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.704 total time=   0.0s\n",
            "[CV 1/5; 154/216] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 154/216] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.620 total time=   0.0s\n",
            "[CV 2/5; 154/216] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 154/216] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.536 total time=   0.0s\n",
            "[CV 3/5; 154/216] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 154/216] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.600 total time=   0.0s\n",
            "[CV 4/5; 154/216] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 154/216] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.628 total time=   0.0s\n",
            "[CV 5/5; 154/216] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 154/216] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.628 total time=   0.0s\n",
            "[CV 1/5; 155/216] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 155/216] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.636 total time=   0.0s\n",
            "[CV 2/5; 155/216] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 155/216] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.624 total time=   0.0s\n",
            "[CV 3/5; 155/216] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 155/216] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.676 total time=   0.0s\n",
            "[CV 4/5; 155/216] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 155/216] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.632 total time=   0.0s\n",
            "[CV 5/5; 155/216] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 155/216] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.668 total time=   0.0s\n",
            "[CV 1/5; 156/216] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 156/216] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.564 total time=   0.0s\n",
            "[CV 2/5; 156/216] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 156/216] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.572 total time=   0.0s\n",
            "[CV 3/5; 156/216] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 156/216] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.692 total time=   0.0s\n",
            "[CV 4/5; 156/216] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 156/216] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.592 total time=   0.0s\n",
            "[CV 5/5; 156/216] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 156/216] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.604 total time=   0.0s\n",
            "[CV 1/5; 157/216] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 157/216] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.624 total time=   0.0s\n",
            "[CV 2/5; 157/216] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 157/216] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.640 total time=   0.0s\n",
            "[CV 3/5; 157/216] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 157/216] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.664 total time=   0.0s\n",
            "[CV 4/5; 157/216] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 157/216] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.540 total time=   0.0s\n",
            "[CV 5/5; 157/216] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 157/216] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.664 total time=   0.0s\n",
            "[CV 1/5; 158/216] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 158/216] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.640 total time=   0.0s\n",
            "[CV 2/5; 158/216] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 158/216] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.620 total time=   0.0s\n",
            "[CV 3/5; 158/216] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 158/216] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.544 total time=   0.0s\n",
            "[CV 4/5; 158/216] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 158/216] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.604 total time=   0.0s\n",
            "[CV 5/5; 158/216] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 158/216] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.580 total time=   0.0s\n",
            "[CV 1/5; 159/216] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 159/216] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.668 total time=   0.0s\n",
            "[CV 2/5; 159/216] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 159/216] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.608 total time=   0.0s\n",
            "[CV 3/5; 159/216] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 159/216] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.676 total time=   0.0s\n",
            "[CV 4/5; 159/216] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 159/216] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.568 total time=   0.0s\n",
            "[CV 5/5; 159/216] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 159/216] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.648 total time=   0.0s\n",
            "[CV 1/5; 160/216] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 160/216] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.608 total time=   0.0s\n",
            "[CV 2/5; 160/216] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 160/216] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.528 total time=   0.0s\n",
            "[CV 3/5; 160/216] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 160/216] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.644 total time=   0.0s\n",
            "[CV 4/5; 160/216] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 160/216] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.556 total time=   0.0s\n",
            "[CV 5/5; 160/216] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 160/216] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.620 total time=   0.0s\n",
            "[CV 1/5; 161/216] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 161/216] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.704 total time=   0.0s\n",
            "[CV 2/5; 161/216] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 161/216] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.648 total time=   0.0s\n",
            "[CV 3/5; 161/216] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 161/216] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.652 total time=   0.0s\n",
            "[CV 4/5; 161/216] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 161/216] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.572 total time=   0.0s\n",
            "[CV 5/5; 161/216] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 161/216] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.672 total time=   0.0s\n",
            "[CV 1/5; 162/216] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 162/216] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.540 total time=   0.0s\n",
            "[CV 2/5; 162/216] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 162/216] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.592 total time=   0.0s\n",
            "[CV 3/5; 162/216] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 162/216] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.540 total time=   0.0s\n",
            "[CV 4/5; 162/216] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 162/216] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.572 total time=   0.0s\n",
            "[CV 5/5; 162/216] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 162/216] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.568 total time=   0.0s\n",
            "[CV 1/5; 163/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 163/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.660 total time=   0.0s\n",
            "[CV 2/5; 163/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 163/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.660 total time=   0.0s\n",
            "[CV 3/5; 163/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 163/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.672 total time=   0.0s\n",
            "[CV 4/5; 163/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 163/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.648 total time=   0.0s\n",
            "[CV 5/5; 163/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 163/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.672 total time=   0.0s\n",
            "[CV 1/5; 164/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 164/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.572 total time=   0.0s\n",
            "[CV 2/5; 164/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 164/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.612 total time=   0.0s\n",
            "[CV 3/5; 164/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 164/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.608 total time=   0.0s\n",
            "[CV 4/5; 164/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 164/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.700 total time=   0.0s\n",
            "[CV 5/5; 164/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 164/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.576 total time=   0.0s\n",
            "[CV 1/5; 165/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 165/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.644 total time=   0.0s\n",
            "[CV 2/5; 165/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 165/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.628 total time=   0.0s\n",
            "[CV 3/5; 165/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 165/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.620 total time=   0.0s\n",
            "[CV 4/5; 165/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 165/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.624 total time=   0.0s\n",
            "[CV 5/5; 165/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 165/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.700 total time=   0.0s\n",
            "[CV 1/5; 166/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 166/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.648 total time=   0.0s\n",
            "[CV 2/5; 166/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 166/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.652 total time=   0.0s\n",
            "[CV 3/5; 166/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 166/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.608 total time=   0.0s\n",
            "[CV 4/5; 166/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 166/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.576 total time=   0.0s\n",
            "[CV 5/5; 166/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 166/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.688 total time=   0.0s\n",
            "[CV 1/5; 167/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 167/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.668 total time=   0.0s\n",
            "[CV 2/5; 167/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 167/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.648 total time=   0.0s\n",
            "[CV 3/5; 167/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 167/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.596 total time=   0.0s\n",
            "[CV 4/5; 167/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 167/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.596 total time=   0.0s\n",
            "[CV 5/5; 167/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 167/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.664 total time=   0.0s\n",
            "[CV 1/5; 168/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 168/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.652 total time=   0.0s\n",
            "[CV 2/5; 168/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 168/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.640 total time=   0.0s\n",
            "[CV 3/5; 168/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 168/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.612 total time=   0.0s\n",
            "[CV 4/5; 168/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 168/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.560 total time=   0.0s\n",
            "[CV 5/5; 168/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 168/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.632 total time=   0.0s\n",
            "[CV 1/5; 169/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 169/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.632 total time=   0.0s\n",
            "[CV 2/5; 169/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 169/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.580 total time=   0.0s\n",
            "[CV 3/5; 169/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 169/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.680 total time=   0.0s\n",
            "[CV 4/5; 169/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 169/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.696 total time=   0.0s\n",
            "[CV 5/5; 169/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 169/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.644 total time=   0.0s\n",
            "[CV 1/5; 170/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 170/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.532 total time=   0.0s\n",
            "[CV 2/5; 170/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 170/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.524 total time=   0.0s\n",
            "[CV 3/5; 170/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 170/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.536 total time=   0.0s\n",
            "[CV 4/5; 170/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 170/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.560 total time=   0.0s\n",
            "[CV 5/5; 170/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 170/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.576 total time=   0.0s\n",
            "[CV 1/5; 171/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 171/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.632 total time=   0.0s\n",
            "[CV 2/5; 171/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 171/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.688 total time=   0.0s\n",
            "[CV 3/5; 171/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 171/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.644 total time=   0.0s\n",
            "[CV 4/5; 171/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 171/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.736 total time=   0.0s\n",
            "[CV 5/5; 171/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 171/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.656 total time=   0.0s\n",
            "[CV 1/5; 172/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 172/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.632 total time=   0.0s\n",
            "[CV 2/5; 172/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 172/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.548 total time=   0.0s\n",
            "[CV 3/5; 172/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 172/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.496 total time=   0.0s\n",
            "[CV 4/5; 172/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 172/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.532 total time=   0.0s\n",
            "[CV 5/5; 172/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 172/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.664 total time=   0.0s\n",
            "[CV 1/5; 173/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 173/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.704 total time=   0.0s\n",
            "[CV 2/5; 173/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 173/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.584 total time=   0.0s\n",
            "[CV 3/5; 173/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 173/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.656 total time=   0.0s\n",
            "[CV 4/5; 173/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 173/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.604 total time=   0.0s\n",
            "[CV 5/5; 173/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 173/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.660 total time=   0.0s\n",
            "[CV 1/5; 174/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 174/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.540 total time=   0.0s\n",
            "[CV 2/5; 174/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 174/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.592 total time=   0.0s\n",
            "[CV 3/5; 174/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 174/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.608 total time=   0.0s\n",
            "[CV 4/5; 174/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 174/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.540 total time=   0.0s\n",
            "[CV 5/5; 174/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 174/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.592 total time=   0.0s\n",
            "[CV 1/5; 175/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 175/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.656 total time=   0.0s\n",
            "[CV 2/5; 175/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 175/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.620 total time=   0.0s\n",
            "[CV 3/5; 175/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 175/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.656 total time=   0.0s\n",
            "[CV 4/5; 175/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 175/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.692 total time=   0.0s\n",
            "[CV 5/5; 175/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 175/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.656 total time=   0.0s\n",
            "[CV 1/5; 176/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 176/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.540 total time=   0.0s\n",
            "[CV 2/5; 176/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 176/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.556 total time=   0.0s\n",
            "[CV 3/5; 176/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 176/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.584 total time=   0.0s\n",
            "[CV 4/5; 176/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 176/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.568 total time=   0.0s\n",
            "[CV 5/5; 176/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 176/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.632 total time=   0.0s\n",
            "[CV 1/5; 177/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 177/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.584 total time=   0.0s\n",
            "[CV 2/5; 177/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 177/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.612 total time=   0.0s\n",
            "[CV 3/5; 177/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 177/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.636 total time=   0.0s\n",
            "[CV 4/5; 177/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 177/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.648 total time=   0.0s\n",
            "[CV 5/5; 177/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 177/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.684 total time=   0.0s\n",
            "[CV 1/5; 178/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 178/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.520 total time=   0.0s\n",
            "[CV 2/5; 178/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 178/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.528 total time=   0.0s\n",
            "[CV 3/5; 178/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 178/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.608 total time=   0.0s\n",
            "[CV 4/5; 178/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 178/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.600 total time=   0.0s\n",
            "[CV 5/5; 178/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 178/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.596 total time=   0.0s\n",
            "[CV 1/5; 179/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 179/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.644 total time=   0.0s\n",
            "[CV 2/5; 179/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 179/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.616 total time=   0.0s\n",
            "[CV 3/5; 179/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 179/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.608 total time=   0.0s\n",
            "[CV 4/5; 179/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 179/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.644 total time=   0.0s\n",
            "[CV 5/5; 179/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 179/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.616 total time=   0.0s\n",
            "[CV 1/5; 180/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 180/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.584 total time=   0.0s\n",
            "[CV 2/5; 180/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 180/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.572 total time=   0.0s\n",
            "[CV 3/5; 180/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 180/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.548 total time=   0.0s\n",
            "[CV 4/5; 180/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 180/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.556 total time=   0.0s\n",
            "[CV 5/5; 180/216] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 180/216] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.592 total time=   0.0s\n",
            "[CV 1/5; 181/216] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 181/216] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.716 total time=   0.0s\n",
            "[CV 2/5; 181/216] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 181/216] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.664 total time=   0.0s\n",
            "[CV 3/5; 181/216] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 181/216] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.648 total time=   0.0s\n",
            "[CV 4/5; 181/216] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 181/216] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.768 total time=   0.0s\n",
            "[CV 5/5; 181/216] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 181/216] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.680 total time=   0.0s\n",
            "[CV 1/5; 182/216] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 182/216] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.584 total time=   0.0s\n",
            "[CV 2/5; 182/216] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 182/216] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.684 total time=   0.0s\n",
            "[CV 3/5; 182/216] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 182/216] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.652 total time=   0.0s\n",
            "[CV 4/5; 182/216] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 182/216] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.624 total time=   0.0s\n",
            "[CV 5/5; 182/216] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 182/216] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.600 total time=   0.0s\n",
            "[CV 1/5; 183/216] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 183/216] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.696 total time=   0.0s\n",
            "[CV 2/5; 183/216] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 183/216] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.640 total time=   0.0s\n",
            "[CV 3/5; 183/216] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 183/216] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.736 total time=   0.0s\n",
            "[CV 4/5; 183/216] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 183/216] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.612 total time=   0.0s\n",
            "[CV 5/5; 183/216] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 183/216] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.700 total time=   0.0s\n",
            "[CV 1/5; 184/216] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 184/216] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.636 total time=   0.0s\n",
            "[CV 2/5; 184/216] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 184/216] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.768 total time=   0.0s\n",
            "[CV 3/5; 184/216] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 184/216] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.592 total time=   0.0s\n",
            "[CV 4/5; 184/216] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 184/216] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.704 total time=   0.0s\n",
            "[CV 5/5; 184/216] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 184/216] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.612 total time=   0.0s\n",
            "[CV 1/5; 185/216] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 185/216] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.720 total time=   0.0s\n",
            "[CV 2/5; 185/216] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 185/216] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.672 total time=   0.0s\n",
            "[CV 3/5; 185/216] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 185/216] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.756 total time=   0.0s\n",
            "[CV 4/5; 185/216] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 185/216] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.676 total time=   0.0s\n",
            "[CV 5/5; 185/216] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 185/216] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.684 total time=   0.0s\n",
            "[CV 1/5; 186/216] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 186/216] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.600 total time=   0.0s\n",
            "[CV 2/5; 186/216] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 186/216] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.648 total time=   0.0s\n",
            "[CV 3/5; 186/216] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 186/216] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.684 total time=   0.0s\n",
            "[CV 4/5; 186/216] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 186/216] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.708 total time=   0.0s\n",
            "[CV 5/5; 186/216] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 186/216] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.640 total time=   0.0s\n",
            "[CV 1/5; 187/216] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 187/216] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.672 total time=   0.0s\n",
            "[CV 2/5; 187/216] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 187/216] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.664 total time=   0.0s\n",
            "[CV 3/5; 187/216] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 187/216] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.664 total time=   0.0s\n",
            "[CV 4/5; 187/216] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 187/216] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.732 total time=   0.0s\n",
            "[CV 5/5; 187/216] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 187/216] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.684 total time=   0.0s\n",
            "[CV 1/5; 188/216] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 188/216] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.668 total time=   0.0s\n",
            "[CV 2/5; 188/216] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 188/216] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.640 total time=   0.0s\n",
            "[CV 3/5; 188/216] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 188/216] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.692 total time=   0.0s\n",
            "[CV 4/5; 188/216] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 188/216] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.548 total time=   0.0s\n",
            "[CV 5/5; 188/216] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 188/216] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.644 total time=   0.0s\n",
            "[CV 1/5; 189/216] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 189/216] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.712 total time=   0.0s\n",
            "[CV 2/5; 189/216] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 189/216] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.656 total time=   0.0s\n",
            "[CV 3/5; 189/216] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 189/216] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.780 total time=   0.0s\n",
            "[CV 4/5; 189/216] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 189/216] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.660 total time=   0.0s\n",
            "[CV 5/5; 189/216] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 189/216] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.724 total time=   0.0s\n",
            "[CV 1/5; 190/216] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 190/216] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.640 total time=   0.0s\n",
            "[CV 2/5; 190/216] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 190/216] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.628 total time=   0.0s\n",
            "[CV 3/5; 190/216] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 190/216] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.608 total time=   0.0s\n",
            "[CV 4/5; 190/216] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 190/216] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.660 total time=   0.0s\n",
            "[CV 5/5; 190/216] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 190/216] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.596 total time=   0.0s\n",
            "[CV 1/5; 191/216] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 191/216] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.660 total time=   0.0s\n",
            "[CV 2/5; 191/216] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 191/216] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.696 total time=   0.0s\n",
            "[CV 3/5; 191/216] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 191/216] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.668 total time=   0.0s\n",
            "[CV 4/5; 191/216] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 191/216] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.636 total time=   0.0s\n",
            "[CV 5/5; 191/216] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 191/216] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.696 total time=   0.0s\n",
            "[CV 1/5; 192/216] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 192/216] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.680 total time=   0.0s\n",
            "[CV 2/5; 192/216] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 192/216] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.652 total time=   0.0s\n",
            "[CV 3/5; 192/216] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 192/216] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.608 total time=   0.0s\n",
            "[CV 4/5; 192/216] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 192/216] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.620 total time=   0.0s\n",
            "[CV 5/5; 192/216] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 192/216] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.604 total time=   0.0s\n",
            "[CV 1/5; 193/216] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 193/216] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.724 total time=   0.0s\n",
            "[CV 2/5; 193/216] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 193/216] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.620 total time=   0.0s\n",
            "[CV 3/5; 193/216] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 193/216] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.708 total time=   0.0s\n",
            "[CV 4/5; 193/216] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 193/216] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.636 total time=   0.0s\n",
            "[CV 5/5; 193/216] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 193/216] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.700 total time=   0.0s\n",
            "[CV 1/5; 194/216] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 194/216] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.584 total time=   0.0s\n",
            "[CV 2/5; 194/216] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 194/216] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.584 total time=   0.0s\n",
            "[CV 3/5; 194/216] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 194/216] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.640 total time=   0.0s\n",
            "[CV 4/5; 194/216] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 194/216] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.664 total time=   0.0s\n",
            "[CV 5/5; 194/216] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 194/216] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.544 total time=   0.0s\n",
            "[CV 1/5; 195/216] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 195/216] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.700 total time=   0.0s\n",
            "[CV 2/5; 195/216] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 195/216] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.648 total time=   0.0s\n",
            "[CV 3/5; 195/216] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 195/216] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.680 total time=   0.0s\n",
            "[CV 4/5; 195/216] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 195/216] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.648 total time=   0.0s\n",
            "[CV 5/5; 195/216] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 195/216] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.716 total time=   0.0s\n",
            "[CV 1/5; 196/216] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 196/216] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.644 total time=   0.0s\n",
            "[CV 2/5; 196/216] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 196/216] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.564 total time=   0.0s\n",
            "[CV 3/5; 196/216] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 196/216] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.620 total time=   0.0s\n",
            "[CV 4/5; 196/216] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 196/216] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.616 total time=   0.0s\n",
            "[CV 5/5; 196/216] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 196/216] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.620 total time=   0.0s\n",
            "[CV 1/5; 197/216] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 197/216] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.692 total time=   0.0s\n",
            "[CV 2/5; 197/216] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 197/216] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.676 total time=   0.0s\n",
            "[CV 3/5; 197/216] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 197/216] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.664 total time=   0.0s\n",
            "[CV 4/5; 197/216] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 197/216] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.596 total time=   0.0s\n",
            "[CV 5/5; 197/216] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 197/216] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.768 total time=   0.0s\n",
            "[CV 1/5; 198/216] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 198/216] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.616 total time=   0.0s\n",
            "[CV 2/5; 198/216] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 198/216] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.592 total time=   0.0s\n",
            "[CV 3/5; 198/216] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 198/216] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.516 total time=   0.0s\n",
            "[CV 4/5; 198/216] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 198/216] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.668 total time=   0.0s\n",
            "[CV 5/5; 198/216] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 198/216] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.620 total time=   0.0s\n",
            "[CV 1/5; 199/216] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 199/216] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.728 total time=   0.0s\n",
            "[CV 2/5; 199/216] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 199/216] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.768 total time=   0.0s\n",
            "[CV 3/5; 199/216] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 199/216] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.844 total time=   0.0s\n",
            "[CV 4/5; 199/216] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 199/216] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.788 total time=   0.0s\n",
            "[CV 5/5; 199/216] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 199/216] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.796 total time=   0.0s\n",
            "[CV 1/5; 200/216] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 200/216] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.732 total time=   0.0s\n",
            "[CV 2/5; 200/216] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 200/216] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.664 total time=   0.0s\n",
            "[CV 3/5; 200/216] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 200/216] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.652 total time=   0.0s\n",
            "[CV 4/5; 200/216] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 200/216] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.628 total time=   0.0s\n",
            "[CV 5/5; 200/216] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 200/216] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.752 total time=   0.0s\n",
            "[CV 1/5; 201/216] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 201/216] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.736 total time=   0.0s\n",
            "[CV 2/5; 201/216] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 201/216] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.752 total time=   0.0s\n",
            "[CV 3/5; 201/216] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 201/216] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.856 total time=   0.0s\n",
            "[CV 4/5; 201/216] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 201/216] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.788 total time=   0.0s\n",
            "[CV 5/5; 201/216] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 201/216] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.792 total time=   0.0s\n",
            "[CV 1/5; 202/216] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 202/216] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.784 total time=   0.0s\n",
            "[CV 2/5; 202/216] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 202/216] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.668 total time=   0.0s\n",
            "[CV 3/5; 202/216] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 202/216] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.636 total time=   0.0s\n",
            "[CV 4/5; 202/216] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 202/216] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.728 total time=   0.0s\n",
            "[CV 5/5; 202/216] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 202/216] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.756 total time=   0.0s\n",
            "[CV 1/5; 203/216] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 203/216] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.724 total time=   0.0s\n",
            "[CV 2/5; 203/216] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 203/216] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.752 total time=   0.0s\n",
            "[CV 3/5; 203/216] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 203/216] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.852 total time=   0.0s\n",
            "[CV 4/5; 203/216] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 203/216] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.796 total time=   0.0s\n",
            "[CV 5/5; 203/216] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 203/216] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.800 total time=   0.0s\n",
            "[CV 1/5; 204/216] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 204/216] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.736 total time=   0.0s\n",
            "[CV 2/5; 204/216] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 204/216] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.680 total time=   0.0s\n",
            "[CV 3/5; 204/216] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 204/216] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.684 total time=   0.0s\n",
            "[CV 4/5; 204/216] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 204/216] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.644 total time=   0.0s\n",
            "[CV 5/5; 204/216] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 204/216] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.716 total time=   0.0s\n",
            "[CV 1/5; 205/216] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 205/216] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.752 total time=   0.0s\n",
            "[CV 2/5; 205/216] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 205/216] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.776 total time=   0.0s\n",
            "[CV 3/5; 205/216] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 205/216] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.852 total time=   0.0s\n",
            "[CV 4/5; 205/216] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 205/216] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.800 total time=   0.0s\n",
            "[CV 5/5; 205/216] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 205/216] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.808 total time=   0.0s\n",
            "[CV 1/5; 206/216] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 206/216] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.672 total time=   0.0s\n",
            "[CV 2/5; 206/216] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 206/216] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.592 total time=   0.0s\n",
            "[CV 3/5; 206/216] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 206/216] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.696 total time=   0.0s\n",
            "[CV 4/5; 206/216] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 206/216] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.724 total time=   0.0s\n",
            "[CV 5/5; 206/216] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 206/216] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.680 total time=   0.0s\n",
            "[CV 1/5; 207/216] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 207/216] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.744 total time=   0.0s\n",
            "[CV 2/5; 207/216] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 207/216] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.760 total time=   0.0s\n",
            "[CV 3/5; 207/216] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 207/216] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.848 total time=   0.0s\n",
            "[CV 4/5; 207/216] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 207/216] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.796 total time=   0.0s\n",
            "[CV 5/5; 207/216] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 207/216] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.808 total time=   0.0s\n",
            "[CV 1/5; 208/216] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 208/216] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.732 total time=   0.0s\n",
            "[CV 2/5; 208/216] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 208/216] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.616 total time=   0.0s\n",
            "[CV 3/5; 208/216] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 208/216] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.704 total time=   0.0s\n",
            "[CV 4/5; 208/216] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 208/216] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.584 total time=   0.0s\n",
            "[CV 5/5; 208/216] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 208/216] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.720 total time=   0.0s\n",
            "[CV 1/5; 209/216] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 209/216] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.732 total time=   0.0s\n",
            "[CV 2/5; 209/216] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 209/216] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.756 total time=   0.0s\n",
            "[CV 3/5; 209/216] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 209/216] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.856 total time=   0.0s\n",
            "[CV 4/5; 209/216] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 209/216] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.816 total time=   0.0s\n",
            "[CV 5/5; 209/216] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 209/216] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.800 total time=   0.0s\n",
            "[CV 1/5; 210/216] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 210/216] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.740 total time=   0.0s\n",
            "[CV 2/5; 210/216] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 210/216] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.668 total time=   0.0s\n",
            "[CV 3/5; 210/216] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 210/216] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.716 total time=   0.0s\n",
            "[CV 4/5; 210/216] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 210/216] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.644 total time=   0.0s\n",
            "[CV 5/5; 210/216] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 210/216] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.752 total time=   0.0s\n",
            "[CV 1/5; 211/216] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 211/216] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.748 total time=   0.0s\n",
            "[CV 2/5; 211/216] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 211/216] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.760 total time=   0.0s\n",
            "[CV 3/5; 211/216] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 211/216] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.848 total time=   0.0s\n",
            "[CV 4/5; 211/216] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 211/216] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.772 total time=   0.0s\n",
            "[CV 5/5; 211/216] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 211/216] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.816 total time=   0.0s\n",
            "[CV 1/5; 212/216] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 212/216] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.732 total time=   0.0s\n",
            "[CV 2/5; 212/216] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 212/216] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.704 total time=   0.0s\n",
            "[CV 3/5; 212/216] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 212/216] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.624 total time=   0.0s\n",
            "[CV 4/5; 212/216] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 212/216] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.616 total time=   0.0s\n",
            "[CV 5/5; 212/216] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 212/216] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.616 total time=   0.0s\n",
            "[CV 1/5; 213/216] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 213/216] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.740 total time=   0.0s\n",
            "[CV 2/5; 213/216] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 213/216] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.740 total time=   0.0s\n",
            "[CV 3/5; 213/216] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 213/216] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.844 total time=   0.0s\n",
            "[CV 4/5; 213/216] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 213/216] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.792 total time=   0.0s\n",
            "[CV 5/5; 213/216] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 213/216] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.828 total time=   0.0s\n",
            "[CV 1/5; 214/216] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 214/216] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.688 total time=   0.0s\n",
            "[CV 2/5; 214/216] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 214/216] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.640 total time=   0.0s\n",
            "[CV 3/5; 214/216] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 214/216] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.708 total time=   0.0s\n",
            "[CV 4/5; 214/216] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 214/216] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.608 total time=   0.0s\n",
            "[CV 5/5; 214/216] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 214/216] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.688 total time=   0.0s\n",
            "[CV 1/5; 215/216] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 215/216] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.736 total time=   0.0s\n",
            "[CV 2/5; 215/216] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 215/216] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.740 total time=   0.0s\n",
            "[CV 3/5; 215/216] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 215/216] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.848 total time=   0.0s\n",
            "[CV 4/5; 215/216] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 215/216] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.800 total time=   0.0s\n",
            "[CV 5/5; 215/216] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 215/216] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.800 total time=   0.0s\n",
            "[CV 1/5; 216/216] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 216/216] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.676 total time=   0.0s\n",
            "[CV 2/5; 216/216] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 216/216] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.632 total time=   0.0s\n",
            "[CV 3/5; 216/216] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 216/216] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.668 total time=   0.0s\n",
            "[CV 4/5; 216/216] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 216/216] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.672 total time=   0.0s\n",
            "[CV 5/5; 216/216] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 216/216] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.716 total time=   0.0s\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;knnc&#x27;,\n",
              "                 GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
              "                              param_grid=[{&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;,\n",
              "                                                         &#x27;log_loss&#x27;],\n",
              "                                           &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;,\n",
              "                                                            &#x27;log2&#x27;, None],\n",
              "                                           &#x27;min_samples_leaf&#x27;: [1, 2, 3],\n",
              "                                           &#x27;min_samples_split&#x27;: [2, 3, 4],\n",
              "                                           &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]}],\n",
              "                              verbose=10))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;knnc&#x27;,\n",
              "                 GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
              "                              param_grid=[{&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;,\n",
              "                                                         &#x27;log_loss&#x27;],\n",
              "                                           &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;,\n",
              "                                                            &#x27;log2&#x27;, None],\n",
              "                                           &#x27;min_samples_leaf&#x27;: [1, 2, 3],\n",
              "                                           &#x27;min_samples_split&#x27;: [2, 3, 4],\n",
              "                                           &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]}],\n",
              "                              verbose=10))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">knnc: GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
              "             param_grid=[{&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
              "                          &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n",
              "                          &#x27;min_samples_leaf&#x27;: [1, 2, 3],\n",
              "                          &#x27;min_samples_split&#x27;: [2, 3, 4],\n",
              "                          &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]}],\n",
              "             verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                ('knnc',\n",
              "                 GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
              "                              param_grid=[{'criterion': ['gini', 'entropy',\n",
              "                                                         'log_loss'],\n",
              "                                           'max_features': ['auto', 'sqrt',\n",
              "                                                            'log2', None],\n",
              "                                           'min_samples_leaf': [1, 2, 3],\n",
              "                                           'min_samples_split': [2, 3, 4],\n",
              "                                           'splitter': ['best', 'random']}],\n",
              "                              verbose=10))])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "param_grid = [{'criterion': ['gini', 'entropy', 'log_loss'],\n",
        "               'splitter': ['best', 'random'],\n",
        "               'min_samples_split': [2, 3, 4],\n",
        "               'min_samples_leaf': [1, 2, 3],\n",
        "               'max_features': ['auto', 'sqrt', 'log2', None]}]\n",
        "\n",
        "clf = Pipeline([('scaler', StandardScaler()),\n",
        "                ('knnc', GridSearchCV(DecisionTreeClassifier(),\n",
        "                              param_grid=param_grid,\n",
        "                              cv=5,\n",
        "                              refit=True,\n",
        "                              verbose=10))])\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxACxbgvm0Z8"
      },
      "source": [
        "#### Evaluating Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RdFfgZkm8VI",
        "outputId": "eac093ff-1ab1-43ba-a1c3-d198d5cb069c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation f1 Score:  0.766355140186916\n",
            "Test f1 Score:  0.6976744186046512\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "y_valid_pred = clf.predict(X_valid)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Validation f1 Score: \", f1_score(y_valid, y_valid_pred))\n",
        "print(\"Test f1 Score: \", f1_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5buC5sXm95s"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkJgIM6nnYim"
      },
      "source": [
        "#### Training Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t84x-z6Gna_E",
        "outputId": "9d142701-f2b3-4901-c9a3-af23506a9b30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 448 candidates, totalling 2240 fits\n",
            "[CV 1/5; 1/448] START C=0.1, penalty=l1, solver=liblinear, tol=0.001............\n",
            "[CV 1/5; 1/448] END C=0.1, penalty=l1, solver=liblinear, tol=0.001;, score=0.928 total time=   0.0s\n",
            "[CV 2/5; 1/448] START C=0.1, penalty=l1, solver=liblinear, tol=0.001............\n",
            "[CV 2/5; 1/448] END C=0.1, penalty=l1, solver=liblinear, tol=0.001;, score=0.856 total time=   0.0s\n",
            "[CV 3/5; 1/448] START C=0.1, penalty=l1, solver=liblinear, tol=0.001............\n",
            "[CV 3/5; 1/448] END C=0.1, penalty=l1, solver=liblinear, tol=0.001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 1/448] START C=0.1, penalty=l1, solver=liblinear, tol=0.001............\n",
            "[CV 4/5; 1/448] END C=0.1, penalty=l1, solver=liblinear, tol=0.001;, score=0.912 total time=   0.0s\n",
            "[CV 5/5; 1/448] START C=0.1, penalty=l1, solver=liblinear, tol=0.001............\n",
            "[CV 5/5; 1/448] END C=0.1, penalty=l1, solver=liblinear, tol=0.001;, score=0.940 total time=   0.0s\n",
            "[CV 1/5; 2/448] START C=0.1, penalty=l1, solver=liblinear, tol=0.0001...........\n",
            "[CV 1/5; 2/448] END C=0.1, penalty=l1, solver=liblinear, tol=0.0001;, score=0.928 total time=   0.0s\n",
            "[CV 2/5; 2/448] START C=0.1, penalty=l1, solver=liblinear, tol=0.0001...........\n",
            "[CV 2/5; 2/448] END C=0.1, penalty=l1, solver=liblinear, tol=0.0001;, score=0.856 total time=   0.0s\n",
            "[CV 3/5; 2/448] START C=0.1, penalty=l1, solver=liblinear, tol=0.0001...........\n",
            "[CV 3/5; 2/448] END C=0.1, penalty=l1, solver=liblinear, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 2/448] START C=0.1, penalty=l1, solver=liblinear, tol=0.0001...........\n",
            "[CV 4/5; 2/448] END C=0.1, penalty=l1, solver=liblinear, tol=0.0001;, score=0.912 total time=   0.0s\n",
            "[CV 5/5; 2/448] START C=0.1, penalty=l1, solver=liblinear, tol=0.0001...........\n",
            "[CV 5/5; 2/448] END C=0.1, penalty=l1, solver=liblinear, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 1/5; 3/448] START C=0.1, penalty=l1, solver=liblinear, tol=1e-05............\n",
            "[CV 1/5; 3/448] END C=0.1, penalty=l1, solver=liblinear, tol=1e-05;, score=0.928 total time=   0.0s\n",
            "[CV 2/5; 3/448] START C=0.1, penalty=l1, solver=liblinear, tol=1e-05............\n",
            "[CV 2/5; 3/448] END C=0.1, penalty=l1, solver=liblinear, tol=1e-05;, score=0.856 total time=   0.0s\n",
            "[CV 3/5; 3/448] START C=0.1, penalty=l1, solver=liblinear, tol=1e-05............\n",
            "[CV 3/5; 3/448] END C=0.1, penalty=l1, solver=liblinear, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 3/448] START C=0.1, penalty=l1, solver=liblinear, tol=1e-05............\n",
            "[CV 4/5; 3/448] END C=0.1, penalty=l1, solver=liblinear, tol=1e-05;, score=0.912 total time=   0.0s\n",
            "[CV 5/5; 3/448] START C=0.1, penalty=l1, solver=liblinear, tol=1e-05............\n",
            "[CV 5/5; 3/448] END C=0.1, penalty=l1, solver=liblinear, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 1/5; 4/448] START C=0.1, penalty=l1, solver=liblinear, tol=1e-06............\n",
            "[CV 1/5; 4/448] END C=0.1, penalty=l1, solver=liblinear, tol=1e-06;, score=0.928 total time=   0.0s\n",
            "[CV 2/5; 4/448] START C=0.1, penalty=l1, solver=liblinear, tol=1e-06............\n",
            "[CV 2/5; 4/448] END C=0.1, penalty=l1, solver=liblinear, tol=1e-06;, score=0.856 total time=   0.0s\n",
            "[CV 3/5; 4/448] START C=0.1, penalty=l1, solver=liblinear, tol=1e-06............\n",
            "[CV 3/5; 4/448] END C=0.1, penalty=l1, solver=liblinear, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 4/448] START C=0.1, penalty=l1, solver=liblinear, tol=1e-06............\n",
            "[CV 4/5; 4/448] END C=0.1, penalty=l1, solver=liblinear, tol=1e-06;, score=0.912 total time=   0.0s\n",
            "[CV 5/5; 4/448] START C=0.1, penalty=l1, solver=liblinear, tol=1e-06............\n",
            "[CV 5/5; 4/448] END C=0.1, penalty=l1, solver=liblinear, tol=1e-06;, score=0.940 total time=   0.0s\n",
            "[CV 1/5; 5/448] START C=0.1, penalty=l2, solver=liblinear, tol=0.001............\n",
            "[CV 1/5; 5/448] END C=0.1, penalty=l2, solver=liblinear, tol=0.001;, score=0.792 total time=   0.0s\n",
            "[CV 2/5; 5/448] START C=0.1, penalty=l2, solver=liblinear, tol=0.001............\n",
            "[CV 2/5; 5/448] END C=0.1, penalty=l2, solver=liblinear, tol=0.001;, score=0.652 total time=   0.0s\n",
            "[CV 3/5; 5/448] START C=0.1, penalty=l2, solver=liblinear, tol=0.001............\n",
            "[CV 3/5; 5/448] END C=0.1, penalty=l2, solver=liblinear, tol=0.001;, score=0.724 total time=   0.0s\n",
            "[CV 4/5; 5/448] START C=0.1, penalty=l2, solver=liblinear, tol=0.001............\n",
            "[CV 4/5; 5/448] END C=0.1, penalty=l2, solver=liblinear, tol=0.001;, score=0.720 total time=   0.0s\n",
            "[CV 5/5; 5/448] START C=0.1, penalty=l2, solver=liblinear, tol=0.001............\n",
            "[CV 5/5; 5/448] END C=0.1, penalty=l2, solver=liblinear, tol=0.001;, score=0.780 total time=   0.0s\n",
            "[CV 1/5; 6/448] START C=0.1, penalty=l2, solver=liblinear, tol=0.0001...........\n",
            "[CV 1/5; 6/448] END C=0.1, penalty=l2, solver=liblinear, tol=0.0001;, score=0.792 total time=   0.0s\n",
            "[CV 2/5; 6/448] START C=0.1, penalty=l2, solver=liblinear, tol=0.0001...........\n",
            "[CV 2/5; 6/448] END C=0.1, penalty=l2, solver=liblinear, tol=0.0001;, score=0.652 total time=   0.0s\n",
            "[CV 3/5; 6/448] START C=0.1, penalty=l2, solver=liblinear, tol=0.0001...........\n",
            "[CV 3/5; 6/448] END C=0.1, penalty=l2, solver=liblinear, tol=0.0001;, score=0.724 total time=   0.0s\n",
            "[CV 4/5; 6/448] START C=0.1, penalty=l2, solver=liblinear, tol=0.0001...........\n",
            "[CV 4/5; 6/448] END C=0.1, penalty=l2, solver=liblinear, tol=0.0001;, score=0.720 total time=   0.0s\n",
            "[CV 5/5; 6/448] START C=0.1, penalty=l2, solver=liblinear, tol=0.0001...........\n",
            "[CV 5/5; 6/448] END C=0.1, penalty=l2, solver=liblinear, tol=0.0001;, score=0.780 total time=   0.0s\n",
            "[CV 1/5; 7/448] START C=0.1, penalty=l2, solver=liblinear, tol=1e-05............\n",
            "[CV 1/5; 7/448] END C=0.1, penalty=l2, solver=liblinear, tol=1e-05;, score=0.792 total time=   0.0s\n",
            "[CV 2/5; 7/448] START C=0.1, penalty=l2, solver=liblinear, tol=1e-05............\n",
            "[CV 2/5; 7/448] END C=0.1, penalty=l2, solver=liblinear, tol=1e-05;, score=0.652 total time=   0.0s\n",
            "[CV 3/5; 7/448] START C=0.1, penalty=l2, solver=liblinear, tol=1e-05............\n",
            "[CV 3/5; 7/448] END C=0.1, penalty=l2, solver=liblinear, tol=1e-05;, score=0.724 total time=   0.0s\n",
            "[CV 4/5; 7/448] START C=0.1, penalty=l2, solver=liblinear, tol=1e-05............\n",
            "[CV 4/5; 7/448] END C=0.1, penalty=l2, solver=liblinear, tol=1e-05;, score=0.720 total time=   0.0s\n",
            "[CV 5/5; 7/448] START C=0.1, penalty=l2, solver=liblinear, tol=1e-05............\n",
            "[CV 5/5; 7/448] END C=0.1, penalty=l2, solver=liblinear, tol=1e-05;, score=0.780 total time=   0.0s\n",
            "[CV 1/5; 8/448] START C=0.1, penalty=l2, solver=liblinear, tol=1e-06............\n",
            "[CV 1/5; 8/448] END C=0.1, penalty=l2, solver=liblinear, tol=1e-06;, score=0.792 total time=   0.0s\n",
            "[CV 2/5; 8/448] START C=0.1, penalty=l2, solver=liblinear, tol=1e-06............\n",
            "[CV 2/5; 8/448] END C=0.1, penalty=l2, solver=liblinear, tol=1e-06;, score=0.652 total time=   0.0s\n",
            "[CV 3/5; 8/448] START C=0.1, penalty=l2, solver=liblinear, tol=1e-06............\n",
            "[CV 3/5; 8/448] END C=0.1, penalty=l2, solver=liblinear, tol=1e-06;, score=0.724 total time=   0.0s\n",
            "[CV 4/5; 8/448] START C=0.1, penalty=l2, solver=liblinear, tol=1e-06............\n",
            "[CV 4/5; 8/448] END C=0.1, penalty=l2, solver=liblinear, tol=1e-06;, score=0.720 total time=   0.0s\n",
            "[CV 5/5; 8/448] START C=0.1, penalty=l2, solver=liblinear, tol=1e-06............\n",
            "[CV 5/5; 8/448] END C=0.1, penalty=l2, solver=liblinear, tol=1e-06;, score=0.780 total time=   0.0s\n",
            "[CV 1/5; 9/448] START C=1, penalty=l1, solver=liblinear, tol=0.001..............\n",
            "[CV 1/5; 9/448] END C=1, penalty=l1, solver=liblinear, tol=0.001;, score=0.988 total time=   0.1s\n",
            "[CV 2/5; 9/448] START C=1, penalty=l1, solver=liblinear, tol=0.001..............\n",
            "[CV 2/5; 9/448] END C=1, penalty=l1, solver=liblinear, tol=0.001;, score=0.988 total time=   0.1s\n",
            "[CV 3/5; 9/448] START C=1, penalty=l1, solver=liblinear, tol=0.001..............\n",
            "[CV 3/5; 9/448] END C=1, penalty=l1, solver=liblinear, tol=0.001;, score=0.968 total time=   0.1s\n",
            "[CV 4/5; 9/448] START C=1, penalty=l1, solver=liblinear, tol=0.001..............\n",
            "[CV 4/5; 9/448] END C=1, penalty=l1, solver=liblinear, tol=0.001;, score=0.972 total time=   0.1s\n",
            "[CV 5/5; 9/448] START C=1, penalty=l1, solver=liblinear, tol=0.001..............\n",
            "[CV 5/5; 9/448] END C=1, penalty=l1, solver=liblinear, tol=0.001;, score=0.988 total time=   0.1s\n",
            "[CV 1/5; 10/448] START C=1, penalty=l1, solver=liblinear, tol=0.0001............\n",
            "[CV 1/5; 10/448] END C=1, penalty=l1, solver=liblinear, tol=0.0001;, score=0.988 total time=   0.1s\n",
            "[CV 2/5; 10/448] START C=1, penalty=l1, solver=liblinear, tol=0.0001............\n",
            "[CV 2/5; 10/448] END C=1, penalty=l1, solver=liblinear, tol=0.0001;, score=0.988 total time=   0.1s\n",
            "[CV 3/5; 10/448] START C=1, penalty=l1, solver=liblinear, tol=0.0001............\n",
            "[CV 3/5; 10/448] END C=1, penalty=l1, solver=liblinear, tol=0.0001;, score=0.968 total time=   0.1s\n",
            "[CV 4/5; 10/448] START C=1, penalty=l1, solver=liblinear, tol=0.0001............\n",
            "[CV 4/5; 10/448] END C=1, penalty=l1, solver=liblinear, tol=0.0001;, score=0.972 total time=   0.1s\n",
            "[CV 5/5; 10/448] START C=1, penalty=l1, solver=liblinear, tol=0.0001............\n",
            "[CV 5/5; 10/448] END C=1, penalty=l1, solver=liblinear, tol=0.0001;, score=0.988 total time=   0.1s\n",
            "[CV 1/5; 11/448] START C=1, penalty=l1, solver=liblinear, tol=1e-05.............\n",
            "[CV 1/5; 11/448] END C=1, penalty=l1, solver=liblinear, tol=1e-05;, score=0.988 total time=   0.1s\n",
            "[CV 2/5; 11/448] START C=1, penalty=l1, solver=liblinear, tol=1e-05.............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 11/448] END C=1, penalty=l1, solver=liblinear, tol=1e-05;, score=0.988 total time=   0.2s\n",
            "[CV 3/5; 11/448] START C=1, penalty=l1, solver=liblinear, tol=1e-05.............\n",
            "[CV 3/5; 11/448] END C=1, penalty=l1, solver=liblinear, tol=1e-05;, score=0.968 total time=   0.1s\n",
            "[CV 4/5; 11/448] START C=1, penalty=l1, solver=liblinear, tol=1e-05.............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 11/448] END C=1, penalty=l1, solver=liblinear, tol=1e-05;, score=0.972 total time=   0.1s\n",
            "[CV 5/5; 11/448] START C=1, penalty=l1, solver=liblinear, tol=1e-05.............\n",
            "[CV 5/5; 11/448] END C=1, penalty=l1, solver=liblinear, tol=1e-05;, score=0.988 total time=   0.1s\n",
            "[CV 1/5; 12/448] START C=1, penalty=l1, solver=liblinear, tol=1e-06.............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 12/448] END C=1, penalty=l1, solver=liblinear, tol=1e-06;, score=0.988 total time=   0.2s\n",
            "[CV 2/5; 12/448] START C=1, penalty=l1, solver=liblinear, tol=1e-06.............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 12/448] END C=1, penalty=l1, solver=liblinear, tol=1e-06;, score=0.988 total time=   0.2s\n",
            "[CV 3/5; 12/448] START C=1, penalty=l1, solver=liblinear, tol=1e-06.............\n",
            "[CV 3/5; 12/448] END C=1, penalty=l1, solver=liblinear, tol=1e-06;, score=0.968 total time=   0.2s\n",
            "[CV 4/5; 12/448] START C=1, penalty=l1, solver=liblinear, tol=1e-06.............\n",
            "[CV 4/5; 12/448] END C=1, penalty=l1, solver=liblinear, tol=1e-06;, score=0.972 total time=   0.2s\n",
            "[CV 5/5; 12/448] START C=1, penalty=l1, solver=liblinear, tol=1e-06.............\n",
            "[CV 5/5; 12/448] END C=1, penalty=l1, solver=liblinear, tol=1e-06;, score=0.988 total time=   0.1s\n",
            "[CV 1/5; 13/448] START C=1, penalty=l2, solver=liblinear, tol=0.001.............\n",
            "[CV 1/5; 13/448] END C=1, penalty=l2, solver=liblinear, tol=0.001;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 13/448] START C=1, penalty=l2, solver=liblinear, tol=0.001.............\n",
            "[CV 2/5; 13/448] END C=1, penalty=l2, solver=liblinear, tol=0.001;, score=0.884 total time=   0.0s\n",
            "[CV 3/5; 13/448] START C=1, penalty=l2, solver=liblinear, tol=0.001.............\n",
            "[CV 3/5; 13/448] END C=1, penalty=l2, solver=liblinear, tol=0.001;, score=0.912 total time=   0.0s\n",
            "[CV 4/5; 13/448] START C=1, penalty=l2, solver=liblinear, tol=0.001.............\n",
            "[CV 4/5; 13/448] END C=1, penalty=l2, solver=liblinear, tol=0.001;, score=0.916 total time=   0.0s\n",
            "[CV 5/5; 13/448] START C=1, penalty=l2, solver=liblinear, tol=0.001.............\n",
            "[CV 5/5; 13/448] END C=1, penalty=l2, solver=liblinear, tol=0.001;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 14/448] START C=1, penalty=l2, solver=liblinear, tol=0.0001............\n",
            "[CV 1/5; 14/448] END C=1, penalty=l2, solver=liblinear, tol=0.0001;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 14/448] START C=1, penalty=l2, solver=liblinear, tol=0.0001............\n",
            "[CV 2/5; 14/448] END C=1, penalty=l2, solver=liblinear, tol=0.0001;, score=0.884 total time=   0.0s\n",
            "[CV 3/5; 14/448] START C=1, penalty=l2, solver=liblinear, tol=0.0001............\n",
            "[CV 3/5; 14/448] END C=1, penalty=l2, solver=liblinear, tol=0.0001;, score=0.912 total time=   0.0s\n",
            "[CV 4/5; 14/448] START C=1, penalty=l2, solver=liblinear, tol=0.0001............\n",
            "[CV 4/5; 14/448] END C=1, penalty=l2, solver=liblinear, tol=0.0001;, score=0.916 total time=   0.0s\n",
            "[CV 5/5; 14/448] START C=1, penalty=l2, solver=liblinear, tol=0.0001............\n",
            "[CV 5/5; 14/448] END C=1, penalty=l2, solver=liblinear, tol=0.0001;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 15/448] START C=1, penalty=l2, solver=liblinear, tol=1e-05.............\n",
            "[CV 1/5; 15/448] END C=1, penalty=l2, solver=liblinear, tol=1e-05;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 15/448] START C=1, penalty=l2, solver=liblinear, tol=1e-05.............\n",
            "[CV 2/5; 15/448] END C=1, penalty=l2, solver=liblinear, tol=1e-05;, score=0.884 total time=   0.0s\n",
            "[CV 3/5; 15/448] START C=1, penalty=l2, solver=liblinear, tol=1e-05.............\n",
            "[CV 3/5; 15/448] END C=1, penalty=l2, solver=liblinear, tol=1e-05;, score=0.912 total time=   0.0s\n",
            "[CV 4/5; 15/448] START C=1, penalty=l2, solver=liblinear, tol=1e-05.............\n",
            "[CV 4/5; 15/448] END C=1, penalty=l2, solver=liblinear, tol=1e-05;, score=0.916 total time=   0.0s\n",
            "[CV 5/5; 15/448] START C=1, penalty=l2, solver=liblinear, tol=1e-05.............\n",
            "[CV 5/5; 15/448] END C=1, penalty=l2, solver=liblinear, tol=1e-05;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 16/448] START C=1, penalty=l2, solver=liblinear, tol=1e-06.............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 16/448] END C=1, penalty=l2, solver=liblinear, tol=1e-06;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 16/448] START C=1, penalty=l2, solver=liblinear, tol=1e-06.............\n",
            "[CV 2/5; 16/448] END C=1, penalty=l2, solver=liblinear, tol=1e-06;, score=0.884 total time=   0.0s\n",
            "[CV 3/5; 16/448] START C=1, penalty=l2, solver=liblinear, tol=1e-06.............\n",
            "[CV 3/5; 16/448] END C=1, penalty=l2, solver=liblinear, tol=1e-06;, score=0.912 total time=   0.0s\n",
            "[CV 4/5; 16/448] START C=1, penalty=l2, solver=liblinear, tol=1e-06.............\n",
            "[CV 4/5; 16/448] END C=1, penalty=l2, solver=liblinear, tol=1e-06;, score=0.916 total time=   0.0s\n",
            "[CV 5/5; 16/448] START C=1, penalty=l2, solver=liblinear, tol=1e-06.............\n",
            "[CV 5/5; 16/448] END C=1, penalty=l2, solver=liblinear, tol=1e-06;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 17/448] START C=10.0, penalty=l1, solver=liblinear, tol=0.001..........\n",
            "[CV 1/5; 17/448] END C=10.0, penalty=l1, solver=liblinear, tol=0.001;, score=0.988 total time=   0.4s\n",
            "[CV 2/5; 17/448] START C=10.0, penalty=l1, solver=liblinear, tol=0.001..........\n",
            "[CV 2/5; 17/448] END C=10.0, penalty=l1, solver=liblinear, tol=0.001;, score=0.988 total time=   0.4s\n",
            "[CV 3/5; 17/448] START C=10.0, penalty=l1, solver=liblinear, tol=0.001..........\n",
            "[CV 3/5; 17/448] END C=10.0, penalty=l1, solver=liblinear, tol=0.001;, score=0.972 total time=   0.5s\n",
            "[CV 4/5; 17/448] START C=10.0, penalty=l1, solver=liblinear, tol=0.001..........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 17/448] END C=10.0, penalty=l1, solver=liblinear, tol=0.001;, score=0.980 total time=   0.4s\n",
            "[CV 5/5; 17/448] START C=10.0, penalty=l1, solver=liblinear, tol=0.001..........\n",
            "[CV 5/5; 17/448] END C=10.0, penalty=l1, solver=liblinear, tol=0.001;, score=0.992 total time=   0.7s\n",
            "[CV 1/5; 18/448] START C=10.0, penalty=l1, solver=liblinear, tol=0.0001.........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 18/448] END C=10.0, penalty=l1, solver=liblinear, tol=0.0001;, score=0.988 total time=   0.5s\n",
            "[CV 2/5; 18/448] START C=10.0, penalty=l1, solver=liblinear, tol=0.0001.........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 18/448] END C=10.0, penalty=l1, solver=liblinear, tol=0.0001;, score=0.992 total time=   0.6s\n",
            "[CV 3/5; 18/448] START C=10.0, penalty=l1, solver=liblinear, tol=0.0001.........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 18/448] END C=10.0, penalty=l1, solver=liblinear, tol=0.0001;, score=0.972 total time=   1.0s\n",
            "[CV 4/5; 18/448] START C=10.0, penalty=l1, solver=liblinear, tol=0.0001.........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 18/448] END C=10.0, penalty=l1, solver=liblinear, tol=0.0001;, score=0.980 total time=   1.2s\n",
            "[CV 5/5; 18/448] START C=10.0, penalty=l1, solver=liblinear, tol=0.0001.........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 18/448] END C=10.0, penalty=l1, solver=liblinear, tol=0.0001;, score=0.992 total time=   1.1s\n",
            "[CV 1/5; 19/448] START C=10.0, penalty=l1, solver=liblinear, tol=1e-05..........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 19/448] END C=10.0, penalty=l1, solver=liblinear, tol=1e-05;, score=0.988 total time=   0.8s\n",
            "[CV 2/5; 19/448] START C=10.0, penalty=l1, solver=liblinear, tol=1e-05..........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 19/448] END C=10.0, penalty=l1, solver=liblinear, tol=1e-05;, score=0.988 total time=   0.4s\n",
            "[CV 3/5; 19/448] START C=10.0, penalty=l1, solver=liblinear, tol=1e-05..........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 19/448] END C=10.0, penalty=l1, solver=liblinear, tol=1e-05;, score=0.972 total time=   0.5s\n",
            "[CV 4/5; 19/448] START C=10.0, penalty=l1, solver=liblinear, tol=1e-05..........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 19/448] END C=10.0, penalty=l1, solver=liblinear, tol=1e-05;, score=0.980 total time=   0.6s\n",
            "[CV 5/5; 19/448] START C=10.0, penalty=l1, solver=liblinear, tol=1e-05..........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 19/448] END C=10.0, penalty=l1, solver=liblinear, tol=1e-05;, score=0.992 total time=   0.7s\n",
            "[CV 1/5; 20/448] START C=10.0, penalty=l1, solver=liblinear, tol=1e-06..........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 20/448] END C=10.0, penalty=l1, solver=liblinear, tol=1e-06;, score=0.988 total time=   0.7s\n",
            "[CV 2/5; 20/448] START C=10.0, penalty=l1, solver=liblinear, tol=1e-06..........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 20/448] END C=10.0, penalty=l1, solver=liblinear, tol=1e-06;, score=0.988 total time=   0.5s\n",
            "[CV 3/5; 20/448] START C=10.0, penalty=l1, solver=liblinear, tol=1e-06..........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 20/448] END C=10.0, penalty=l1, solver=liblinear, tol=1e-06;, score=0.972 total time=   0.3s\n",
            "[CV 4/5; 20/448] START C=10.0, penalty=l1, solver=liblinear, tol=1e-06..........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 20/448] END C=10.0, penalty=l1, solver=liblinear, tol=1e-06;, score=0.980 total time=   0.6s\n",
            "[CV 5/5; 20/448] START C=10.0, penalty=l1, solver=liblinear, tol=1e-06..........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 20/448] END C=10.0, penalty=l1, solver=liblinear, tol=1e-06;, score=0.992 total time=   0.4s\n",
            "[CV 1/5; 21/448] START C=10.0, penalty=l2, solver=liblinear, tol=0.001..........\n",
            "[CV 1/5; 21/448] END C=10.0, penalty=l2, solver=liblinear, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 2/5; 21/448] START C=10.0, penalty=l2, solver=liblinear, tol=0.001..........\n",
            "[CV 2/5; 21/448] END C=10.0, penalty=l2, solver=liblinear, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 21/448] START C=10.0, penalty=l2, solver=liblinear, tol=0.001..........\n",
            "[CV 3/5; 21/448] END C=10.0, penalty=l2, solver=liblinear, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 21/448] START C=10.0, penalty=l2, solver=liblinear, tol=0.001..........\n",
            "[CV 4/5; 21/448] END C=10.0, penalty=l2, solver=liblinear, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 5/5; 21/448] START C=10.0, penalty=l2, solver=liblinear, tol=0.001..........\n",
            "[CV 5/5; 21/448] END C=10.0, penalty=l2, solver=liblinear, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 22/448] START C=10.0, penalty=l2, solver=liblinear, tol=0.0001.........\n",
            "[CV 1/5; 22/448] END C=10.0, penalty=l2, solver=liblinear, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 2/5; 22/448] START C=10.0, penalty=l2, solver=liblinear, tol=0.0001.........\n",
            "[CV 2/5; 22/448] END C=10.0, penalty=l2, solver=liblinear, tol=0.0001;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 22/448] START C=10.0, penalty=l2, solver=liblinear, tol=0.0001.........\n",
            "[CV 3/5; 22/448] END C=10.0, penalty=l2, solver=liblinear, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 22/448] START C=10.0, penalty=l2, solver=liblinear, tol=0.0001.........\n",
            "[CV 4/5; 22/448] END C=10.0, penalty=l2, solver=liblinear, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 5/5; 22/448] START C=10.0, penalty=l2, solver=liblinear, tol=0.0001.........\n",
            "[CV 5/5; 22/448] END C=10.0, penalty=l2, solver=liblinear, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 23/448] START C=10.0, penalty=l2, solver=liblinear, tol=1e-05..........\n",
            "[CV 1/5; 23/448] END C=10.0, penalty=l2, solver=liblinear, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 2/5; 23/448] START C=10.0, penalty=l2, solver=liblinear, tol=1e-05..........\n",
            "[CV 2/5; 23/448] END C=10.0, penalty=l2, solver=liblinear, tol=1e-05;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 23/448] START C=10.0, penalty=l2, solver=liblinear, tol=1e-05..........\n",
            "[CV 3/5; 23/448] END C=10.0, penalty=l2, solver=liblinear, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 23/448] START C=10.0, penalty=l2, solver=liblinear, tol=1e-05..........\n",
            "[CV 4/5; 23/448] END C=10.0, penalty=l2, solver=liblinear, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 5/5; 23/448] START C=10.0, penalty=l2, solver=liblinear, tol=1e-05..........\n",
            "[CV 5/5; 23/448] END C=10.0, penalty=l2, solver=liblinear, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 24/448] START C=10.0, penalty=l2, solver=liblinear, tol=1e-06..........\n",
            "[CV 1/5; 24/448] END C=10.0, penalty=l2, solver=liblinear, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 2/5; 24/448] START C=10.0, penalty=l2, solver=liblinear, tol=1e-06..........\n",
            "[CV 2/5; 24/448] END C=10.0, penalty=l2, solver=liblinear, tol=1e-06;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 24/448] START C=10.0, penalty=l2, solver=liblinear, tol=1e-06..........\n",
            "[CV 3/5; 24/448] END C=10.0, penalty=l2, solver=liblinear, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 24/448] START C=10.0, penalty=l2, solver=liblinear, tol=1e-06..........\n",
            "[CV 4/5; 24/448] END C=10.0, penalty=l2, solver=liblinear, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 5/5; 24/448] START C=10.0, penalty=l2, solver=liblinear, tol=1e-06..........\n",
            "[CV 5/5; 24/448] END C=10.0, penalty=l2, solver=liblinear, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 25/448] START C=100.0, penalty=l1, solver=liblinear, tol=0.001.........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 25/448] END C=100.0, penalty=l1, solver=liblinear, tol=0.001;, score=0.988 total time=   0.2s\n",
            "[CV 2/5; 25/448] START C=100.0, penalty=l1, solver=liblinear, tol=0.001.........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 25/448] END C=100.0, penalty=l1, solver=liblinear, tol=0.001;, score=0.992 total time=   0.3s\n",
            "[CV 3/5; 25/448] START C=100.0, penalty=l1, solver=liblinear, tol=0.001.........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 25/448] END C=100.0, penalty=l1, solver=liblinear, tol=0.001;, score=0.976 total time=   0.6s\n",
            "[CV 4/5; 25/448] START C=100.0, penalty=l1, solver=liblinear, tol=0.001.........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 25/448] END C=100.0, penalty=l1, solver=liblinear, tol=0.001;, score=0.980 total time=   0.3s\n",
            "[CV 5/5; 25/448] START C=100.0, penalty=l1, solver=liblinear, tol=0.001.........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 25/448] END C=100.0, penalty=l1, solver=liblinear, tol=0.001;, score=0.984 total time=   0.3s\n",
            "[CV 1/5; 26/448] START C=100.0, penalty=l1, solver=liblinear, tol=0.0001........\n",
            "[CV 1/5; 26/448] END C=100.0, penalty=l1, solver=liblinear, tol=0.0001;, score=0.988 total time=   0.1s\n",
            "[CV 2/5; 26/448] START C=100.0, penalty=l1, solver=liblinear, tol=0.0001........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 26/448] END C=100.0, penalty=l1, solver=liblinear, tol=0.0001;, score=0.988 total time=   0.1s\n",
            "[CV 3/5; 26/448] START C=100.0, penalty=l1, solver=liblinear, tol=0.0001........\n",
            "[CV 3/5; 26/448] END C=100.0, penalty=l1, solver=liblinear, tol=0.0001;, score=0.980 total time=   0.2s\n",
            "[CV 4/5; 26/448] START C=100.0, penalty=l1, solver=liblinear, tol=0.0001........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 26/448] END C=100.0, penalty=l1, solver=liblinear, tol=0.0001;, score=0.980 total time=   0.3s\n",
            "[CV 5/5; 26/448] START C=100.0, penalty=l1, solver=liblinear, tol=0.0001........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 26/448] END C=100.0, penalty=l1, solver=liblinear, tol=0.0001;, score=0.984 total time=   0.3s\n",
            "[CV 1/5; 27/448] START C=100.0, penalty=l1, solver=liblinear, tol=1e-05.........\n",
            "[CV 1/5; 27/448] END C=100.0, penalty=l1, solver=liblinear, tol=1e-05;, score=0.988 total time=   0.2s\n",
            "[CV 2/5; 27/448] START C=100.0, penalty=l1, solver=liblinear, tol=1e-05.........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 27/448] END C=100.0, penalty=l1, solver=liblinear, tol=1e-05;, score=0.988 total time=   0.7s\n",
            "[CV 3/5; 27/448] START C=100.0, penalty=l1, solver=liblinear, tol=1e-05.........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 27/448] END C=100.0, penalty=l1, solver=liblinear, tol=1e-05;, score=0.972 total time=   0.5s\n",
            "[CV 4/5; 27/448] START C=100.0, penalty=l1, solver=liblinear, tol=1e-05.........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 27/448] END C=100.0, penalty=l1, solver=liblinear, tol=1e-05;, score=0.980 total time=   0.3s\n",
            "[CV 5/5; 27/448] START C=100.0, penalty=l1, solver=liblinear, tol=1e-05.........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 27/448] END C=100.0, penalty=l1, solver=liblinear, tol=1e-05;, score=0.984 total time=   0.4s\n",
            "[CV 1/5; 28/448] START C=100.0, penalty=l1, solver=liblinear, tol=1e-06.........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 28/448] END C=100.0, penalty=l1, solver=liblinear, tol=1e-06;, score=0.988 total time=   0.8s\n",
            "[CV 2/5; 28/448] START C=100.0, penalty=l1, solver=liblinear, tol=1e-06.........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 28/448] END C=100.0, penalty=l1, solver=liblinear, tol=1e-06;, score=0.988 total time=   0.3s\n",
            "[CV 3/5; 28/448] START C=100.0, penalty=l1, solver=liblinear, tol=1e-06.........\n",
            "[CV 3/5; 28/448] END C=100.0, penalty=l1, solver=liblinear, tol=1e-06;, score=0.980 total time=   0.1s\n",
            "[CV 4/5; 28/448] START C=100.0, penalty=l1, solver=liblinear, tol=1e-06.........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 28/448] END C=100.0, penalty=l1, solver=liblinear, tol=1e-06;, score=0.980 total time=   0.5s\n",
            "[CV 5/5; 28/448] START C=100.0, penalty=l1, solver=liblinear, tol=1e-06.........\n",
            "[CV 5/5; 28/448] END C=100.0, penalty=l1, solver=liblinear, tol=1e-06;, score=0.984 total time=   0.2s\n",
            "[CV 1/5; 29/448] START C=100.0, penalty=l2, solver=liblinear, tol=0.001.........\n",
            "[CV 1/5; 29/448] END C=100.0, penalty=l2, solver=liblinear, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 29/448] START C=100.0, penalty=l2, solver=liblinear, tol=0.001.........\n",
            "[CV 2/5; 29/448] END C=100.0, penalty=l2, solver=liblinear, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 29/448] START C=100.0, penalty=l2, solver=liblinear, tol=0.001.........\n",
            "[CV 3/5; 29/448] END C=100.0, penalty=l2, solver=liblinear, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 29/448] START C=100.0, penalty=l2, solver=liblinear, tol=0.001.........\n",
            "[CV 4/5; 29/448] END C=100.0, penalty=l2, solver=liblinear, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 29/448] START C=100.0, penalty=l2, solver=liblinear, tol=0.001.........\n",
            "[CV 5/5; 29/448] END C=100.0, penalty=l2, solver=liblinear, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 1/5; 30/448] START C=100.0, penalty=l2, solver=liblinear, tol=0.0001........\n",
            "[CV 1/5; 30/448] END C=100.0, penalty=l2, solver=liblinear, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 30/448] START C=100.0, penalty=l2, solver=liblinear, tol=0.0001........\n",
            "[CV 2/5; 30/448] END C=100.0, penalty=l2, solver=liblinear, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 30/448] START C=100.0, penalty=l2, solver=liblinear, tol=0.0001........\n",
            "[CV 3/5; 30/448] END C=100.0, penalty=l2, solver=liblinear, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 30/448] START C=100.0, penalty=l2, solver=liblinear, tol=0.0001........\n",
            "[CV 4/5; 30/448] END C=100.0, penalty=l2, solver=liblinear, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 30/448] START C=100.0, penalty=l2, solver=liblinear, tol=0.0001........\n",
            "[CV 5/5; 30/448] END C=100.0, penalty=l2, solver=liblinear, tol=0.0001;, score=0.980 total time=   0.0s\n",
            "[CV 1/5; 31/448] START C=100.0, penalty=l2, solver=liblinear, tol=1e-05.........\n",
            "[CV 1/5; 31/448] END C=100.0, penalty=l2, solver=liblinear, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 31/448] START C=100.0, penalty=l2, solver=liblinear, tol=1e-05.........\n",
            "[CV 2/5; 31/448] END C=100.0, penalty=l2, solver=liblinear, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 31/448] START C=100.0, penalty=l2, solver=liblinear, tol=1e-05.........\n",
            "[CV 3/5; 31/448] END C=100.0, penalty=l2, solver=liblinear, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 31/448] START C=100.0, penalty=l2, solver=liblinear, tol=1e-05.........\n",
            "[CV 4/5; 31/448] END C=100.0, penalty=l2, solver=liblinear, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 31/448] START C=100.0, penalty=l2, solver=liblinear, tol=1e-05.........\n",
            "[CV 5/5; 31/448] END C=100.0, penalty=l2, solver=liblinear, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 1/5; 32/448] START C=100.0, penalty=l2, solver=liblinear, tol=1e-06.........\n",
            "[CV 1/5; 32/448] END C=100.0, penalty=l2, solver=liblinear, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 32/448] START C=100.0, penalty=l2, solver=liblinear, tol=1e-06.........\n",
            "[CV 2/5; 32/448] END C=100.0, penalty=l2, solver=liblinear, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 32/448] START C=100.0, penalty=l2, solver=liblinear, tol=1e-06.........\n",
            "[CV 3/5; 32/448] END C=100.0, penalty=l2, solver=liblinear, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 32/448] START C=100.0, penalty=l2, solver=liblinear, tol=1e-06.........\n",
            "[CV 4/5; 32/448] END C=100.0, penalty=l2, solver=liblinear, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 32/448] START C=100.0, penalty=l2, solver=liblinear, tol=1e-06.........\n",
            "[CV 5/5; 32/448] END C=100.0, penalty=l2, solver=liblinear, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 1/5; 33/448] START C=1000.0, penalty=l1, solver=liblinear, tol=0.001........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 33/448] END C=1000.0, penalty=l1, solver=liblinear, tol=0.001;, score=0.988 total time=   0.5s\n",
            "[CV 2/5; 33/448] START C=1000.0, penalty=l1, solver=liblinear, tol=0.001........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 33/448] END C=1000.0, penalty=l1, solver=liblinear, tol=0.001;, score=0.992 total time=   0.4s\n",
            "[CV 3/5; 33/448] START C=1000.0, penalty=l1, solver=liblinear, tol=0.001........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 33/448] END C=1000.0, penalty=l1, solver=liblinear, tol=0.001;, score=0.976 total time=   0.4s\n",
            "[CV 4/5; 33/448] START C=1000.0, penalty=l1, solver=liblinear, tol=0.001........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 33/448] END C=1000.0, penalty=l1, solver=liblinear, tol=0.001;, score=0.980 total time=   0.3s\n",
            "[CV 5/5; 33/448] START C=1000.0, penalty=l1, solver=liblinear, tol=0.001........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 33/448] END C=1000.0, penalty=l1, solver=liblinear, tol=0.001;, score=0.984 total time=   0.3s\n",
            "[CV 1/5; 34/448] START C=1000.0, penalty=l1, solver=liblinear, tol=0.0001.......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 34/448] END C=1000.0, penalty=l1, solver=liblinear, tol=0.0001;, score=0.988 total time=   0.5s\n",
            "[CV 2/5; 34/448] START C=1000.0, penalty=l1, solver=liblinear, tol=0.0001.......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 34/448] END C=1000.0, penalty=l1, solver=liblinear, tol=0.0001;, score=0.988 total time=   0.6s\n",
            "[CV 3/5; 34/448] START C=1000.0, penalty=l1, solver=liblinear, tol=0.0001.......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 34/448] END C=1000.0, penalty=l1, solver=liblinear, tol=0.0001;, score=0.976 total time=   0.4s\n",
            "[CV 4/5; 34/448] START C=1000.0, penalty=l1, solver=liblinear, tol=0.0001.......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 34/448] END C=1000.0, penalty=l1, solver=liblinear, tol=0.0001;, score=0.980 total time=   0.3s\n",
            "[CV 5/5; 34/448] START C=1000.0, penalty=l1, solver=liblinear, tol=0.0001.......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 34/448] END C=1000.0, penalty=l1, solver=liblinear, tol=0.0001;, score=0.984 total time=   0.6s\n",
            "[CV 1/5; 35/448] START C=1000.0, penalty=l1, solver=liblinear, tol=1e-05........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 35/448] END C=1000.0, penalty=l1, solver=liblinear, tol=1e-05;, score=0.988 total time=   0.3s\n",
            "[CV 2/5; 35/448] START C=1000.0, penalty=l1, solver=liblinear, tol=1e-05........\n",
            "[CV 2/5; 35/448] END C=1000.0, penalty=l1, solver=liblinear, tol=1e-05;, score=0.992 total time=   0.2s\n",
            "[CV 3/5; 35/448] START C=1000.0, penalty=l1, solver=liblinear, tol=1e-05........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 35/448] END C=1000.0, penalty=l1, solver=liblinear, tol=1e-05;, score=0.976 total time=   0.2s\n",
            "[CV 4/5; 35/448] START C=1000.0, penalty=l1, solver=liblinear, tol=1e-05........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 35/448] END C=1000.0, penalty=l1, solver=liblinear, tol=1e-05;, score=0.980 total time=   0.5s\n",
            "[CV 5/5; 35/448] START C=1000.0, penalty=l1, solver=liblinear, tol=1e-05........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 35/448] END C=1000.0, penalty=l1, solver=liblinear, tol=1e-05;, score=0.984 total time=   0.3s\n",
            "[CV 1/5; 36/448] START C=1000.0, penalty=l1, solver=liblinear, tol=1e-06........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 36/448] END C=1000.0, penalty=l1, solver=liblinear, tol=1e-06;, score=0.988 total time=   0.8s\n",
            "[CV 2/5; 36/448] START C=1000.0, penalty=l1, solver=liblinear, tol=1e-06........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 36/448] END C=1000.0, penalty=l1, solver=liblinear, tol=1e-06;, score=0.988 total time=   0.6s\n",
            "[CV 3/5; 36/448] START C=1000.0, penalty=l1, solver=liblinear, tol=1e-06........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 36/448] END C=1000.0, penalty=l1, solver=liblinear, tol=1e-06;, score=0.976 total time=   0.8s\n",
            "[CV 4/5; 36/448] START C=1000.0, penalty=l1, solver=liblinear, tol=1e-06........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 36/448] END C=1000.0, penalty=l1, solver=liblinear, tol=1e-06;, score=0.980 total time=   0.3s\n",
            "[CV 5/5; 36/448] START C=1000.0, penalty=l1, solver=liblinear, tol=1e-06........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 36/448] END C=1000.0, penalty=l1, solver=liblinear, tol=1e-06;, score=0.984 total time=   0.3s\n",
            "[CV 1/5; 37/448] START C=1000.0, penalty=l2, solver=liblinear, tol=0.001........\n",
            "[CV 1/5; 37/448] END C=1000.0, penalty=l2, solver=liblinear, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 37/448] START C=1000.0, penalty=l2, solver=liblinear, tol=0.001........\n",
            "[CV 2/5; 37/448] END C=1000.0, penalty=l2, solver=liblinear, tol=0.001;, score=0.992 total time=   0.0s\n",
            "[CV 3/5; 37/448] START C=1000.0, penalty=l2, solver=liblinear, tol=0.001........\n",
            "[CV 3/5; 37/448] END C=1000.0, penalty=l2, solver=liblinear, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 4/5; 37/448] START C=1000.0, penalty=l2, solver=liblinear, tol=0.001........\n",
            "[CV 4/5; 37/448] END C=1000.0, penalty=l2, solver=liblinear, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 37/448] START C=1000.0, penalty=l2, solver=liblinear, tol=0.001........\n",
            "[CV 5/5; 37/448] END C=1000.0, penalty=l2, solver=liblinear, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 38/448] START C=1000.0, penalty=l2, solver=liblinear, tol=0.0001.......\n",
            "[CV 1/5; 38/448] END C=1000.0, penalty=l2, solver=liblinear, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 38/448] START C=1000.0, penalty=l2, solver=liblinear, tol=0.0001.......\n",
            "[CV 2/5; 38/448] END C=1000.0, penalty=l2, solver=liblinear, tol=0.0001;, score=0.992 total time=   0.0s\n",
            "[CV 3/5; 38/448] START C=1000.0, penalty=l2, solver=liblinear, tol=0.0001.......\n",
            "[CV 3/5; 38/448] END C=1000.0, penalty=l2, solver=liblinear, tol=0.0001;, score=0.980 total time=   0.0s\n",
            "[CV 4/5; 38/448] START C=1000.0, penalty=l2, solver=liblinear, tol=0.0001.......\n",
            "[CV 4/5; 38/448] END C=1000.0, penalty=l2, solver=liblinear, tol=0.0001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 38/448] START C=1000.0, penalty=l2, solver=liblinear, tol=0.0001.......\n",
            "[CV 5/5; 38/448] END C=1000.0, penalty=l2, solver=liblinear, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 39/448] START C=1000.0, penalty=l2, solver=liblinear, tol=1e-05........\n",
            "[CV 1/5; 39/448] END C=1000.0, penalty=l2, solver=liblinear, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 39/448] START C=1000.0, penalty=l2, solver=liblinear, tol=1e-05........\n",
            "[CV 2/5; 39/448] END C=1000.0, penalty=l2, solver=liblinear, tol=1e-05;, score=0.992 total time=   0.0s\n",
            "[CV 3/5; 39/448] START C=1000.0, penalty=l2, solver=liblinear, tol=1e-05........\n",
            "[CV 3/5; 39/448] END C=1000.0, penalty=l2, solver=liblinear, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 4/5; 39/448] START C=1000.0, penalty=l2, solver=liblinear, tol=1e-05........\n",
            "[CV 4/5; 39/448] END C=1000.0, penalty=l2, solver=liblinear, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 39/448] START C=1000.0, penalty=l2, solver=liblinear, tol=1e-05........\n",
            "[CV 5/5; 39/448] END C=1000.0, penalty=l2, solver=liblinear, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 40/448] START C=1000.0, penalty=l2, solver=liblinear, tol=1e-06........\n",
            "[CV 1/5; 40/448] END C=1000.0, penalty=l2, solver=liblinear, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 40/448] START C=1000.0, penalty=l2, solver=liblinear, tol=1e-06........\n",
            "[CV 2/5; 40/448] END C=1000.0, penalty=l2, solver=liblinear, tol=1e-06;, score=0.992 total time=   0.0s\n",
            "[CV 3/5; 40/448] START C=1000.0, penalty=l2, solver=liblinear, tol=1e-06........\n",
            "[CV 3/5; 40/448] END C=1000.0, penalty=l2, solver=liblinear, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 4/5; 40/448] START C=1000.0, penalty=l2, solver=liblinear, tol=1e-06........\n",
            "[CV 4/5; 40/448] END C=1000.0, penalty=l2, solver=liblinear, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 40/448] START C=1000.0, penalty=l2, solver=liblinear, tol=1e-06........\n",
            "[CV 5/5; 40/448] END C=1000.0, penalty=l2, solver=liblinear, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 41/448] START C=10000.0, penalty=l1, solver=liblinear, tol=0.001.......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 41/448] END C=10000.0, penalty=l1, solver=liblinear, tol=0.001;, score=0.988 total time=   0.4s\n",
            "[CV 2/5; 41/448] START C=10000.0, penalty=l1, solver=liblinear, tol=0.001.......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 41/448] END C=10000.0, penalty=l1, solver=liblinear, tol=0.001;, score=0.992 total time=   0.8s\n",
            "[CV 3/5; 41/448] START C=10000.0, penalty=l1, solver=liblinear, tol=0.001.......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 41/448] END C=10000.0, penalty=l1, solver=liblinear, tol=0.001;, score=0.976 total time=   0.6s\n",
            "[CV 4/5; 41/448] START C=10000.0, penalty=l1, solver=liblinear, tol=0.001.......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 41/448] END C=10000.0, penalty=l1, solver=liblinear, tol=0.001;, score=0.980 total time=   0.7s\n",
            "[CV 5/5; 41/448] START C=10000.0, penalty=l1, solver=liblinear, tol=0.001.......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 41/448] END C=10000.0, penalty=l1, solver=liblinear, tol=0.001;, score=0.984 total time=   0.2s\n",
            "[CV 1/5; 42/448] START C=10000.0, penalty=l1, solver=liblinear, tol=0.0001......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 42/448] END C=10000.0, penalty=l1, solver=liblinear, tol=0.0001;, score=0.988 total time=   0.9s\n",
            "[CV 2/5; 42/448] START C=10000.0, penalty=l1, solver=liblinear, tol=0.0001......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 42/448] END C=10000.0, penalty=l1, solver=liblinear, tol=0.0001;, score=0.992 total time=   0.4s\n",
            "[CV 3/5; 42/448] START C=10000.0, penalty=l1, solver=liblinear, tol=0.0001......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 42/448] END C=10000.0, penalty=l1, solver=liblinear, tol=0.0001;, score=0.976 total time=   0.5s\n",
            "[CV 4/5; 42/448] START C=10000.0, penalty=l1, solver=liblinear, tol=0.0001......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 42/448] END C=10000.0, penalty=l1, solver=liblinear, tol=0.0001;, score=0.980 total time=   0.7s\n",
            "[CV 5/5; 42/448] START C=10000.0, penalty=l1, solver=liblinear, tol=0.0001......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 42/448] END C=10000.0, penalty=l1, solver=liblinear, tol=0.0001;, score=0.984 total time=   0.6s\n",
            "[CV 1/5; 43/448] START C=10000.0, penalty=l1, solver=liblinear, tol=1e-05.......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 43/448] END C=10000.0, penalty=l1, solver=liblinear, tol=1e-05;, score=0.988 total time=   0.5s\n",
            "[CV 2/5; 43/448] START C=10000.0, penalty=l1, solver=liblinear, tol=1e-05.......\n",
            "[CV 2/5; 43/448] END C=10000.0, penalty=l1, solver=liblinear, tol=1e-05;, score=0.988 total time=   0.2s\n",
            "[CV 3/5; 43/448] START C=10000.0, penalty=l1, solver=liblinear, tol=1e-05.......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 43/448] END C=10000.0, penalty=l1, solver=liblinear, tol=1e-05;, score=0.976 total time=   0.4s\n",
            "[CV 4/5; 43/448] START C=10000.0, penalty=l1, solver=liblinear, tol=1e-05.......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 43/448] END C=10000.0, penalty=l1, solver=liblinear, tol=1e-05;, score=0.980 total time=   0.6s\n",
            "[CV 5/5; 43/448] START C=10000.0, penalty=l1, solver=liblinear, tol=1e-05.......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 43/448] END C=10000.0, penalty=l1, solver=liblinear, tol=1e-05;, score=0.984 total time=   0.5s\n",
            "[CV 1/5; 44/448] START C=10000.0, penalty=l1, solver=liblinear, tol=1e-06.......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 44/448] END C=10000.0, penalty=l1, solver=liblinear, tol=1e-06;, score=0.988 total time=   0.3s\n",
            "[CV 2/5; 44/448] START C=10000.0, penalty=l1, solver=liblinear, tol=1e-06.......\n",
            "[CV 2/5; 44/448] END C=10000.0, penalty=l1, solver=liblinear, tol=1e-06;, score=0.988 total time=   0.2s\n",
            "[CV 3/5; 44/448] START C=10000.0, penalty=l1, solver=liblinear, tol=1e-06.......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 44/448] END C=10000.0, penalty=l1, solver=liblinear, tol=1e-06;, score=0.980 total time=   0.3s\n",
            "[CV 4/5; 44/448] START C=10000.0, penalty=l1, solver=liblinear, tol=1e-06.......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 44/448] END C=10000.0, penalty=l1, solver=liblinear, tol=1e-06;, score=0.980 total time=   0.3s\n",
            "[CV 5/5; 44/448] START C=10000.0, penalty=l1, solver=liblinear, tol=1e-06.......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 44/448] END C=10000.0, penalty=l1, solver=liblinear, tol=1e-06;, score=0.984 total time=   0.5s\n",
            "[CV 1/5; 45/448] START C=10000.0, penalty=l2, solver=liblinear, tol=0.001.......\n",
            "[CV 1/5; 45/448] END C=10000.0, penalty=l2, solver=liblinear, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 45/448] START C=10000.0, penalty=l2, solver=liblinear, tol=0.001.......\n",
            "[CV 2/5; 45/448] END C=10000.0, penalty=l2, solver=liblinear, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 45/448] START C=10000.0, penalty=l2, solver=liblinear, tol=0.001.......\n",
            "[CV 3/5; 45/448] END C=10000.0, penalty=l2, solver=liblinear, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 45/448] START C=10000.0, penalty=l2, solver=liblinear, tol=0.001.......\n",
            "[CV 4/5; 45/448] END C=10000.0, penalty=l2, solver=liblinear, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 45/448] START C=10000.0, penalty=l2, solver=liblinear, tol=0.001.......\n",
            "[CV 5/5; 45/448] END C=10000.0, penalty=l2, solver=liblinear, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 46/448] START C=10000.0, penalty=l2, solver=liblinear, tol=0.0001......\n",
            "[CV 1/5; 46/448] END C=10000.0, penalty=l2, solver=liblinear, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 46/448] START C=10000.0, penalty=l2, solver=liblinear, tol=0.0001......\n",
            "[CV 2/5; 46/448] END C=10000.0, penalty=l2, solver=liblinear, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 46/448] START C=10000.0, penalty=l2, solver=liblinear, tol=0.0001......\n",
            "[CV 3/5; 46/448] END C=10000.0, penalty=l2, solver=liblinear, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 46/448] START C=10000.0, penalty=l2, solver=liblinear, tol=0.0001......\n",
            "[CV 4/5; 46/448] END C=10000.0, penalty=l2, solver=liblinear, tol=0.0001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 46/448] START C=10000.0, penalty=l2, solver=liblinear, tol=0.0001......\n",
            "[CV 5/5; 46/448] END C=10000.0, penalty=l2, solver=liblinear, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 47/448] START C=10000.0, penalty=l2, solver=liblinear, tol=1e-05.......\n",
            "[CV 1/5; 47/448] END C=10000.0, penalty=l2, solver=liblinear, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 47/448] START C=10000.0, penalty=l2, solver=liblinear, tol=1e-05.......\n",
            "[CV 2/5; 47/448] END C=10000.0, penalty=l2, solver=liblinear, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 47/448] START C=10000.0, penalty=l2, solver=liblinear, tol=1e-05.......\n",
            "[CV 3/5; 47/448] END C=10000.0, penalty=l2, solver=liblinear, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 47/448] START C=10000.0, penalty=l2, solver=liblinear, tol=1e-05.......\n",
            "[CV 4/5; 47/448] END C=10000.0, penalty=l2, solver=liblinear, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 47/448] START C=10000.0, penalty=l2, solver=liblinear, tol=1e-05.......\n",
            "[CV 5/5; 47/448] END C=10000.0, penalty=l2, solver=liblinear, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 48/448] START C=10000.0, penalty=l2, solver=liblinear, tol=1e-06.......\n",
            "[CV 1/5; 48/448] END C=10000.0, penalty=l2, solver=liblinear, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 48/448] START C=10000.0, penalty=l2, solver=liblinear, tol=1e-06.......\n",
            "[CV 2/5; 48/448] END C=10000.0, penalty=l2, solver=liblinear, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 48/448] START C=10000.0, penalty=l2, solver=liblinear, tol=1e-06.......\n",
            "[CV 3/5; 48/448] END C=10000.0, penalty=l2, solver=liblinear, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 48/448] START C=10000.0, penalty=l2, solver=liblinear, tol=1e-06.......\n",
            "[CV 4/5; 48/448] END C=10000.0, penalty=l2, solver=liblinear, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 48/448] START C=10000.0, penalty=l2, solver=liblinear, tol=1e-06.......\n",
            "[CV 5/5; 48/448] END C=10000.0, penalty=l2, solver=liblinear, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 49/448] START C=100000.0, penalty=l1, solver=liblinear, tol=0.001......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 49/448] END C=100000.0, penalty=l1, solver=liblinear, tol=0.001;, score=0.988 total time=   0.2s\n",
            "[CV 2/5; 49/448] START C=100000.0, penalty=l1, solver=liblinear, tol=0.001......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 49/448] END C=100000.0, penalty=l1, solver=liblinear, tol=0.001;, score=0.992 total time=   0.4s\n",
            "[CV 3/5; 49/448] START C=100000.0, penalty=l1, solver=liblinear, tol=0.001......\n",
            "[CV 3/5; 49/448] END C=100000.0, penalty=l1, solver=liblinear, tol=0.001;, score=0.980 total time=   0.2s\n",
            "[CV 4/5; 49/448] START C=100000.0, penalty=l1, solver=liblinear, tol=0.001......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 49/448] END C=100000.0, penalty=l1, solver=liblinear, tol=0.001;, score=0.980 total time=   0.4s\n",
            "[CV 5/5; 49/448] START C=100000.0, penalty=l1, solver=liblinear, tol=0.001......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 49/448] END C=100000.0, penalty=l1, solver=liblinear, tol=0.001;, score=0.984 total time=   0.3s\n",
            "[CV 1/5; 50/448] START C=100000.0, penalty=l1, solver=liblinear, tol=0.0001.....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 50/448] END C=100000.0, penalty=l1, solver=liblinear, tol=0.0001;, score=0.988 total time=   0.2s\n",
            "[CV 2/5; 50/448] START C=100000.0, penalty=l1, solver=liblinear, tol=0.0001.....\n",
            "[CV 2/5; 50/448] END C=100000.0, penalty=l1, solver=liblinear, tol=0.0001;, score=0.988 total time=   0.2s\n",
            "[CV 3/5; 50/448] START C=100000.0, penalty=l1, solver=liblinear, tol=0.0001.....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 50/448] END C=100000.0, penalty=l1, solver=liblinear, tol=0.0001;, score=0.976 total time=   0.3s\n",
            "[CV 4/5; 50/448] START C=100000.0, penalty=l1, solver=liblinear, tol=0.0001.....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 50/448] END C=100000.0, penalty=l1, solver=liblinear, tol=0.0001;, score=0.980 total time=   1.1s\n",
            "[CV 5/5; 50/448] START C=100000.0, penalty=l1, solver=liblinear, tol=0.0001.....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 50/448] END C=100000.0, penalty=l1, solver=liblinear, tol=0.0001;, score=0.984 total time=   0.3s\n",
            "[CV 1/5; 51/448] START C=100000.0, penalty=l1, solver=liblinear, tol=1e-05......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 51/448] END C=100000.0, penalty=l1, solver=liblinear, tol=1e-05;, score=0.988 total time=   0.3s\n",
            "[CV 2/5; 51/448] START C=100000.0, penalty=l1, solver=liblinear, tol=1e-05......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 51/448] END C=100000.0, penalty=l1, solver=liblinear, tol=1e-05;, score=0.992 total time=   0.4s\n",
            "[CV 3/5; 51/448] START C=100000.0, penalty=l1, solver=liblinear, tol=1e-05......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 51/448] END C=100000.0, penalty=l1, solver=liblinear, tol=1e-05;, score=0.976 total time=   0.8s\n",
            "[CV 4/5; 51/448] START C=100000.0, penalty=l1, solver=liblinear, tol=1e-05......\n",
            "[CV 4/5; 51/448] END C=100000.0, penalty=l1, solver=liblinear, tol=1e-05;, score=0.980 total time=   0.1s\n",
            "[CV 5/5; 51/448] START C=100000.0, penalty=l1, solver=liblinear, tol=1e-05......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 51/448] END C=100000.0, penalty=l1, solver=liblinear, tol=1e-05;, score=0.984 total time=   0.3s\n",
            "[CV 1/5; 52/448] START C=100000.0, penalty=l1, solver=liblinear, tol=1e-06......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 52/448] END C=100000.0, penalty=l1, solver=liblinear, tol=1e-06;, score=0.988 total time=   0.4s\n",
            "[CV 2/5; 52/448] START C=100000.0, penalty=l1, solver=liblinear, tol=1e-06......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 52/448] END C=100000.0, penalty=l1, solver=liblinear, tol=1e-06;, score=0.992 total time=   0.4s\n",
            "[CV 3/5; 52/448] START C=100000.0, penalty=l1, solver=liblinear, tol=1e-06......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 52/448] END C=100000.0, penalty=l1, solver=liblinear, tol=1e-06;, score=0.976 total time=   0.3s\n",
            "[CV 4/5; 52/448] START C=100000.0, penalty=l1, solver=liblinear, tol=1e-06......\n",
            "[CV 4/5; 52/448] END C=100000.0, penalty=l1, solver=liblinear, tol=1e-06;, score=0.980 total time=   0.1s\n",
            "[CV 5/5; 52/448] START C=100000.0, penalty=l1, solver=liblinear, tol=1e-06......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 52/448] END C=100000.0, penalty=l1, solver=liblinear, tol=1e-06;, score=0.984 total time=   0.5s\n",
            "[CV 1/5; 53/448] START C=100000.0, penalty=l2, solver=liblinear, tol=0.001......\n",
            "[CV 1/5; 53/448] END C=100000.0, penalty=l2, solver=liblinear, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 53/448] START C=100000.0, penalty=l2, solver=liblinear, tol=0.001......\n",
            "[CV 2/5; 53/448] END C=100000.0, penalty=l2, solver=liblinear, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 53/448] START C=100000.0, penalty=l2, solver=liblinear, tol=0.001......\n",
            "[CV 3/5; 53/448] END C=100000.0, penalty=l2, solver=liblinear, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 53/448] START C=100000.0, penalty=l2, solver=liblinear, tol=0.001......\n",
            "[CV 4/5; 53/448] END C=100000.0, penalty=l2, solver=liblinear, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 53/448] START C=100000.0, penalty=l2, solver=liblinear, tol=0.001......\n",
            "[CV 5/5; 53/448] END C=100000.0, penalty=l2, solver=liblinear, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 54/448] START C=100000.0, penalty=l2, solver=liblinear, tol=0.0001.....\n",
            "[CV 1/5; 54/448] END C=100000.0, penalty=l2, solver=liblinear, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 54/448] START C=100000.0, penalty=l2, solver=liblinear, tol=0.0001.....\n",
            "[CV 2/5; 54/448] END C=100000.0, penalty=l2, solver=liblinear, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 54/448] START C=100000.0, penalty=l2, solver=liblinear, tol=0.0001.....\n",
            "[CV 3/5; 54/448] END C=100000.0, penalty=l2, solver=liblinear, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 54/448] START C=100000.0, penalty=l2, solver=liblinear, tol=0.0001.....\n",
            "[CV 4/5; 54/448] END C=100000.0, penalty=l2, solver=liblinear, tol=0.0001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 54/448] START C=100000.0, penalty=l2, solver=liblinear, tol=0.0001.....\n",
            "[CV 5/5; 54/448] END C=100000.0, penalty=l2, solver=liblinear, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 55/448] START C=100000.0, penalty=l2, solver=liblinear, tol=1e-05......\n",
            "[CV 1/5; 55/448] END C=100000.0, penalty=l2, solver=liblinear, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 55/448] START C=100000.0, penalty=l2, solver=liblinear, tol=1e-05......\n",
            "[CV 2/5; 55/448] END C=100000.0, penalty=l2, solver=liblinear, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 55/448] START C=100000.0, penalty=l2, solver=liblinear, tol=1e-05......\n",
            "[CV 3/5; 55/448] END C=100000.0, penalty=l2, solver=liblinear, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 55/448] START C=100000.0, penalty=l2, solver=liblinear, tol=1e-05......\n",
            "[CV 4/5; 55/448] END C=100000.0, penalty=l2, solver=liblinear, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 55/448] START C=100000.0, penalty=l2, solver=liblinear, tol=1e-05......\n",
            "[CV 5/5; 55/448] END C=100000.0, penalty=l2, solver=liblinear, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 56/448] START C=100000.0, penalty=l2, solver=liblinear, tol=1e-06......\n",
            "[CV 1/5; 56/448] END C=100000.0, penalty=l2, solver=liblinear, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 56/448] START C=100000.0, penalty=l2, solver=liblinear, tol=1e-06......\n",
            "[CV 2/5; 56/448] END C=100000.0, penalty=l2, solver=liblinear, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 56/448] START C=100000.0, penalty=l2, solver=liblinear, tol=1e-06......\n",
            "[CV 3/5; 56/448] END C=100000.0, penalty=l2, solver=liblinear, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 56/448] START C=100000.0, penalty=l2, solver=liblinear, tol=1e-06......\n",
            "[CV 4/5; 56/448] END C=100000.0, penalty=l2, solver=liblinear, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 56/448] START C=100000.0, penalty=l2, solver=liblinear, tol=1e-06......\n",
            "[CV 5/5; 56/448] END C=100000.0, penalty=l2, solver=liblinear, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 57/448] START C=1000000.0, penalty=l1, solver=liblinear, tol=0.001.....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 57/448] END C=1000000.0, penalty=l1, solver=liblinear, tol=0.001;, score=0.988 total time=   0.5s\n",
            "[CV 2/5; 57/448] START C=1000000.0, penalty=l1, solver=liblinear, tol=0.001.....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 57/448] END C=1000000.0, penalty=l1, solver=liblinear, tol=0.001;, score=0.992 total time=   0.5s\n",
            "[CV 3/5; 57/448] START C=1000000.0, penalty=l1, solver=liblinear, tol=0.001.....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 57/448] END C=1000000.0, penalty=l1, solver=liblinear, tol=0.001;, score=0.976 total time=   0.5s\n",
            "[CV 4/5; 57/448] START C=1000000.0, penalty=l1, solver=liblinear, tol=0.001.....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 57/448] END C=1000000.0, penalty=l1, solver=liblinear, tol=0.001;, score=0.980 total time=   0.4s\n",
            "[CV 5/5; 57/448] START C=1000000.0, penalty=l1, solver=liblinear, tol=0.001.....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 57/448] END C=1000000.0, penalty=l1, solver=liblinear, tol=0.001;, score=0.984 total time=   0.3s\n",
            "[CV 1/5; 58/448] START C=1000000.0, penalty=l1, solver=liblinear, tol=0.0001....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 58/448] END C=1000000.0, penalty=l1, solver=liblinear, tol=0.0001;, score=0.988 total time=   0.5s\n",
            "[CV 2/5; 58/448] START C=1000000.0, penalty=l1, solver=liblinear, tol=0.0001....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 58/448] END C=1000000.0, penalty=l1, solver=liblinear, tol=0.0001;, score=0.992 total time=   0.4s\n",
            "[CV 3/5; 58/448] START C=1000000.0, penalty=l1, solver=liblinear, tol=0.0001....\n",
            "[CV 3/5; 58/448] END C=1000000.0, penalty=l1, solver=liblinear, tol=0.0001;, score=0.980 total time=   0.1s\n",
            "[CV 4/5; 58/448] START C=1000000.0, penalty=l1, solver=liblinear, tol=0.0001....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 58/448] END C=1000000.0, penalty=l1, solver=liblinear, tol=0.0001;, score=0.980 total time=   0.2s\n",
            "[CV 5/5; 58/448] START C=1000000.0, penalty=l1, solver=liblinear, tol=0.0001....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 58/448] END C=1000000.0, penalty=l1, solver=liblinear, tol=0.0001;, score=0.984 total time=   0.2s\n",
            "[CV 1/5; 59/448] START C=1000000.0, penalty=l1, solver=liblinear, tol=1e-05.....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 59/448] END C=1000000.0, penalty=l1, solver=liblinear, tol=1e-05;, score=0.988 total time=   0.5s\n",
            "[CV 2/5; 59/448] START C=1000000.0, penalty=l1, solver=liblinear, tol=1e-05.....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 59/448] END C=1000000.0, penalty=l1, solver=liblinear, tol=1e-05;, score=0.988 total time=   0.7s\n",
            "[CV 3/5; 59/448] START C=1000000.0, penalty=l1, solver=liblinear, tol=1e-05.....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 59/448] END C=1000000.0, penalty=l1, solver=liblinear, tol=1e-05;, score=0.980 total time=   0.3s\n",
            "[CV 4/5; 59/448] START C=1000000.0, penalty=l1, solver=liblinear, tol=1e-05.....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 59/448] END C=1000000.0, penalty=l1, solver=liblinear, tol=1e-05;, score=0.980 total time=   0.4s\n",
            "[CV 5/5; 59/448] START C=1000000.0, penalty=l1, solver=liblinear, tol=1e-05.....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 59/448] END C=1000000.0, penalty=l1, solver=liblinear, tol=1e-05;, score=0.984 total time=   0.5s\n",
            "[CV 1/5; 60/448] START C=1000000.0, penalty=l1, solver=liblinear, tol=1e-06.....\n",
            "[CV 1/5; 60/448] END C=1000000.0, penalty=l1, solver=liblinear, tol=1e-06;, score=0.988 total time=   0.2s\n",
            "[CV 2/5; 60/448] START C=1000000.0, penalty=l1, solver=liblinear, tol=1e-06.....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 60/448] END C=1000000.0, penalty=l1, solver=liblinear, tol=1e-06;, score=0.992 total time=   0.5s\n",
            "[CV 3/5; 60/448] START C=1000000.0, penalty=l1, solver=liblinear, tol=1e-06.....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 60/448] END C=1000000.0, penalty=l1, solver=liblinear, tol=1e-06;, score=0.976 total time=   0.4s\n",
            "[CV 4/5; 60/448] START C=1000000.0, penalty=l1, solver=liblinear, tol=1e-06.....\n",
            "[CV 4/5; 60/448] END C=1000000.0, penalty=l1, solver=liblinear, tol=1e-06;, score=0.976 total time=   0.1s\n",
            "[CV 5/5; 60/448] START C=1000000.0, penalty=l1, solver=liblinear, tol=1e-06.....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 60/448] END C=1000000.0, penalty=l1, solver=liblinear, tol=1e-06;, score=0.984 total time=   1.0s\n",
            "[CV 1/5; 61/448] START C=1000000.0, penalty=l2, solver=liblinear, tol=0.001.....\n",
            "[CV 1/5; 61/448] END C=1000000.0, penalty=l2, solver=liblinear, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 61/448] START C=1000000.0, penalty=l2, solver=liblinear, tol=0.001.....\n",
            "[CV 2/5; 61/448] END C=1000000.0, penalty=l2, solver=liblinear, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 61/448] START C=1000000.0, penalty=l2, solver=liblinear, tol=0.001.....\n",
            "[CV 3/5; 61/448] END C=1000000.0, penalty=l2, solver=liblinear, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 61/448] START C=1000000.0, penalty=l2, solver=liblinear, tol=0.001.....\n",
            "[CV 4/5; 61/448] END C=1000000.0, penalty=l2, solver=liblinear, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 61/448] START C=1000000.0, penalty=l2, solver=liblinear, tol=0.001.....\n",
            "[CV 5/5; 61/448] END C=1000000.0, penalty=l2, solver=liblinear, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 62/448] START C=1000000.0, penalty=l2, solver=liblinear, tol=0.0001....\n",
            "[CV 1/5; 62/448] END C=1000000.0, penalty=l2, solver=liblinear, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 62/448] START C=1000000.0, penalty=l2, solver=liblinear, tol=0.0001....\n",
            "[CV 2/5; 62/448] END C=1000000.0, penalty=l2, solver=liblinear, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 62/448] START C=1000000.0, penalty=l2, solver=liblinear, tol=0.0001....\n",
            "[CV 3/5; 62/448] END C=1000000.0, penalty=l2, solver=liblinear, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 62/448] START C=1000000.0, penalty=l2, solver=liblinear, tol=0.0001....\n",
            "[CV 4/5; 62/448] END C=1000000.0, penalty=l2, solver=liblinear, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 62/448] START C=1000000.0, penalty=l2, solver=liblinear, tol=0.0001....\n",
            "[CV 5/5; 62/448] END C=1000000.0, penalty=l2, solver=liblinear, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 63/448] START C=1000000.0, penalty=l2, solver=liblinear, tol=1e-05.....\n",
            "[CV 1/5; 63/448] END C=1000000.0, penalty=l2, solver=liblinear, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 63/448] START C=1000000.0, penalty=l2, solver=liblinear, tol=1e-05.....\n",
            "[CV 2/5; 63/448] END C=1000000.0, penalty=l2, solver=liblinear, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 63/448] START C=1000000.0, penalty=l2, solver=liblinear, tol=1e-05.....\n",
            "[CV 3/5; 63/448] END C=1000000.0, penalty=l2, solver=liblinear, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 63/448] START C=1000000.0, penalty=l2, solver=liblinear, tol=1e-05.....\n",
            "[CV 4/5; 63/448] END C=1000000.0, penalty=l2, solver=liblinear, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 63/448] START C=1000000.0, penalty=l2, solver=liblinear, tol=1e-05.....\n",
            "[CV 5/5; 63/448] END C=1000000.0, penalty=l2, solver=liblinear, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 64/448] START C=1000000.0, penalty=l2, solver=liblinear, tol=1e-06.....\n",
            "[CV 1/5; 64/448] END C=1000000.0, penalty=l2, solver=liblinear, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 64/448] START C=1000000.0, penalty=l2, solver=liblinear, tol=1e-06.....\n",
            "[CV 2/5; 64/448] END C=1000000.0, penalty=l2, solver=liblinear, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 64/448] START C=1000000.0, penalty=l2, solver=liblinear, tol=1e-06.....\n",
            "[CV 3/5; 64/448] END C=1000000.0, penalty=l2, solver=liblinear, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 64/448] START C=1000000.0, penalty=l2, solver=liblinear, tol=1e-06.....\n",
            "[CV 4/5; 64/448] END C=1000000.0, penalty=l2, solver=liblinear, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 64/448] START C=1000000.0, penalty=l2, solver=liblinear, tol=1e-06.....\n",
            "[CV 5/5; 64/448] END C=1000000.0, penalty=l2, solver=liblinear, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 65/448] START C=0.1, penalty=l2, solver=lbfgs, tol=0.001...............\n",
            "[CV 1/5; 65/448] END C=0.1, penalty=l2, solver=lbfgs, tol=0.001;, score=0.792 total time=   0.0s\n",
            "[CV 2/5; 65/448] START C=0.1, penalty=l2, solver=lbfgs, tol=0.001...............\n",
            "[CV 2/5; 65/448] END C=0.1, penalty=l2, solver=lbfgs, tol=0.001;, score=0.656 total time=   0.0s\n",
            "[CV 3/5; 65/448] START C=0.1, penalty=l2, solver=lbfgs, tol=0.001...............\n",
            "[CV 3/5; 65/448] END C=0.1, penalty=l2, solver=lbfgs, tol=0.001;, score=0.720 total time=   0.0s\n",
            "[CV 4/5; 65/448] START C=0.1, penalty=l2, solver=lbfgs, tol=0.001...............\n",
            "[CV 4/5; 65/448] END C=0.1, penalty=l2, solver=lbfgs, tol=0.001;, score=0.716 total time=   0.0s\n",
            "[CV 5/5; 65/448] START C=0.1, penalty=l2, solver=lbfgs, tol=0.001...............\n",
            "[CV 5/5; 65/448] END C=0.1, penalty=l2, solver=lbfgs, tol=0.001;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 66/448] START C=0.1, penalty=l2, solver=lbfgs, tol=0.0001..............\n",
            "[CV 1/5; 66/448] END C=0.1, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.792 total time=   0.0s\n",
            "[CV 2/5; 66/448] START C=0.1, penalty=l2, solver=lbfgs, tol=0.0001..............\n",
            "[CV 2/5; 66/448] END C=0.1, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.656 total time=   0.0s\n",
            "[CV 3/5; 66/448] START C=0.1, penalty=l2, solver=lbfgs, tol=0.0001..............\n",
            "[CV 3/5; 66/448] END C=0.1, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.720 total time=   0.0s\n",
            "[CV 4/5; 66/448] START C=0.1, penalty=l2, solver=lbfgs, tol=0.0001..............\n",
            "[CV 4/5; 66/448] END C=0.1, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.716 total time=   0.0s\n",
            "[CV 5/5; 66/448] START C=0.1, penalty=l2, solver=lbfgs, tol=0.0001..............\n",
            "[CV 5/5; 66/448] END C=0.1, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 67/448] START C=0.1, penalty=l2, solver=lbfgs, tol=1e-05...............\n",
            "[CV 1/5; 67/448] END C=0.1, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.792 total time=   0.0s\n",
            "[CV 2/5; 67/448] START C=0.1, penalty=l2, solver=lbfgs, tol=1e-05...............\n",
            "[CV 2/5; 67/448] END C=0.1, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.656 total time=   0.0s\n",
            "[CV 3/5; 67/448] START C=0.1, penalty=l2, solver=lbfgs, tol=1e-05...............\n",
            "[CV 3/5; 67/448] END C=0.1, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.720 total time=   0.0s\n",
            "[CV 4/5; 67/448] START C=0.1, penalty=l2, solver=lbfgs, tol=1e-05...............\n",
            "[CV 4/5; 67/448] END C=0.1, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.716 total time=   0.0s\n",
            "[CV 5/5; 67/448] START C=0.1, penalty=l2, solver=lbfgs, tol=1e-05...............\n",
            "[CV 5/5; 67/448] END C=0.1, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 68/448] START C=0.1, penalty=l2, solver=lbfgs, tol=1e-06...............\n",
            "[CV 1/5; 68/448] END C=0.1, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.792 total time=   0.0s\n",
            "[CV 2/5; 68/448] START C=0.1, penalty=l2, solver=lbfgs, tol=1e-06...............\n",
            "[CV 2/5; 68/448] END C=0.1, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.656 total time=   0.0s\n",
            "[CV 3/5; 68/448] START C=0.1, penalty=l2, solver=lbfgs, tol=1e-06...............\n",
            "[CV 3/5; 68/448] END C=0.1, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.720 total time=   0.0s\n",
            "[CV 4/5; 68/448] START C=0.1, penalty=l2, solver=lbfgs, tol=1e-06...............\n",
            "[CV 4/5; 68/448] END C=0.1, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.716 total time=   0.0s\n",
            "[CV 5/5; 68/448] START C=0.1, penalty=l2, solver=lbfgs, tol=1e-06...............\n",
            "[CV 5/5; 68/448] END C=0.1, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 69/448] START C=0.1, penalty=None, solver=lbfgs, tol=0.001.............\n",
            "[CV 1/5; 69/448] END C=0.1, penalty=None, solver=lbfgs, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 69/448] START C=0.1, penalty=None, solver=lbfgs, tol=0.001.............\n",
            "[CV 2/5; 69/448] END C=0.1, penalty=None, solver=lbfgs, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 69/448] START C=0.1, penalty=None, solver=lbfgs, tol=0.001.............\n",
            "[CV 3/5; 69/448] END C=0.1, penalty=None, solver=lbfgs, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 69/448] START C=0.1, penalty=None, solver=lbfgs, tol=0.001.............\n",
            "[CV 4/5; 69/448] END C=0.1, penalty=None, solver=lbfgs, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 69/448] START C=0.1, penalty=None, solver=lbfgs, tol=0.001.............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 69/448] END C=0.1, penalty=None, solver=lbfgs, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 70/448] START C=0.1, penalty=None, solver=lbfgs, tol=0.0001............\n",
            "[CV 1/5; 70/448] END C=0.1, penalty=None, solver=lbfgs, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 70/448] START C=0.1, penalty=None, solver=lbfgs, tol=0.0001............\n",
            "[CV 2/5; 70/448] END C=0.1, penalty=None, solver=lbfgs, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 70/448] START C=0.1, penalty=None, solver=lbfgs, tol=0.0001............\n",
            "[CV 3/5; 70/448] END C=0.1, penalty=None, solver=lbfgs, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 70/448] START C=0.1, penalty=None, solver=lbfgs, tol=0.0001............\n",
            "[CV 4/5; 70/448] END C=0.1, penalty=None, solver=lbfgs, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 70/448] START C=0.1, penalty=None, solver=lbfgs, tol=0.0001............\n",
            "[CV 5/5; 70/448] END C=0.1, penalty=None, solver=lbfgs, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 71/448] START C=0.1, penalty=None, solver=lbfgs, tol=1e-05.............\n",
            "[CV 1/5; 71/448] END C=0.1, penalty=None, solver=lbfgs, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 71/448] START C=0.1, penalty=None, solver=lbfgs, tol=1e-05.............\n",
            "[CV 2/5; 71/448] END C=0.1, penalty=None, solver=lbfgs, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 71/448] START C=0.1, penalty=None, solver=lbfgs, tol=1e-05.............\n",
            "[CV 3/5; 71/448] END C=0.1, penalty=None, solver=lbfgs, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 71/448] START C=0.1, penalty=None, solver=lbfgs, tol=1e-05.............\n",
            "[CV 4/5; 71/448] END C=0.1, penalty=None, solver=lbfgs, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 71/448] START C=0.1, penalty=None, solver=lbfgs, tol=1e-05.............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 71/448] END C=0.1, penalty=None, solver=lbfgs, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 72/448] START C=0.1, penalty=None, solver=lbfgs, tol=1e-06.............\n",
            "[CV 1/5; 72/448] END C=0.1, penalty=None, solver=lbfgs, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 72/448] START C=0.1, penalty=None, solver=lbfgs, tol=1e-06.............\n",
            "[CV 2/5; 72/448] END C=0.1, penalty=None, solver=lbfgs, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 72/448] START C=0.1, penalty=None, solver=lbfgs, tol=1e-06.............\n",
            "[CV 3/5; 72/448] END C=0.1, penalty=None, solver=lbfgs, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 72/448] START C=0.1, penalty=None, solver=lbfgs, tol=1e-06.............\n",
            "[CV 4/5; 72/448] END C=0.1, penalty=None, solver=lbfgs, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 72/448] START C=0.1, penalty=None, solver=lbfgs, tol=1e-06.............\n",
            "[CV 5/5; 72/448] END C=0.1, penalty=None, solver=lbfgs, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 73/448] START C=1, penalty=l2, solver=lbfgs, tol=0.001.................\n",
            "[CV 1/5; 73/448] END C=1, penalty=l2, solver=lbfgs, tol=0.001;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 73/448] START C=1, penalty=l2, solver=lbfgs, tol=0.001.................\n",
            "[CV 2/5; 73/448] END C=1, penalty=l2, solver=lbfgs, tol=0.001;, score=0.880 total time=   0.0s\n",
            "[CV 3/5; 73/448] START C=1, penalty=l2, solver=lbfgs, tol=0.001.................\n",
            "[CV 3/5; 73/448] END C=1, penalty=l2, solver=lbfgs, tol=0.001;, score=0.912 total time=   0.0s\n",
            "[CV 4/5; 73/448] START C=1, penalty=l2, solver=lbfgs, tol=0.001.................\n",
            "[CV 4/5; 73/448] END C=1, penalty=l2, solver=lbfgs, tol=0.001;, score=0.916 total time=   0.0s\n",
            "[CV 5/5; 73/448] START C=1, penalty=l2, solver=lbfgs, tol=0.001.................\n",
            "[CV 5/5; 73/448] END C=1, penalty=l2, solver=lbfgs, tol=0.001;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 74/448] START C=1, penalty=l2, solver=lbfgs, tol=0.0001................\n",
            "[CV 1/5; 74/448] END C=1, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 74/448] START C=1, penalty=l2, solver=lbfgs, tol=0.0001................\n",
            "[CV 2/5; 74/448] END C=1, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.880 total time=   0.0s\n",
            "[CV 3/5; 74/448] START C=1, penalty=l2, solver=lbfgs, tol=0.0001................\n",
            "[CV 3/5; 74/448] END C=1, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.912 total time=   0.0s\n",
            "[CV 4/5; 74/448] START C=1, penalty=l2, solver=lbfgs, tol=0.0001................\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 74/448] END C=1, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.916 total time=   0.0s\n",
            "[CV 5/5; 74/448] START C=1, penalty=l2, solver=lbfgs, tol=0.0001................\n",
            "[CV 5/5; 74/448] END C=1, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 75/448] START C=1, penalty=l2, solver=lbfgs, tol=1e-05.................\n",
            "[CV 1/5; 75/448] END C=1, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 75/448] START C=1, penalty=l2, solver=lbfgs, tol=1e-05.................\n",
            "[CV 2/5; 75/448] END C=1, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.880 total time=   0.0s\n",
            "[CV 3/5; 75/448] START C=1, penalty=l2, solver=lbfgs, tol=1e-05.................\n",
            "[CV 3/5; 75/448] END C=1, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.912 total time=   0.0s\n",
            "[CV 4/5; 75/448] START C=1, penalty=l2, solver=lbfgs, tol=1e-05.................\n",
            "[CV 4/5; 75/448] END C=1, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.916 total time=   0.0s\n",
            "[CV 5/5; 75/448] START C=1, penalty=l2, solver=lbfgs, tol=1e-05.................\n",
            "[CV 5/5; 75/448] END C=1, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 76/448] START C=1, penalty=l2, solver=lbfgs, tol=1e-06.................\n",
            "[CV 1/5; 76/448] END C=1, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 76/448] START C=1, penalty=l2, solver=lbfgs, tol=1e-06.................\n",
            "[CV 2/5; 76/448] END C=1, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.880 total time=   0.0s\n",
            "[CV 3/5; 76/448] START C=1, penalty=l2, solver=lbfgs, tol=1e-06.................\n",
            "[CV 3/5; 76/448] END C=1, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.912 total time=   0.0s\n",
            "[CV 4/5; 76/448] START C=1, penalty=l2, solver=lbfgs, tol=1e-06.................\n",
            "[CV 4/5; 76/448] END C=1, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.916 total time=   0.0s\n",
            "[CV 5/5; 76/448] START C=1, penalty=l2, solver=lbfgs, tol=1e-06.................\n",
            "[CV 5/5; 76/448] END C=1, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 77/448] START C=1, penalty=None, solver=lbfgs, tol=0.001...............\n",
            "[CV 1/5; 77/448] END C=1, penalty=None, solver=lbfgs, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 77/448] START C=1, penalty=None, solver=lbfgs, tol=0.001...............\n",
            "[CV 2/5; 77/448] END C=1, penalty=None, solver=lbfgs, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 77/448] START C=1, penalty=None, solver=lbfgs, tol=0.001...............\n",
            "[CV 3/5; 77/448] END C=1, penalty=None, solver=lbfgs, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 77/448] START C=1, penalty=None, solver=lbfgs, tol=0.001...............\n",
            "[CV 4/5; 77/448] END C=1, penalty=None, solver=lbfgs, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 77/448] START C=1, penalty=None, solver=lbfgs, tol=0.001...............\n",
            "[CV 5/5; 77/448] END C=1, penalty=None, solver=lbfgs, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 78/448] START C=1, penalty=None, solver=lbfgs, tol=0.0001..............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 78/448] END C=1, penalty=None, solver=lbfgs, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 78/448] START C=1, penalty=None, solver=lbfgs, tol=0.0001..............\n",
            "[CV 2/5; 78/448] END C=1, penalty=None, solver=lbfgs, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 78/448] START C=1, penalty=None, solver=lbfgs, tol=0.0001..............\n",
            "[CV 3/5; 78/448] END C=1, penalty=None, solver=lbfgs, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 78/448] START C=1, penalty=None, solver=lbfgs, tol=0.0001..............\n",
            "[CV 4/5; 78/448] END C=1, penalty=None, solver=lbfgs, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 78/448] START C=1, penalty=None, solver=lbfgs, tol=0.0001..............\n",
            "[CV 5/5; 78/448] END C=1, penalty=None, solver=lbfgs, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 79/448] START C=1, penalty=None, solver=lbfgs, tol=1e-05...............\n",
            "[CV 1/5; 79/448] END C=1, penalty=None, solver=lbfgs, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 79/448] START C=1, penalty=None, solver=lbfgs, tol=1e-05...............\n",
            "[CV 2/5; 79/448] END C=1, penalty=None, solver=lbfgs, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 79/448] START C=1, penalty=None, solver=lbfgs, tol=1e-05...............\n",
            "[CV 3/5; 79/448] END C=1, penalty=None, solver=lbfgs, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 79/448] START C=1, penalty=None, solver=lbfgs, tol=1e-05...............\n",
            "[CV 4/5; 79/448] END C=1, penalty=None, solver=lbfgs, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 79/448] START C=1, penalty=None, solver=lbfgs, tol=1e-05...............\n",
            "[CV 5/5; 79/448] END C=1, penalty=None, solver=lbfgs, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 80/448] START C=1, penalty=None, solver=lbfgs, tol=1e-06...............\n",
            "[CV 1/5; 80/448] END C=1, penalty=None, solver=lbfgs, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 80/448] START C=1, penalty=None, solver=lbfgs, tol=1e-06...............\n",
            "[CV 2/5; 80/448] END C=1, penalty=None, solver=lbfgs, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 80/448] START C=1, penalty=None, solver=lbfgs, tol=1e-06...............\n",
            "[CV 3/5; 80/448] END C=1, penalty=None, solver=lbfgs, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 80/448] START C=1, penalty=None, solver=lbfgs, tol=1e-06...............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 80/448] END C=1, penalty=None, solver=lbfgs, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 80/448] START C=1, penalty=None, solver=lbfgs, tol=1e-06...............\n",
            "[CV 5/5; 80/448] END C=1, penalty=None, solver=lbfgs, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 81/448] START C=10.0, penalty=l2, solver=lbfgs, tol=0.001..............\n",
            "[CV 1/5; 81/448] END C=10.0, penalty=l2, solver=lbfgs, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 2/5; 81/448] START C=10.0, penalty=l2, solver=lbfgs, tol=0.001..............\n",
            "[CV 2/5; 81/448] END C=10.0, penalty=l2, solver=lbfgs, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 81/448] START C=10.0, penalty=l2, solver=lbfgs, tol=0.001..............\n",
            "[CV 3/5; 81/448] END C=10.0, penalty=l2, solver=lbfgs, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 81/448] START C=10.0, penalty=l2, solver=lbfgs, tol=0.001..............\n",
            "[CV 4/5; 81/448] END C=10.0, penalty=l2, solver=lbfgs, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 5/5; 81/448] START C=10.0, penalty=l2, solver=lbfgs, tol=0.001..............\n",
            "[CV 5/5; 81/448] END C=10.0, penalty=l2, solver=lbfgs, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 82/448] START C=10.0, penalty=l2, solver=lbfgs, tol=0.0001.............\n",
            "[CV 1/5; 82/448] END C=10.0, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 2/5; 82/448] START C=10.0, penalty=l2, solver=lbfgs, tol=0.0001.............\n",
            "[CV 2/5; 82/448] END C=10.0, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 82/448] START C=10.0, penalty=l2, solver=lbfgs, tol=0.0001.............\n",
            "[CV 3/5; 82/448] END C=10.0, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 82/448] START C=10.0, penalty=l2, solver=lbfgs, tol=0.0001.............\n",
            "[CV 4/5; 82/448] END C=10.0, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 5/5; 82/448] START C=10.0, penalty=l2, solver=lbfgs, tol=0.0001.............\n",
            "[CV 5/5; 82/448] END C=10.0, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 83/448] START C=10.0, penalty=l2, solver=lbfgs, tol=1e-05..............\n",
            "[CV 1/5; 83/448] END C=10.0, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 2/5; 83/448] START C=10.0, penalty=l2, solver=lbfgs, tol=1e-05..............\n",
            "[CV 2/5; 83/448] END C=10.0, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 83/448] START C=10.0, penalty=l2, solver=lbfgs, tol=1e-05..............\n",
            "[CV 3/5; 83/448] END C=10.0, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 83/448] START C=10.0, penalty=l2, solver=lbfgs, tol=1e-05..............\n",
            "[CV 4/5; 83/448] END C=10.0, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 5/5; 83/448] START C=10.0, penalty=l2, solver=lbfgs, tol=1e-05..............\n",
            "[CV 5/5; 83/448] END C=10.0, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 84/448] START C=10.0, penalty=l2, solver=lbfgs, tol=1e-06..............\n",
            "[CV 1/5; 84/448] END C=10.0, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 2/5; 84/448] START C=10.0, penalty=l2, solver=lbfgs, tol=1e-06..............\n",
            "[CV 2/5; 84/448] END C=10.0, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 84/448] START C=10.0, penalty=l2, solver=lbfgs, tol=1e-06..............\n",
            "[CV 3/5; 84/448] END C=10.0, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 84/448] START C=10.0, penalty=l2, solver=lbfgs, tol=1e-06..............\n",
            "[CV 4/5; 84/448] END C=10.0, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 5/5; 84/448] START C=10.0, penalty=l2, solver=lbfgs, tol=1e-06..............\n",
            "[CV 5/5; 84/448] END C=10.0, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 85/448] START C=10.0, penalty=None, solver=lbfgs, tol=0.001............\n",
            "[CV 1/5; 85/448] END C=10.0, penalty=None, solver=lbfgs, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 85/448] START C=10.0, penalty=None, solver=lbfgs, tol=0.001............\n",
            "[CV 2/5; 85/448] END C=10.0, penalty=None, solver=lbfgs, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 85/448] START C=10.0, penalty=None, solver=lbfgs, tol=0.001............\n",
            "[CV 3/5; 85/448] END C=10.0, penalty=None, solver=lbfgs, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 85/448] START C=10.0, penalty=None, solver=lbfgs, tol=0.001............\n",
            "[CV 4/5; 85/448] END C=10.0, penalty=None, solver=lbfgs, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 85/448] START C=10.0, penalty=None, solver=lbfgs, tol=0.001............\n",
            "[CV 5/5; 85/448] END C=10.0, penalty=None, solver=lbfgs, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 86/448] START C=10.0, penalty=None, solver=lbfgs, tol=0.0001...........\n",
            "[CV 1/5; 86/448] END C=10.0, penalty=None, solver=lbfgs, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 86/448] START C=10.0, penalty=None, solver=lbfgs, tol=0.0001...........\n",
            "[CV 2/5; 86/448] END C=10.0, penalty=None, solver=lbfgs, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 86/448] START C=10.0, penalty=None, solver=lbfgs, tol=0.0001...........\n",
            "[CV 3/5; 86/448] END C=10.0, penalty=None, solver=lbfgs, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 86/448] START C=10.0, penalty=None, solver=lbfgs, tol=0.0001...........\n",
            "[CV 4/5; 86/448] END C=10.0, penalty=None, solver=lbfgs, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 86/448] START C=10.0, penalty=None, solver=lbfgs, tol=0.0001...........\n",
            "[CV 5/5; 86/448] END C=10.0, penalty=None, solver=lbfgs, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 87/448] START C=10.0, penalty=None, solver=lbfgs, tol=1e-05............\n",
            "[CV 1/5; 87/448] END C=10.0, penalty=None, solver=lbfgs, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 87/448] START C=10.0, penalty=None, solver=lbfgs, tol=1e-05............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 87/448] END C=10.0, penalty=None, solver=lbfgs, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 87/448] START C=10.0, penalty=None, solver=lbfgs, tol=1e-05............\n",
            "[CV 3/5; 87/448] END C=10.0, penalty=None, solver=lbfgs, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 87/448] START C=10.0, penalty=None, solver=lbfgs, tol=1e-05............\n",
            "[CV 4/5; 87/448] END C=10.0, penalty=None, solver=lbfgs, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 87/448] START C=10.0, penalty=None, solver=lbfgs, tol=1e-05............\n",
            "[CV 5/5; 87/448] END C=10.0, penalty=None, solver=lbfgs, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 88/448] START C=10.0, penalty=None, solver=lbfgs, tol=1e-06............\n",
            "[CV 1/5; 88/448] END C=10.0, penalty=None, solver=lbfgs, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 88/448] START C=10.0, penalty=None, solver=lbfgs, tol=1e-06............\n",
            "[CV 2/5; 88/448] END C=10.0, penalty=None, solver=lbfgs, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 88/448] START C=10.0, penalty=None, solver=lbfgs, tol=1e-06............\n",
            "[CV 3/5; 88/448] END C=10.0, penalty=None, solver=lbfgs, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 88/448] START C=10.0, penalty=None, solver=lbfgs, tol=1e-06............\n",
            "[CV 4/5; 88/448] END C=10.0, penalty=None, solver=lbfgs, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 88/448] START C=10.0, penalty=None, solver=lbfgs, tol=1e-06............\n",
            "[CV 5/5; 88/448] END C=10.0, penalty=None, solver=lbfgs, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 89/448] START C=100.0, penalty=l2, solver=lbfgs, tol=0.001.............\n",
            "[CV 1/5; 89/448] END C=100.0, penalty=l2, solver=lbfgs, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 89/448] START C=100.0, penalty=l2, solver=lbfgs, tol=0.001.............\n",
            "[CV 2/5; 89/448] END C=100.0, penalty=l2, solver=lbfgs, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 89/448] START C=100.0, penalty=l2, solver=lbfgs, tol=0.001.............\n",
            "[CV 3/5; 89/448] END C=100.0, penalty=l2, solver=lbfgs, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 89/448] START C=100.0, penalty=l2, solver=lbfgs, tol=0.001.............\n",
            "[CV 4/5; 89/448] END C=100.0, penalty=l2, solver=lbfgs, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 89/448] START C=100.0, penalty=l2, solver=lbfgs, tol=0.001.............\n",
            "[CV 5/5; 89/448] END C=100.0, penalty=l2, solver=lbfgs, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 1/5; 90/448] START C=100.0, penalty=l2, solver=lbfgs, tol=0.0001............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 90/448] END C=100.0, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 90/448] START C=100.0, penalty=l2, solver=lbfgs, tol=0.0001............\n",
            "[CV 2/5; 90/448] END C=100.0, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 90/448] START C=100.0, penalty=l2, solver=lbfgs, tol=0.0001............\n",
            "[CV 3/5; 90/448] END C=100.0, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 90/448] START C=100.0, penalty=l2, solver=lbfgs, tol=0.0001............\n",
            "[CV 4/5; 90/448] END C=100.0, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 90/448] START C=100.0, penalty=l2, solver=lbfgs, tol=0.0001............\n",
            "[CV 5/5; 90/448] END C=100.0, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.980 total time=   0.0s\n",
            "[CV 1/5; 91/448] START C=100.0, penalty=l2, solver=lbfgs, tol=1e-05.............\n",
            "[CV 1/5; 91/448] END C=100.0, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 91/448] START C=100.0, penalty=l2, solver=lbfgs, tol=1e-05.............\n",
            "[CV 2/5; 91/448] END C=100.0, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 91/448] START C=100.0, penalty=l2, solver=lbfgs, tol=1e-05.............\n",
            "[CV 3/5; 91/448] END C=100.0, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 91/448] START C=100.0, penalty=l2, solver=lbfgs, tol=1e-05.............\n",
            "[CV 4/5; 91/448] END C=100.0, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 91/448] START C=100.0, penalty=l2, solver=lbfgs, tol=1e-05.............\n",
            "[CV 5/5; 91/448] END C=100.0, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 1/5; 92/448] START C=100.0, penalty=l2, solver=lbfgs, tol=1e-06.............\n",
            "[CV 1/5; 92/448] END C=100.0, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 92/448] START C=100.0, penalty=l2, solver=lbfgs, tol=1e-06.............\n",
            "[CV 2/5; 92/448] END C=100.0, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 92/448] START C=100.0, penalty=l2, solver=lbfgs, tol=1e-06.............\n",
            "[CV 3/5; 92/448] END C=100.0, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 92/448] START C=100.0, penalty=l2, solver=lbfgs, tol=1e-06.............\n",
            "[CV 4/5; 92/448] END C=100.0, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 92/448] START C=100.0, penalty=l2, solver=lbfgs, tol=1e-06.............\n",
            "[CV 5/5; 92/448] END C=100.0, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 1/5; 93/448] START C=100.0, penalty=None, solver=lbfgs, tol=0.001...........\n",
            "[CV 1/5; 93/448] END C=100.0, penalty=None, solver=lbfgs, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 93/448] START C=100.0, penalty=None, solver=lbfgs, tol=0.001...........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 93/448] END C=100.0, penalty=None, solver=lbfgs, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 93/448] START C=100.0, penalty=None, solver=lbfgs, tol=0.001...........\n",
            "[CV 3/5; 93/448] END C=100.0, penalty=None, solver=lbfgs, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 93/448] START C=100.0, penalty=None, solver=lbfgs, tol=0.001...........\n",
            "[CV 4/5; 93/448] END C=100.0, penalty=None, solver=lbfgs, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 93/448] START C=100.0, penalty=None, solver=lbfgs, tol=0.001...........\n",
            "[CV 5/5; 93/448] END C=100.0, penalty=None, solver=lbfgs, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 94/448] START C=100.0, penalty=None, solver=lbfgs, tol=0.0001..........\n",
            "[CV 1/5; 94/448] END C=100.0, penalty=None, solver=lbfgs, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 94/448] START C=100.0, penalty=None, solver=lbfgs, tol=0.0001..........\n",
            "[CV 2/5; 94/448] END C=100.0, penalty=None, solver=lbfgs, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 94/448] START C=100.0, penalty=None, solver=lbfgs, tol=0.0001..........\n",
            "[CV 3/5; 94/448] END C=100.0, penalty=None, solver=lbfgs, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 94/448] START C=100.0, penalty=None, solver=lbfgs, tol=0.0001..........\n",
            "[CV 4/5; 94/448] END C=100.0, penalty=None, solver=lbfgs, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 94/448] START C=100.0, penalty=None, solver=lbfgs, tol=0.0001..........\n",
            "[CV 5/5; 94/448] END C=100.0, penalty=None, solver=lbfgs, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 95/448] START C=100.0, penalty=None, solver=lbfgs, tol=1e-05...........\n",
            "[CV 1/5; 95/448] END C=100.0, penalty=None, solver=lbfgs, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 95/448] START C=100.0, penalty=None, solver=lbfgs, tol=1e-05...........\n",
            "[CV 2/5; 95/448] END C=100.0, penalty=None, solver=lbfgs, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 95/448] START C=100.0, penalty=None, solver=lbfgs, tol=1e-05...........\n",
            "[CV 3/5; 95/448] END C=100.0, penalty=None, solver=lbfgs, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 95/448] START C=100.0, penalty=None, solver=lbfgs, tol=1e-05...........\n",
            "[CV 4/5; 95/448] END C=100.0, penalty=None, solver=lbfgs, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 95/448] START C=100.0, penalty=None, solver=lbfgs, tol=1e-05...........\n",
            "[CV 5/5; 95/448] END C=100.0, penalty=None, solver=lbfgs, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 96/448] START C=100.0, penalty=None, solver=lbfgs, tol=1e-06...........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 96/448] END C=100.0, penalty=None, solver=lbfgs, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 96/448] START C=100.0, penalty=None, solver=lbfgs, tol=1e-06...........\n",
            "[CV 2/5; 96/448] END C=100.0, penalty=None, solver=lbfgs, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 96/448] START C=100.0, penalty=None, solver=lbfgs, tol=1e-06...........\n",
            "[CV 3/5; 96/448] END C=100.0, penalty=None, solver=lbfgs, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 96/448] START C=100.0, penalty=None, solver=lbfgs, tol=1e-06...........\n",
            "[CV 4/5; 96/448] END C=100.0, penalty=None, solver=lbfgs, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 96/448] START C=100.0, penalty=None, solver=lbfgs, tol=1e-06...........\n",
            "[CV 5/5; 96/448] END C=100.0, penalty=None, solver=lbfgs, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 97/448] START C=1000.0, penalty=l2, solver=lbfgs, tol=0.001............\n",
            "[CV 1/5; 97/448] END C=1000.0, penalty=l2, solver=lbfgs, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 97/448] START C=1000.0, penalty=l2, solver=lbfgs, tol=0.001............\n",
            "[CV 2/5; 97/448] END C=1000.0, penalty=l2, solver=lbfgs, tol=0.001;, score=0.992 total time=   0.0s\n",
            "[CV 3/5; 97/448] START C=1000.0, penalty=l2, solver=lbfgs, tol=0.001............\n",
            "[CV 3/5; 97/448] END C=1000.0, penalty=l2, solver=lbfgs, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 4/5; 97/448] START C=1000.0, penalty=l2, solver=lbfgs, tol=0.001............\n",
            "[CV 4/5; 97/448] END C=1000.0, penalty=l2, solver=lbfgs, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 97/448] START C=1000.0, penalty=l2, solver=lbfgs, tol=0.001............\n",
            "[CV 5/5; 97/448] END C=1000.0, penalty=l2, solver=lbfgs, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 98/448] START C=1000.0, penalty=l2, solver=lbfgs, tol=0.0001...........\n",
            "[CV 1/5; 98/448] END C=1000.0, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 98/448] START C=1000.0, penalty=l2, solver=lbfgs, tol=0.0001...........\n",
            "[CV 2/5; 98/448] END C=1000.0, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.992 total time=   0.0s\n",
            "[CV 3/5; 98/448] START C=1000.0, penalty=l2, solver=lbfgs, tol=0.0001...........\n",
            "[CV 3/5; 98/448] END C=1000.0, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.980 total time=   0.0s\n",
            "[CV 4/5; 98/448] START C=1000.0, penalty=l2, solver=lbfgs, tol=0.0001...........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 98/448] END C=1000.0, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 98/448] START C=1000.0, penalty=l2, solver=lbfgs, tol=0.0001...........\n",
            "[CV 5/5; 98/448] END C=1000.0, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 99/448] START C=1000.0, penalty=l2, solver=lbfgs, tol=1e-05............\n",
            "[CV 1/5; 99/448] END C=1000.0, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 99/448] START C=1000.0, penalty=l2, solver=lbfgs, tol=1e-05............\n",
            "[CV 2/5; 99/448] END C=1000.0, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.992 total time=   0.0s\n",
            "[CV 3/5; 99/448] START C=1000.0, penalty=l2, solver=lbfgs, tol=1e-05............\n",
            "[CV 3/5; 99/448] END C=1000.0, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 4/5; 99/448] START C=1000.0, penalty=l2, solver=lbfgs, tol=1e-05............\n",
            "[CV 4/5; 99/448] END C=1000.0, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 99/448] START C=1000.0, penalty=l2, solver=lbfgs, tol=1e-05............\n",
            "[CV 5/5; 99/448] END C=1000.0, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 100/448] START C=1000.0, penalty=l2, solver=lbfgs, tol=1e-06...........\n",
            "[CV 1/5; 100/448] END C=1000.0, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 100/448] START C=1000.0, penalty=l2, solver=lbfgs, tol=1e-06...........\n",
            "[CV 2/5; 100/448] END C=1000.0, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.992 total time=   0.0s\n",
            "[CV 3/5; 100/448] START C=1000.0, penalty=l2, solver=lbfgs, tol=1e-06...........\n",
            "[CV 3/5; 100/448] END C=1000.0, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 4/5; 100/448] START C=1000.0, penalty=l2, solver=lbfgs, tol=1e-06...........\n",
            "[CV 4/5; 100/448] END C=1000.0, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 100/448] START C=1000.0, penalty=l2, solver=lbfgs, tol=1e-06...........\n",
            "[CV 5/5; 100/448] END C=1000.0, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 101/448] START C=1000.0, penalty=None, solver=lbfgs, tol=0.001.........\n",
            "[CV 1/5; 101/448] END C=1000.0, penalty=None, solver=lbfgs, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 101/448] START C=1000.0, penalty=None, solver=lbfgs, tol=0.001.........\n",
            "[CV 2/5; 101/448] END C=1000.0, penalty=None, solver=lbfgs, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 101/448] START C=1000.0, penalty=None, solver=lbfgs, tol=0.001.........\n",
            "[CV 3/5; 101/448] END C=1000.0, penalty=None, solver=lbfgs, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 101/448] START C=1000.0, penalty=None, solver=lbfgs, tol=0.001.........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 101/448] END C=1000.0, penalty=None, solver=lbfgs, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 101/448] START C=1000.0, penalty=None, solver=lbfgs, tol=0.001.........\n",
            "[CV 5/5; 101/448] END C=1000.0, penalty=None, solver=lbfgs, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 102/448] START C=1000.0, penalty=None, solver=lbfgs, tol=0.0001........\n",
            "[CV 1/5; 102/448] END C=1000.0, penalty=None, solver=lbfgs, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 102/448] START C=1000.0, penalty=None, solver=lbfgs, tol=0.0001........\n",
            "[CV 2/5; 102/448] END C=1000.0, penalty=None, solver=lbfgs, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 102/448] START C=1000.0, penalty=None, solver=lbfgs, tol=0.0001........\n",
            "[CV 3/5; 102/448] END C=1000.0, penalty=None, solver=lbfgs, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 102/448] START C=1000.0, penalty=None, solver=lbfgs, tol=0.0001........\n",
            "[CV 4/5; 102/448] END C=1000.0, penalty=None, solver=lbfgs, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 102/448] START C=1000.0, penalty=None, solver=lbfgs, tol=0.0001........\n",
            "[CV 5/5; 102/448] END C=1000.0, penalty=None, solver=lbfgs, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 103/448] START C=1000.0, penalty=None, solver=lbfgs, tol=1e-05.........\n",
            "[CV 1/5; 103/448] END C=1000.0, penalty=None, solver=lbfgs, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 103/448] START C=1000.0, penalty=None, solver=lbfgs, tol=1e-05.........\n",
            "[CV 2/5; 103/448] END C=1000.0, penalty=None, solver=lbfgs, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 103/448] START C=1000.0, penalty=None, solver=lbfgs, tol=1e-05.........\n",
            "[CV 3/5; 103/448] END C=1000.0, penalty=None, solver=lbfgs, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 103/448] START C=1000.0, penalty=None, solver=lbfgs, tol=1e-05.........\n",
            "[CV 4/5; 103/448] END C=1000.0, penalty=None, solver=lbfgs, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 103/448] START C=1000.0, penalty=None, solver=lbfgs, tol=1e-05.........\n",
            "[CV 5/5; 103/448] END C=1000.0, penalty=None, solver=lbfgs, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 104/448] START C=1000.0, penalty=None, solver=lbfgs, tol=1e-06.........\n",
            "[CV 1/5; 104/448] END C=1000.0, penalty=None, solver=lbfgs, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 104/448] START C=1000.0, penalty=None, solver=lbfgs, tol=1e-06.........\n",
            "[CV 2/5; 104/448] END C=1000.0, penalty=None, solver=lbfgs, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 104/448] START C=1000.0, penalty=None, solver=lbfgs, tol=1e-06.........\n",
            "[CV 3/5; 104/448] END C=1000.0, penalty=None, solver=lbfgs, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 104/448] START C=1000.0, penalty=None, solver=lbfgs, tol=1e-06.........\n",
            "[CV 4/5; 104/448] END C=1000.0, penalty=None, solver=lbfgs, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 104/448] START C=1000.0, penalty=None, solver=lbfgs, tol=1e-06.........\n",
            "[CV 5/5; 104/448] END C=1000.0, penalty=None, solver=lbfgs, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 105/448] START C=10000.0, penalty=l2, solver=lbfgs, tol=0.001..........\n",
            "[CV 1/5; 105/448] END C=10000.0, penalty=l2, solver=lbfgs, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 105/448] START C=10000.0, penalty=l2, solver=lbfgs, tol=0.001..........\n",
            "[CV 2/5; 105/448] END C=10000.0, penalty=l2, solver=lbfgs, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 105/448] START C=10000.0, penalty=l2, solver=lbfgs, tol=0.001..........\n",
            "[CV 3/5; 105/448] END C=10000.0, penalty=l2, solver=lbfgs, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 105/448] START C=10000.0, penalty=l2, solver=lbfgs, tol=0.001..........\n",
            "[CV 4/5; 105/448] END C=10000.0, penalty=l2, solver=lbfgs, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 105/448] START C=10000.0, penalty=l2, solver=lbfgs, tol=0.001..........\n",
            "[CV 5/5; 105/448] END C=10000.0, penalty=l2, solver=lbfgs, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 106/448] START C=10000.0, penalty=l2, solver=lbfgs, tol=0.0001.........\n",
            "[CV 1/5; 106/448] END C=10000.0, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 106/448] START C=10000.0, penalty=l2, solver=lbfgs, tol=0.0001.........\n",
            "[CV 2/5; 106/448] END C=10000.0, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 106/448] START C=10000.0, penalty=l2, solver=lbfgs, tol=0.0001.........\n",
            "[CV 3/5; 106/448] END C=10000.0, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 106/448] START C=10000.0, penalty=l2, solver=lbfgs, tol=0.0001.........\n",
            "[CV 4/5; 106/448] END C=10000.0, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 106/448] START C=10000.0, penalty=l2, solver=lbfgs, tol=0.0001.........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 106/448] END C=10000.0, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 107/448] START C=10000.0, penalty=l2, solver=lbfgs, tol=1e-05..........\n",
            "[CV 1/5; 107/448] END C=10000.0, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 107/448] START C=10000.0, penalty=l2, solver=lbfgs, tol=1e-05..........\n",
            "[CV 2/5; 107/448] END C=10000.0, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 107/448] START C=10000.0, penalty=l2, solver=lbfgs, tol=1e-05..........\n",
            "[CV 3/5; 107/448] END C=10000.0, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 107/448] START C=10000.0, penalty=l2, solver=lbfgs, tol=1e-05..........\n",
            "[CV 4/5; 107/448] END C=10000.0, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 107/448] START C=10000.0, penalty=l2, solver=lbfgs, tol=1e-05..........\n",
            "[CV 5/5; 107/448] END C=10000.0, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 108/448] START C=10000.0, penalty=l2, solver=lbfgs, tol=1e-06..........\n",
            "[CV 1/5; 108/448] END C=10000.0, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 108/448] START C=10000.0, penalty=l2, solver=lbfgs, tol=1e-06..........\n",
            "[CV 2/5; 108/448] END C=10000.0, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 108/448] START C=10000.0, penalty=l2, solver=lbfgs, tol=1e-06..........\n",
            "[CV 3/5; 108/448] END C=10000.0, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 108/448] START C=10000.0, penalty=l2, solver=lbfgs, tol=1e-06..........\n",
            "[CV 4/5; 108/448] END C=10000.0, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 108/448] START C=10000.0, penalty=l2, solver=lbfgs, tol=1e-06..........\n",
            "[CV 5/5; 108/448] END C=10000.0, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 109/448] START C=10000.0, penalty=None, solver=lbfgs, tol=0.001........\n",
            "[CV 1/5; 109/448] END C=10000.0, penalty=None, solver=lbfgs, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 109/448] START C=10000.0, penalty=None, solver=lbfgs, tol=0.001........\n",
            "[CV 2/5; 109/448] END C=10000.0, penalty=None, solver=lbfgs, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 109/448] START C=10000.0, penalty=None, solver=lbfgs, tol=0.001........"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[CV 3/5; 109/448] END C=10000.0, penalty=None, solver=lbfgs, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 109/448] START C=10000.0, penalty=None, solver=lbfgs, tol=0.001........\n",
            "[CV 4/5; 109/448] END C=10000.0, penalty=None, solver=lbfgs, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 109/448] START C=10000.0, penalty=None, solver=lbfgs, tol=0.001........\n",
            "[CV 5/5; 109/448] END C=10000.0, penalty=None, solver=lbfgs, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 110/448] START C=10000.0, penalty=None, solver=lbfgs, tol=0.0001.......\n",
            "[CV 1/5; 110/448] END C=10000.0, penalty=None, solver=lbfgs, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 110/448] START C=10000.0, penalty=None, solver=lbfgs, tol=0.0001.......\n",
            "[CV 2/5; 110/448] END C=10000.0, penalty=None, solver=lbfgs, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 110/448] START C=10000.0, penalty=None, solver=lbfgs, tol=0.0001.......\n",
            "[CV 3/5; 110/448] END C=10000.0, penalty=None, solver=lbfgs, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 110/448] START C=10000.0, penalty=None, solver=lbfgs, tol=0.0001.......\n",
            "[CV 4/5; 110/448] END C=10000.0, penalty=None, solver=lbfgs, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 110/448] START C=10000.0, penalty=None, solver=lbfgs, tol=0.0001.......\n",
            "[CV 5/5; 110/448] END C=10000.0, penalty=None, solver=lbfgs, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 111/448] START C=10000.0, penalty=None, solver=lbfgs, tol=1e-05........\n",
            "[CV 1/5; 111/448] END C=10000.0, penalty=None, solver=lbfgs, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 111/448] START C=10000.0, penalty=None, solver=lbfgs, tol=1e-05........\n",
            "[CV 2/5; 111/448] END C=10000.0, penalty=None, solver=lbfgs, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 111/448] START C=10000.0, penalty=None, solver=lbfgs, tol=1e-05........\n",
            "[CV 3/5; 111/448] END C=10000.0, penalty=None, solver=lbfgs, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 111/448] START C=10000.0, penalty=None, solver=lbfgs, tol=1e-05........\n",
            "[CV 4/5; 111/448] END C=10000.0, penalty=None, solver=lbfgs, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 111/448] START C=10000.0, penalty=None, solver=lbfgs, tol=1e-05........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 111/448] END C=10000.0, penalty=None, solver=lbfgs, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 112/448] START C=10000.0, penalty=None, solver=lbfgs, tol=1e-06........\n",
            "[CV 1/5; 112/448] END C=10000.0, penalty=None, solver=lbfgs, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 112/448] START C=10000.0, penalty=None, solver=lbfgs, tol=1e-06........\n",
            "[CV 2/5; 112/448] END C=10000.0, penalty=None, solver=lbfgs, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 112/448] START C=10000.0, penalty=None, solver=lbfgs, tol=1e-06........\n",
            "[CV 3/5; 112/448] END C=10000.0, penalty=None, solver=lbfgs, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 112/448] START C=10000.0, penalty=None, solver=lbfgs, tol=1e-06........\n",
            "[CV 4/5; 112/448] END C=10000.0, penalty=None, solver=lbfgs, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 112/448] START C=10000.0, penalty=None, solver=lbfgs, tol=1e-06........\n",
            "[CV 5/5; 112/448] END C=10000.0, penalty=None, solver=lbfgs, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 113/448] START C=100000.0, penalty=l2, solver=lbfgs, tol=0.001.........\n",
            "[CV 1/5; 113/448] END C=100000.0, penalty=l2, solver=lbfgs, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 113/448] START C=100000.0, penalty=l2, solver=lbfgs, tol=0.001.........\n",
            "[CV 2/5; 113/448] END C=100000.0, penalty=l2, solver=lbfgs, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 113/448] START C=100000.0, penalty=l2, solver=lbfgs, tol=0.001.........\n",
            "[CV 3/5; 113/448] END C=100000.0, penalty=l2, solver=lbfgs, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 113/448] START C=100000.0, penalty=l2, solver=lbfgs, tol=0.001.........\n",
            "[CV 4/5; 113/448] END C=100000.0, penalty=l2, solver=lbfgs, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 113/448] START C=100000.0, penalty=l2, solver=lbfgs, tol=0.001.........\n",
            "[CV 5/5; 113/448] END C=100000.0, penalty=l2, solver=lbfgs, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 114/448] START C=100000.0, penalty=l2, solver=lbfgs, tol=0.0001........\n",
            "[CV 1/5; 114/448] END C=100000.0, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 114/448] START C=100000.0, penalty=l2, solver=lbfgs, tol=0.0001........\n",
            "[CV 2/5; 114/448] END C=100000.0, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 114/448] START C=100000.0, penalty=l2, solver=lbfgs, tol=0.0001........\n",
            "[CV 3/5; 114/448] END C=100000.0, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 114/448] START C=100000.0, penalty=l2, solver=lbfgs, tol=0.0001........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 114/448] END C=100000.0, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 114/448] START C=100000.0, penalty=l2, solver=lbfgs, tol=0.0001........\n",
            "[CV 5/5; 114/448] END C=100000.0, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 115/448] START C=100000.0, penalty=l2, solver=lbfgs, tol=1e-05.........\n",
            "[CV 1/5; 115/448] END C=100000.0, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 115/448] START C=100000.0, penalty=l2, solver=lbfgs, tol=1e-05.........\n",
            "[CV 2/5; 115/448] END C=100000.0, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 115/448] START C=100000.0, penalty=l2, solver=lbfgs, tol=1e-05.........\n",
            "[CV 3/5; 115/448] END C=100000.0, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 115/448] START C=100000.0, penalty=l2, solver=lbfgs, tol=1e-05.........\n",
            "[CV 4/5; 115/448] END C=100000.0, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 115/448] START C=100000.0, penalty=l2, solver=lbfgs, tol=1e-05.........\n",
            "[CV 5/5; 115/448] END C=100000.0, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 116/448] START C=100000.0, penalty=l2, solver=lbfgs, tol=1e-06.........\n",
            "[CV 1/5; 116/448] END C=100000.0, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 116/448] START C=100000.0, penalty=l2, solver=lbfgs, tol=1e-06.........\n",
            "[CV 2/5; 116/448] END C=100000.0, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 116/448] START C=100000.0, penalty=l2, solver=lbfgs, tol=1e-06.........\n",
            "[CV 3/5; 116/448] END C=100000.0, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 116/448] START C=100000.0, penalty=l2, solver=lbfgs, tol=1e-06.........\n",
            "[CV 4/5; 116/448] END C=100000.0, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 116/448] START C=100000.0, penalty=l2, solver=lbfgs, tol=1e-06.........\n",
            "[CV 5/5; 116/448] END C=100000.0, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 117/448] START C=100000.0, penalty=None, solver=lbfgs, tol=0.001.......\n",
            "[CV 1/5; 117/448] END C=100000.0, penalty=None, solver=lbfgs, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 117/448] START C=100000.0, penalty=None, solver=lbfgs, tol=0.001.......\n",
            "[CV 2/5; 117/448] END C=100000.0, penalty=None, solver=lbfgs, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 117/448] START C=100000.0, penalty=None, solver=lbfgs, tol=0.001.......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 117/448] END C=100000.0, penalty=None, solver=lbfgs, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 117/448] START C=100000.0, penalty=None, solver=lbfgs, tol=0.001.......\n",
            "[CV 4/5; 117/448] END C=100000.0, penalty=None, solver=lbfgs, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 117/448] START C=100000.0, penalty=None, solver=lbfgs, tol=0.001.......\n",
            "[CV 5/5; 117/448] END C=100000.0, penalty=None, solver=lbfgs, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 118/448] START C=100000.0, penalty=None, solver=lbfgs, tol=0.0001......\n",
            "[CV 1/5; 118/448] END C=100000.0, penalty=None, solver=lbfgs, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 118/448] START C=100000.0, penalty=None, solver=lbfgs, tol=0.0001......\n",
            "[CV 2/5; 118/448] END C=100000.0, penalty=None, solver=lbfgs, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 118/448] START C=100000.0, penalty=None, solver=lbfgs, tol=0.0001......\n",
            "[CV 3/5; 118/448] END C=100000.0, penalty=None, solver=lbfgs, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 118/448] START C=100000.0, penalty=None, solver=lbfgs, tol=0.0001......\n",
            "[CV 4/5; 118/448] END C=100000.0, penalty=None, solver=lbfgs, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 118/448] START C=100000.0, penalty=None, solver=lbfgs, tol=0.0001......\n",
            "[CV 5/5; 118/448] END C=100000.0, penalty=None, solver=lbfgs, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 119/448] START C=100000.0, penalty=None, solver=lbfgs, tol=1e-05.......\n",
            "[CV 1/5; 119/448] END C=100000.0, penalty=None, solver=lbfgs, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 119/448] START C=100000.0, penalty=None, solver=lbfgs, tol=1e-05.......\n",
            "[CV 2/5; 119/448] END C=100000.0, penalty=None, solver=lbfgs, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 119/448] START C=100000.0, penalty=None, solver=lbfgs, tol=1e-05.......\n",
            "[CV 3/5; 119/448] END C=100000.0, penalty=None, solver=lbfgs, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 119/448] START C=100000.0, penalty=None, solver=lbfgs, tol=1e-05.......\n",
            "[CV 4/5; 119/448] END C=100000.0, penalty=None, solver=lbfgs, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 119/448] START C=100000.0, penalty=None, solver=lbfgs, tol=1e-05.......\n",
            "[CV 5/5; 119/448] END C=100000.0, penalty=None, solver=lbfgs, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 120/448] START C=100000.0, penalty=None, solver=lbfgs, tol=1e-06.......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 120/448] END C=100000.0, penalty=None, solver=lbfgs, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 120/448] START C=100000.0, penalty=None, solver=lbfgs, tol=1e-06.......\n",
            "[CV 2/5; 120/448] END C=100000.0, penalty=None, solver=lbfgs, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 120/448] START C=100000.0, penalty=None, solver=lbfgs, tol=1e-06.......\n",
            "[CV 3/5; 120/448] END C=100000.0, penalty=None, solver=lbfgs, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 120/448] START C=100000.0, penalty=None, solver=lbfgs, tol=1e-06.......\n",
            "[CV 4/5; 120/448] END C=100000.0, penalty=None, solver=lbfgs, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 120/448] START C=100000.0, penalty=None, solver=lbfgs, tol=1e-06.......\n",
            "[CV 5/5; 120/448] END C=100000.0, penalty=None, solver=lbfgs, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 121/448] START C=1000000.0, penalty=l2, solver=lbfgs, tol=0.001........\n",
            "[CV 1/5; 121/448] END C=1000000.0, penalty=l2, solver=lbfgs, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 121/448] START C=1000000.0, penalty=l2, solver=lbfgs, tol=0.001........\n",
            "[CV 2/5; 121/448] END C=1000000.0, penalty=l2, solver=lbfgs, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 121/448] START C=1000000.0, penalty=l2, solver=lbfgs, tol=0.001........\n",
            "[CV 3/5; 121/448] END C=1000000.0, penalty=l2, solver=lbfgs, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 121/448] START C=1000000.0, penalty=l2, solver=lbfgs, tol=0.001........\n",
            "[CV 4/5; 121/448] END C=1000000.0, penalty=l2, solver=lbfgs, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 121/448] START C=1000000.0, penalty=l2, solver=lbfgs, tol=0.001........\n",
            "[CV 5/5; 121/448] END C=1000000.0, penalty=l2, solver=lbfgs, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 122/448] START C=1000000.0, penalty=l2, solver=lbfgs, tol=0.0001.......\n",
            "[CV 1/5; 122/448] END C=1000000.0, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 122/448] START C=1000000.0, penalty=l2, solver=lbfgs, tol=0.0001.......\n",
            "[CV 2/5; 122/448] END C=1000000.0, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 122/448] START C=1000000.0, penalty=l2, solver=lbfgs, tol=0.0001.......\n",
            "[CV 3/5; 122/448] END C=1000000.0, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 122/448] START C=1000000.0, penalty=l2, solver=lbfgs, tol=0.0001.......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 122/448] END C=1000000.0, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 122/448] START C=1000000.0, penalty=l2, solver=lbfgs, tol=0.0001.......\n",
            "[CV 5/5; 122/448] END C=1000000.0, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 123/448] START C=1000000.0, penalty=l2, solver=lbfgs, tol=1e-05........\n",
            "[CV 1/5; 123/448] END C=1000000.0, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 123/448] START C=1000000.0, penalty=l2, solver=lbfgs, tol=1e-05........\n",
            "[CV 2/5; 123/448] END C=1000000.0, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 123/448] START C=1000000.0, penalty=l2, solver=lbfgs, tol=1e-05........\n",
            "[CV 3/5; 123/448] END C=1000000.0, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 123/448] START C=1000000.0, penalty=l2, solver=lbfgs, tol=1e-05........\n",
            "[CV 4/5; 123/448] END C=1000000.0, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 123/448] START C=1000000.0, penalty=l2, solver=lbfgs, tol=1e-05........\n",
            "[CV 5/5; 123/448] END C=1000000.0, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 124/448] START C=1000000.0, penalty=l2, solver=lbfgs, tol=1e-06........\n",
            "[CV 1/5; 124/448] END C=1000000.0, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 124/448] START C=1000000.0, penalty=l2, solver=lbfgs, tol=1e-06........\n",
            "[CV 2/5; 124/448] END C=1000000.0, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 124/448] START C=1000000.0, penalty=l2, solver=lbfgs, tol=1e-06........\n",
            "[CV 3/5; 124/448] END C=1000000.0, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 124/448] START C=1000000.0, penalty=l2, solver=lbfgs, tol=1e-06........\n",
            "[CV 4/5; 124/448] END C=1000000.0, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 124/448] START C=1000000.0, penalty=l2, solver=lbfgs, tol=1e-06........\n",
            "[CV 5/5; 124/448] END C=1000000.0, penalty=l2, solver=lbfgs, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 125/448] START C=1000000.0, penalty=None, solver=lbfgs, tol=0.001......\n",
            "[CV 1/5; 125/448] END C=1000000.0, penalty=None, solver=lbfgs, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 125/448] START C=1000000.0, penalty=None, solver=lbfgs, tol=0.001......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 125/448] END C=1000000.0, penalty=None, solver=lbfgs, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 125/448] START C=1000000.0, penalty=None, solver=lbfgs, tol=0.001......\n",
            "[CV 3/5; 125/448] END C=1000000.0, penalty=None, solver=lbfgs, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 125/448] START C=1000000.0, penalty=None, solver=lbfgs, tol=0.001......\n",
            "[CV 4/5; 125/448] END C=1000000.0, penalty=None, solver=lbfgs, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 125/448] START C=1000000.0, penalty=None, solver=lbfgs, tol=0.001......\n",
            "[CV 5/5; 125/448] END C=1000000.0, penalty=None, solver=lbfgs, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 126/448] START C=1000000.0, penalty=None, solver=lbfgs, tol=0.0001.....\n",
            "[CV 1/5; 126/448] END C=1000000.0, penalty=None, solver=lbfgs, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 126/448] START C=1000000.0, penalty=None, solver=lbfgs, tol=0.0001.....\n",
            "[CV 2/5; 126/448] END C=1000000.0, penalty=None, solver=lbfgs, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 126/448] START C=1000000.0, penalty=None, solver=lbfgs, tol=0.0001.....\n",
            "[CV 3/5; 126/448] END C=1000000.0, penalty=None, solver=lbfgs, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 126/448] START C=1000000.0, penalty=None, solver=lbfgs, tol=0.0001.....\n",
            "[CV 4/5; 126/448] END C=1000000.0, penalty=None, solver=lbfgs, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 126/448] START C=1000000.0, penalty=None, solver=lbfgs, tol=0.0001.....\n",
            "[CV 5/5; 126/448] END C=1000000.0, penalty=None, solver=lbfgs, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 127/448] START C=1000000.0, penalty=None, solver=lbfgs, tol=1e-05......\n",
            "[CV 1/5; 127/448] END C=1000000.0, penalty=None, solver=lbfgs, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 127/448] START C=1000000.0, penalty=None, solver=lbfgs, tol=1e-05......\n",
            "[CV 2/5; 127/448] END C=1000000.0, penalty=None, solver=lbfgs, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 127/448] START C=1000000.0, penalty=None, solver=lbfgs, tol=1e-05......\n",
            "[CV 3/5; 127/448] END C=1000000.0, penalty=None, solver=lbfgs, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 127/448] START C=1000000.0, penalty=None, solver=lbfgs, tol=1e-05......\n",
            "[CV 4/5; 127/448] END C=1000000.0, penalty=None, solver=lbfgs, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 127/448] START C=1000000.0, penalty=None, solver=lbfgs, tol=1e-05......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 127/448] END C=1000000.0, penalty=None, solver=lbfgs, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 128/448] START C=1000000.0, penalty=None, solver=lbfgs, tol=1e-06......\n",
            "[CV 1/5; 128/448] END C=1000000.0, penalty=None, solver=lbfgs, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 128/448] START C=1000000.0, penalty=None, solver=lbfgs, tol=1e-06......\n",
            "[CV 2/5; 128/448] END C=1000000.0, penalty=None, solver=lbfgs, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 128/448] START C=1000000.0, penalty=None, solver=lbfgs, tol=1e-06......\n",
            "[CV 3/5; 128/448] END C=1000000.0, penalty=None, solver=lbfgs, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 128/448] START C=1000000.0, penalty=None, solver=lbfgs, tol=1e-06......\n",
            "[CV 4/5; 128/448] END C=1000000.0, penalty=None, solver=lbfgs, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 128/448] START C=1000000.0, penalty=None, solver=lbfgs, tol=1e-06......\n",
            "[CV 5/5; 128/448] END C=1000000.0, penalty=None, solver=lbfgs, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 129/448] START C=0.1, penalty=l2, solver=newton-cg, tol=0.001..........\n",
            "[CV 1/5; 129/448] END C=0.1, penalty=l2, solver=newton-cg, tol=0.001;, score=0.792 total time=   0.0s\n",
            "[CV 2/5; 129/448] START C=0.1, penalty=l2, solver=newton-cg, tol=0.001..........\n",
            "[CV 2/5; 129/448] END C=0.1, penalty=l2, solver=newton-cg, tol=0.001;, score=0.656 total time=   0.0s\n",
            "[CV 3/5; 129/448] START C=0.1, penalty=l2, solver=newton-cg, tol=0.001..........\n",
            "[CV 3/5; 129/448] END C=0.1, penalty=l2, solver=newton-cg, tol=0.001;, score=0.720 total time=   0.0s\n",
            "[CV 4/5; 129/448] START C=0.1, penalty=l2, solver=newton-cg, tol=0.001..........\n",
            "[CV 4/5; 129/448] END C=0.1, penalty=l2, solver=newton-cg, tol=0.001;, score=0.720 total time=   0.0s\n",
            "[CV 5/5; 129/448] START C=0.1, penalty=l2, solver=newton-cg, tol=0.001..........\n",
            "[CV 5/5; 129/448] END C=0.1, penalty=l2, solver=newton-cg, tol=0.001;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 130/448] START C=0.1, penalty=l2, solver=newton-cg, tol=0.0001.........\n",
            "[CV 1/5; 130/448] END C=0.1, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.792 total time=   0.0s\n",
            "[CV 2/5; 130/448] START C=0.1, penalty=l2, solver=newton-cg, tol=0.0001.........\n",
            "[CV 2/5; 130/448] END C=0.1, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.656 total time=   0.0s\n",
            "[CV 3/5; 130/448] START C=0.1, penalty=l2, solver=newton-cg, tol=0.0001.........\n",
            "[CV 3/5; 130/448] END C=0.1, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.720 total time=   0.0s\n",
            "[CV 4/5; 130/448] START C=0.1, penalty=l2, solver=newton-cg, tol=0.0001.........\n",
            "[CV 4/5; 130/448] END C=0.1, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.720 total time=   0.0s\n",
            "[CV 5/5; 130/448] START C=0.1, penalty=l2, solver=newton-cg, tol=0.0001.........\n",
            "[CV 5/5; 130/448] END C=0.1, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 131/448] START C=0.1, penalty=l2, solver=newton-cg, tol=1e-05..........\n",
            "[CV 1/5; 131/448] END C=0.1, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.792 total time=   0.0s\n",
            "[CV 2/5; 131/448] START C=0.1, penalty=l2, solver=newton-cg, tol=1e-05..........\n",
            "[CV 2/5; 131/448] END C=0.1, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.656 total time=   0.0s\n",
            "[CV 3/5; 131/448] START C=0.1, penalty=l2, solver=newton-cg, tol=1e-05..........\n",
            "[CV 3/5; 131/448] END C=0.1, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.720 total time=   0.0s\n",
            "[CV 4/5; 131/448] START C=0.1, penalty=l2, solver=newton-cg, tol=1e-05..........\n",
            "[CV 4/5; 131/448] END C=0.1, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.720 total time=   0.0s\n",
            "[CV 5/5; 131/448] START C=0.1, penalty=l2, solver=newton-cg, tol=1e-05..........\n",
            "[CV 5/5; 131/448] END C=0.1, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 132/448] START C=0.1, penalty=l2, solver=newton-cg, tol=1e-06..........\n",
            "[CV 1/5; 132/448] END C=0.1, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.792 total time=   0.0s\n",
            "[CV 2/5; 132/448] START C=0.1, penalty=l2, solver=newton-cg, tol=1e-06..........\n",
            "[CV 2/5; 132/448] END C=0.1, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.656 total time=   0.0s\n",
            "[CV 3/5; 132/448] START C=0.1, penalty=l2, solver=newton-cg, tol=1e-06..........\n",
            "[CV 3/5; 132/448] END C=0.1, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.720 total time=   0.0s\n",
            "[CV 4/5; 132/448] START C=0.1, penalty=l2, solver=newton-cg, tol=1e-06..........\n",
            "[CV 4/5; 132/448] END C=0.1, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.720 total time=   0.0s\n",
            "[CV 5/5; 132/448] START C=0.1, penalty=l2, solver=newton-cg, tol=1e-06..........\n",
            "[CV 5/5; 132/448] END C=0.1, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 133/448] START C=0.1, penalty=l2, solver=newton-cholesky, tol=0.001....\n",
            "[CV 1/5; 133/448] END C=0.1, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.788 total time=   0.0s\n",
            "[CV 2/5; 133/448] START C=0.1, penalty=l2, solver=newton-cholesky, tol=0.001....\n",
            "[CV 2/5; 133/448] END C=0.1, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.664 total time=   0.0s\n",
            "[CV 3/5; 133/448] START C=0.1, penalty=l2, solver=newton-cholesky, tol=0.001....\n",
            "[CV 3/5; 133/448] END C=0.1, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.724 total time=   0.0s\n",
            "[CV 4/5; 133/448] START C=0.1, penalty=l2, solver=newton-cholesky, tol=0.001....\n",
            "[CV 4/5; 133/448] END C=0.1, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.720 total time=   0.0s\n",
            "[CV 5/5; 133/448] START C=0.1, penalty=l2, solver=newton-cholesky, tol=0.001....\n",
            "[CV 5/5; 133/448] END C=0.1, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 134/448] START C=0.1, penalty=l2, solver=newton-cholesky, tol=0.0001...\n",
            "[CV 1/5; 134/448] END C=0.1, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.792 total time=   0.0s\n",
            "[CV 2/5; 134/448] START C=0.1, penalty=l2, solver=newton-cholesky, tol=0.0001...\n",
            "[CV 2/5; 134/448] END C=0.1, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.656 total time=   0.0s\n",
            "[CV 3/5; 134/448] START C=0.1, penalty=l2, solver=newton-cholesky, tol=0.0001...\n",
            "[CV 3/5; 134/448] END C=0.1, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.720 total time=   0.0s\n",
            "[CV 4/5; 134/448] START C=0.1, penalty=l2, solver=newton-cholesky, tol=0.0001...\n",
            "[CV 4/5; 134/448] END C=0.1, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.720 total time=   0.0s\n",
            "[CV 5/5; 134/448] START C=0.1, penalty=l2, solver=newton-cholesky, tol=0.0001...\n",
            "[CV 5/5; 134/448] END C=0.1, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 135/448] START C=0.1, penalty=l2, solver=newton-cholesky, tol=1e-05....\n",
            "[CV 1/5; 135/448] END C=0.1, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.792 total time=   0.0s\n",
            "[CV 2/5; 135/448] START C=0.1, penalty=l2, solver=newton-cholesky, tol=1e-05....\n",
            "[CV 2/5; 135/448] END C=0.1, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.656 total time=   0.0s\n",
            "[CV 3/5; 135/448] START C=0.1, penalty=l2, solver=newton-cholesky, tol=1e-05....\n",
            "[CV 3/5; 135/448] END C=0.1, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.720 total time=   0.0s\n",
            "[CV 4/5; 135/448] START C=0.1, penalty=l2, solver=newton-cholesky, tol=1e-05....\n",
            "[CV 4/5; 135/448] END C=0.1, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.720 total time=   0.0s\n",
            "[CV 5/5; 135/448] START C=0.1, penalty=l2, solver=newton-cholesky, tol=1e-05....\n",
            "[CV 5/5; 135/448] END C=0.1, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 136/448] START C=0.1, penalty=l2, solver=newton-cholesky, tol=1e-06....\n",
            "[CV 1/5; 136/448] END C=0.1, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.792 total time=   0.0s\n",
            "[CV 2/5; 136/448] START C=0.1, penalty=l2, solver=newton-cholesky, tol=1e-06....\n",
            "[CV 2/5; 136/448] END C=0.1, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.656 total time=   0.0s\n",
            "[CV 3/5; 136/448] START C=0.1, penalty=l2, solver=newton-cholesky, tol=1e-06....\n",
            "[CV 3/5; 136/448] END C=0.1, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.720 total time=   0.0s\n",
            "[CV 4/5; 136/448] START C=0.1, penalty=l2, solver=newton-cholesky, tol=1e-06....\n",
            "[CV 4/5; 136/448] END C=0.1, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.720 total time=   0.0s\n",
            "[CV 5/5; 136/448] START C=0.1, penalty=l2, solver=newton-cholesky, tol=1e-06....\n",
            "[CV 5/5; 136/448] END C=0.1, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 137/448] START C=0.1, penalty=None, solver=newton-cg, tol=0.001........\n",
            "[CV 1/5; 137/448] END C=0.1, penalty=None, solver=newton-cg, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 137/448] START C=0.1, penalty=None, solver=newton-cg, tol=0.001........\n",
            "[CV 2/5; 137/448] END C=0.1, penalty=None, solver=newton-cg, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 137/448] START C=0.1, penalty=None, solver=newton-cg, tol=0.001........\n",
            "[CV 3/5; 137/448] END C=0.1, penalty=None, solver=newton-cg, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 137/448] START C=0.1, penalty=None, solver=newton-cg, tol=0.001........\n",
            "[CV 4/5; 137/448] END C=0.1, penalty=None, solver=newton-cg, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 137/448] START C=0.1, penalty=None, solver=newton-cg, tol=0.001........\n",
            "[CV 5/5; 137/448] END C=0.1, penalty=None, solver=newton-cg, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 138/448] START C=0.1, penalty=None, solver=newton-cg, tol=0.0001.......\n",
            "[CV 1/5; 138/448] END C=0.1, penalty=None, solver=newton-cg, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 138/448] START C=0.1, penalty=None, solver=newton-cg, tol=0.0001.......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 138/448] END C=0.1, penalty=None, solver=newton-cg, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 138/448] START C=0.1, penalty=None, solver=newton-cg, tol=0.0001.......\n",
            "[CV 3/5; 138/448] END C=0.1, penalty=None, solver=newton-cg, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 138/448] START C=0.1, penalty=None, solver=newton-cg, tol=0.0001.......\n",
            "[CV 4/5; 138/448] END C=0.1, penalty=None, solver=newton-cg, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 138/448] START C=0.1, penalty=None, solver=newton-cg, tol=0.0001.......\n",
            "[CV 5/5; 138/448] END C=0.1, penalty=None, solver=newton-cg, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 139/448] START C=0.1, penalty=None, solver=newton-cg, tol=1e-05........\n",
            "[CV 1/5; 139/448] END C=0.1, penalty=None, solver=newton-cg, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 139/448] START C=0.1, penalty=None, solver=newton-cg, tol=1e-05........\n",
            "[CV 2/5; 139/448] END C=0.1, penalty=None, solver=newton-cg, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 139/448] START C=0.1, penalty=None, solver=newton-cg, tol=1e-05........\n",
            "[CV 3/5; 139/448] END C=0.1, penalty=None, solver=newton-cg, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 139/448] START C=0.1, penalty=None, solver=newton-cg, tol=1e-05........\n",
            "[CV 4/5; 139/448] END C=0.1, penalty=None, solver=newton-cg, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 139/448] START C=0.1, penalty=None, solver=newton-cg, tol=1e-05........\n",
            "[CV 5/5; 139/448] END C=0.1, penalty=None, solver=newton-cg, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 140/448] START C=0.1, penalty=None, solver=newton-cg, tol=1e-06........\n",
            "[CV 1/5; 140/448] END C=0.1, penalty=None, solver=newton-cg, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 140/448] START C=0.1, penalty=None, solver=newton-cg, tol=1e-06........\n",
            "[CV 2/5; 140/448] END C=0.1, penalty=None, solver=newton-cg, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 140/448] START C=0.1, penalty=None, solver=newton-cg, tol=1e-06........\n",
            "[CV 3/5; 140/448] END C=0.1, penalty=None, solver=newton-cg, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 140/448] START C=0.1, penalty=None, solver=newton-cg, tol=1e-06........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 140/448] END C=0.1, penalty=None, solver=newton-cg, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 140/448] START C=0.1, penalty=None, solver=newton-cg, tol=1e-06........\n",
            "[CV 5/5; 140/448] END C=0.1, penalty=None, solver=newton-cg, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 141/448] START C=0.1, penalty=None, solver=newton-cholesky, tol=0.001..\n",
            "[CV 1/5; 141/448] END C=0.1, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.968 total time=   0.0s\n",
            "[CV 2/5; 141/448] START C=0.1, penalty=None, solver=newton-cholesky, tol=0.001..\n",
            "[CV 2/5; 141/448] END C=0.1, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 141/448] START C=0.1, penalty=None, solver=newton-cholesky, tol=0.001..\n",
            "[CV 3/5; 141/448] END C=0.1, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 141/448] START C=0.1, penalty=None, solver=newton-cholesky, tol=0.001..\n",
            "[CV 4/5; 141/448] END C=0.1, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 5/5; 141/448] START C=0.1, penalty=None, solver=newton-cholesky, tol=0.001..\n",
            "[CV 5/5; 141/448] END C=0.1, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 142/448] START C=0.1, penalty=None, solver=newton-cholesky, tol=0.0001.\n",
            "[CV 1/5; 142/448] END C=0.1, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 2/5; 142/448] START C=0.1, penalty=None, solver=newton-cholesky, tol=0.0001.\n",
            "[CV 2/5; 142/448] END C=0.1, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 142/448] START C=0.1, penalty=None, solver=newton-cholesky, tol=0.0001.\n",
            "[CV 3/5; 142/448] END C=0.1, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 142/448] START C=0.1, penalty=None, solver=newton-cholesky, tol=0.0001.\n",
            "[CV 4/5; 142/448] END C=0.1, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 5/5; 142/448] START C=0.1, penalty=None, solver=newton-cholesky, tol=0.0001.\n",
            "[CV 5/5; 142/448] END C=0.1, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 143/448] START C=0.1, penalty=None, solver=newton-cholesky, tol=1e-05..\n",
            "[CV 1/5; 143/448] END C=0.1, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 143/448] START C=0.1, penalty=None, solver=newton-cholesky, tol=1e-05..\n",
            "[CV 2/5; 143/448] END C=0.1, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 143/448] START C=0.1, penalty=None, solver=newton-cholesky, tol=1e-05..\n",
            "[CV 3/5; 143/448] END C=0.1, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 143/448] START C=0.1, penalty=None, solver=newton-cholesky, tol=1e-05..\n",
            "[CV 4/5; 143/448] END C=0.1, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 5/5; 143/448] START C=0.1, penalty=None, solver=newton-cholesky, tol=1e-05..\n",
            "[CV 5/5; 143/448] END C=0.1, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 144/448] START C=0.1, penalty=None, solver=newton-cholesky, tol=1e-06..\n",
            "[CV 1/5; 144/448] END C=0.1, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 144/448] START C=0.1, penalty=None, solver=newton-cholesky, tol=1e-06..\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 144/448] END C=0.1, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 144/448] START C=0.1, penalty=None, solver=newton-cholesky, tol=1e-06..\n",
            "[CV 3/5; 144/448] END C=0.1, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 144/448] START C=0.1, penalty=None, solver=newton-cholesky, tol=1e-06..\n",
            "[CV 4/5; 144/448] END C=0.1, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 144/448] START C=0.1, penalty=None, solver=newton-cholesky, tol=1e-06..\n",
            "[CV 5/5; 144/448] END C=0.1, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 145/448] START C=1, penalty=l2, solver=newton-cg, tol=0.001............\n",
            "[CV 1/5; 145/448] END C=1, penalty=l2, solver=newton-cg, tol=0.001;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 145/448] START C=1, penalty=l2, solver=newton-cg, tol=0.001............\n",
            "[CV 2/5; 145/448] END C=1, penalty=l2, solver=newton-cg, tol=0.001;, score=0.880 total time=   0.0s\n",
            "[CV 3/5; 145/448] START C=1, penalty=l2, solver=newton-cg, tol=0.001............\n",
            "[CV 3/5; 145/448] END C=1, penalty=l2, solver=newton-cg, tol=0.001;, score=0.912 total time=   0.0s\n",
            "[CV 4/5; 145/448] START C=1, penalty=l2, solver=newton-cg, tol=0.001............\n",
            "[CV 4/5; 145/448] END C=1, penalty=l2, solver=newton-cg, tol=0.001;, score=0.916 total time=   0.0s\n",
            "[CV 5/5; 145/448] START C=1, penalty=l2, solver=newton-cg, tol=0.001............\n",
            "[CV 5/5; 145/448] END C=1, penalty=l2, solver=newton-cg, tol=0.001;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 146/448] START C=1, penalty=l2, solver=newton-cg, tol=0.0001...........\n",
            "[CV 1/5; 146/448] END C=1, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 146/448] START C=1, penalty=l2, solver=newton-cg, tol=0.0001...........\n",
            "[CV 2/5; 146/448] END C=1, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.880 total time=   0.0s\n",
            "[CV 3/5; 146/448] START C=1, penalty=l2, solver=newton-cg, tol=0.0001...........\n",
            "[CV 3/5; 146/448] END C=1, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.912 total time=   0.0s\n",
            "[CV 4/5; 146/448] START C=1, penalty=l2, solver=newton-cg, tol=0.0001...........\n",
            "[CV 4/5; 146/448] END C=1, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.916 total time=   0.0s\n",
            "[CV 5/5; 146/448] START C=1, penalty=l2, solver=newton-cg, tol=0.0001...........\n",
            "[CV 5/5; 146/448] END C=1, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 147/448] START C=1, penalty=l2, solver=newton-cg, tol=1e-05............\n",
            "[CV 1/5; 147/448] END C=1, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 147/448] START C=1, penalty=l2, solver=newton-cg, tol=1e-05............\n",
            "[CV 2/5; 147/448] END C=1, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.880 total time=   0.0s\n",
            "[CV 3/5; 147/448] START C=1, penalty=l2, solver=newton-cg, tol=1e-05............\n",
            "[CV 3/5; 147/448] END C=1, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.912 total time=   0.0s\n",
            "[CV 4/5; 147/448] START C=1, penalty=l2, solver=newton-cg, tol=1e-05............\n",
            "[CV 4/5; 147/448] END C=1, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.916 total time=   0.0s\n",
            "[CV 5/5; 147/448] START C=1, penalty=l2, solver=newton-cg, tol=1e-05............\n",
            "[CV 5/5; 147/448] END C=1, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 148/448] START C=1, penalty=l2, solver=newton-cg, tol=1e-06............\n",
            "[CV 1/5; 148/448] END C=1, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 148/448] START C=1, penalty=l2, solver=newton-cg, tol=1e-06............\n",
            "[CV 2/5; 148/448] END C=1, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.880 total time=   0.0s\n",
            "[CV 3/5; 148/448] START C=1, penalty=l2, solver=newton-cg, tol=1e-06............\n",
            "[CV 3/5; 148/448] END C=1, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.912 total time=   0.0s\n",
            "[CV 4/5; 148/448] START C=1, penalty=l2, solver=newton-cg, tol=1e-06............\n",
            "[CV 4/5; 148/448] END C=1, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.916 total time=   0.0s\n",
            "[CV 5/5; 148/448] START C=1, penalty=l2, solver=newton-cg, tol=1e-06............\n",
            "[CV 5/5; 148/448] END C=1, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 149/448] START C=1, penalty=l2, solver=newton-cholesky, tol=0.001......\n",
            "[CV 1/5; 149/448] END C=1, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 149/448] START C=1, penalty=l2, solver=newton-cholesky, tol=0.001......\n",
            "[CV 2/5; 149/448] END C=1, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.880 total time=   0.0s\n",
            "[CV 3/5; 149/448] START C=1, penalty=l2, solver=newton-cholesky, tol=0.001......\n",
            "[CV 3/5; 149/448] END C=1, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.912 total time=   0.0s\n",
            "[CV 4/5; 149/448] START C=1, penalty=l2, solver=newton-cholesky, tol=0.001......\n",
            "[CV 4/5; 149/448] END C=1, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.908 total time=   0.0s\n",
            "[CV 5/5; 149/448] START C=1, penalty=l2, solver=newton-cholesky, tol=0.001......\n",
            "[CV 5/5; 149/448] END C=1, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 150/448] START C=1, penalty=l2, solver=newton-cholesky, tol=0.0001.....\n",
            "[CV 1/5; 150/448] END C=1, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 150/448] START C=1, penalty=l2, solver=newton-cholesky, tol=0.0001.....\n",
            "[CV 2/5; 150/448] END C=1, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.880 total time=   0.0s\n",
            "[CV 3/5; 150/448] START C=1, penalty=l2, solver=newton-cholesky, tol=0.0001.....\n",
            "[CV 3/5; 150/448] END C=1, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.912 total time=   0.0s\n",
            "[CV 4/5; 150/448] START C=1, penalty=l2, solver=newton-cholesky, tol=0.0001.....\n",
            "[CV 4/5; 150/448] END C=1, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.916 total time=   0.0s\n",
            "[CV 5/5; 150/448] START C=1, penalty=l2, solver=newton-cholesky, tol=0.0001.....\n",
            "[CV 5/5; 150/448] END C=1, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 151/448] START C=1, penalty=l2, solver=newton-cholesky, tol=1e-05......\n",
            "[CV 1/5; 151/448] END C=1, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 151/448] START C=1, penalty=l2, solver=newton-cholesky, tol=1e-05......\n",
            "[CV 2/5; 151/448] END C=1, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.880 total time=   0.0s\n",
            "[CV 3/5; 151/448] START C=1, penalty=l2, solver=newton-cholesky, tol=1e-05......\n",
            "[CV 3/5; 151/448] END C=1, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.912 total time=   0.0s\n",
            "[CV 4/5; 151/448] START C=1, penalty=l2, solver=newton-cholesky, tol=1e-05......\n",
            "[CV 4/5; 151/448] END C=1, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.916 total time=   0.0s\n",
            "[CV 5/5; 151/448] START C=1, penalty=l2, solver=newton-cholesky, tol=1e-05......\n",
            "[CV 5/5; 151/448] END C=1, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 152/448] START C=1, penalty=l2, solver=newton-cholesky, tol=1e-06......\n",
            "[CV 1/5; 152/448] END C=1, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.920 total time=   0.0s\n",
            "[CV 2/5; 152/448] START C=1, penalty=l2, solver=newton-cholesky, tol=1e-06......\n",
            "[CV 2/5; 152/448] END C=1, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.880 total time=   0.0s\n",
            "[CV 3/5; 152/448] START C=1, penalty=l2, solver=newton-cholesky, tol=1e-06......\n",
            "[CV 3/5; 152/448] END C=1, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.912 total time=   0.0s\n",
            "[CV 4/5; 152/448] START C=1, penalty=l2, solver=newton-cholesky, tol=1e-06......\n",
            "[CV 4/5; 152/448] END C=1, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.916 total time=   0.0s\n",
            "[CV 5/5; 152/448] START C=1, penalty=l2, solver=newton-cholesky, tol=1e-06......\n",
            "[CV 5/5; 152/448] END C=1, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 153/448] START C=1, penalty=None, solver=newton-cg, tol=0.001..........\n",
            "[CV 1/5; 153/448] END C=1, penalty=None, solver=newton-cg, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 153/448] START C=1, penalty=None, solver=newton-cg, tol=0.001..........\n",
            "[CV 2/5; 153/448] END C=1, penalty=None, solver=newton-cg, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 153/448] START C=1, penalty=None, solver=newton-cg, tol=0.001..........\n",
            "[CV 3/5; 153/448] END C=1, penalty=None, solver=newton-cg, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 153/448] START C=1, penalty=None, solver=newton-cg, tol=0.001..........\n",
            "[CV 4/5; 153/448] END C=1, penalty=None, solver=newton-cg, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 153/448] START C=1, penalty=None, solver=newton-cg, tol=0.001..........\n",
            "[CV 5/5; 153/448] END C=1, penalty=None, solver=newton-cg, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 154/448] START C=1, penalty=None, solver=newton-cg, tol=0.0001.........\n",
            "[CV 1/5; 154/448] END C=1, penalty=None, solver=newton-cg, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 154/448] START C=1, penalty=None, solver=newton-cg, tol=0.0001.........\n",
            "[CV 2/5; 154/448] END C=1, penalty=None, solver=newton-cg, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 154/448] START C=1, penalty=None, solver=newton-cg, tol=0.0001.........\n",
            "[CV 3/5; 154/448] END C=1, penalty=None, solver=newton-cg, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 154/448] START C=1, penalty=None, solver=newton-cg, tol=0.0001.........\n",
            "[CV 4/5; 154/448] END C=1, penalty=None, solver=newton-cg, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 154/448] START C=1, penalty=None, solver=newton-cg, tol=0.0001.........\n",
            "[CV 5/5; 154/448] END C=1, penalty=None, solver=newton-cg, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 155/448] START C=1, penalty=None, solver=newton-cg, tol=1e-05..........\n",
            "[CV 1/5; 155/448] END C=1, penalty=None, solver=newton-cg, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 155/448] START C=1, penalty=None, solver=newton-cg, tol=1e-05..........\n",
            "[CV 2/5; 155/448] END C=1, penalty=None, solver=newton-cg, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 155/448] START C=1, penalty=None, solver=newton-cg, tol=1e-05..........\n",
            "[CV 3/5; 155/448] END C=1, penalty=None, solver=newton-cg, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 155/448] START C=1, penalty=None, solver=newton-cg, tol=1e-05..........\n",
            "[CV 4/5; 155/448] END C=1, penalty=None, solver=newton-cg, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 155/448] START C=1, penalty=None, solver=newton-cg, tol=1e-05..........\n",
            "[CV 5/5; 155/448] END C=1, penalty=None, solver=newton-cg, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 156/448] START C=1, penalty=None, solver=newton-cg, tol=1e-06..........\n",
            "[CV 1/5; 156/448] END C=1, penalty=None, solver=newton-cg, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 156/448] START C=1, penalty=None, solver=newton-cg, tol=1e-06..........\n",
            "[CV 2/5; 156/448] END C=1, penalty=None, solver=newton-cg, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 156/448] START C=1, penalty=None, solver=newton-cg, tol=1e-06..........\n",
            "[CV 3/5; 156/448] END C=1, penalty=None, solver=newton-cg, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 156/448] START C=1, penalty=None, solver=newton-cg, tol=1e-06..........\n",
            "[CV 4/5; 156/448] END C=1, penalty=None, solver=newton-cg, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 156/448] START C=1, penalty=None, solver=newton-cg, tol=1e-06..........\n",
            "[CV 5/5; 156/448] END C=1, penalty=None, solver=newton-cg, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 157/448] START C=1, penalty=None, solver=newton-cholesky, tol=0.001....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 157/448] END C=1, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.968 total time=   0.0s\n",
            "[CV 2/5; 157/448] START C=1, penalty=None, solver=newton-cholesky, tol=0.001....\n",
            "[CV 2/5; 157/448] END C=1, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 157/448] START C=1, penalty=None, solver=newton-cholesky, tol=0.001....\n",
            "[CV 3/5; 157/448] END C=1, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 157/448] START C=1, penalty=None, solver=newton-cholesky, tol=0.001....\n",
            "[CV 4/5; 157/448] END C=1, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 5/5; 157/448] START C=1, penalty=None, solver=newton-cholesky, tol=0.001....\n",
            "[CV 5/5; 157/448] END C=1, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 158/448] START C=1, penalty=None, solver=newton-cholesky, tol=0.0001...\n",
            "[CV 1/5; 158/448] END C=1, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 2/5; 158/448] START C=1, penalty=None, solver=newton-cholesky, tol=0.0001...\n",
            "[CV 2/5; 158/448] END C=1, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 158/448] START C=1, penalty=None, solver=newton-cholesky, tol=0.0001...\n",
            "[CV 3/5; 158/448] END C=1, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 158/448] START C=1, penalty=None, solver=newton-cholesky, tol=0.0001...\n",
            "[CV 4/5; 158/448] END C=1, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 5/5; 158/448] START C=1, penalty=None, solver=newton-cholesky, tol=0.0001...\n",
            "[CV 5/5; 158/448] END C=1, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 159/448] START C=1, penalty=None, solver=newton-cholesky, tol=1e-05....\n",
            "[CV 1/5; 159/448] END C=1, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 159/448] START C=1, penalty=None, solver=newton-cholesky, tol=1e-05....\n",
            "[CV 2/5; 159/448] END C=1, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 159/448] START C=1, penalty=None, solver=newton-cholesky, tol=1e-05....\n",
            "[CV 3/5; 159/448] END C=1, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 159/448] START C=1, penalty=None, solver=newton-cholesky, tol=1e-05....\n",
            "[CV 4/5; 159/448] END C=1, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 5/5; 159/448] START C=1, penalty=None, solver=newton-cholesky, tol=1e-05....\n",
            "[CV 5/5; 159/448] END C=1, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 160/448] START C=1, penalty=None, solver=newton-cholesky, tol=1e-06....\n",
            "[CV 1/5; 160/448] END C=1, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 160/448] START C=1, penalty=None, solver=newton-cholesky, tol=1e-06....\n",
            "[CV 2/5; 160/448] END C=1, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 160/448] START C=1, penalty=None, solver=newton-cholesky, tol=1e-06....\n",
            "[CV 3/5; 160/448] END C=1, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 160/448] START C=1, penalty=None, solver=newton-cholesky, tol=1e-06....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 160/448] END C=1, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 160/448] START C=1, penalty=None, solver=newton-cholesky, tol=1e-06....\n",
            "[CV 5/5; 160/448] END C=1, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 161/448] START C=10.0, penalty=l2, solver=newton-cg, tol=0.001.........\n",
            "[CV 1/5; 161/448] END C=10.0, penalty=l2, solver=newton-cg, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 2/5; 161/448] START C=10.0, penalty=l2, solver=newton-cg, tol=0.001.........\n",
            "[CV 2/5; 161/448] END C=10.0, penalty=l2, solver=newton-cg, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 161/448] START C=10.0, penalty=l2, solver=newton-cg, tol=0.001.........\n",
            "[CV 3/5; 161/448] END C=10.0, penalty=l2, solver=newton-cg, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 161/448] START C=10.0, penalty=l2, solver=newton-cg, tol=0.001.........\n",
            "[CV 4/5; 161/448] END C=10.0, penalty=l2, solver=newton-cg, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 5/5; 161/448] START C=10.0, penalty=l2, solver=newton-cg, tol=0.001.........\n",
            "[CV 5/5; 161/448] END C=10.0, penalty=l2, solver=newton-cg, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 162/448] START C=10.0, penalty=l2, solver=newton-cg, tol=0.0001........\n",
            "[CV 1/5; 162/448] END C=10.0, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 2/5; 162/448] START C=10.0, penalty=l2, solver=newton-cg, tol=0.0001........\n",
            "[CV 2/5; 162/448] END C=10.0, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 162/448] START C=10.0, penalty=l2, solver=newton-cg, tol=0.0001........\n",
            "[CV 3/5; 162/448] END C=10.0, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 162/448] START C=10.0, penalty=l2, solver=newton-cg, tol=0.0001........\n",
            "[CV 4/5; 162/448] END C=10.0, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 5/5; 162/448] START C=10.0, penalty=l2, solver=newton-cg, tol=0.0001........\n",
            "[CV 5/5; 162/448] END C=10.0, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 163/448] START C=10.0, penalty=l2, solver=newton-cg, tol=1e-05.........\n",
            "[CV 1/5; 163/448] END C=10.0, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 2/5; 163/448] START C=10.0, penalty=l2, solver=newton-cg, tol=1e-05.........\n",
            "[CV 2/5; 163/448] END C=10.0, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 163/448] START C=10.0, penalty=l2, solver=newton-cg, tol=1e-05.........\n",
            "[CV 3/5; 163/448] END C=10.0, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 163/448] START C=10.0, penalty=l2, solver=newton-cg, tol=1e-05.........\n",
            "[CV 4/5; 163/448] END C=10.0, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 5/5; 163/448] START C=10.0, penalty=l2, solver=newton-cg, tol=1e-05.........\n",
            "[CV 5/5; 163/448] END C=10.0, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 164/448] START C=10.0, penalty=l2, solver=newton-cg, tol=1e-06.........\n",
            "[CV 1/5; 164/448] END C=10.0, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 2/5; 164/448] START C=10.0, penalty=l2, solver=newton-cg, tol=1e-06.........\n",
            "[CV 2/5; 164/448] END C=10.0, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 164/448] START C=10.0, penalty=l2, solver=newton-cg, tol=1e-06.........\n",
            "[CV 3/5; 164/448] END C=10.0, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 164/448] START C=10.0, penalty=l2, solver=newton-cg, tol=1e-06.........\n",
            "[CV 4/5; 164/448] END C=10.0, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 5/5; 164/448] START C=10.0, penalty=l2, solver=newton-cg, tol=1e-06.........\n",
            "[CV 5/5; 164/448] END C=10.0, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 165/448] START C=10.0, penalty=l2, solver=newton-cholesky, tol=0.001...\n",
            "[CV 1/5; 165/448] END C=10.0, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 2/5; 165/448] START C=10.0, penalty=l2, solver=newton-cholesky, tol=0.001...\n",
            "[CV 2/5; 165/448] END C=10.0, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 165/448] START C=10.0, penalty=l2, solver=newton-cholesky, tol=0.001...\n",
            "[CV 3/5; 165/448] END C=10.0, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 165/448] START C=10.0, penalty=l2, solver=newton-cholesky, tol=0.001...\n",
            "[CV 4/5; 165/448] END C=10.0, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 5/5; 165/448] START C=10.0, penalty=l2, solver=newton-cholesky, tol=0.001...\n",
            "[CV 5/5; 165/448] END C=10.0, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 166/448] START C=10.0, penalty=l2, solver=newton-cholesky, tol=0.0001..\n",
            "[CV 1/5; 166/448] END C=10.0, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 2/5; 166/448] START C=10.0, penalty=l2, solver=newton-cholesky, tol=0.0001..\n",
            "[CV 2/5; 166/448] END C=10.0, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 166/448] START C=10.0, penalty=l2, solver=newton-cholesky, tol=0.0001..\n",
            "[CV 3/5; 166/448] END C=10.0, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 166/448] START C=10.0, penalty=l2, solver=newton-cholesky, tol=0.0001..\n",
            "[CV 4/5; 166/448] END C=10.0, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 5/5; 166/448] START C=10.0, penalty=l2, solver=newton-cholesky, tol=0.0001..\n",
            "[CV 5/5; 166/448] END C=10.0, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 167/448] START C=10.0, penalty=l2, solver=newton-cholesky, tol=1e-05...\n",
            "[CV 1/5; 167/448] END C=10.0, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 2/5; 167/448] START C=10.0, penalty=l2, solver=newton-cholesky, tol=1e-05...\n",
            "[CV 2/5; 167/448] END C=10.0, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 167/448] START C=10.0, penalty=l2, solver=newton-cholesky, tol=1e-05...\n",
            "[CV 3/5; 167/448] END C=10.0, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 167/448] START C=10.0, penalty=l2, solver=newton-cholesky, tol=1e-05...\n",
            "[CV 4/5; 167/448] END C=10.0, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 5/5; 167/448] START C=10.0, penalty=l2, solver=newton-cholesky, tol=1e-05...\n",
            "[CV 5/5; 167/448] END C=10.0, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 168/448] START C=10.0, penalty=l2, solver=newton-cholesky, tol=1e-06...\n",
            "[CV 1/5; 168/448] END C=10.0, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 2/5; 168/448] START C=10.0, penalty=l2, solver=newton-cholesky, tol=1e-06...\n",
            "[CV 2/5; 168/448] END C=10.0, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.960 total time=   0.0s\n",
            "[CV 3/5; 168/448] START C=10.0, penalty=l2, solver=newton-cholesky, tol=1e-06...\n",
            "[CV 3/5; 168/448] END C=10.0, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 168/448] START C=10.0, penalty=l2, solver=newton-cholesky, tol=1e-06...\n",
            "[CV 4/5; 168/448] END C=10.0, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 5/5; 168/448] START C=10.0, penalty=l2, solver=newton-cholesky, tol=1e-06...\n",
            "[CV 5/5; 168/448] END C=10.0, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 169/448] START C=10.0, penalty=None, solver=newton-cg, tol=0.001.......\n",
            "[CV 1/5; 169/448] END C=10.0, penalty=None, solver=newton-cg, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 169/448] START C=10.0, penalty=None, solver=newton-cg, tol=0.001.......\n",
            "[CV 2/5; 169/448] END C=10.0, penalty=None, solver=newton-cg, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 169/448] START C=10.0, penalty=None, solver=newton-cg, tol=0.001.......\n",
            "[CV 3/5; 169/448] END C=10.0, penalty=None, solver=newton-cg, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 169/448] START C=10.0, penalty=None, solver=newton-cg, tol=0.001.......\n",
            "[CV 4/5; 169/448] END C=10.0, penalty=None, solver=newton-cg, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 169/448] START C=10.0, penalty=None, solver=newton-cg, tol=0.001.......\n",
            "[CV 5/5; 169/448] END C=10.0, penalty=None, solver=newton-cg, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 170/448] START C=10.0, penalty=None, solver=newton-cg, tol=0.0001......\n",
            "[CV 1/5; 170/448] END C=10.0, penalty=None, solver=newton-cg, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 170/448] START C=10.0, penalty=None, solver=newton-cg, tol=0.0001......\n",
            "[CV 2/5; 170/448] END C=10.0, penalty=None, solver=newton-cg, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 170/448] START C=10.0, penalty=None, solver=newton-cg, tol=0.0001......\n",
            "[CV 3/5; 170/448] END C=10.0, penalty=None, solver=newton-cg, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 170/448] START C=10.0, penalty=None, solver=newton-cg, tol=0.0001......\n",
            "[CV 4/5; 170/448] END C=10.0, penalty=None, solver=newton-cg, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 170/448] START C=10.0, penalty=None, solver=newton-cg, tol=0.0001......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 170/448] END C=10.0, penalty=None, solver=newton-cg, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 171/448] START C=10.0, penalty=None, solver=newton-cg, tol=1e-05.......\n",
            "[CV 1/5; 171/448] END C=10.0, penalty=None, solver=newton-cg, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 171/448] START C=10.0, penalty=None, solver=newton-cg, tol=1e-05.......\n",
            "[CV 2/5; 171/448] END C=10.0, penalty=None, solver=newton-cg, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 171/448] START C=10.0, penalty=None, solver=newton-cg, tol=1e-05.......\n",
            "[CV 3/5; 171/448] END C=10.0, penalty=None, solver=newton-cg, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 171/448] START C=10.0, penalty=None, solver=newton-cg, tol=1e-05.......\n",
            "[CV 4/5; 171/448] END C=10.0, penalty=None, solver=newton-cg, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 171/448] START C=10.0, penalty=None, solver=newton-cg, tol=1e-05.......\n",
            "[CV 5/5; 171/448] END C=10.0, penalty=None, solver=newton-cg, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 172/448] START C=10.0, penalty=None, solver=newton-cg, tol=1e-06.......\n",
            "[CV 1/5; 172/448] END C=10.0, penalty=None, solver=newton-cg, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 172/448] START C=10.0, penalty=None, solver=newton-cg, tol=1e-06.......\n",
            "[CV 2/5; 172/448] END C=10.0, penalty=None, solver=newton-cg, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 172/448] START C=10.0, penalty=None, solver=newton-cg, tol=1e-06.......\n",
            "[CV 3/5; 172/448] END C=10.0, penalty=None, solver=newton-cg, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 172/448] START C=10.0, penalty=None, solver=newton-cg, tol=1e-06.......\n",
            "[CV 4/5; 172/448] END C=10.0, penalty=None, solver=newton-cg, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 172/448] START C=10.0, penalty=None, solver=newton-cg, tol=1e-06.......\n",
            "[CV 5/5; 172/448] END C=10.0, penalty=None, solver=newton-cg, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 173/448] START C=10.0, penalty=None, solver=newton-cholesky, tol=0.001.\n",
            "[CV 1/5; 173/448] END C=10.0, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.968 total time=   0.0s\n",
            "[CV 2/5; 173/448] START C=10.0, penalty=None, solver=newton-cholesky, tol=0.001.\n",
            "[CV 2/5; 173/448] END C=10.0, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 173/448] START C=10.0, penalty=None, solver=newton-cholesky, tol=0.001.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 173/448] END C=10.0, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 173/448] START C=10.0, penalty=None, solver=newton-cholesky, tol=0.001.\n",
            "[CV 4/5; 173/448] END C=10.0, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 5/5; 173/448] START C=10.0, penalty=None, solver=newton-cholesky, tol=0.001.\n",
            "[CV 5/5; 173/448] END C=10.0, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 174/448] START C=10.0, penalty=None, solver=newton-cholesky, tol=0.0001\n",
            "[CV 1/5; 174/448] END C=10.0, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 2/5; 174/448] START C=10.0, penalty=None, solver=newton-cholesky, tol=0.0001\n",
            "[CV 2/5; 174/448] END C=10.0, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 174/448] START C=10.0, penalty=None, solver=newton-cholesky, tol=0.0001\n",
            "[CV 3/5; 174/448] END C=10.0, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 174/448] START C=10.0, penalty=None, solver=newton-cholesky, tol=0.0001\n",
            "[CV 4/5; 174/448] END C=10.0, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 5/5; 174/448] START C=10.0, penalty=None, solver=newton-cholesky, tol=0.0001\n",
            "[CV 5/5; 174/448] END C=10.0, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 175/448] START C=10.0, penalty=None, solver=newton-cholesky, tol=1e-05.\n",
            "[CV 1/5; 175/448] END C=10.0, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 175/448] START C=10.0, penalty=None, solver=newton-cholesky, tol=1e-05.\n",
            "[CV 2/5; 175/448] END C=10.0, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 175/448] START C=10.0, penalty=None, solver=newton-cholesky, tol=1e-05.\n",
            "[CV 3/5; 175/448] END C=10.0, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 175/448] START C=10.0, penalty=None, solver=newton-cholesky, tol=1e-05.\n",
            "[CV 4/5; 175/448] END C=10.0, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 5/5; 175/448] START C=10.0, penalty=None, solver=newton-cholesky, tol=1e-05.\n",
            "[CV 5/5; 175/448] END C=10.0, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 176/448] START C=10.0, penalty=None, solver=newton-cholesky, tol=1e-06.\n",
            "[CV 1/5; 176/448] END C=10.0, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 176/448] START C=10.0, penalty=None, solver=newton-cholesky, tol=1e-06.\n",
            "[CV 2/5; 176/448] END C=10.0, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 176/448] START C=10.0, penalty=None, solver=newton-cholesky, tol=1e-06.\n",
            "[CV 3/5; 176/448] END C=10.0, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 176/448] START C=10.0, penalty=None, solver=newton-cholesky, tol=1e-06.\n",
            "[CV 4/5; 176/448] END C=10.0, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 176/448] START C=10.0, penalty=None, solver=newton-cholesky, tol=1e-06.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 176/448] END C=10.0, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 177/448] START C=100.0, penalty=l2, solver=newton-cg, tol=0.001........\n",
            "[CV 1/5; 177/448] END C=100.0, penalty=l2, solver=newton-cg, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 177/448] START C=100.0, penalty=l2, solver=newton-cg, tol=0.001........\n",
            "[CV 2/5; 177/448] END C=100.0, penalty=l2, solver=newton-cg, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 177/448] START C=100.0, penalty=l2, solver=newton-cg, tol=0.001........\n",
            "[CV 3/5; 177/448] END C=100.0, penalty=l2, solver=newton-cg, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 177/448] START C=100.0, penalty=l2, solver=newton-cg, tol=0.001........\n",
            "[CV 4/5; 177/448] END C=100.0, penalty=l2, solver=newton-cg, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 177/448] START C=100.0, penalty=l2, solver=newton-cg, tol=0.001........\n",
            "[CV 5/5; 177/448] END C=100.0, penalty=l2, solver=newton-cg, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 1/5; 178/448] START C=100.0, penalty=l2, solver=newton-cg, tol=0.0001.......\n",
            "[CV 1/5; 178/448] END C=100.0, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 178/448] START C=100.0, penalty=l2, solver=newton-cg, tol=0.0001.......\n",
            "[CV 2/5; 178/448] END C=100.0, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 178/448] START C=100.0, penalty=l2, solver=newton-cg, tol=0.0001.......\n",
            "[CV 3/5; 178/448] END C=100.0, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 178/448] START C=100.0, penalty=l2, solver=newton-cg, tol=0.0001.......\n",
            "[CV 4/5; 178/448] END C=100.0, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 178/448] START C=100.0, penalty=l2, solver=newton-cg, tol=0.0001.......\n",
            "[CV 5/5; 178/448] END C=100.0, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.980 total time=   0.0s\n",
            "[CV 1/5; 179/448] START C=100.0, penalty=l2, solver=newton-cg, tol=1e-05........\n",
            "[CV 1/5; 179/448] END C=100.0, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 179/448] START C=100.0, penalty=l2, solver=newton-cg, tol=1e-05........\n",
            "[CV 2/5; 179/448] END C=100.0, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 179/448] START C=100.0, penalty=l2, solver=newton-cg, tol=1e-05........\n",
            "[CV 3/5; 179/448] END C=100.0, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 179/448] START C=100.0, penalty=l2, solver=newton-cg, tol=1e-05........\n",
            "[CV 4/5; 179/448] END C=100.0, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 179/448] START C=100.0, penalty=l2, solver=newton-cg, tol=1e-05........\n",
            "[CV 5/5; 179/448] END C=100.0, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 1/5; 180/448] START C=100.0, penalty=l2, solver=newton-cg, tol=1e-06........\n",
            "[CV 1/5; 180/448] END C=100.0, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 180/448] START C=100.0, penalty=l2, solver=newton-cg, tol=1e-06........\n",
            "[CV 2/5; 180/448] END C=100.0, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 180/448] START C=100.0, penalty=l2, solver=newton-cg, tol=1e-06........\n",
            "[CV 3/5; 180/448] END C=100.0, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 180/448] START C=100.0, penalty=l2, solver=newton-cg, tol=1e-06........\n",
            "[CV 4/5; 180/448] END C=100.0, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 180/448] START C=100.0, penalty=l2, solver=newton-cg, tol=1e-06........\n",
            "[CV 5/5; 180/448] END C=100.0, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 1/5; 181/448] START C=100.0, penalty=l2, solver=newton-cholesky, tol=0.001..\n",
            "[CV 1/5; 181/448] END C=100.0, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 181/448] START C=100.0, penalty=l2, solver=newton-cholesky, tol=0.001..\n",
            "[CV 2/5; 181/448] END C=100.0, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 181/448] START C=100.0, penalty=l2, solver=newton-cholesky, tol=0.001..\n",
            "[CV 3/5; 181/448] END C=100.0, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 181/448] START C=100.0, penalty=l2, solver=newton-cholesky, tol=0.001..\n",
            "[CV 4/5; 181/448] END C=100.0, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 181/448] START C=100.0, penalty=l2, solver=newton-cholesky, tol=0.001..\n",
            "[CV 5/5; 181/448] END C=100.0, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 1/5; 182/448] START C=100.0, penalty=l2, solver=newton-cholesky, tol=0.0001.\n",
            "[CV 1/5; 182/448] END C=100.0, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 182/448] START C=100.0, penalty=l2, solver=newton-cholesky, tol=0.0001.\n",
            "[CV 2/5; 182/448] END C=100.0, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 182/448] START C=100.0, penalty=l2, solver=newton-cholesky, tol=0.0001.\n",
            "[CV 3/5; 182/448] END C=100.0, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 182/448] START C=100.0, penalty=l2, solver=newton-cholesky, tol=0.0001.\n",
            "[CV 4/5; 182/448] END C=100.0, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 182/448] START C=100.0, penalty=l2, solver=newton-cholesky, tol=0.0001.\n",
            "[CV 5/5; 182/448] END C=100.0, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.980 total time=   0.0s\n",
            "[CV 1/5; 183/448] START C=100.0, penalty=l2, solver=newton-cholesky, tol=1e-05..\n",
            "[CV 1/5; 183/448] END C=100.0, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 183/448] START C=100.0, penalty=l2, solver=newton-cholesky, tol=1e-05..\n",
            "[CV 2/5; 183/448] END C=100.0, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 183/448] START C=100.0, penalty=l2, solver=newton-cholesky, tol=1e-05..\n",
            "[CV 3/5; 183/448] END C=100.0, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 183/448] START C=100.0, penalty=l2, solver=newton-cholesky, tol=1e-05..\n",
            "[CV 4/5; 183/448] END C=100.0, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 183/448] START C=100.0, penalty=l2, solver=newton-cholesky, tol=1e-05..\n",
            "[CV 5/5; 183/448] END C=100.0, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 1/5; 184/448] START C=100.0, penalty=l2, solver=newton-cholesky, tol=1e-06..\n",
            "[CV 1/5; 184/448] END C=100.0, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 184/448] START C=100.0, penalty=l2, solver=newton-cholesky, tol=1e-06..\n",
            "[CV 2/5; 184/448] END C=100.0, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 184/448] START C=100.0, penalty=l2, solver=newton-cholesky, tol=1e-06..\n",
            "[CV 3/5; 184/448] END C=100.0, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 184/448] START C=100.0, penalty=l2, solver=newton-cholesky, tol=1e-06..\n",
            "[CV 4/5; 184/448] END C=100.0, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 184/448] START C=100.0, penalty=l2, solver=newton-cholesky, tol=1e-06..\n",
            "[CV 5/5; 184/448] END C=100.0, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 1/5; 185/448] START C=100.0, penalty=None, solver=newton-cg, tol=0.001......\n",
            "[CV 1/5; 185/448] END C=100.0, penalty=None, solver=newton-cg, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 185/448] START C=100.0, penalty=None, solver=newton-cg, tol=0.001......\n",
            "[CV 2/5; 185/448] END C=100.0, penalty=None, solver=newton-cg, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 185/448] START C=100.0, penalty=None, solver=newton-cg, tol=0.001......\n",
            "[CV 3/5; 185/448] END C=100.0, penalty=None, solver=newton-cg, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 185/448] START C=100.0, penalty=None, solver=newton-cg, tol=0.001......\n",
            "[CV 4/5; 185/448] END C=100.0, penalty=None, solver=newton-cg, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 185/448] START C=100.0, penalty=None, solver=newton-cg, tol=0.001......\n",
            "[CV 5/5; 185/448] END C=100.0, penalty=None, solver=newton-cg, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 186/448] START C=100.0, penalty=None, solver=newton-cg, tol=0.0001.....\n",
            "[CV 1/5; 186/448] END C=100.0, penalty=None, solver=newton-cg, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 186/448] START C=100.0, penalty=None, solver=newton-cg, tol=0.0001.....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 186/448] END C=100.0, penalty=None, solver=newton-cg, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 186/448] START C=100.0, penalty=None, solver=newton-cg, tol=0.0001.....\n",
            "[CV 3/5; 186/448] END C=100.0, penalty=None, solver=newton-cg, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 186/448] START C=100.0, penalty=None, solver=newton-cg, tol=0.0001.....\n",
            "[CV 4/5; 186/448] END C=100.0, penalty=None, solver=newton-cg, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 186/448] START C=100.0, penalty=None, solver=newton-cg, tol=0.0001.....\n",
            "[CV 5/5; 186/448] END C=100.0, penalty=None, solver=newton-cg, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 187/448] START C=100.0, penalty=None, solver=newton-cg, tol=1e-05......\n",
            "[CV 1/5; 187/448] END C=100.0, penalty=None, solver=newton-cg, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 187/448] START C=100.0, penalty=None, solver=newton-cg, tol=1e-05......\n",
            "[CV 2/5; 187/448] END C=100.0, penalty=None, solver=newton-cg, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 187/448] START C=100.0, penalty=None, solver=newton-cg, tol=1e-05......\n",
            "[CV 3/5; 187/448] END C=100.0, penalty=None, solver=newton-cg, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 187/448] START C=100.0, penalty=None, solver=newton-cg, tol=1e-05......\n",
            "[CV 4/5; 187/448] END C=100.0, penalty=None, solver=newton-cg, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 187/448] START C=100.0, penalty=None, solver=newton-cg, tol=1e-05......\n",
            "[CV 5/5; 187/448] END C=100.0, penalty=None, solver=newton-cg, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 188/448] START C=100.0, penalty=None, solver=newton-cg, tol=1e-06......\n",
            "[CV 1/5; 188/448] END C=100.0, penalty=None, solver=newton-cg, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 188/448] START C=100.0, penalty=None, solver=newton-cg, tol=1e-06......\n",
            "[CV 2/5; 188/448] END C=100.0, penalty=None, solver=newton-cg, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 188/448] START C=100.0, penalty=None, solver=newton-cg, tol=1e-06......\n",
            "[CV 3/5; 188/448] END C=100.0, penalty=None, solver=newton-cg, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 188/448] START C=100.0, penalty=None, solver=newton-cg, tol=1e-06......\n",
            "[CV 4/5; 188/448] END C=100.0, penalty=None, solver=newton-cg, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 188/448] START C=100.0, penalty=None, solver=newton-cg, tol=1e-06......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 188/448] END C=100.0, penalty=None, solver=newton-cg, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 189/448] START C=100.0, penalty=None, solver=newton-cholesky, tol=0.001\n",
            "[CV 1/5; 189/448] END C=100.0, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.968 total time=   0.0s\n",
            "[CV 2/5; 189/448] START C=100.0, penalty=None, solver=newton-cholesky, tol=0.001\n",
            "[CV 2/5; 189/448] END C=100.0, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 189/448] START C=100.0, penalty=None, solver=newton-cholesky, tol=0.001\n",
            "[CV 3/5; 189/448] END C=100.0, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 189/448] START C=100.0, penalty=None, solver=newton-cholesky, tol=0.001\n",
            "[CV 4/5; 189/448] END C=100.0, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 5/5; 189/448] START C=100.0, penalty=None, solver=newton-cholesky, tol=0.001\n",
            "[CV 5/5; 189/448] END C=100.0, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 190/448] START C=100.0, penalty=None, solver=newton-cholesky, tol=0.0001\n",
            "[CV 1/5; 190/448] END C=100.0, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 2/5; 190/448] START C=100.0, penalty=None, solver=newton-cholesky, tol=0.0001\n",
            "[CV 2/5; 190/448] END C=100.0, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 190/448] START C=100.0, penalty=None, solver=newton-cholesky, tol=0.0001\n",
            "[CV 3/5; 190/448] END C=100.0, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 190/448] START C=100.0, penalty=None, solver=newton-cholesky, tol=0.0001\n",
            "[CV 4/5; 190/448] END C=100.0, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 5/5; 190/448] START C=100.0, penalty=None, solver=newton-cholesky, tol=0.0001\n",
            "[CV 5/5; 190/448] END C=100.0, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 191/448] START C=100.0, penalty=None, solver=newton-cholesky, tol=1e-05\n",
            "[CV 1/5; 191/448] END C=100.0, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 191/448] START C=100.0, penalty=None, solver=newton-cholesky, tol=1e-05\n",
            "[CV 2/5; 191/448] END C=100.0, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 191/448] START C=100.0, penalty=None, solver=newton-cholesky, tol=1e-05\n",
            "[CV 3/5; 191/448] END C=100.0, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 191/448] START C=100.0, penalty=None, solver=newton-cholesky, tol=1e-05\n",
            "[CV 4/5; 191/448] END C=100.0, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 5/5; 191/448] START C=100.0, penalty=None, solver=newton-cholesky, tol=1e-05\n",
            "[CV 5/5; 191/448] END C=100.0, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 192/448] START C=100.0, penalty=None, solver=newton-cholesky, tol=1e-06\n",
            "[CV 1/5; 192/448] END C=100.0, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 192/448] START C=100.0, penalty=None, solver=newton-cholesky, tol=1e-06\n",
            "[CV 2/5; 192/448] END C=100.0, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 192/448] START C=100.0, penalty=None, solver=newton-cholesky, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 192/448] END C=100.0, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 192/448] START C=100.0, penalty=None, solver=newton-cholesky, tol=1e-06\n",
            "[CV 4/5; 192/448] END C=100.0, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 192/448] START C=100.0, penalty=None, solver=newton-cholesky, tol=1e-06\n",
            "[CV 5/5; 192/448] END C=100.0, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 193/448] START C=1000.0, penalty=l2, solver=newton-cg, tol=0.001.......\n",
            "[CV 1/5; 193/448] END C=1000.0, penalty=l2, solver=newton-cg, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 193/448] START C=1000.0, penalty=l2, solver=newton-cg, tol=0.001.......\n",
            "[CV 2/5; 193/448] END C=1000.0, penalty=l2, solver=newton-cg, tol=0.001;, score=0.992 total time=   0.0s\n",
            "[CV 3/5; 193/448] START C=1000.0, penalty=l2, solver=newton-cg, tol=0.001.......\n",
            "[CV 3/5; 193/448] END C=1000.0, penalty=l2, solver=newton-cg, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 4/5; 193/448] START C=1000.0, penalty=l2, solver=newton-cg, tol=0.001.......\n",
            "[CV 4/5; 193/448] END C=1000.0, penalty=l2, solver=newton-cg, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 193/448] START C=1000.0, penalty=l2, solver=newton-cg, tol=0.001.......\n",
            "[CV 5/5; 193/448] END C=1000.0, penalty=l2, solver=newton-cg, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 194/448] START C=1000.0, penalty=l2, solver=newton-cg, tol=0.0001......\n",
            "[CV 1/5; 194/448] END C=1000.0, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 194/448] START C=1000.0, penalty=l2, solver=newton-cg, tol=0.0001......\n",
            "[CV 2/5; 194/448] END C=1000.0, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.992 total time=   0.0s\n",
            "[CV 3/5; 194/448] START C=1000.0, penalty=l2, solver=newton-cg, tol=0.0001......\n",
            "[CV 3/5; 194/448] END C=1000.0, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.980 total time=   0.0s\n",
            "[CV 4/5; 194/448] START C=1000.0, penalty=l2, solver=newton-cg, tol=0.0001......\n",
            "[CV 4/5; 194/448] END C=1000.0, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 194/448] START C=1000.0, penalty=l2, solver=newton-cg, tol=0.0001......\n",
            "[CV 5/5; 194/448] END C=1000.0, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 195/448] START C=1000.0, penalty=l2, solver=newton-cg, tol=1e-05.......\n",
            "[CV 1/5; 195/448] END C=1000.0, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 195/448] START C=1000.0, penalty=l2, solver=newton-cg, tol=1e-05.......\n",
            "[CV 2/5; 195/448] END C=1000.0, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.992 total time=   0.0s\n",
            "[CV 3/5; 195/448] START C=1000.0, penalty=l2, solver=newton-cg, tol=1e-05.......\n",
            "[CV 3/5; 195/448] END C=1000.0, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 4/5; 195/448] START C=1000.0, penalty=l2, solver=newton-cg, tol=1e-05.......\n",
            "[CV 4/5; 195/448] END C=1000.0, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 195/448] START C=1000.0, penalty=l2, solver=newton-cg, tol=1e-05.......\n",
            "[CV 5/5; 195/448] END C=1000.0, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 196/448] START C=1000.0, penalty=l2, solver=newton-cg, tol=1e-06.......\n",
            "[CV 1/5; 196/448] END C=1000.0, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 196/448] START C=1000.0, penalty=l2, solver=newton-cg, tol=1e-06.......\n",
            "[CV 2/5; 196/448] END C=1000.0, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.992 total time=   0.0s\n",
            "[CV 3/5; 196/448] START C=1000.0, penalty=l2, solver=newton-cg, tol=1e-06.......\n",
            "[CV 3/5; 196/448] END C=1000.0, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 4/5; 196/448] START C=1000.0, penalty=l2, solver=newton-cg, tol=1e-06.......\n",
            "[CV 4/5; 196/448] END C=1000.0, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 196/448] START C=1000.0, penalty=l2, solver=newton-cg, tol=1e-06.......\n",
            "[CV 5/5; 196/448] END C=1000.0, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 197/448] START C=1000.0, penalty=l2, solver=newton-cholesky, tol=0.001.\n",
            "[CV 1/5; 197/448] END C=1000.0, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 197/448] START C=1000.0, penalty=l2, solver=newton-cholesky, tol=0.001.\n",
            "[CV 2/5; 197/448] END C=1000.0, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.992 total time=   0.0s\n",
            "[CV 3/5; 197/448] START C=1000.0, penalty=l2, solver=newton-cholesky, tol=0.001.\n",
            "[CV 3/5; 197/448] END C=1000.0, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 4/5; 197/448] START C=1000.0, penalty=l2, solver=newton-cholesky, tol=0.001.\n",
            "[CV 4/5; 197/448] END C=1000.0, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 197/448] START C=1000.0, penalty=l2, solver=newton-cholesky, tol=0.001.\n",
            "[CV 5/5; 197/448] END C=1000.0, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 198/448] START C=1000.0, penalty=l2, solver=newton-cholesky, tol=0.0001\n",
            "[CV 1/5; 198/448] END C=1000.0, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 198/448] START C=1000.0, penalty=l2, solver=newton-cholesky, tol=0.0001\n",
            "[CV 2/5; 198/448] END C=1000.0, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.992 total time=   0.0s\n",
            "[CV 3/5; 198/448] START C=1000.0, penalty=l2, solver=newton-cholesky, tol=0.0001\n",
            "[CV 3/5; 198/448] END C=1000.0, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.980 total time=   0.0s\n",
            "[CV 4/5; 198/448] START C=1000.0, penalty=l2, solver=newton-cholesky, tol=0.0001\n",
            "[CV 4/5; 198/448] END C=1000.0, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 198/448] START C=1000.0, penalty=l2, solver=newton-cholesky, tol=0.0001\n",
            "[CV 5/5; 198/448] END C=1000.0, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 199/448] START C=1000.0, penalty=l2, solver=newton-cholesky, tol=1e-05.\n",
            "[CV 1/5; 199/448] END C=1000.0, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 199/448] START C=1000.0, penalty=l2, solver=newton-cholesky, tol=1e-05.\n",
            "[CV 2/5; 199/448] END C=1000.0, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.992 total time=   0.0s\n",
            "[CV 3/5; 199/448] START C=1000.0, penalty=l2, solver=newton-cholesky, tol=1e-05.\n",
            "[CV 3/5; 199/448] END C=1000.0, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 4/5; 199/448] START C=1000.0, penalty=l2, solver=newton-cholesky, tol=1e-05.\n",
            "[CV 4/5; 199/448] END C=1000.0, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 199/448] START C=1000.0, penalty=l2, solver=newton-cholesky, tol=1e-05.\n",
            "[CV 5/5; 199/448] END C=1000.0, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 200/448] START C=1000.0, penalty=l2, solver=newton-cholesky, tol=1e-06.\n",
            "[CV 1/5; 200/448] END C=1000.0, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 200/448] START C=1000.0, penalty=l2, solver=newton-cholesky, tol=1e-06.\n",
            "[CV 2/5; 200/448] END C=1000.0, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.992 total time=   0.0s\n",
            "[CV 3/5; 200/448] START C=1000.0, penalty=l2, solver=newton-cholesky, tol=1e-06.\n",
            "[CV 3/5; 200/448] END C=1000.0, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 4/5; 200/448] START C=1000.0, penalty=l2, solver=newton-cholesky, tol=1e-06.\n",
            "[CV 4/5; 200/448] END C=1000.0, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 200/448] START C=1000.0, penalty=l2, solver=newton-cholesky, tol=1e-06.\n",
            "[CV 5/5; 200/448] END C=1000.0, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 201/448] START C=1000.0, penalty=None, solver=newton-cg, tol=0.001.....\n",
            "[CV 1/5; 201/448] END C=1000.0, penalty=None, solver=newton-cg, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 201/448] START C=1000.0, penalty=None, solver=newton-cg, tol=0.001.....\n",
            "[CV 2/5; 201/448] END C=1000.0, penalty=None, solver=newton-cg, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 201/448] START C=1000.0, penalty=None, solver=newton-cg, tol=0.001.....\n",
            "[CV 3/5; 201/448] END C=1000.0, penalty=None, solver=newton-cg, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 201/448] START C=1000.0, penalty=None, solver=newton-cg, tol=0.001.....\n",
            "[CV 4/5; 201/448] END C=1000.0, penalty=None, solver=newton-cg, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 201/448] START C=1000.0, penalty=None, solver=newton-cg, tol=0.001.....\n",
            "[CV 5/5; 201/448] END C=1000.0, penalty=None, solver=newton-cg, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 202/448] START C=1000.0, penalty=None, solver=newton-cg, tol=0.0001....\n",
            "[CV 1/5; 202/448] END C=1000.0, penalty=None, solver=newton-cg, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 202/448] START C=1000.0, penalty=None, solver=newton-cg, tol=0.0001....\n",
            "[CV 2/5; 202/448] END C=1000.0, penalty=None, solver=newton-cg, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 202/448] START C=1000.0, penalty=None, solver=newton-cg, tol=0.0001....\n",
            "[CV 3/5; 202/448] END C=1000.0, penalty=None, solver=newton-cg, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 202/448] START C=1000.0, penalty=None, solver=newton-cg, tol=0.0001....\n",
            "[CV 4/5; 202/448] END C=1000.0, penalty=None, solver=newton-cg, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 202/448] START C=1000.0, penalty=None, solver=newton-cg, tol=0.0001....\n",
            "[CV 5/5; 202/448] END C=1000.0, penalty=None, solver=newton-cg, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 203/448] START C=1000.0, penalty=None, solver=newton-cg, tol=1e-05.....\n",
            "[CV 1/5; 203/448] END C=1000.0, penalty=None, solver=newton-cg, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 203/448] START C=1000.0, penalty=None, solver=newton-cg, tol=1e-05.....\n",
            "[CV 2/5; 203/448] END C=1000.0, penalty=None, solver=newton-cg, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 203/448] START C=1000.0, penalty=None, solver=newton-cg, tol=1e-05.....\n",
            "[CV 3/5; 203/448] END C=1000.0, penalty=None, solver=newton-cg, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 203/448] START C=1000.0, penalty=None, solver=newton-cg, tol=1e-05.....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 203/448] END C=1000.0, penalty=None, solver=newton-cg, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 203/448] START C=1000.0, penalty=None, solver=newton-cg, tol=1e-05.....\n",
            "[CV 5/5; 203/448] END C=1000.0, penalty=None, solver=newton-cg, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 204/448] START C=1000.0, penalty=None, solver=newton-cg, tol=1e-06.....\n",
            "[CV 1/5; 204/448] END C=1000.0, penalty=None, solver=newton-cg, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 204/448] START C=1000.0, penalty=None, solver=newton-cg, tol=1e-06.....\n",
            "[CV 2/5; 204/448] END C=1000.0, penalty=None, solver=newton-cg, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 204/448] START C=1000.0, penalty=None, solver=newton-cg, tol=1e-06.....\n",
            "[CV 3/5; 204/448] END C=1000.0, penalty=None, solver=newton-cg, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 204/448] START C=1000.0, penalty=None, solver=newton-cg, tol=1e-06.....\n",
            "[CV 4/5; 204/448] END C=1000.0, penalty=None, solver=newton-cg, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 204/448] START C=1000.0, penalty=None, solver=newton-cg, tol=1e-06.....\n",
            "[CV 5/5; 204/448] END C=1000.0, penalty=None, solver=newton-cg, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 205/448] START C=1000.0, penalty=None, solver=newton-cholesky, tol=0.001\n",
            "[CV 1/5; 205/448] END C=1000.0, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.968 total time=   0.0s\n",
            "[CV 2/5; 205/448] START C=1000.0, penalty=None, solver=newton-cholesky, tol=0.001\n",
            "[CV 2/5; 205/448] END C=1000.0, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 205/448] START C=1000.0, penalty=None, solver=newton-cholesky, tol=0.001\n",
            "[CV 3/5; 205/448] END C=1000.0, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 205/448] START C=1000.0, penalty=None, solver=newton-cholesky, tol=0.001\n",
            "[CV 4/5; 205/448] END C=1000.0, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 5/5; 205/448] START C=1000.0, penalty=None, solver=newton-cholesky, tol=0.001\n",
            "[CV 5/5; 205/448] END C=1000.0, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 206/448] START C=1000.0, penalty=None, solver=newton-cholesky, tol=0.0001\n",
            "[CV 1/5; 206/448] END C=1000.0, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 2/5; 206/448] START C=1000.0, penalty=None, solver=newton-cholesky, tol=0.0001\n",
            "[CV 2/5; 206/448] END C=1000.0, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 206/448] START C=1000.0, penalty=None, solver=newton-cholesky, tol=0.0001\n",
            "[CV 3/5; 206/448] END C=1000.0, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 206/448] START C=1000.0, penalty=None, solver=newton-cholesky, tol=0.0001\n",
            "[CV 4/5; 206/448] END C=1000.0, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 5/5; 206/448] START C=1000.0, penalty=None, solver=newton-cholesky, tol=0.0001\n",
            "[CV 5/5; 206/448] END C=1000.0, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 207/448] START C=1000.0, penalty=None, solver=newton-cholesky, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 207/448] END C=1000.0, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 207/448] START C=1000.0, penalty=None, solver=newton-cholesky, tol=1e-05\n",
            "[CV 2/5; 207/448] END C=1000.0, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 207/448] START C=1000.0, penalty=None, solver=newton-cholesky, tol=1e-05\n",
            "[CV 3/5; 207/448] END C=1000.0, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 207/448] START C=1000.0, penalty=None, solver=newton-cholesky, tol=1e-05\n",
            "[CV 4/5; 207/448] END C=1000.0, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 5/5; 207/448] START C=1000.0, penalty=None, solver=newton-cholesky, tol=1e-05\n",
            "[CV 5/5; 207/448] END C=1000.0, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 208/448] START C=1000.0, penalty=None, solver=newton-cholesky, tol=1e-06\n",
            "[CV 1/5; 208/448] END C=1000.0, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 208/448] START C=1000.0, penalty=None, solver=newton-cholesky, tol=1e-06\n",
            "[CV 2/5; 208/448] END C=1000.0, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 208/448] START C=1000.0, penalty=None, solver=newton-cholesky, tol=1e-06\n",
            "[CV 3/5; 208/448] END C=1000.0, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 208/448] START C=1000.0, penalty=None, solver=newton-cholesky, tol=1e-06\n",
            "[CV 4/5; 208/448] END C=1000.0, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 208/448] START C=1000.0, penalty=None, solver=newton-cholesky, tol=1e-06\n",
            "[CV 5/5; 208/448] END C=1000.0, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 209/448] START C=10000.0, penalty=l2, solver=newton-cg, tol=0.001......\n",
            "[CV 1/5; 209/448] END C=10000.0, penalty=l2, solver=newton-cg, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 209/448] START C=10000.0, penalty=l2, solver=newton-cg, tol=0.001......\n",
            "[CV 2/5; 209/448] END C=10000.0, penalty=l2, solver=newton-cg, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 209/448] START C=10000.0, penalty=l2, solver=newton-cg, tol=0.001......\n",
            "[CV 3/5; 209/448] END C=10000.0, penalty=l2, solver=newton-cg, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 209/448] START C=10000.0, penalty=l2, solver=newton-cg, tol=0.001......\n",
            "[CV 4/5; 209/448] END C=10000.0, penalty=l2, solver=newton-cg, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 209/448] START C=10000.0, penalty=l2, solver=newton-cg, tol=0.001......\n",
            "[CV 5/5; 209/448] END C=10000.0, penalty=l2, solver=newton-cg, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 210/448] START C=10000.0, penalty=l2, solver=newton-cg, tol=0.0001.....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 210/448] END C=10000.0, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 210/448] START C=10000.0, penalty=l2, solver=newton-cg, tol=0.0001.....\n",
            "[CV 2/5; 210/448] END C=10000.0, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 210/448] START C=10000.0, penalty=l2, solver=newton-cg, tol=0.0001.....\n",
            "[CV 3/5; 210/448] END C=10000.0, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 210/448] START C=10000.0, penalty=l2, solver=newton-cg, tol=0.0001.....\n",
            "[CV 4/5; 210/448] END C=10000.0, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 210/448] START C=10000.0, penalty=l2, solver=newton-cg, tol=0.0001.....\n",
            "[CV 5/5; 210/448] END C=10000.0, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 211/448] START C=10000.0, penalty=l2, solver=newton-cg, tol=1e-05......\n",
            "[CV 1/5; 211/448] END C=10000.0, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 211/448] START C=10000.0, penalty=l2, solver=newton-cg, tol=1e-05......\n",
            "[CV 2/5; 211/448] END C=10000.0, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 211/448] START C=10000.0, penalty=l2, solver=newton-cg, tol=1e-05......\n",
            "[CV 3/5; 211/448] END C=10000.0, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 211/448] START C=10000.0, penalty=l2, solver=newton-cg, tol=1e-05......\n",
            "[CV 4/5; 211/448] END C=10000.0, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 211/448] START C=10000.0, penalty=l2, solver=newton-cg, tol=1e-05......\n",
            "[CV 5/5; 211/448] END C=10000.0, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 212/448] START C=10000.0, penalty=l2, solver=newton-cg, tol=1e-06......\n",
            "[CV 1/5; 212/448] END C=10000.0, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 212/448] START C=10000.0, penalty=l2, solver=newton-cg, tol=1e-06......\n",
            "[CV 2/5; 212/448] END C=10000.0, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 212/448] START C=10000.0, penalty=l2, solver=newton-cg, tol=1e-06......\n",
            "[CV 3/5; 212/448] END C=10000.0, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 212/448] START C=10000.0, penalty=l2, solver=newton-cg, tol=1e-06......\n",
            "[CV 4/5; 212/448] END C=10000.0, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 212/448] START C=10000.0, penalty=l2, solver=newton-cg, tol=1e-06......\n",
            "[CV 5/5; 212/448] END C=10000.0, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 213/448] START C=10000.0, penalty=l2, solver=newton-cholesky, tol=0.001\n",
            "[CV 1/5; 213/448] END C=10000.0, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 213/448] START C=10000.0, penalty=l2, solver=newton-cholesky, tol=0.001\n",
            "[CV 2/5; 213/448] END C=10000.0, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 213/448] START C=10000.0, penalty=l2, solver=newton-cholesky, tol=0.001\n",
            "[CV 3/5; 213/448] END C=10000.0, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 213/448] START C=10000.0, penalty=l2, solver=newton-cholesky, tol=0.001\n",
            "[CV 4/5; 213/448] END C=10000.0, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 213/448] START C=10000.0, penalty=l2, solver=newton-cholesky, tol=0.001\n",
            "[CV 5/5; 213/448] END C=10000.0, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 214/448] START C=10000.0, penalty=l2, solver=newton-cholesky, tol=0.0001\n",
            "[CV 1/5; 214/448] END C=10000.0, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 214/448] START C=10000.0, penalty=l2, solver=newton-cholesky, tol=0.0001\n",
            "[CV 2/5; 214/448] END C=10000.0, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 214/448] START C=10000.0, penalty=l2, solver=newton-cholesky, tol=0.0001\n",
            "[CV 3/5; 214/448] END C=10000.0, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 214/448] START C=10000.0, penalty=l2, solver=newton-cholesky, tol=0.0001\n",
            "[CV 4/5; 214/448] END C=10000.0, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 214/448] START C=10000.0, penalty=l2, solver=newton-cholesky, tol=0.0001\n",
            "[CV 5/5; 214/448] END C=10000.0, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 215/448] START C=10000.0, penalty=l2, solver=newton-cholesky, tol=1e-05\n",
            "[CV 1/5; 215/448] END C=10000.0, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 215/448] START C=10000.0, penalty=l2, solver=newton-cholesky, tol=1e-05\n",
            "[CV 2/5; 215/448] END C=10000.0, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 215/448] START C=10000.0, penalty=l2, solver=newton-cholesky, tol=1e-05\n",
            "[CV 3/5; 215/448] END C=10000.0, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 215/448] START C=10000.0, penalty=l2, solver=newton-cholesky, tol=1e-05\n",
            "[CV 4/5; 215/448] END C=10000.0, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 215/448] START C=10000.0, penalty=l2, solver=newton-cholesky, tol=1e-05\n",
            "[CV 5/5; 215/448] END C=10000.0, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 216/448] START C=10000.0, penalty=l2, solver=newton-cholesky, tol=1e-06\n",
            "[CV 1/5; 216/448] END C=10000.0, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 216/448] START C=10000.0, penalty=l2, solver=newton-cholesky, tol=1e-06\n",
            "[CV 2/5; 216/448] END C=10000.0, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 216/448] START C=10000.0, penalty=l2, solver=newton-cholesky, tol=1e-06\n",
            "[CV 3/5; 216/448] END C=10000.0, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 216/448] START C=10000.0, penalty=l2, solver=newton-cholesky, tol=1e-06\n",
            "[CV 4/5; 216/448] END C=10000.0, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 216/448] START C=10000.0, penalty=l2, solver=newton-cholesky, tol=1e-06\n",
            "[CV 5/5; 216/448] END C=10000.0, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 217/448] START C=10000.0, penalty=None, solver=newton-cg, tol=0.001....\n",
            "[CV 1/5; 217/448] END C=10000.0, penalty=None, solver=newton-cg, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 217/448] START C=10000.0, penalty=None, solver=newton-cg, tol=0.001....\n",
            "[CV 2/5; 217/448] END C=10000.0, penalty=None, solver=newton-cg, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 217/448] START C=10000.0, penalty=None, solver=newton-cg, tol=0.001....\n",
            "[CV 3/5; 217/448] END C=10000.0, penalty=None, solver=newton-cg, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 217/448] START C=10000.0, penalty=None, solver=newton-cg, tol=0.001....\n",
            "[CV 4/5; 217/448] END C=10000.0, penalty=None, solver=newton-cg, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 217/448] START C=10000.0, penalty=None, solver=newton-cg, tol=0.001....\n",
            "[CV 5/5; 217/448] END C=10000.0, penalty=None, solver=newton-cg, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 218/448] START C=10000.0, penalty=None, solver=newton-cg, tol=0.0001...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 218/448] END C=10000.0, penalty=None, solver=newton-cg, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 218/448] START C=10000.0, penalty=None, solver=newton-cg, tol=0.0001...\n",
            "[CV 2/5; 218/448] END C=10000.0, penalty=None, solver=newton-cg, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 218/448] START C=10000.0, penalty=None, solver=newton-cg, tol=0.0001...\n",
            "[CV 3/5; 218/448] END C=10000.0, penalty=None, solver=newton-cg, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 218/448] START C=10000.0, penalty=None, solver=newton-cg, tol=0.0001...\n",
            "[CV 4/5; 218/448] END C=10000.0, penalty=None, solver=newton-cg, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 218/448] START C=10000.0, penalty=None, solver=newton-cg, tol=0.0001...\n",
            "[CV 5/5; 218/448] END C=10000.0, penalty=None, solver=newton-cg, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 219/448] START C=10000.0, penalty=None, solver=newton-cg, tol=1e-05....\n",
            "[CV 1/5; 219/448] END C=10000.0, penalty=None, solver=newton-cg, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 219/448] START C=10000.0, penalty=None, solver=newton-cg, tol=1e-05....\n",
            "[CV 2/5; 219/448] END C=10000.0, penalty=None, solver=newton-cg, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 219/448] START C=10000.0, penalty=None, solver=newton-cg, tol=1e-05....\n",
            "[CV 3/5; 219/448] END C=10000.0, penalty=None, solver=newton-cg, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 219/448] START C=10000.0, penalty=None, solver=newton-cg, tol=1e-05....\n",
            "[CV 4/5; 219/448] END C=10000.0, penalty=None, solver=newton-cg, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 219/448] START C=10000.0, penalty=None, solver=newton-cg, tol=1e-05....\n",
            "[CV 5/5; 219/448] END C=10000.0, penalty=None, solver=newton-cg, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 220/448] START C=10000.0, penalty=None, solver=newton-cg, tol=1e-06....\n",
            "[CV 1/5; 220/448] END C=10000.0, penalty=None, solver=newton-cg, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 220/448] START C=10000.0, penalty=None, solver=newton-cg, tol=1e-06....\n",
            "[CV 2/5; 220/448] END C=10000.0, penalty=None, solver=newton-cg, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 220/448] START C=10000.0, penalty=None, solver=newton-cg, tol=1e-06....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 220/448] END C=10000.0, penalty=None, solver=newton-cg, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 220/448] START C=10000.0, penalty=None, solver=newton-cg, tol=1e-06....\n",
            "[CV 4/5; 220/448] END C=10000.0, penalty=None, solver=newton-cg, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 220/448] START C=10000.0, penalty=None, solver=newton-cg, tol=1e-06....\n",
            "[CV 5/5; 220/448] END C=10000.0, penalty=None, solver=newton-cg, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 221/448] START C=10000.0, penalty=None, solver=newton-cholesky, tol=0.001\n",
            "[CV 1/5; 221/448] END C=10000.0, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.968 total time=   0.0s\n",
            "[CV 2/5; 221/448] START C=10000.0, penalty=None, solver=newton-cholesky, tol=0.001\n",
            "[CV 2/5; 221/448] END C=10000.0, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 221/448] START C=10000.0, penalty=None, solver=newton-cholesky, tol=0.001\n",
            "[CV 3/5; 221/448] END C=10000.0, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 221/448] START C=10000.0, penalty=None, solver=newton-cholesky, tol=0.001\n",
            "[CV 4/5; 221/448] END C=10000.0, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 5/5; 221/448] START C=10000.0, penalty=None, solver=newton-cholesky, tol=0.001\n",
            "[CV 5/5; 221/448] END C=10000.0, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 222/448] START C=10000.0, penalty=None, solver=newton-cholesky, tol=0.0001\n",
            "[CV 1/5; 222/448] END C=10000.0, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 2/5; 222/448] START C=10000.0, penalty=None, solver=newton-cholesky, tol=0.0001\n",
            "[CV 2/5; 222/448] END C=10000.0, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 222/448] START C=10000.0, penalty=None, solver=newton-cholesky, tol=0.0001\n",
            "[CV 3/5; 222/448] END C=10000.0, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 222/448] START C=10000.0, penalty=None, solver=newton-cholesky, tol=0.0001\n",
            "[CV 4/5; 222/448] END C=10000.0, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 5/5; 222/448] START C=10000.0, penalty=None, solver=newton-cholesky, tol=0.0001\n",
            "[CV 5/5; 222/448] END C=10000.0, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 223/448] START C=10000.0, penalty=None, solver=newton-cholesky, tol=1e-05\n",
            "[CV 1/5; 223/448] END C=10000.0, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 223/448] START C=10000.0, penalty=None, solver=newton-cholesky, tol=1e-05\n",
            "[CV 2/5; 223/448] END C=10000.0, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 223/448] START C=10000.0, penalty=None, solver=newton-cholesky, tol=1e-05\n",
            "[CV 3/5; 223/448] END C=10000.0, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 223/448] START C=10000.0, penalty=None, solver=newton-cholesky, tol=1e-05\n",
            "[CV 4/5; 223/448] END C=10000.0, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 5/5; 223/448] START C=10000.0, penalty=None, solver=newton-cholesky, tol=1e-05\n",
            "[CV 5/5; 223/448] END C=10000.0, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 224/448] START C=10000.0, penalty=None, solver=newton-cholesky, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 224/448] END C=10000.0, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 224/448] START C=10000.0, penalty=None, solver=newton-cholesky, tol=1e-06\n",
            "[CV 2/5; 224/448] END C=10000.0, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 224/448] START C=10000.0, penalty=None, solver=newton-cholesky, tol=1e-06\n",
            "[CV 3/5; 224/448] END C=10000.0, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 224/448] START C=10000.0, penalty=None, solver=newton-cholesky, tol=1e-06\n",
            "[CV 4/5; 224/448] END C=10000.0, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 224/448] START C=10000.0, penalty=None, solver=newton-cholesky, tol=1e-06\n",
            "[CV 5/5; 224/448] END C=10000.0, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 225/448] START C=100000.0, penalty=l2, solver=newton-cg, tol=0.001.....\n",
            "[CV 1/5; 225/448] END C=100000.0, penalty=l2, solver=newton-cg, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 225/448] START C=100000.0, penalty=l2, solver=newton-cg, tol=0.001.....\n",
            "[CV 2/5; 225/448] END C=100000.0, penalty=l2, solver=newton-cg, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 225/448] START C=100000.0, penalty=l2, solver=newton-cg, tol=0.001.....\n",
            "[CV 3/5; 225/448] END C=100000.0, penalty=l2, solver=newton-cg, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 225/448] START C=100000.0, penalty=l2, solver=newton-cg, tol=0.001.....\n",
            "[CV 4/5; 225/448] END C=100000.0, penalty=l2, solver=newton-cg, tol=0.001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 225/448] START C=100000.0, penalty=l2, solver=newton-cg, tol=0.001.....\n",
            "[CV 5/5; 225/448] END C=100000.0, penalty=l2, solver=newton-cg, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 226/448] START C=100000.0, penalty=l2, solver=newton-cg, tol=0.0001....\n",
            "[CV 1/5; 226/448] END C=100000.0, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 226/448] START C=100000.0, penalty=l2, solver=newton-cg, tol=0.0001....\n",
            "[CV 2/5; 226/448] END C=100000.0, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 226/448] START C=100000.0, penalty=l2, solver=newton-cg, tol=0.0001....\n",
            "[CV 3/5; 226/448] END C=100000.0, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 226/448] START C=100000.0, penalty=l2, solver=newton-cg, tol=0.0001....\n",
            "[CV 4/5; 226/448] END C=100000.0, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 226/448] START C=100000.0, penalty=l2, solver=newton-cg, tol=0.0001....\n",
            "[CV 5/5; 226/448] END C=100000.0, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 227/448] START C=100000.0, penalty=l2, solver=newton-cg, tol=1e-05.....\n",
            "[CV 1/5; 227/448] END C=100000.0, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 227/448] START C=100000.0, penalty=l2, solver=newton-cg, tol=1e-05.....\n",
            "[CV 2/5; 227/448] END C=100000.0, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 227/448] START C=100000.0, penalty=l2, solver=newton-cg, tol=1e-05.....\n",
            "[CV 3/5; 227/448] END C=100000.0, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 227/448] START C=100000.0, penalty=l2, solver=newton-cg, tol=1e-05.....\n",
            "[CV 4/5; 227/448] END C=100000.0, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 227/448] START C=100000.0, penalty=l2, solver=newton-cg, tol=1e-05.....\n",
            "[CV 5/5; 227/448] END C=100000.0, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 228/448] START C=100000.0, penalty=l2, solver=newton-cg, tol=1e-06.....\n",
            "[CV 1/5; 228/448] END C=100000.0, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 228/448] START C=100000.0, penalty=l2, solver=newton-cg, tol=1e-06.....\n",
            "[CV 2/5; 228/448] END C=100000.0, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 228/448] START C=100000.0, penalty=l2, solver=newton-cg, tol=1e-06.....\n",
            "[CV 3/5; 228/448] END C=100000.0, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 228/448] START C=100000.0, penalty=l2, solver=newton-cg, tol=1e-06.....\n",
            "[CV 4/5; 228/448] END C=100000.0, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 228/448] START C=100000.0, penalty=l2, solver=newton-cg, tol=1e-06.....\n",
            "[CV 5/5; 228/448] END C=100000.0, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 229/448] START C=100000.0, penalty=l2, solver=newton-cholesky, tol=0.001\n",
            "[CV 1/5; 229/448] END C=100000.0, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 229/448] START C=100000.0, penalty=l2, solver=newton-cholesky, tol=0.001\n",
            "[CV 2/5; 229/448] END C=100000.0, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 229/448] START C=100000.0, penalty=l2, solver=newton-cholesky, tol=0.001\n",
            "[CV 3/5; 229/448] END C=100000.0, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 229/448] START C=100000.0, penalty=l2, solver=newton-cholesky, tol=0.001\n",
            "[CV 4/5; 229/448] END C=100000.0, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 229/448] START C=100000.0, penalty=l2, solver=newton-cholesky, tol=0.001\n",
            "[CV 5/5; 229/448] END C=100000.0, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 230/448] START C=100000.0, penalty=l2, solver=newton-cholesky, tol=0.0001\n",
            "[CV 1/5; 230/448] END C=100000.0, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 230/448] START C=100000.0, penalty=l2, solver=newton-cholesky, tol=0.0001\n",
            "[CV 2/5; 230/448] END C=100000.0, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 230/448] START C=100000.0, penalty=l2, solver=newton-cholesky, tol=0.0001\n",
            "[CV 3/5; 230/448] END C=100000.0, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 230/448] START C=100000.0, penalty=l2, solver=newton-cholesky, tol=0.0001\n",
            "[CV 4/5; 230/448] END C=100000.0, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 230/448] START C=100000.0, penalty=l2, solver=newton-cholesky, tol=0.0001\n",
            "[CV 5/5; 230/448] END C=100000.0, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 231/448] START C=100000.0, penalty=l2, solver=newton-cholesky, tol=1e-05\n",
            "[CV 1/5; 231/448] END C=100000.0, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 231/448] START C=100000.0, penalty=l2, solver=newton-cholesky, tol=1e-05\n",
            "[CV 2/5; 231/448] END C=100000.0, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 231/448] START C=100000.0, penalty=l2, solver=newton-cholesky, tol=1e-05\n",
            "[CV 3/5; 231/448] END C=100000.0, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 231/448] START C=100000.0, penalty=l2, solver=newton-cholesky, tol=1e-05\n",
            "[CV 4/5; 231/448] END C=100000.0, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 231/448] START C=100000.0, penalty=l2, solver=newton-cholesky, tol=1e-05\n",
            "[CV 5/5; 231/448] END C=100000.0, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 232/448] START C=100000.0, penalty=l2, solver=newton-cholesky, tol=1e-06\n",
            "[CV 1/5; 232/448] END C=100000.0, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 232/448] START C=100000.0, penalty=l2, solver=newton-cholesky, tol=1e-06\n",
            "[CV 2/5; 232/448] END C=100000.0, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 232/448] START C=100000.0, penalty=l2, solver=newton-cholesky, tol=1e-06\n",
            "[CV 3/5; 232/448] END C=100000.0, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 232/448] START C=100000.0, penalty=l2, solver=newton-cholesky, tol=1e-06\n",
            "[CV 4/5; 232/448] END C=100000.0, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.980 total time=   0.0s\n",
            "[CV 5/5; 232/448] START C=100000.0, penalty=l2, solver=newton-cholesky, tol=1e-06\n",
            "[CV 5/5; 232/448] END C=100000.0, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 233/448] START C=100000.0, penalty=None, solver=newton-cg, tol=0.001...\n",
            "[CV 1/5; 233/448] END C=100000.0, penalty=None, solver=newton-cg, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 233/448] START C=100000.0, penalty=None, solver=newton-cg, tol=0.001...\n",
            "[CV 2/5; 233/448] END C=100000.0, penalty=None, solver=newton-cg, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 233/448] START C=100000.0, penalty=None, solver=newton-cg, tol=0.001...\n",
            "[CV 3/5; 233/448] END C=100000.0, penalty=None, solver=newton-cg, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 233/448] START C=100000.0, penalty=None, solver=newton-cg, tol=0.001...\n",
            "[CV 4/5; 233/448] END C=100000.0, penalty=None, solver=newton-cg, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 233/448] START C=100000.0, penalty=None, solver=newton-cg, tol=0.001...\n",
            "[CV 5/5; 233/448] END C=100000.0, penalty=None, solver=newton-cg, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 234/448] START C=100000.0, penalty=None, solver=newton-cg, tol=0.0001..\n",
            "[CV 1/5; 234/448] END C=100000.0, penalty=None, solver=newton-cg, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 234/448] START C=100000.0, penalty=None, solver=newton-cg, tol=0.0001..\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 234/448] END C=100000.0, penalty=None, solver=newton-cg, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 234/448] START C=100000.0, penalty=None, solver=newton-cg, tol=0.0001..\n",
            "[CV 3/5; 234/448] END C=100000.0, penalty=None, solver=newton-cg, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 234/448] START C=100000.0, penalty=None, solver=newton-cg, tol=0.0001..\n",
            "[CV 4/5; 234/448] END C=100000.0, penalty=None, solver=newton-cg, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 234/448] START C=100000.0, penalty=None, solver=newton-cg, tol=0.0001..\n",
            "[CV 5/5; 234/448] END C=100000.0, penalty=None, solver=newton-cg, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 235/448] START C=100000.0, penalty=None, solver=newton-cg, tol=1e-05...\n",
            "[CV 1/5; 235/448] END C=100000.0, penalty=None, solver=newton-cg, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 235/448] START C=100000.0, penalty=None, solver=newton-cg, tol=1e-05...\n",
            "[CV 2/5; 235/448] END C=100000.0, penalty=None, solver=newton-cg, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 235/448] START C=100000.0, penalty=None, solver=newton-cg, tol=1e-05...\n",
            "[CV 3/5; 235/448] END C=100000.0, penalty=None, solver=newton-cg, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 235/448] START C=100000.0, penalty=None, solver=newton-cg, tol=1e-05...\n",
            "[CV 4/5; 235/448] END C=100000.0, penalty=None, solver=newton-cg, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 235/448] START C=100000.0, penalty=None, solver=newton-cg, tol=1e-05...\n",
            "[CV 5/5; 235/448] END C=100000.0, penalty=None, solver=newton-cg, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 236/448] START C=100000.0, penalty=None, solver=newton-cg, tol=1e-06...\n",
            "[CV 1/5; 236/448] END C=100000.0, penalty=None, solver=newton-cg, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 236/448] START C=100000.0, penalty=None, solver=newton-cg, tol=1e-06...\n",
            "[CV 2/5; 236/448] END C=100000.0, penalty=None, solver=newton-cg, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 236/448] START C=100000.0, penalty=None, solver=newton-cg, tol=1e-06...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 236/448] END C=100000.0, penalty=None, solver=newton-cg, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 236/448] START C=100000.0, penalty=None, solver=newton-cg, tol=1e-06...\n",
            "[CV 4/5; 236/448] END C=100000.0, penalty=None, solver=newton-cg, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 236/448] START C=100000.0, penalty=None, solver=newton-cg, tol=1e-06...\n",
            "[CV 5/5; 236/448] END C=100000.0, penalty=None, solver=newton-cg, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 237/448] START C=100000.0, penalty=None, solver=newton-cholesky, tol=0.001\n",
            "[CV 1/5; 237/448] END C=100000.0, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.968 total time=   0.0s\n",
            "[CV 2/5; 237/448] START C=100000.0, penalty=None, solver=newton-cholesky, tol=0.001\n",
            "[CV 2/5; 237/448] END C=100000.0, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 237/448] START C=100000.0, penalty=None, solver=newton-cholesky, tol=0.001\n",
            "[CV 3/5; 237/448] END C=100000.0, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 237/448] START C=100000.0, penalty=None, solver=newton-cholesky, tol=0.001\n",
            "[CV 4/5; 237/448] END C=100000.0, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 5/5; 237/448] START C=100000.0, penalty=None, solver=newton-cholesky, tol=0.001\n",
            "[CV 5/5; 237/448] END C=100000.0, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 238/448] START C=100000.0, penalty=None, solver=newton-cholesky, tol=0.0001\n",
            "[CV 1/5; 238/448] END C=100000.0, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 2/5; 238/448] START C=100000.0, penalty=None, solver=newton-cholesky, tol=0.0001\n",
            "[CV 2/5; 238/448] END C=100000.0, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 238/448] START C=100000.0, penalty=None, solver=newton-cholesky, tol=0.0001\n",
            "[CV 3/5; 238/448] END C=100000.0, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 238/448] START C=100000.0, penalty=None, solver=newton-cholesky, tol=0.0001\n",
            "[CV 4/5; 238/448] END C=100000.0, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 5/5; 238/448] START C=100000.0, penalty=None, solver=newton-cholesky, tol=0.0001\n",
            "[CV 5/5; 238/448] END C=100000.0, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 239/448] START C=100000.0, penalty=None, solver=newton-cholesky, tol=1e-05\n",
            "[CV 1/5; 239/448] END C=100000.0, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 239/448] START C=100000.0, penalty=None, solver=newton-cholesky, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 239/448] END C=100000.0, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 239/448] START C=100000.0, penalty=None, solver=newton-cholesky, tol=1e-05\n",
            "[CV 3/5; 239/448] END C=100000.0, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 239/448] START C=100000.0, penalty=None, solver=newton-cholesky, tol=1e-05\n",
            "[CV 4/5; 239/448] END C=100000.0, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 5/5; 239/448] START C=100000.0, penalty=None, solver=newton-cholesky, tol=1e-05\n",
            "[CV 5/5; 239/448] END C=100000.0, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 240/448] START C=100000.0, penalty=None, solver=newton-cholesky, tol=1e-06\n",
            "[CV 1/5; 240/448] END C=100000.0, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 240/448] START C=100000.0, penalty=None, solver=newton-cholesky, tol=1e-06\n",
            "[CV 2/5; 240/448] END C=100000.0, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 240/448] START C=100000.0, penalty=None, solver=newton-cholesky, tol=1e-06\n",
            "[CV 3/5; 240/448] END C=100000.0, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 240/448] START C=100000.0, penalty=None, solver=newton-cholesky, tol=1e-06\n",
            "[CV 4/5; 240/448] END C=100000.0, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 240/448] START C=100000.0, penalty=None, solver=newton-cholesky, tol=1e-06\n",
            "[CV 5/5; 240/448] END C=100000.0, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 241/448] START C=1000000.0, penalty=l2, solver=newton-cg, tol=0.001....\n",
            "[CV 1/5; 241/448] END C=1000000.0, penalty=l2, solver=newton-cg, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 241/448] START C=1000000.0, penalty=l2, solver=newton-cg, tol=0.001....\n",
            "[CV 2/5; 241/448] END C=1000000.0, penalty=l2, solver=newton-cg, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 241/448] START C=1000000.0, penalty=l2, solver=newton-cg, tol=0.001....\n",
            "[CV 3/5; 241/448] END C=1000000.0, penalty=l2, solver=newton-cg, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 241/448] START C=1000000.0, penalty=l2, solver=newton-cg, tol=0.001....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 241/448] END C=1000000.0, penalty=l2, solver=newton-cg, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 241/448] START C=1000000.0, penalty=l2, solver=newton-cg, tol=0.001....\n",
            "[CV 5/5; 241/448] END C=1000000.0, penalty=l2, solver=newton-cg, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 242/448] START C=1000000.0, penalty=l2, solver=newton-cg, tol=0.0001...\n",
            "[CV 1/5; 242/448] END C=1000000.0, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 242/448] START C=1000000.0, penalty=l2, solver=newton-cg, tol=0.0001...\n",
            "[CV 2/5; 242/448] END C=1000000.0, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 242/448] START C=1000000.0, penalty=l2, solver=newton-cg, tol=0.0001...\n",
            "[CV 3/5; 242/448] END C=1000000.0, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 242/448] START C=1000000.0, penalty=l2, solver=newton-cg, tol=0.0001...\n",
            "[CV 4/5; 242/448] END C=1000000.0, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 242/448] START C=1000000.0, penalty=l2, solver=newton-cg, tol=0.0001...\n",
            "[CV 5/5; 242/448] END C=1000000.0, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 243/448] START C=1000000.0, penalty=l2, solver=newton-cg, tol=1e-05....\n",
            "[CV 1/5; 243/448] END C=1000000.0, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 243/448] START C=1000000.0, penalty=l2, solver=newton-cg, tol=1e-05....\n",
            "[CV 2/5; 243/448] END C=1000000.0, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 243/448] START C=1000000.0, penalty=l2, solver=newton-cg, tol=1e-05....\n",
            "[CV 3/5; 243/448] END C=1000000.0, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 243/448] START C=1000000.0, penalty=l2, solver=newton-cg, tol=1e-05....\n",
            "[CV 4/5; 243/448] END C=1000000.0, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 243/448] START C=1000000.0, penalty=l2, solver=newton-cg, tol=1e-05....\n",
            "[CV 5/5; 243/448] END C=1000000.0, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 244/448] START C=1000000.0, penalty=l2, solver=newton-cg, tol=1e-06....\n",
            "[CV 1/5; 244/448] END C=1000000.0, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 244/448] START C=1000000.0, penalty=l2, solver=newton-cg, tol=1e-06....\n",
            "[CV 2/5; 244/448] END C=1000000.0, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 244/448] START C=1000000.0, penalty=l2, solver=newton-cg, tol=1e-06....\n",
            "[CV 3/5; 244/448] END C=1000000.0, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 244/448] START C=1000000.0, penalty=l2, solver=newton-cg, tol=1e-06....\n",
            "[CV 4/5; 244/448] END C=1000000.0, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 244/448] START C=1000000.0, penalty=l2, solver=newton-cg, tol=1e-06....\n",
            "[CV 5/5; 244/448] END C=1000000.0, penalty=l2, solver=newton-cg, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 245/448] START C=1000000.0, penalty=l2, solver=newton-cholesky, tol=0.001\n",
            "[CV 1/5; 245/448] END C=1000000.0, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 245/448] START C=1000000.0, penalty=l2, solver=newton-cholesky, tol=0.001\n",
            "[CV 2/5; 245/448] END C=1000000.0, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 245/448] START C=1000000.0, penalty=l2, solver=newton-cholesky, tol=0.001\n",
            "[CV 3/5; 245/448] END C=1000000.0, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 245/448] START C=1000000.0, penalty=l2, solver=newton-cholesky, tol=0.001\n",
            "[CV 4/5; 245/448] END C=1000000.0, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 245/448] START C=1000000.0, penalty=l2, solver=newton-cholesky, tol=0.001\n",
            "[CV 5/5; 245/448] END C=1000000.0, penalty=l2, solver=newton-cholesky, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 246/448] START C=1000000.0, penalty=l2, solver=newton-cholesky, tol=0.0001\n",
            "[CV 1/5; 246/448] END C=1000000.0, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 246/448] START C=1000000.0, penalty=l2, solver=newton-cholesky, tol=0.0001\n",
            "[CV 2/5; 246/448] END C=1000000.0, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 246/448] START C=1000000.0, penalty=l2, solver=newton-cholesky, tol=0.0001\n",
            "[CV 3/5; 246/448] END C=1000000.0, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 246/448] START C=1000000.0, penalty=l2, solver=newton-cholesky, tol=0.0001\n",
            "[CV 4/5; 246/448] END C=1000000.0, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 246/448] START C=1000000.0, penalty=l2, solver=newton-cholesky, tol=0.0001\n",
            "[CV 5/5; 246/448] END C=1000000.0, penalty=l2, solver=newton-cholesky, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 247/448] START C=1000000.0, penalty=l2, solver=newton-cholesky, tol=1e-05\n",
            "[CV 1/5; 247/448] END C=1000000.0, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 247/448] START C=1000000.0, penalty=l2, solver=newton-cholesky, tol=1e-05\n",
            "[CV 2/5; 247/448] END C=1000000.0, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 247/448] START C=1000000.0, penalty=l2, solver=newton-cholesky, tol=1e-05\n",
            "[CV 3/5; 247/448] END C=1000000.0, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 247/448] START C=1000000.0, penalty=l2, solver=newton-cholesky, tol=1e-05\n",
            "[CV 4/5; 247/448] END C=1000000.0, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 247/448] START C=1000000.0, penalty=l2, solver=newton-cholesky, tol=1e-05\n",
            "[CV 5/5; 247/448] END C=1000000.0, penalty=l2, solver=newton-cholesky, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 248/448] START C=1000000.0, penalty=l2, solver=newton-cholesky, tol=1e-06\n",
            "[CV 1/5; 248/448] END C=1000000.0, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 248/448] START C=1000000.0, penalty=l2, solver=newton-cholesky, tol=1e-06\n",
            "[CV 2/5; 248/448] END C=1000000.0, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 248/448] START C=1000000.0, penalty=l2, solver=newton-cholesky, tol=1e-06\n",
            "[CV 3/5; 248/448] END C=1000000.0, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 248/448] START C=1000000.0, penalty=l2, solver=newton-cholesky, tol=1e-06\n",
            "[CV 4/5; 248/448] END C=1000000.0, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 248/448] START C=1000000.0, penalty=l2, solver=newton-cholesky, tol=1e-06\n",
            "[CV 5/5; 248/448] END C=1000000.0, penalty=l2, solver=newton-cholesky, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 249/448] START C=1000000.0, penalty=None, solver=newton-cg, tol=0.001..\n",
            "[CV 1/5; 249/448] END C=1000000.0, penalty=None, solver=newton-cg, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 249/448] START C=1000000.0, penalty=None, solver=newton-cg, tol=0.001..\n",
            "[CV 2/5; 249/448] END C=1000000.0, penalty=None, solver=newton-cg, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 249/448] START C=1000000.0, penalty=None, solver=newton-cg, tol=0.001..\n",
            "[CV 3/5; 249/448] END C=1000000.0, penalty=None, solver=newton-cg, tol=0.001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 249/448] START C=1000000.0, penalty=None, solver=newton-cg, tol=0.001..\n",
            "[CV 4/5; 249/448] END C=1000000.0, penalty=None, solver=newton-cg, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 249/448] START C=1000000.0, penalty=None, solver=newton-cg, tol=0.001..\n",
            "[CV 5/5; 249/448] END C=1000000.0, penalty=None, solver=newton-cg, tol=0.001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 250/448] START C=1000000.0, penalty=None, solver=newton-cg, tol=0.0001.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 250/448] END C=1000000.0, penalty=None, solver=newton-cg, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 250/448] START C=1000000.0, penalty=None, solver=newton-cg, tol=0.0001.\n",
            "[CV 2/5; 250/448] END C=1000000.0, penalty=None, solver=newton-cg, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 250/448] START C=1000000.0, penalty=None, solver=newton-cg, tol=0.0001.\n",
            "[CV 3/5; 250/448] END C=1000000.0, penalty=None, solver=newton-cg, tol=0.0001;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 250/448] START C=1000000.0, penalty=None, solver=newton-cg, tol=0.0001.\n",
            "[CV 4/5; 250/448] END C=1000000.0, penalty=None, solver=newton-cg, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 250/448] START C=1000000.0, penalty=None, solver=newton-cg, tol=0.0001.\n",
            "[CV 5/5; 250/448] END C=1000000.0, penalty=None, solver=newton-cg, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 251/448] START C=1000000.0, penalty=None, solver=newton-cg, tol=1e-05..\n",
            "[CV 1/5; 251/448] END C=1000000.0, penalty=None, solver=newton-cg, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 251/448] START C=1000000.0, penalty=None, solver=newton-cg, tol=1e-05..\n",
            "[CV 2/5; 251/448] END C=1000000.0, penalty=None, solver=newton-cg, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 251/448] START C=1000000.0, penalty=None, solver=newton-cg, tol=1e-05..\n",
            "[CV 3/5; 251/448] END C=1000000.0, penalty=None, solver=newton-cg, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 251/448] START C=1000000.0, penalty=None, solver=newton-cg, tol=1e-05..\n",
            "[CV 4/5; 251/448] END C=1000000.0, penalty=None, solver=newton-cg, tol=1e-05;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 251/448] START C=1000000.0, penalty=None, solver=newton-cg, tol=1e-05..\n",
            "[CV 5/5; 251/448] END C=1000000.0, penalty=None, solver=newton-cg, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 252/448] START C=1000000.0, penalty=None, solver=newton-cg, tol=1e-06..\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 252/448] END C=1000000.0, penalty=None, solver=newton-cg, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 252/448] START C=1000000.0, penalty=None, solver=newton-cg, tol=1e-06..\n",
            "[CV 2/5; 252/448] END C=1000000.0, penalty=None, solver=newton-cg, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 252/448] START C=1000000.0, penalty=None, solver=newton-cg, tol=1e-06..\n",
            "[CV 3/5; 252/448] END C=1000000.0, penalty=None, solver=newton-cg, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 252/448] START C=1000000.0, penalty=None, solver=newton-cg, tol=1e-06..\n",
            "[CV 4/5; 252/448] END C=1000000.0, penalty=None, solver=newton-cg, tol=1e-06;, score=0.976 total time=   0.0s\n",
            "[CV 5/5; 252/448] START C=1000000.0, penalty=None, solver=newton-cg, tol=1e-06..\n",
            "[CV 5/5; 252/448] END C=1000000.0, penalty=None, solver=newton-cg, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 253/448] START C=1000000.0, penalty=None, solver=newton-cholesky, tol=0.001\n",
            "[CV 1/5; 253/448] END C=1000000.0, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.968 total time=   0.0s\n",
            "[CV 2/5; 253/448] START C=1000000.0, penalty=None, solver=newton-cholesky, tol=0.001\n",
            "[CV 2/5; 253/448] END C=1000000.0, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.976 total time=   0.0s\n",
            "[CV 3/5; 253/448] START C=1000000.0, penalty=None, solver=newton-cholesky, tol=0.001\n",
            "[CV 3/5; 253/448] END C=1000000.0, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.956 total time=   0.0s\n",
            "[CV 4/5; 253/448] START C=1000000.0, penalty=None, solver=newton-cholesky, tol=0.001\n",
            "[CV 4/5; 253/448] END C=1000000.0, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.988 total time=   0.0s\n",
            "[CV 5/5; 253/448] START C=1000000.0, penalty=None, solver=newton-cholesky, tol=0.001\n",
            "[CV 5/5; 253/448] END C=1000000.0, penalty=None, solver=newton-cholesky, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 254/448] START C=1000000.0, penalty=None, solver=newton-cholesky, tol=0.0001\n",
            "[CV 1/5; 254/448] END C=1000000.0, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 2/5; 254/448] START C=1000000.0, penalty=None, solver=newton-cholesky, tol=0.0001\n",
            "[CV 2/5; 254/448] END C=1000000.0, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 254/448] START C=1000000.0, penalty=None, solver=newton-cholesky, tol=0.0001\n",
            "[CV 3/5; 254/448] END C=1000000.0, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.976 total time=   0.0s\n",
            "[CV 4/5; 254/448] START C=1000000.0, penalty=None, solver=newton-cholesky, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 254/448] END C=1000000.0, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.988 total time=   0.0s\n",
            "[CV 5/5; 254/448] START C=1000000.0, penalty=None, solver=newton-cholesky, tol=0.0001\n",
            "[CV 5/5; 254/448] END C=1000000.0, penalty=None, solver=newton-cholesky, tol=0.0001;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 255/448] START C=1000000.0, penalty=None, solver=newton-cholesky, tol=1e-05\n",
            "[CV 1/5; 255/448] END C=1000000.0, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 255/448] START C=1000000.0, penalty=None, solver=newton-cholesky, tol=1e-05\n",
            "[CV 2/5; 255/448] END C=1000000.0, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 3/5; 255/448] START C=1000000.0, penalty=None, solver=newton-cholesky, tol=1e-05\n",
            "[CV 3/5; 255/448] END C=1000000.0, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 255/448] START C=1000000.0, penalty=None, solver=newton-cholesky, tol=1e-05\n",
            "[CV 4/5; 255/448] END C=1000000.0, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.988 total time=   0.0s\n",
            "[CV 5/5; 255/448] START C=1000000.0, penalty=None, solver=newton-cholesky, tol=1e-05\n",
            "[CV 5/5; 255/448] END C=1000000.0, penalty=None, solver=newton-cholesky, tol=1e-05;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 256/448] START C=1000000.0, penalty=None, solver=newton-cholesky, tol=1e-06\n",
            "[CV 1/5; 256/448] END C=1000000.0, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.988 total time=   0.0s\n",
            "[CV 2/5; 256/448] START C=1000000.0, penalty=None, solver=newton-cholesky, tol=1e-06\n",
            "[CV 2/5; 256/448] END C=1000000.0, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 3/5; 256/448] START C=1000000.0, penalty=None, solver=newton-cholesky, tol=1e-06\n",
            "[CV 3/5; 256/448] END C=1000000.0, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.972 total time=   0.0s\n",
            "[CV 4/5; 256/448] START C=1000000.0, penalty=None, solver=newton-cholesky, tol=1e-06\n",
            "[CV 4/5; 256/448] END C=1000000.0, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 5/5; 256/448] START C=1000000.0, penalty=None, solver=newton-cholesky, tol=1e-06\n",
            "[CV 5/5; 256/448] END C=1000000.0, penalty=None, solver=newton-cholesky, tol=1e-06;, score=0.984 total time=   0.0s\n",
            "[CV 1/5; 257/448] START C=0.1, penalty=l2, solver=sag, tol=0.001................\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 257/448] END C=0.1, penalty=l2, solver=sag, tol=0.001;, score=0.792 total time=   0.0s\n",
            "[CV 2/5; 257/448] START C=0.1, penalty=l2, solver=sag, tol=0.001................\n",
            "[CV 2/5; 257/448] END C=0.1, penalty=l2, solver=sag, tol=0.001;, score=0.656 total time=   0.0s\n",
            "[CV 3/5; 257/448] START C=0.1, penalty=l2, solver=sag, tol=0.001................\n",
            "[CV 3/5; 257/448] END C=0.1, penalty=l2, solver=sag, tol=0.001;, score=0.720 total time=   0.0s\n",
            "[CV 4/5; 257/448] START C=0.1, penalty=l2, solver=sag, tol=0.001................\n",
            "[CV 4/5; 257/448] END C=0.1, penalty=l2, solver=sag, tol=0.001;, score=0.716 total time=   0.0s\n",
            "[CV 5/5; 257/448] START C=0.1, penalty=l2, solver=sag, tol=0.001................\n",
            "[CV 5/5; 257/448] END C=0.1, penalty=l2, solver=sag, tol=0.001;, score=0.756 total time=   0.0s\n",
            "[CV 1/5; 258/448] START C=0.1, penalty=l2, solver=sag, tol=0.0001...............\n",
            "[CV 1/5; 258/448] END C=0.1, penalty=l2, solver=sag, tol=0.0001;, score=0.792 total time=   0.0s\n",
            "[CV 2/5; 258/448] START C=0.1, penalty=l2, solver=sag, tol=0.0001...............\n",
            "[CV 2/5; 258/448] END C=0.1, penalty=l2, solver=sag, tol=0.0001;, score=0.656 total time=   0.0s\n",
            "[CV 3/5; 258/448] START C=0.1, penalty=l2, solver=sag, tol=0.0001...............\n",
            "[CV 3/5; 258/448] END C=0.1, penalty=l2, solver=sag, tol=0.0001;, score=0.720 total time=   0.0s\n",
            "[CV 4/5; 258/448] START C=0.1, penalty=l2, solver=sag, tol=0.0001...............\n",
            "[CV 4/5; 258/448] END C=0.1, penalty=l2, solver=sag, tol=0.0001;, score=0.716 total time=   0.0s\n",
            "[CV 5/5; 258/448] START C=0.1, penalty=l2, solver=sag, tol=0.0001...............\n",
            "[CV 5/5; 258/448] END C=0.1, penalty=l2, solver=sag, tol=0.0001;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 259/448] START C=0.1, penalty=l2, solver=sag, tol=1e-05................\n",
            "[CV 1/5; 259/448] END C=0.1, penalty=l2, solver=sag, tol=1e-05;, score=0.792 total time=   0.0s\n",
            "[CV 2/5; 259/448] START C=0.1, penalty=l2, solver=sag, tol=1e-05................\n",
            "[CV 2/5; 259/448] END C=0.1, penalty=l2, solver=sag, tol=1e-05;, score=0.656 total time=   0.0s\n",
            "[CV 3/5; 259/448] START C=0.1, penalty=l2, solver=sag, tol=1e-05................\n",
            "[CV 3/5; 259/448] END C=0.1, penalty=l2, solver=sag, tol=1e-05;, score=0.720 total time=   0.0s\n",
            "[CV 4/5; 259/448] START C=0.1, penalty=l2, solver=sag, tol=1e-05................\n",
            "[CV 4/5; 259/448] END C=0.1, penalty=l2, solver=sag, tol=1e-05;, score=0.716 total time=   0.0s\n",
            "[CV 5/5; 259/448] START C=0.1, penalty=l2, solver=sag, tol=1e-05................\n",
            "[CV 5/5; 259/448] END C=0.1, penalty=l2, solver=sag, tol=1e-05;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 260/448] START C=0.1, penalty=l2, solver=sag, tol=1e-06................\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 260/448] END C=0.1, penalty=l2, solver=sag, tol=1e-06;, score=0.792 total time=   0.0s\n",
            "[CV 2/5; 260/448] START C=0.1, penalty=l2, solver=sag, tol=1e-06................\n",
            "[CV 2/5; 260/448] END C=0.1, penalty=l2, solver=sag, tol=1e-06;, score=0.656 total time=   0.0s\n",
            "[CV 3/5; 260/448] START C=0.1, penalty=l2, solver=sag, tol=1e-06................\n",
            "[CV 3/5; 260/448] END C=0.1, penalty=l2, solver=sag, tol=1e-06;, score=0.720 total time=   0.0s\n",
            "[CV 4/5; 260/448] START C=0.1, penalty=l2, solver=sag, tol=1e-06................\n",
            "[CV 4/5; 260/448] END C=0.1, penalty=l2, solver=sag, tol=1e-06;, score=0.716 total time=   0.0s\n",
            "[CV 5/5; 260/448] START C=0.1, penalty=l2, solver=sag, tol=1e-06................\n",
            "[CV 5/5; 260/448] END C=0.1, penalty=l2, solver=sag, tol=1e-06;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 261/448] START C=0.1, penalty=None, solver=sag, tol=0.001..............\n",
            "[CV 1/5; 261/448] END C=0.1, penalty=None, solver=sag, tol=0.001;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 261/448] START C=0.1, penalty=None, solver=sag, tol=0.001..............\n",
            "[CV 2/5; 261/448] END C=0.1, penalty=None, solver=sag, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 261/448] START C=0.1, penalty=None, solver=sag, tol=0.001..............\n",
            "[CV 3/5; 261/448] END C=0.1, penalty=None, solver=sag, tol=0.001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 261/448] START C=0.1, penalty=None, solver=sag, tol=0.001..............\n",
            "[CV 4/5; 261/448] END C=0.1, penalty=None, solver=sag, tol=0.001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 261/448] START C=0.1, penalty=None, solver=sag, tol=0.001..............\n",
            "[CV 5/5; 261/448] END C=0.1, penalty=None, solver=sag, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 262/448] START C=0.1, penalty=None, solver=sag, tol=0.0001.............\n",
            "[CV 1/5; 262/448] END C=0.1, penalty=None, solver=sag, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 262/448] START C=0.1, penalty=None, solver=sag, tol=0.0001.............\n",
            "[CV 2/5; 262/448] END C=0.1, penalty=None, solver=sag, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 262/448] START C=0.1, penalty=None, solver=sag, tol=0.0001.............\n",
            "[CV 3/5; 262/448] END C=0.1, penalty=None, solver=sag, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 262/448] START C=0.1, penalty=None, solver=sag, tol=0.0001.............\n",
            "[CV 4/5; 262/448] END C=0.1, penalty=None, solver=sag, tol=0.0001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 262/448] START C=0.1, penalty=None, solver=sag, tol=0.0001.............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 262/448] END C=0.1, penalty=None, solver=sag, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 263/448] START C=0.1, penalty=None, solver=sag, tol=1e-05..............\n",
            "[CV 1/5; 263/448] END C=0.1, penalty=None, solver=sag, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 263/448] START C=0.1, penalty=None, solver=sag, tol=1e-05..............\n",
            "[CV 2/5; 263/448] END C=0.1, penalty=None, solver=sag, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 263/448] START C=0.1, penalty=None, solver=sag, tol=1e-05..............\n",
            "[CV 3/5; 263/448] END C=0.1, penalty=None, solver=sag, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 263/448] START C=0.1, penalty=None, solver=sag, tol=1e-05..............\n",
            "[CV 4/5; 263/448] END C=0.1, penalty=None, solver=sag, tol=1e-05;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 263/448] START C=0.1, penalty=None, solver=sag, tol=1e-05..............\n",
            "[CV 5/5; 263/448] END C=0.1, penalty=None, solver=sag, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 264/448] START C=0.1, penalty=None, solver=sag, tol=1e-06..............\n",
            "[CV 1/5; 264/448] END C=0.1, penalty=None, solver=sag, tol=1e-06;, score=0.884 total time=   0.0s\n",
            "[CV 2/5; 264/448] START C=0.1, penalty=None, solver=sag, tol=1e-06..............\n",
            "[CV 2/5; 264/448] END C=0.1, penalty=None, solver=sag, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 264/448] START C=0.1, penalty=None, solver=sag, tol=1e-06..............\n",
            "[CV 3/5; 264/448] END C=0.1, penalty=None, solver=sag, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 264/448] START C=0.1, penalty=None, solver=sag, tol=1e-06..............\n",
            "[CV 4/5; 264/448] END C=0.1, penalty=None, solver=sag, tol=1e-06;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 264/448] START C=0.1, penalty=None, solver=sag, tol=1e-06..............\n",
            "[CV 5/5; 264/448] END C=0.1, penalty=None, solver=sag, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 265/448] START C=1, penalty=l2, solver=sag, tol=0.001..................\n",
            "[CV 1/5; 265/448] END C=1, penalty=l2, solver=sag, tol=0.001;, score=0.876 total time=   0.0s\n",
            "[CV 2/5; 265/448] START C=1, penalty=l2, solver=sag, tol=0.001..................\n",
            "[CV 2/5; 265/448] END C=1, penalty=l2, solver=sag, tol=0.001;, score=0.832 total time=   0.0s\n",
            "[CV 3/5; 265/448] START C=1, penalty=l2, solver=sag, tol=0.001..................\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 265/448] END C=1, penalty=l2, solver=sag, tol=0.001;, score=0.868 total time=   0.0s\n",
            "[CV 4/5; 265/448] START C=1, penalty=l2, solver=sag, tol=0.001..................\n",
            "[CV 4/5; 265/448] END C=1, penalty=l2, solver=sag, tol=0.001;, score=0.884 total time=   0.0s\n",
            "[CV 5/5; 265/448] START C=1, penalty=l2, solver=sag, tol=0.001..................\n",
            "[CV 5/5; 265/448] END C=1, penalty=l2, solver=sag, tol=0.001;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 266/448] START C=1, penalty=l2, solver=sag, tol=0.0001.................\n",
            "[CV 1/5; 266/448] END C=1, penalty=l2, solver=sag, tol=0.0001;, score=0.876 total time=   0.0s\n",
            "[CV 2/5; 266/448] START C=1, penalty=l2, solver=sag, tol=0.0001.................\n",
            "[CV 2/5; 266/448] END C=1, penalty=l2, solver=sag, tol=0.0001;, score=0.832 total time=   0.0s\n",
            "[CV 3/5; 266/448] START C=1, penalty=l2, solver=sag, tol=0.0001.................\n",
            "[CV 3/5; 266/448] END C=1, penalty=l2, solver=sag, tol=0.0001;, score=0.868 total time=   0.0s\n",
            "[CV 4/5; 266/448] START C=1, penalty=l2, solver=sag, tol=0.0001.................\n",
            "[CV 4/5; 266/448] END C=1, penalty=l2, solver=sag, tol=0.0001;, score=0.884 total time=   0.0s\n",
            "[CV 5/5; 266/448] START C=1, penalty=l2, solver=sag, tol=0.0001.................\n",
            "[CV 5/5; 266/448] END C=1, penalty=l2, solver=sag, tol=0.0001;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 267/448] START C=1, penalty=l2, solver=sag, tol=1e-05..................\n",
            "[CV 1/5; 267/448] END C=1, penalty=l2, solver=sag, tol=1e-05;, score=0.876 total time=   0.0s\n",
            "[CV 2/5; 267/448] START C=1, penalty=l2, solver=sag, tol=1e-05..................\n",
            "[CV 2/5; 267/448] END C=1, penalty=l2, solver=sag, tol=1e-05;, score=0.832 total time=   0.0s\n",
            "[CV 3/5; 267/448] START C=1, penalty=l2, solver=sag, tol=1e-05..................\n",
            "[CV 3/5; 267/448] END C=1, penalty=l2, solver=sag, tol=1e-05;, score=0.868 total time=   0.0s\n",
            "[CV 4/5; 267/448] START C=1, penalty=l2, solver=sag, tol=1e-05..................\n",
            "[CV 4/5; 267/448] END C=1, penalty=l2, solver=sag, tol=1e-05;, score=0.884 total time=   0.0s\n",
            "[CV 5/5; 267/448] START C=1, penalty=l2, solver=sag, tol=1e-05..................\n",
            "[CV 5/5; 267/448] END C=1, penalty=l2, solver=sag, tol=1e-05;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 268/448] START C=1, penalty=l2, solver=sag, tol=1e-06..................\n",
            "[CV 1/5; 268/448] END C=1, penalty=l2, solver=sag, tol=1e-06;, score=0.872 total time=   0.0s\n",
            "[CV 2/5; 268/448] START C=1, penalty=l2, solver=sag, tol=1e-06..................\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 268/448] END C=1, penalty=l2, solver=sag, tol=1e-06;, score=0.832 total time=   0.0s\n",
            "[CV 3/5; 268/448] START C=1, penalty=l2, solver=sag, tol=1e-06..................\n",
            "[CV 3/5; 268/448] END C=1, penalty=l2, solver=sag, tol=1e-06;, score=0.868 total time=   0.0s\n",
            "[CV 4/5; 268/448] START C=1, penalty=l2, solver=sag, tol=1e-06..................\n",
            "[CV 4/5; 268/448] END C=1, penalty=l2, solver=sag, tol=1e-06;, score=0.884 total time=   0.0s\n",
            "[CV 5/5; 268/448] START C=1, penalty=l2, solver=sag, tol=1e-06..................\n",
            "[CV 5/5; 268/448] END C=1, penalty=l2, solver=sag, tol=1e-06;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 269/448] START C=1, penalty=None, solver=sag, tol=0.001................\n",
            "[CV 1/5; 269/448] END C=1, penalty=None, solver=sag, tol=0.001;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 269/448] START C=1, penalty=None, solver=sag, tol=0.001................\n",
            "[CV 2/5; 269/448] END C=1, penalty=None, solver=sag, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 269/448] START C=1, penalty=None, solver=sag, tol=0.001................\n",
            "[CV 3/5; 269/448] END C=1, penalty=None, solver=sag, tol=0.001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 269/448] START C=1, penalty=None, solver=sag, tol=0.001................\n",
            "[CV 4/5; 269/448] END C=1, penalty=None, solver=sag, tol=0.001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 269/448] START C=1, penalty=None, solver=sag, tol=0.001................\n",
            "[CV 5/5; 269/448] END C=1, penalty=None, solver=sag, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 270/448] START C=1, penalty=None, solver=sag, tol=0.0001...............\n",
            "[CV 1/5; 270/448] END C=1, penalty=None, solver=sag, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 270/448] START C=1, penalty=None, solver=sag, tol=0.0001...............\n",
            "[CV 2/5; 270/448] END C=1, penalty=None, solver=sag, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 270/448] START C=1, penalty=None, solver=sag, tol=0.0001...............\n",
            "[CV 3/5; 270/448] END C=1, penalty=None, solver=sag, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 270/448] START C=1, penalty=None, solver=sag, tol=0.0001...............\n",
            "[CV 4/5; 270/448] END C=1, penalty=None, solver=sag, tol=0.0001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 270/448] START C=1, penalty=None, solver=sag, tol=0.0001...............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 270/448] END C=1, penalty=None, solver=sag, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 271/448] START C=1, penalty=None, solver=sag, tol=1e-05................\n",
            "[CV 1/5; 271/448] END C=1, penalty=None, solver=sag, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 271/448] START C=1, penalty=None, solver=sag, tol=1e-05................\n",
            "[CV 2/5; 271/448] END C=1, penalty=None, solver=sag, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 271/448] START C=1, penalty=None, solver=sag, tol=1e-05................\n",
            "[CV 3/5; 271/448] END C=1, penalty=None, solver=sag, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 271/448] START C=1, penalty=None, solver=sag, tol=1e-05................\n",
            "[CV 4/5; 271/448] END C=1, penalty=None, solver=sag, tol=1e-05;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 271/448] START C=1, penalty=None, solver=sag, tol=1e-05................\n",
            "[CV 5/5; 271/448] END C=1, penalty=None, solver=sag, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 272/448] START C=1, penalty=None, solver=sag, tol=1e-06................\n",
            "[CV 1/5; 272/448] END C=1, penalty=None, solver=sag, tol=1e-06;, score=0.884 total time=   0.0s\n",
            "[CV 2/5; 272/448] START C=1, penalty=None, solver=sag, tol=1e-06................\n",
            "[CV 2/5; 272/448] END C=1, penalty=None, solver=sag, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 272/448] START C=1, penalty=None, solver=sag, tol=1e-06................\n",
            "[CV 3/5; 272/448] END C=1, penalty=None, solver=sag, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 272/448] START C=1, penalty=None, solver=sag, tol=1e-06................\n",
            "[CV 4/5; 272/448] END C=1, penalty=None, solver=sag, tol=1e-06;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 272/448] START C=1, penalty=None, solver=sag, tol=1e-06................\n",
            "[CV 5/5; 272/448] END C=1, penalty=None, solver=sag, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 273/448] START C=10.0, penalty=l2, solver=sag, tol=0.001...............\n",
            "[CV 1/5; 273/448] END C=10.0, penalty=l2, solver=sag, tol=0.001;, score=0.884 total time=   0.0s\n",
            "[CV 2/5; 273/448] START C=10.0, penalty=l2, solver=sag, tol=0.001...............\n",
            "[CV 2/5; 273/448] END C=10.0, penalty=l2, solver=sag, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 273/448] START C=10.0, penalty=l2, solver=sag, tol=0.001...............\n",
            "[CV 3/5; 273/448] END C=10.0, penalty=l2, solver=sag, tol=0.001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 273/448] START C=10.0, penalty=l2, solver=sag, tol=0.001...............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 273/448] END C=10.0, penalty=l2, solver=sag, tol=0.001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 273/448] START C=10.0, penalty=l2, solver=sag, tol=0.001...............\n",
            "[CV 5/5; 273/448] END C=10.0, penalty=l2, solver=sag, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 274/448] START C=10.0, penalty=l2, solver=sag, tol=0.0001..............\n",
            "[CV 1/5; 274/448] END C=10.0, penalty=l2, solver=sag, tol=0.0001;, score=0.884 total time=   0.0s\n",
            "[CV 2/5; 274/448] START C=10.0, penalty=l2, solver=sag, tol=0.0001..............\n",
            "[CV 2/5; 274/448] END C=10.0, penalty=l2, solver=sag, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 274/448] START C=10.0, penalty=l2, solver=sag, tol=0.0001..............\n",
            "[CV 3/5; 274/448] END C=10.0, penalty=l2, solver=sag, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 274/448] START C=10.0, penalty=l2, solver=sag, tol=0.0001..............\n",
            "[CV 4/5; 274/448] END C=10.0, penalty=l2, solver=sag, tol=0.0001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 274/448] START C=10.0, penalty=l2, solver=sag, tol=0.0001..............\n",
            "[CV 5/5; 274/448] END C=10.0, penalty=l2, solver=sag, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 275/448] START C=10.0, penalty=l2, solver=sag, tol=1e-05...............\n",
            "[CV 1/5; 275/448] END C=10.0, penalty=l2, solver=sag, tol=1e-05;, score=0.884 total time=   0.0s\n",
            "[CV 2/5; 275/448] START C=10.0, penalty=l2, solver=sag, tol=1e-05...............\n",
            "[CV 2/5; 275/448] END C=10.0, penalty=l2, solver=sag, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 275/448] START C=10.0, penalty=l2, solver=sag, tol=1e-05...............\n",
            "[CV 3/5; 275/448] END C=10.0, penalty=l2, solver=sag, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 275/448] START C=10.0, penalty=l2, solver=sag, tol=1e-05...............\n",
            "[CV 4/5; 275/448] END C=10.0, penalty=l2, solver=sag, tol=1e-05;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 275/448] START C=10.0, penalty=l2, solver=sag, tol=1e-05...............\n",
            "[CV 5/5; 275/448] END C=10.0, penalty=l2, solver=sag, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 276/448] START C=10.0, penalty=l2, solver=sag, tol=1e-06...............\n",
            "[CV 1/5; 276/448] END C=10.0, penalty=l2, solver=sag, tol=1e-06;, score=0.884 total time=   0.0s\n",
            "[CV 2/5; 276/448] START C=10.0, penalty=l2, solver=sag, tol=1e-06...............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 276/448] END C=10.0, penalty=l2, solver=sag, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 276/448] START C=10.0, penalty=l2, solver=sag, tol=1e-06...............\n",
            "[CV 3/5; 276/448] END C=10.0, penalty=l2, solver=sag, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 276/448] START C=10.0, penalty=l2, solver=sag, tol=1e-06...............\n",
            "[CV 4/5; 276/448] END C=10.0, penalty=l2, solver=sag, tol=1e-06;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 276/448] START C=10.0, penalty=l2, solver=sag, tol=1e-06...............\n",
            "[CV 5/5; 276/448] END C=10.0, penalty=l2, solver=sag, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 277/448] START C=10.0, penalty=None, solver=sag, tol=0.001.............\n",
            "[CV 1/5; 277/448] END C=10.0, penalty=None, solver=sag, tol=0.001;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 277/448] START C=10.0, penalty=None, solver=sag, tol=0.001.............\n",
            "[CV 2/5; 277/448] END C=10.0, penalty=None, solver=sag, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 277/448] START C=10.0, penalty=None, solver=sag, tol=0.001.............\n",
            "[CV 3/5; 277/448] END C=10.0, penalty=None, solver=sag, tol=0.001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 277/448] START C=10.0, penalty=None, solver=sag, tol=0.001.............\n",
            "[CV 4/5; 277/448] END C=10.0, penalty=None, solver=sag, tol=0.001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 277/448] START C=10.0, penalty=None, solver=sag, tol=0.001.............\n",
            "[CV 5/5; 277/448] END C=10.0, penalty=None, solver=sag, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 278/448] START C=10.0, penalty=None, solver=sag, tol=0.0001............\n",
            "[CV 1/5; 278/448] END C=10.0, penalty=None, solver=sag, tol=0.0001;, score=0.884 total time=   0.0s\n",
            "[CV 2/5; 278/448] START C=10.0, penalty=None, solver=sag, tol=0.0001............\n",
            "[CV 2/5; 278/448] END C=10.0, penalty=None, solver=sag, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 278/448] START C=10.0, penalty=None, solver=sag, tol=0.0001............\n",
            "[CV 3/5; 278/448] END C=10.0, penalty=None, solver=sag, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 278/448] START C=10.0, penalty=None, solver=sag, tol=0.0001............\n",
            "[CV 4/5; 278/448] END C=10.0, penalty=None, solver=sag, tol=0.0001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 278/448] START C=10.0, penalty=None, solver=sag, tol=0.0001............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 278/448] END C=10.0, penalty=None, solver=sag, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 279/448] START C=10.0, penalty=None, solver=sag, tol=1e-05.............\n",
            "[CV 1/5; 279/448] END C=10.0, penalty=None, solver=sag, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 279/448] START C=10.0, penalty=None, solver=sag, tol=1e-05.............\n",
            "[CV 2/5; 279/448] END C=10.0, penalty=None, solver=sag, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 279/448] START C=10.0, penalty=None, solver=sag, tol=1e-05.............\n",
            "[CV 3/5; 279/448] END C=10.0, penalty=None, solver=sag, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 279/448] START C=10.0, penalty=None, solver=sag, tol=1e-05.............\n",
            "[CV 4/5; 279/448] END C=10.0, penalty=None, solver=sag, tol=1e-05;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 279/448] START C=10.0, penalty=None, solver=sag, tol=1e-05.............\n",
            "[CV 5/5; 279/448] END C=10.0, penalty=None, solver=sag, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 280/448] START C=10.0, penalty=None, solver=sag, tol=1e-06.............\n",
            "[CV 1/5; 280/448] END C=10.0, penalty=None, solver=sag, tol=1e-06;, score=0.884 total time=   0.0s\n",
            "[CV 2/5; 280/448] START C=10.0, penalty=None, solver=sag, tol=1e-06.............\n",
            "[CV 2/5; 280/448] END C=10.0, penalty=None, solver=sag, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 280/448] START C=10.0, penalty=None, solver=sag, tol=1e-06.............\n",
            "[CV 3/5; 280/448] END C=10.0, penalty=None, solver=sag, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 280/448] START C=10.0, penalty=None, solver=sag, tol=1e-06.............\n",
            "[CV 4/5; 280/448] END C=10.0, penalty=None, solver=sag, tol=1e-06;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 280/448] START C=10.0, penalty=None, solver=sag, tol=1e-06.............\n",
            "[CV 5/5; 280/448] END C=10.0, penalty=None, solver=sag, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 281/448] START C=100.0, penalty=l2, solver=sag, tol=0.001..............\n",
            "[CV 1/5; 281/448] END C=100.0, penalty=l2, solver=sag, tol=0.001;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 281/448] START C=100.0, penalty=l2, solver=sag, tol=0.001..............\n",
            "[CV 2/5; 281/448] END C=100.0, penalty=l2, solver=sag, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 281/448] START C=100.0, penalty=l2, solver=sag, tol=0.001..............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 281/448] END C=100.0, penalty=l2, solver=sag, tol=0.001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 281/448] START C=100.0, penalty=l2, solver=sag, tol=0.001..............\n",
            "[CV 4/5; 281/448] END C=100.0, penalty=l2, solver=sag, tol=0.001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 281/448] START C=100.0, penalty=l2, solver=sag, tol=0.001..............\n",
            "[CV 5/5; 281/448] END C=100.0, penalty=l2, solver=sag, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 282/448] START C=100.0, penalty=l2, solver=sag, tol=0.0001.............\n",
            "[CV 1/5; 282/448] END C=100.0, penalty=l2, solver=sag, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 282/448] START C=100.0, penalty=l2, solver=sag, tol=0.0001.............\n",
            "[CV 2/5; 282/448] END C=100.0, penalty=l2, solver=sag, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 282/448] START C=100.0, penalty=l2, solver=sag, tol=0.0001.............\n",
            "[CV 3/5; 282/448] END C=100.0, penalty=l2, solver=sag, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 282/448] START C=100.0, penalty=l2, solver=sag, tol=0.0001.............\n",
            "[CV 4/5; 282/448] END C=100.0, penalty=l2, solver=sag, tol=0.0001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 282/448] START C=100.0, penalty=l2, solver=sag, tol=0.0001.............\n",
            "[CV 5/5; 282/448] END C=100.0, penalty=l2, solver=sag, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 283/448] START C=100.0, penalty=l2, solver=sag, tol=1e-05..............\n",
            "[CV 1/5; 283/448] END C=100.0, penalty=l2, solver=sag, tol=1e-05;, score=0.884 total time=   0.0s\n",
            "[CV 2/5; 283/448] START C=100.0, penalty=l2, solver=sag, tol=1e-05..............\n",
            "[CV 2/5; 283/448] END C=100.0, penalty=l2, solver=sag, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 283/448] START C=100.0, penalty=l2, solver=sag, tol=1e-05..............\n",
            "[CV 3/5; 283/448] END C=100.0, penalty=l2, solver=sag, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 283/448] START C=100.0, penalty=l2, solver=sag, tol=1e-05..............\n",
            "[CV 4/5; 283/448] END C=100.0, penalty=l2, solver=sag, tol=1e-05;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 283/448] START C=100.0, penalty=l2, solver=sag, tol=1e-05..............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 283/448] END C=100.0, penalty=l2, solver=sag, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 284/448] START C=100.0, penalty=l2, solver=sag, tol=1e-06..............\n",
            "[CV 1/5; 284/448] END C=100.0, penalty=l2, solver=sag, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 284/448] START C=100.0, penalty=l2, solver=sag, tol=1e-06..............\n",
            "[CV 2/5; 284/448] END C=100.0, penalty=l2, solver=sag, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 284/448] START C=100.0, penalty=l2, solver=sag, tol=1e-06..............\n",
            "[CV 3/5; 284/448] END C=100.0, penalty=l2, solver=sag, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 284/448] START C=100.0, penalty=l2, solver=sag, tol=1e-06..............\n",
            "[CV 4/5; 284/448] END C=100.0, penalty=l2, solver=sag, tol=1e-06;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 284/448] START C=100.0, penalty=l2, solver=sag, tol=1e-06..............\n",
            "[CV 5/5; 284/448] END C=100.0, penalty=l2, solver=sag, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 285/448] START C=100.0, penalty=None, solver=sag, tol=0.001............\n",
            "[CV 1/5; 285/448] END C=100.0, penalty=None, solver=sag, tol=0.001;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 285/448] START C=100.0, penalty=None, solver=sag, tol=0.001............\n",
            "[CV 2/5; 285/448] END C=100.0, penalty=None, solver=sag, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 285/448] START C=100.0, penalty=None, solver=sag, tol=0.001............\n",
            "[CV 3/5; 285/448] END C=100.0, penalty=None, solver=sag, tol=0.001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 285/448] START C=100.0, penalty=None, solver=sag, tol=0.001............\n",
            "[CV 4/5; 285/448] END C=100.0, penalty=None, solver=sag, tol=0.001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 285/448] START C=100.0, penalty=None, solver=sag, tol=0.001............\n",
            "[CV 5/5; 285/448] END C=100.0, penalty=None, solver=sag, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 286/448] START C=100.0, penalty=None, solver=sag, tol=0.0001...........\n",
            "[CV 1/5; 286/448] END C=100.0, penalty=None, solver=sag, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 286/448] START C=100.0, penalty=None, solver=sag, tol=0.0001...........\n",
            "[CV 2/5; 286/448] END C=100.0, penalty=None, solver=sag, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 286/448] START C=100.0, penalty=None, solver=sag, tol=0.0001...........\n",
            "[CV 3/5; 286/448] END C=100.0, penalty=None, solver=sag, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 286/448] START C=100.0, penalty=None, solver=sag, tol=0.0001...........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 286/448] END C=100.0, penalty=None, solver=sag, tol=0.0001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 286/448] START C=100.0, penalty=None, solver=sag, tol=0.0001...........\n",
            "[CV 5/5; 286/448] END C=100.0, penalty=None, solver=sag, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 287/448] START C=100.0, penalty=None, solver=sag, tol=1e-05............\n",
            "[CV 1/5; 287/448] END C=100.0, penalty=None, solver=sag, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 287/448] START C=100.0, penalty=None, solver=sag, tol=1e-05............\n",
            "[CV 2/5; 287/448] END C=100.0, penalty=None, solver=sag, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 287/448] START C=100.0, penalty=None, solver=sag, tol=1e-05............\n",
            "[CV 3/5; 287/448] END C=100.0, penalty=None, solver=sag, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 287/448] START C=100.0, penalty=None, solver=sag, tol=1e-05............\n",
            "[CV 4/5; 287/448] END C=100.0, penalty=None, solver=sag, tol=1e-05;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 287/448] START C=100.0, penalty=None, solver=sag, tol=1e-05............\n",
            "[CV 5/5; 287/448] END C=100.0, penalty=None, solver=sag, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 288/448] START C=100.0, penalty=None, solver=sag, tol=1e-06............\n",
            "[CV 1/5; 288/448] END C=100.0, penalty=None, solver=sag, tol=1e-06;, score=0.884 total time=   0.0s\n",
            "[CV 2/5; 288/448] START C=100.0, penalty=None, solver=sag, tol=1e-06............\n",
            "[CV 2/5; 288/448] END C=100.0, penalty=None, solver=sag, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 288/448] START C=100.0, penalty=None, solver=sag, tol=1e-06............\n",
            "[CV 3/5; 288/448] END C=100.0, penalty=None, solver=sag, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 288/448] START C=100.0, penalty=None, solver=sag, tol=1e-06............\n",
            "[CV 4/5; 288/448] END C=100.0, penalty=None, solver=sag, tol=1e-06;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 288/448] START C=100.0, penalty=None, solver=sag, tol=1e-06............\n",
            "[CV 5/5; 288/448] END C=100.0, penalty=None, solver=sag, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 289/448] START C=1000.0, penalty=l2, solver=sag, tol=0.001.............\n",
            "[CV 1/5; 289/448] END C=1000.0, penalty=l2, solver=sag, tol=0.001;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 289/448] START C=1000.0, penalty=l2, solver=sag, tol=0.001.............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 289/448] END C=1000.0, penalty=l2, solver=sag, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 289/448] START C=1000.0, penalty=l2, solver=sag, tol=0.001.............\n",
            "[CV 3/5; 289/448] END C=1000.0, penalty=l2, solver=sag, tol=0.001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 289/448] START C=1000.0, penalty=l2, solver=sag, tol=0.001.............\n",
            "[CV 4/5; 289/448] END C=1000.0, penalty=l2, solver=sag, tol=0.001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 289/448] START C=1000.0, penalty=l2, solver=sag, tol=0.001.............\n",
            "[CV 5/5; 289/448] END C=1000.0, penalty=l2, solver=sag, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 290/448] START C=1000.0, penalty=l2, solver=sag, tol=0.0001............\n",
            "[CV 1/5; 290/448] END C=1000.0, penalty=l2, solver=sag, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 290/448] START C=1000.0, penalty=l2, solver=sag, tol=0.0001............\n",
            "[CV 2/5; 290/448] END C=1000.0, penalty=l2, solver=sag, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 290/448] START C=1000.0, penalty=l2, solver=sag, tol=0.0001............\n",
            "[CV 3/5; 290/448] END C=1000.0, penalty=l2, solver=sag, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 290/448] START C=1000.0, penalty=l2, solver=sag, tol=0.0001............\n",
            "[CV 4/5; 290/448] END C=1000.0, penalty=l2, solver=sag, tol=0.0001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 290/448] START C=1000.0, penalty=l2, solver=sag, tol=0.0001............\n",
            "[CV 5/5; 290/448] END C=1000.0, penalty=l2, solver=sag, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 291/448] START C=1000.0, penalty=l2, solver=sag, tol=1e-05.............\n",
            "[CV 1/5; 291/448] END C=1000.0, penalty=l2, solver=sag, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 291/448] START C=1000.0, penalty=l2, solver=sag, tol=1e-05.............\n",
            "[CV 2/5; 291/448] END C=1000.0, penalty=l2, solver=sag, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 291/448] START C=1000.0, penalty=l2, solver=sag, tol=1e-05.............\n",
            "[CV 3/5; 291/448] END C=1000.0, penalty=l2, solver=sag, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 291/448] START C=1000.0, penalty=l2, solver=sag, tol=1e-05.............\n",
            "[CV 4/5; 291/448] END C=1000.0, penalty=l2, solver=sag, tol=1e-05;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 291/448] START C=1000.0, penalty=l2, solver=sag, tol=1e-05.............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 291/448] END C=1000.0, penalty=l2, solver=sag, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 292/448] START C=1000.0, penalty=l2, solver=sag, tol=1e-06.............\n",
            "[CV 1/5; 292/448] END C=1000.0, penalty=l2, solver=sag, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 292/448] START C=1000.0, penalty=l2, solver=sag, tol=1e-06.............\n",
            "[CV 2/5; 292/448] END C=1000.0, penalty=l2, solver=sag, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 292/448] START C=1000.0, penalty=l2, solver=sag, tol=1e-06.............\n",
            "[CV 3/5; 292/448] END C=1000.0, penalty=l2, solver=sag, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 292/448] START C=1000.0, penalty=l2, solver=sag, tol=1e-06.............\n",
            "[CV 4/5; 292/448] END C=1000.0, penalty=l2, solver=sag, tol=1e-06;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 292/448] START C=1000.0, penalty=l2, solver=sag, tol=1e-06.............\n",
            "[CV 5/5; 292/448] END C=1000.0, penalty=l2, solver=sag, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 293/448] START C=1000.0, penalty=None, solver=sag, tol=0.001...........\n",
            "[CV 1/5; 293/448] END C=1000.0, penalty=None, solver=sag, tol=0.001;, score=0.884 total time=   0.0s\n",
            "[CV 2/5; 293/448] START C=1000.0, penalty=None, solver=sag, tol=0.001...........\n",
            "[CV 2/5; 293/448] END C=1000.0, penalty=None, solver=sag, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 293/448] START C=1000.0, penalty=None, solver=sag, tol=0.001...........\n",
            "[CV 3/5; 293/448] END C=1000.0, penalty=None, solver=sag, tol=0.001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 293/448] START C=1000.0, penalty=None, solver=sag, tol=0.001...........\n",
            "[CV 4/5; 293/448] END C=1000.0, penalty=None, solver=sag, tol=0.001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 293/448] START C=1000.0, penalty=None, solver=sag, tol=0.001...........\n",
            "[CV 5/5; 293/448] END C=1000.0, penalty=None, solver=sag, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 294/448] START C=1000.0, penalty=None, solver=sag, tol=0.0001..........\n",
            "[CV 1/5; 294/448] END C=1000.0, penalty=None, solver=sag, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 294/448] START C=1000.0, penalty=None, solver=sag, tol=0.0001..........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 294/448] END C=1000.0, penalty=None, solver=sag, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 294/448] START C=1000.0, penalty=None, solver=sag, tol=0.0001..........\n",
            "[CV 3/5; 294/448] END C=1000.0, penalty=None, solver=sag, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 294/448] START C=1000.0, penalty=None, solver=sag, tol=0.0001..........\n",
            "[CV 4/5; 294/448] END C=1000.0, penalty=None, solver=sag, tol=0.0001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 294/448] START C=1000.0, penalty=None, solver=sag, tol=0.0001..........\n",
            "[CV 5/5; 294/448] END C=1000.0, penalty=None, solver=sag, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 295/448] START C=1000.0, penalty=None, solver=sag, tol=1e-05...........\n",
            "[CV 1/5; 295/448] END C=1000.0, penalty=None, solver=sag, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 295/448] START C=1000.0, penalty=None, solver=sag, tol=1e-05...........\n",
            "[CV 2/5; 295/448] END C=1000.0, penalty=None, solver=sag, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 295/448] START C=1000.0, penalty=None, solver=sag, tol=1e-05...........\n",
            "[CV 3/5; 295/448] END C=1000.0, penalty=None, solver=sag, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 295/448] START C=1000.0, penalty=None, solver=sag, tol=1e-05...........\n",
            "[CV 4/5; 295/448] END C=1000.0, penalty=None, solver=sag, tol=1e-05;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 295/448] START C=1000.0, penalty=None, solver=sag, tol=1e-05...........\n",
            "[CV 5/5; 295/448] END C=1000.0, penalty=None, solver=sag, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 296/448] START C=1000.0, penalty=None, solver=sag, tol=1e-06...........\n",
            "[CV 1/5; 296/448] END C=1000.0, penalty=None, solver=sag, tol=1e-06;, score=0.884 total time=   0.0s\n",
            "[CV 2/5; 296/448] START C=1000.0, penalty=None, solver=sag, tol=1e-06...........\n",
            "[CV 2/5; 296/448] END C=1000.0, penalty=None, solver=sag, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 296/448] START C=1000.0, penalty=None, solver=sag, tol=1e-06...........\n",
            "[CV 3/5; 296/448] END C=1000.0, penalty=None, solver=sag, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 296/448] START C=1000.0, penalty=None, solver=sag, tol=1e-06...........\n",
            "[CV 4/5; 296/448] END C=1000.0, penalty=None, solver=sag, tol=1e-06;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 296/448] START C=1000.0, penalty=None, solver=sag, tol=1e-06...........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 296/448] END C=1000.0, penalty=None, solver=sag, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 297/448] START C=10000.0, penalty=l2, solver=sag, tol=0.001............\n",
            "[CV 1/5; 297/448] END C=10000.0, penalty=l2, solver=sag, tol=0.001;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 297/448] START C=10000.0, penalty=l2, solver=sag, tol=0.001............\n",
            "[CV 2/5; 297/448] END C=10000.0, penalty=l2, solver=sag, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 297/448] START C=10000.0, penalty=l2, solver=sag, tol=0.001............\n",
            "[CV 3/5; 297/448] END C=10000.0, penalty=l2, solver=sag, tol=0.001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 297/448] START C=10000.0, penalty=l2, solver=sag, tol=0.001............\n",
            "[CV 4/5; 297/448] END C=10000.0, penalty=l2, solver=sag, tol=0.001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 297/448] START C=10000.0, penalty=l2, solver=sag, tol=0.001............\n",
            "[CV 5/5; 297/448] END C=10000.0, penalty=l2, solver=sag, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 298/448] START C=10000.0, penalty=l2, solver=sag, tol=0.0001...........\n",
            "[CV 1/5; 298/448] END C=10000.0, penalty=l2, solver=sag, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 298/448] START C=10000.0, penalty=l2, solver=sag, tol=0.0001...........\n",
            "[CV 2/5; 298/448] END C=10000.0, penalty=l2, solver=sag, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 298/448] START C=10000.0, penalty=l2, solver=sag, tol=0.0001...........\n",
            "[CV 3/5; 298/448] END C=10000.0, penalty=l2, solver=sag, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 298/448] START C=10000.0, penalty=l2, solver=sag, tol=0.0001...........\n",
            "[CV 4/5; 298/448] END C=10000.0, penalty=l2, solver=sag, tol=0.0001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 298/448] START C=10000.0, penalty=l2, solver=sag, tol=0.0001...........\n",
            "[CV 5/5; 298/448] END C=10000.0, penalty=l2, solver=sag, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 299/448] START C=10000.0, penalty=l2, solver=sag, tol=1e-05............\n",
            "[CV 1/5; 299/448] END C=10000.0, penalty=l2, solver=sag, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 299/448] START C=10000.0, penalty=l2, solver=sag, tol=1e-05............\n",
            "[CV 2/5; 299/448] END C=10000.0, penalty=l2, solver=sag, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 299/448] START C=10000.0, penalty=l2, solver=sag, tol=1e-05............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 299/448] END C=10000.0, penalty=l2, solver=sag, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 299/448] START C=10000.0, penalty=l2, solver=sag, tol=1e-05............\n",
            "[CV 4/5; 299/448] END C=10000.0, penalty=l2, solver=sag, tol=1e-05;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 299/448] START C=10000.0, penalty=l2, solver=sag, tol=1e-05............\n",
            "[CV 5/5; 299/448] END C=10000.0, penalty=l2, solver=sag, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 300/448] START C=10000.0, penalty=l2, solver=sag, tol=1e-06............\n",
            "[CV 1/5; 300/448] END C=10000.0, penalty=l2, solver=sag, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 300/448] START C=10000.0, penalty=l2, solver=sag, tol=1e-06............\n",
            "[CV 2/5; 300/448] END C=10000.0, penalty=l2, solver=sag, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 300/448] START C=10000.0, penalty=l2, solver=sag, tol=1e-06............\n",
            "[CV 3/5; 300/448] END C=10000.0, penalty=l2, solver=sag, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 300/448] START C=10000.0, penalty=l2, solver=sag, tol=1e-06............\n",
            "[CV 4/5; 300/448] END C=10000.0, penalty=l2, solver=sag, tol=1e-06;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 300/448] START C=10000.0, penalty=l2, solver=sag, tol=1e-06............\n",
            "[CV 5/5; 300/448] END C=10000.0, penalty=l2, solver=sag, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 301/448] START C=10000.0, penalty=None, solver=sag, tol=0.001..........\n",
            "[CV 1/5; 301/448] END C=10000.0, penalty=None, solver=sag, tol=0.001;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 301/448] START C=10000.0, penalty=None, solver=sag, tol=0.001..........\n",
            "[CV 2/5; 301/448] END C=10000.0, penalty=None, solver=sag, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 301/448] START C=10000.0, penalty=None, solver=sag, tol=0.001..........\n",
            "[CV 3/5; 301/448] END C=10000.0, penalty=None, solver=sag, tol=0.001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 301/448] START C=10000.0, penalty=None, solver=sag, tol=0.001..........\n",
            "[CV 4/5; 301/448] END C=10000.0, penalty=None, solver=sag, tol=0.001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 301/448] START C=10000.0, penalty=None, solver=sag, tol=0.001..........\n",
            "[CV 5/5; 301/448] END C=10000.0, penalty=None, solver=sag, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 302/448] START C=10000.0, penalty=None, solver=sag, tol=0.0001.........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 302/448] END C=10000.0, penalty=None, solver=sag, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 302/448] START C=10000.0, penalty=None, solver=sag, tol=0.0001.........\n",
            "[CV 2/5; 302/448] END C=10000.0, penalty=None, solver=sag, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 302/448] START C=10000.0, penalty=None, solver=sag, tol=0.0001.........\n",
            "[CV 3/5; 302/448] END C=10000.0, penalty=None, solver=sag, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 302/448] START C=10000.0, penalty=None, solver=sag, tol=0.0001.........\n",
            "[CV 4/5; 302/448] END C=10000.0, penalty=None, solver=sag, tol=0.0001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 302/448] START C=10000.0, penalty=None, solver=sag, tol=0.0001.........\n",
            "[CV 5/5; 302/448] END C=10000.0, penalty=None, solver=sag, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 303/448] START C=10000.0, penalty=None, solver=sag, tol=1e-05..........\n",
            "[CV 1/5; 303/448] END C=10000.0, penalty=None, solver=sag, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 303/448] START C=10000.0, penalty=None, solver=sag, tol=1e-05..........\n",
            "[CV 2/5; 303/448] END C=10000.0, penalty=None, solver=sag, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 303/448] START C=10000.0, penalty=None, solver=sag, tol=1e-05..........\n",
            "[CV 3/5; 303/448] END C=10000.0, penalty=None, solver=sag, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 303/448] START C=10000.0, penalty=None, solver=sag, tol=1e-05..........\n",
            "[CV 4/5; 303/448] END C=10000.0, penalty=None, solver=sag, tol=1e-05;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 303/448] START C=10000.0, penalty=None, solver=sag, tol=1e-05..........\n",
            "[CV 5/5; 303/448] END C=10000.0, penalty=None, solver=sag, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 304/448] START C=10000.0, penalty=None, solver=sag, tol=1e-06..........\n",
            "[CV 1/5; 304/448] END C=10000.0, penalty=None, solver=sag, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 304/448] START C=10000.0, penalty=None, solver=sag, tol=1e-06..........\n",
            "[CV 2/5; 304/448] END C=10000.0, penalty=None, solver=sag, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 304/448] START C=10000.0, penalty=None, solver=sag, tol=1e-06..........\n",
            "[CV 3/5; 304/448] END C=10000.0, penalty=None, solver=sag, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 304/448] START C=10000.0, penalty=None, solver=sag, tol=1e-06..........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 304/448] END C=10000.0, penalty=None, solver=sag, tol=1e-06;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 304/448] START C=10000.0, penalty=None, solver=sag, tol=1e-06..........\n",
            "[CV 5/5; 304/448] END C=10000.0, penalty=None, solver=sag, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 305/448] START C=100000.0, penalty=l2, solver=sag, tol=0.001...........\n",
            "[CV 1/5; 305/448] END C=100000.0, penalty=l2, solver=sag, tol=0.001;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 305/448] START C=100000.0, penalty=l2, solver=sag, tol=0.001...........\n",
            "[CV 2/5; 305/448] END C=100000.0, penalty=l2, solver=sag, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 305/448] START C=100000.0, penalty=l2, solver=sag, tol=0.001...........\n",
            "[CV 3/5; 305/448] END C=100000.0, penalty=l2, solver=sag, tol=0.001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 305/448] START C=100000.0, penalty=l2, solver=sag, tol=0.001...........\n",
            "[CV 4/5; 305/448] END C=100000.0, penalty=l2, solver=sag, tol=0.001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 305/448] START C=100000.0, penalty=l2, solver=sag, tol=0.001...........\n",
            "[CV 5/5; 305/448] END C=100000.0, penalty=l2, solver=sag, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 306/448] START C=100000.0, penalty=l2, solver=sag, tol=0.0001..........\n",
            "[CV 1/5; 306/448] END C=100000.0, penalty=l2, solver=sag, tol=0.0001;, score=0.884 total time=   0.0s\n",
            "[CV 2/5; 306/448] START C=100000.0, penalty=l2, solver=sag, tol=0.0001..........\n",
            "[CV 2/5; 306/448] END C=100000.0, penalty=l2, solver=sag, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 306/448] START C=100000.0, penalty=l2, solver=sag, tol=0.0001..........\n",
            "[CV 3/5; 306/448] END C=100000.0, penalty=l2, solver=sag, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 306/448] START C=100000.0, penalty=l2, solver=sag, tol=0.0001..........\n",
            "[CV 4/5; 306/448] END C=100000.0, penalty=l2, solver=sag, tol=0.0001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 306/448] START C=100000.0, penalty=l2, solver=sag, tol=0.0001..........\n",
            "[CV 5/5; 306/448] END C=100000.0, penalty=l2, solver=sag, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 307/448] START C=100000.0, penalty=l2, solver=sag, tol=1e-05...........\n",
            "[CV 1/5; 307/448] END C=100000.0, penalty=l2, solver=sag, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 307/448] START C=100000.0, penalty=l2, solver=sag, tol=1e-05...........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 307/448] END C=100000.0, penalty=l2, solver=sag, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 307/448] START C=100000.0, penalty=l2, solver=sag, tol=1e-05...........\n",
            "[CV 3/5; 307/448] END C=100000.0, penalty=l2, solver=sag, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 307/448] START C=100000.0, penalty=l2, solver=sag, tol=1e-05...........\n",
            "[CV 4/5; 307/448] END C=100000.0, penalty=l2, solver=sag, tol=1e-05;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 307/448] START C=100000.0, penalty=l2, solver=sag, tol=1e-05...........\n",
            "[CV 5/5; 307/448] END C=100000.0, penalty=l2, solver=sag, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 308/448] START C=100000.0, penalty=l2, solver=sag, tol=1e-06...........\n",
            "[CV 1/5; 308/448] END C=100000.0, penalty=l2, solver=sag, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 308/448] START C=100000.0, penalty=l2, solver=sag, tol=1e-06...........\n",
            "[CV 2/5; 308/448] END C=100000.0, penalty=l2, solver=sag, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 308/448] START C=100000.0, penalty=l2, solver=sag, tol=1e-06...........\n",
            "[CV 3/5; 308/448] END C=100000.0, penalty=l2, solver=sag, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 308/448] START C=100000.0, penalty=l2, solver=sag, tol=1e-06...........\n",
            "[CV 4/5; 308/448] END C=100000.0, penalty=l2, solver=sag, tol=1e-06;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 308/448] START C=100000.0, penalty=l2, solver=sag, tol=1e-06...........\n",
            "[CV 5/5; 308/448] END C=100000.0, penalty=l2, solver=sag, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 309/448] START C=100000.0, penalty=None, solver=sag, tol=0.001.........\n",
            "[CV 1/5; 309/448] END C=100000.0, penalty=None, solver=sag, tol=0.001;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 309/448] START C=100000.0, penalty=None, solver=sag, tol=0.001.........\n",
            "[CV 2/5; 309/448] END C=100000.0, penalty=None, solver=sag, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 309/448] START C=100000.0, penalty=None, solver=sag, tol=0.001.........\n",
            "[CV 3/5; 309/448] END C=100000.0, penalty=None, solver=sag, tol=0.001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 309/448] START C=100000.0, penalty=None, solver=sag, tol=0.001.........\n",
            "[CV 4/5; 309/448] END C=100000.0, penalty=None, solver=sag, tol=0.001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 309/448] START C=100000.0, penalty=None, solver=sag, tol=0.001.........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 309/448] END C=100000.0, penalty=None, solver=sag, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 310/448] START C=100000.0, penalty=None, solver=sag, tol=0.0001........\n",
            "[CV 1/5; 310/448] END C=100000.0, penalty=None, solver=sag, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 310/448] START C=100000.0, penalty=None, solver=sag, tol=0.0001........\n",
            "[CV 2/5; 310/448] END C=100000.0, penalty=None, solver=sag, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 310/448] START C=100000.0, penalty=None, solver=sag, tol=0.0001........\n",
            "[CV 3/5; 310/448] END C=100000.0, penalty=None, solver=sag, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 310/448] START C=100000.0, penalty=None, solver=sag, tol=0.0001........\n",
            "[CV 4/5; 310/448] END C=100000.0, penalty=None, solver=sag, tol=0.0001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 310/448] START C=100000.0, penalty=None, solver=sag, tol=0.0001........\n",
            "[CV 5/5; 310/448] END C=100000.0, penalty=None, solver=sag, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 311/448] START C=100000.0, penalty=None, solver=sag, tol=1e-05.........\n",
            "[CV 1/5; 311/448] END C=100000.0, penalty=None, solver=sag, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 311/448] START C=100000.0, penalty=None, solver=sag, tol=1e-05.........\n",
            "[CV 2/5; 311/448] END C=100000.0, penalty=None, solver=sag, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 311/448] START C=100000.0, penalty=None, solver=sag, tol=1e-05.........\n",
            "[CV 3/5; 311/448] END C=100000.0, penalty=None, solver=sag, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 311/448] START C=100000.0, penalty=None, solver=sag, tol=1e-05.........\n",
            "[CV 4/5; 311/448] END C=100000.0, penalty=None, solver=sag, tol=1e-05;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 311/448] START C=100000.0, penalty=None, solver=sag, tol=1e-05.........\n",
            "[CV 5/5; 311/448] END C=100000.0, penalty=None, solver=sag, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 312/448] START C=100000.0, penalty=None, solver=sag, tol=1e-06.........\n",
            "[CV 1/5; 312/448] END C=100000.0, penalty=None, solver=sag, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 312/448] START C=100000.0, penalty=None, solver=sag, tol=1e-06.........\n",
            "[CV 2/5; 312/448] END C=100000.0, penalty=None, solver=sag, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 312/448] START C=100000.0, penalty=None, solver=sag, tol=1e-06.........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 312/448] END C=100000.0, penalty=None, solver=sag, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 312/448] START C=100000.0, penalty=None, solver=sag, tol=1e-06.........\n",
            "[CV 4/5; 312/448] END C=100000.0, penalty=None, solver=sag, tol=1e-06;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 312/448] START C=100000.0, penalty=None, solver=sag, tol=1e-06.........\n",
            "[CV 5/5; 312/448] END C=100000.0, penalty=None, solver=sag, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 313/448] START C=1000000.0, penalty=l2, solver=sag, tol=0.001..........\n",
            "[CV 1/5; 313/448] END C=1000000.0, penalty=l2, solver=sag, tol=0.001;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 313/448] START C=1000000.0, penalty=l2, solver=sag, tol=0.001..........\n",
            "[CV 2/5; 313/448] END C=1000000.0, penalty=l2, solver=sag, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 313/448] START C=1000000.0, penalty=l2, solver=sag, tol=0.001..........\n",
            "[CV 3/5; 313/448] END C=1000000.0, penalty=l2, solver=sag, tol=0.001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 313/448] START C=1000000.0, penalty=l2, solver=sag, tol=0.001..........\n",
            "[CV 4/5; 313/448] END C=1000000.0, penalty=l2, solver=sag, tol=0.001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 313/448] START C=1000000.0, penalty=l2, solver=sag, tol=0.001..........\n",
            "[CV 5/5; 313/448] END C=1000000.0, penalty=l2, solver=sag, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 314/448] START C=1000000.0, penalty=l2, solver=sag, tol=0.0001.........\n",
            "[CV 1/5; 314/448] END C=1000000.0, penalty=l2, solver=sag, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 314/448] START C=1000000.0, penalty=l2, solver=sag, tol=0.0001.........\n",
            "[CV 2/5; 314/448] END C=1000000.0, penalty=l2, solver=sag, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 314/448] START C=1000000.0, penalty=l2, solver=sag, tol=0.0001.........\n",
            "[CV 3/5; 314/448] END C=1000000.0, penalty=l2, solver=sag, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 314/448] START C=1000000.0, penalty=l2, solver=sag, tol=0.0001.........\n",
            "[CV 4/5; 314/448] END C=1000000.0, penalty=l2, solver=sag, tol=0.0001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 314/448] START C=1000000.0, penalty=l2, solver=sag, tol=0.0001.........\n",
            "[CV 5/5; 314/448] END C=1000000.0, penalty=l2, solver=sag, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 315/448] START C=1000000.0, penalty=l2, solver=sag, tol=1e-05..........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 315/448] END C=1000000.0, penalty=l2, solver=sag, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 315/448] START C=1000000.0, penalty=l2, solver=sag, tol=1e-05..........\n",
            "[CV 2/5; 315/448] END C=1000000.0, penalty=l2, solver=sag, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 315/448] START C=1000000.0, penalty=l2, solver=sag, tol=1e-05..........\n",
            "[CV 3/5; 315/448] END C=1000000.0, penalty=l2, solver=sag, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 315/448] START C=1000000.0, penalty=l2, solver=sag, tol=1e-05..........\n",
            "[CV 4/5; 315/448] END C=1000000.0, penalty=l2, solver=sag, tol=1e-05;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 315/448] START C=1000000.0, penalty=l2, solver=sag, tol=1e-05..........\n",
            "[CV 5/5; 315/448] END C=1000000.0, penalty=l2, solver=sag, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 316/448] START C=1000000.0, penalty=l2, solver=sag, tol=1e-06..........\n",
            "[CV 1/5; 316/448] END C=1000000.0, penalty=l2, solver=sag, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 316/448] START C=1000000.0, penalty=l2, solver=sag, tol=1e-06..........\n",
            "[CV 2/5; 316/448] END C=1000000.0, penalty=l2, solver=sag, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 316/448] START C=1000000.0, penalty=l2, solver=sag, tol=1e-06..........\n",
            "[CV 3/5; 316/448] END C=1000000.0, penalty=l2, solver=sag, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 316/448] START C=1000000.0, penalty=l2, solver=sag, tol=1e-06..........\n",
            "[CV 4/5; 316/448] END C=1000000.0, penalty=l2, solver=sag, tol=1e-06;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 316/448] START C=1000000.0, penalty=l2, solver=sag, tol=1e-06..........\n",
            "[CV 5/5; 316/448] END C=1000000.0, penalty=l2, solver=sag, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 317/448] START C=1000000.0, penalty=None, solver=sag, tol=0.001........\n",
            "[CV 1/5; 317/448] END C=1000000.0, penalty=None, solver=sag, tol=0.001;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 317/448] START C=1000000.0, penalty=None, solver=sag, tol=0.001........\n",
            "[CV 2/5; 317/448] END C=1000000.0, penalty=None, solver=sag, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 317/448] START C=1000000.0, penalty=None, solver=sag, tol=0.001........\n",
            "[CV 3/5; 317/448] END C=1000000.0, penalty=None, solver=sag, tol=0.001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 317/448] START C=1000000.0, penalty=None, solver=sag, tol=0.001........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 317/448] END C=1000000.0, penalty=None, solver=sag, tol=0.001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 317/448] START C=1000000.0, penalty=None, solver=sag, tol=0.001........\n",
            "[CV 5/5; 317/448] END C=1000000.0, penalty=None, solver=sag, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 318/448] START C=1000000.0, penalty=None, solver=sag, tol=0.0001.......\n",
            "[CV 1/5; 318/448] END C=1000000.0, penalty=None, solver=sag, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 318/448] START C=1000000.0, penalty=None, solver=sag, tol=0.0001.......\n",
            "[CV 2/5; 318/448] END C=1000000.0, penalty=None, solver=sag, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 318/448] START C=1000000.0, penalty=None, solver=sag, tol=0.0001.......\n",
            "[CV 3/5; 318/448] END C=1000000.0, penalty=None, solver=sag, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 318/448] START C=1000000.0, penalty=None, solver=sag, tol=0.0001.......\n",
            "[CV 4/5; 318/448] END C=1000000.0, penalty=None, solver=sag, tol=0.0001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 318/448] START C=1000000.0, penalty=None, solver=sag, tol=0.0001.......\n",
            "[CV 5/5; 318/448] END C=1000000.0, penalty=None, solver=sag, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 319/448] START C=1000000.0, penalty=None, solver=sag, tol=1e-05........\n",
            "[CV 1/5; 319/448] END C=1000000.0, penalty=None, solver=sag, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 319/448] START C=1000000.0, penalty=None, solver=sag, tol=1e-05........\n",
            "[CV 2/5; 319/448] END C=1000000.0, penalty=None, solver=sag, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 319/448] START C=1000000.0, penalty=None, solver=sag, tol=1e-05........\n",
            "[CV 3/5; 319/448] END C=1000000.0, penalty=None, solver=sag, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 319/448] START C=1000000.0, penalty=None, solver=sag, tol=1e-05........\n",
            "[CV 4/5; 319/448] END C=1000000.0, penalty=None, solver=sag, tol=1e-05;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 319/448] START C=1000000.0, penalty=None, solver=sag, tol=1e-05........\n",
            "[CV 5/5; 319/448] END C=1000000.0, penalty=None, solver=sag, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 320/448] START C=1000000.0, penalty=None, solver=sag, tol=1e-06........\n",
            "[CV 1/5; 320/448] END C=1000000.0, penalty=None, solver=sag, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 320/448] START C=1000000.0, penalty=None, solver=sag, tol=1e-06........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 320/448] END C=1000000.0, penalty=None, solver=sag, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 3/5; 320/448] START C=1000000.0, penalty=None, solver=sag, tol=1e-06........\n",
            "[CV 3/5; 320/448] END C=1000000.0, penalty=None, solver=sag, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 320/448] START C=1000000.0, penalty=None, solver=sag, tol=1e-06........\n",
            "[CV 4/5; 320/448] END C=1000000.0, penalty=None, solver=sag, tol=1e-06;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 320/448] START C=1000000.0, penalty=None, solver=sag, tol=1e-06........\n",
            "[CV 5/5; 320/448] END C=1000000.0, penalty=None, solver=sag, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 321/448] START C=0.1, penalty=l1, solver=saga, tol=0.001...............\n",
            "[CV 1/5; 321/448] END C=0.1, penalty=l1, solver=saga, tol=0.001;, score=0.780 total time=   0.0s\n",
            "[CV 2/5; 321/448] START C=0.1, penalty=l1, solver=saga, tol=0.001...............\n",
            "[CV 2/5; 321/448] END C=0.1, penalty=l1, solver=saga, tol=0.001;, score=0.748 total time=   0.0s\n",
            "[CV 3/5; 321/448] START C=0.1, penalty=l1, solver=saga, tol=0.001...............\n",
            "[CV 3/5; 321/448] END C=0.1, penalty=l1, solver=saga, tol=0.001;, score=0.784 total time=   0.0s\n",
            "[CV 4/5; 321/448] START C=0.1, penalty=l1, solver=saga, tol=0.001...............\n",
            "[CV 4/5; 321/448] END C=0.1, penalty=l1, solver=saga, tol=0.001;, score=0.756 total time=   0.0s\n",
            "[CV 5/5; 321/448] START C=0.1, penalty=l1, solver=saga, tol=0.001...............\n",
            "[CV 5/5; 321/448] END C=0.1, penalty=l1, solver=saga, tol=0.001;, score=0.876 total time=   0.0s\n",
            "[CV 1/5; 322/448] START C=0.1, penalty=l1, solver=saga, tol=0.0001..............\n",
            "[CV 1/5; 322/448] END C=0.1, penalty=l1, solver=saga, tol=0.0001;, score=0.780 total time=   0.0s\n",
            "[CV 2/5; 322/448] START C=0.1, penalty=l1, solver=saga, tol=0.0001..............\n",
            "[CV 2/5; 322/448] END C=0.1, penalty=l1, solver=saga, tol=0.0001;, score=0.748 total time=   0.0s\n",
            "[CV 3/5; 322/448] START C=0.1, penalty=l1, solver=saga, tol=0.0001..............\n",
            "[CV 3/5; 322/448] END C=0.1, penalty=l1, solver=saga, tol=0.0001;, score=0.784 total time=   0.0s\n",
            "[CV 4/5; 322/448] START C=0.1, penalty=l1, solver=saga, tol=0.0001..............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 322/448] END C=0.1, penalty=l1, solver=saga, tol=0.0001;, score=0.756 total time=   0.0s\n",
            "[CV 5/5; 322/448] START C=0.1, penalty=l1, solver=saga, tol=0.0001..............\n",
            "[CV 5/5; 322/448] END C=0.1, penalty=l1, solver=saga, tol=0.0001;, score=0.876 total time=   0.0s\n",
            "[CV 1/5; 323/448] START C=0.1, penalty=l1, solver=saga, tol=1e-05...............\n",
            "[CV 1/5; 323/448] END C=0.1, penalty=l1, solver=saga, tol=1e-05;, score=0.780 total time=   0.0s\n",
            "[CV 2/5; 323/448] START C=0.1, penalty=l1, solver=saga, tol=1e-05...............\n",
            "[CV 2/5; 323/448] END C=0.1, penalty=l1, solver=saga, tol=1e-05;, score=0.748 total time=   0.0s\n",
            "[CV 3/5; 323/448] START C=0.1, penalty=l1, solver=saga, tol=1e-05...............\n",
            "[CV 3/5; 323/448] END C=0.1, penalty=l1, solver=saga, tol=1e-05;, score=0.784 total time=   0.0s\n",
            "[CV 4/5; 323/448] START C=0.1, penalty=l1, solver=saga, tol=1e-05...............\n",
            "[CV 4/5; 323/448] END C=0.1, penalty=l1, solver=saga, tol=1e-05;, score=0.756 total time=   0.0s\n",
            "[CV 5/5; 323/448] START C=0.1, penalty=l1, solver=saga, tol=1e-05...............\n",
            "[CV 5/5; 323/448] END C=0.1, penalty=l1, solver=saga, tol=1e-05;, score=0.876 total time=   0.0s\n",
            "[CV 1/5; 324/448] START C=0.1, penalty=l1, solver=saga, tol=1e-06...............\n",
            "[CV 1/5; 324/448] END C=0.1, penalty=l1, solver=saga, tol=1e-06;, score=0.780 total time=   0.0s\n",
            "[CV 2/5; 324/448] START C=0.1, penalty=l1, solver=saga, tol=1e-06...............\n",
            "[CV 2/5; 324/448] END C=0.1, penalty=l1, solver=saga, tol=1e-06;, score=0.748 total time=   0.0s\n",
            "[CV 3/5; 324/448] START C=0.1, penalty=l1, solver=saga, tol=1e-06...............\n",
            "[CV 3/5; 324/448] END C=0.1, penalty=l1, solver=saga, tol=1e-06;, score=0.784 total time=   0.0s\n",
            "[CV 4/5; 324/448] START C=0.1, penalty=l1, solver=saga, tol=1e-06...............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 324/448] END C=0.1, penalty=l1, solver=saga, tol=1e-06;, score=0.756 total time=   0.0s\n",
            "[CV 5/5; 324/448] START C=0.1, penalty=l1, solver=saga, tol=1e-06...............\n",
            "[CV 5/5; 324/448] END C=0.1, penalty=l1, solver=saga, tol=1e-06;, score=0.876 total time=   0.0s\n",
            "[CV 1/5; 325/448] START C=0.1, penalty=l2, solver=saga, tol=0.001...............\n",
            "[CV 1/5; 325/448] END C=0.1, penalty=l2, solver=saga, tol=0.001;, score=0.792 total time=   0.0s\n",
            "[CV 2/5; 325/448] START C=0.1, penalty=l2, solver=saga, tol=0.001...............\n",
            "[CV 2/5; 325/448] END C=0.1, penalty=l2, solver=saga, tol=0.001;, score=0.644 total time=   0.0s\n",
            "[CV 3/5; 325/448] START C=0.1, penalty=l2, solver=saga, tol=0.001...............\n",
            "[CV 3/5; 325/448] END C=0.1, penalty=l2, solver=saga, tol=0.001;, score=0.720 total time=   0.0s\n",
            "[CV 4/5; 325/448] START C=0.1, penalty=l2, solver=saga, tol=0.001...............\n",
            "[CV 4/5; 325/448] END C=0.1, penalty=l2, solver=saga, tol=0.001;, score=0.712 total time=   0.0s\n",
            "[CV 5/5; 325/448] START C=0.1, penalty=l2, solver=saga, tol=0.001...............\n",
            "[CV 5/5; 325/448] END C=0.1, penalty=l2, solver=saga, tol=0.001;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 326/448] START C=0.1, penalty=l2, solver=saga, tol=0.0001..............\n",
            "[CV 1/5; 326/448] END C=0.1, penalty=l2, solver=saga, tol=0.0001;, score=0.792 total time=   0.0s\n",
            "[CV 2/5; 326/448] START C=0.1, penalty=l2, solver=saga, tol=0.0001..............\n",
            "[CV 2/5; 326/448] END C=0.1, penalty=l2, solver=saga, tol=0.0001;, score=0.644 total time=   0.0s\n",
            "[CV 3/5; 326/448] START C=0.1, penalty=l2, solver=saga, tol=0.0001..............\n",
            "[CV 3/5; 326/448] END C=0.1, penalty=l2, solver=saga, tol=0.0001;, score=0.720 total time=   0.0s\n",
            "[CV 4/5; 326/448] START C=0.1, penalty=l2, solver=saga, tol=0.0001..............\n",
            "[CV 4/5; 326/448] END C=0.1, penalty=l2, solver=saga, tol=0.0001;, score=0.712 total time=   0.0s\n",
            "[CV 5/5; 326/448] START C=0.1, penalty=l2, solver=saga, tol=0.0001..............\n",
            "[CV 5/5; 326/448] END C=0.1, penalty=l2, solver=saga, tol=0.0001;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 327/448] START C=0.1, penalty=l2, solver=saga, tol=1e-05...............\n",
            "[CV 1/5; 327/448] END C=0.1, penalty=l2, solver=saga, tol=1e-05;, score=0.792 total time=   0.0s\n",
            "[CV 2/5; 327/448] START C=0.1, penalty=l2, solver=saga, tol=1e-05...............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 327/448] END C=0.1, penalty=l2, solver=saga, tol=1e-05;, score=0.644 total time=   0.0s\n",
            "[CV 3/5; 327/448] START C=0.1, penalty=l2, solver=saga, tol=1e-05...............\n",
            "[CV 3/5; 327/448] END C=0.1, penalty=l2, solver=saga, tol=1e-05;, score=0.720 total time=   0.0s\n",
            "[CV 4/5; 327/448] START C=0.1, penalty=l2, solver=saga, tol=1e-05...............\n",
            "[CV 4/5; 327/448] END C=0.1, penalty=l2, solver=saga, tol=1e-05;, score=0.712 total time=   0.0s\n",
            "[CV 5/5; 327/448] START C=0.1, penalty=l2, solver=saga, tol=1e-05...............\n",
            "[CV 5/5; 327/448] END C=0.1, penalty=l2, solver=saga, tol=1e-05;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 328/448] START C=0.1, penalty=l2, solver=saga, tol=1e-06...............\n",
            "[CV 1/5; 328/448] END C=0.1, penalty=l2, solver=saga, tol=1e-06;, score=0.792 total time=   0.0s\n",
            "[CV 2/5; 328/448] START C=0.1, penalty=l2, solver=saga, tol=1e-06...............\n",
            "[CV 2/5; 328/448] END C=0.1, penalty=l2, solver=saga, tol=1e-06;, score=0.644 total time=   0.0s\n",
            "[CV 3/5; 328/448] START C=0.1, penalty=l2, solver=saga, tol=1e-06...............\n",
            "[CV 3/5; 328/448] END C=0.1, penalty=l2, solver=saga, tol=1e-06;, score=0.720 total time=   0.0s\n",
            "[CV 4/5; 328/448] START C=0.1, penalty=l2, solver=saga, tol=1e-06...............\n",
            "[CV 4/5; 328/448] END C=0.1, penalty=l2, solver=saga, tol=1e-06;, score=0.712 total time=   0.0s\n",
            "[CV 5/5; 328/448] START C=0.1, penalty=l2, solver=saga, tol=1e-06...............\n",
            "[CV 5/5; 328/448] END C=0.1, penalty=l2, solver=saga, tol=1e-06;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 329/448] START C=0.1, penalty=elasticnet, solver=saga, tol=0.001.......\n",
            "[CV 1/5; 329/448] END C=0.1, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 2/5; 329/448] START C=0.1, penalty=elasticnet, solver=saga, tol=0.001.......\n",
            "[CV 2/5; 329/448] END C=0.1, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 3/5; 329/448] START C=0.1, penalty=elasticnet, solver=saga, tol=0.001.......\n",
            "[CV 3/5; 329/448] END C=0.1, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 4/5; 329/448] START C=0.1, penalty=elasticnet, solver=saga, tol=0.001.......\n",
            "[CV 4/5; 329/448] END C=0.1, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 5/5; 329/448] START C=0.1, penalty=elasticnet, solver=saga, tol=0.001.......\n",
            "[CV 5/5; 329/448] END C=0.1, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 1/5; 330/448] START C=0.1, penalty=elasticnet, solver=saga, tol=0.0001......\n",
            "[CV 1/5; 330/448] END C=0.1, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 2/5; 330/448] START C=0.1, penalty=elasticnet, solver=saga, tol=0.0001......\n",
            "[CV 2/5; 330/448] END C=0.1, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 3/5; 330/448] START C=0.1, penalty=elasticnet, solver=saga, tol=0.0001......\n",
            "[CV 3/5; 330/448] END C=0.1, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 4/5; 330/448] START C=0.1, penalty=elasticnet, solver=saga, tol=0.0001......\n",
            "[CV 4/5; 330/448] END C=0.1, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 5/5; 330/448] START C=0.1, penalty=elasticnet, solver=saga, tol=0.0001......\n",
            "[CV 5/5; 330/448] END C=0.1, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 1/5; 331/448] START C=0.1, penalty=elasticnet, solver=saga, tol=1e-05.......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 331/448] END C=0.1, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 2/5; 331/448] START C=0.1, penalty=elasticnet, solver=saga, tol=1e-05.......\n",
            "[CV 2/5; 331/448] END C=0.1, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 3/5; 331/448] START C=0.1, penalty=elasticnet, solver=saga, tol=1e-05.......\n",
            "[CV 3/5; 331/448] END C=0.1, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 4/5; 331/448] START C=0.1, penalty=elasticnet, solver=saga, tol=1e-05.......\n",
            "[CV 4/5; 331/448] END C=0.1, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 5/5; 331/448] START C=0.1, penalty=elasticnet, solver=saga, tol=1e-05.......\n",
            "[CV 5/5; 331/448] END C=0.1, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 1/5; 332/448] START C=0.1, penalty=elasticnet, solver=saga, tol=1e-06.......\n",
            "[CV 1/5; 332/448] END C=0.1, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 2/5; 332/448] START C=0.1, penalty=elasticnet, solver=saga, tol=1e-06.......\n",
            "[CV 2/5; 332/448] END C=0.1, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 3/5; 332/448] START C=0.1, penalty=elasticnet, solver=saga, tol=1e-06.......\n",
            "[CV 3/5; 332/448] END C=0.1, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 4/5; 332/448] START C=0.1, penalty=elasticnet, solver=saga, tol=1e-06.......\n",
            "[CV 4/5; 332/448] END C=0.1, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 5/5; 332/448] START C=0.1, penalty=elasticnet, solver=saga, tol=1e-06.......\n",
            "[CV 5/5; 332/448] END C=0.1, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 1/5; 333/448] START C=0.1, penalty=None, solver=saga, tol=0.001.............\n",
            "[CV 1/5; 333/448] END C=0.1, penalty=None, solver=saga, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 333/448] START C=0.1, penalty=None, solver=saga, tol=0.001.............\n",
            "[CV 2/5; 333/448] END C=0.1, penalty=None, solver=saga, tol=0.001;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 333/448] START C=0.1, penalty=None, solver=saga, tol=0.001.............\n",
            "[CV 3/5; 333/448] END C=0.1, penalty=None, solver=saga, tol=0.001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 333/448] START C=0.1, penalty=None, solver=saga, tol=0.001.............\n",
            "[CV 4/5; 333/448] END C=0.1, penalty=None, solver=saga, tol=0.001;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 333/448] START C=0.1, penalty=None, solver=saga, tol=0.001.............\n",
            "[CV 5/5; 333/448] END C=0.1, penalty=None, solver=saga, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 334/448] START C=0.1, penalty=None, solver=saga, tol=0.0001............\n",
            "[CV 1/5; 334/448] END C=0.1, penalty=None, solver=saga, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 334/448] START C=0.1, penalty=None, solver=saga, tol=0.0001............\n",
            "[CV 2/5; 334/448] END C=0.1, penalty=None, solver=saga, tol=0.0001;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 334/448] START C=0.1, penalty=None, solver=saga, tol=0.0001............\n",
            "[CV 3/5; 334/448] END C=0.1, penalty=None, solver=saga, tol=0.0001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 334/448] START C=0.1, penalty=None, solver=saga, tol=0.0001............\n",
            "[CV 4/5; 334/448] END C=0.1, penalty=None, solver=saga, tol=0.0001;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 334/448] START C=0.1, penalty=None, solver=saga, tol=0.0001............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 334/448] END C=0.1, penalty=None, solver=saga, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 335/448] START C=0.1, penalty=None, solver=saga, tol=1e-05.............\n",
            "[CV 1/5; 335/448] END C=0.1, penalty=None, solver=saga, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 335/448] START C=0.1, penalty=None, solver=saga, tol=1e-05.............\n",
            "[CV 2/5; 335/448] END C=0.1, penalty=None, solver=saga, tol=1e-05;, score=0.792 total time=   0.0s\n",
            "[CV 3/5; 335/448] START C=0.1, penalty=None, solver=saga, tol=1e-05.............\n",
            "[CV 3/5; 335/448] END C=0.1, penalty=None, solver=saga, tol=1e-05;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 335/448] START C=0.1, penalty=None, solver=saga, tol=1e-05.............\n",
            "[CV 4/5; 335/448] END C=0.1, penalty=None, solver=saga, tol=1e-05;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 335/448] START C=0.1, penalty=None, solver=saga, tol=1e-05.............\n",
            "[CV 5/5; 335/448] END C=0.1, penalty=None, solver=saga, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 336/448] START C=0.1, penalty=None, solver=saga, tol=1e-06.............\n",
            "[CV 1/5; 336/448] END C=0.1, penalty=None, solver=saga, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 336/448] START C=0.1, penalty=None, solver=saga, tol=1e-06.............\n",
            "[CV 2/5; 336/448] END C=0.1, penalty=None, solver=saga, tol=1e-06;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 336/448] START C=0.1, penalty=None, solver=saga, tol=1e-06.............\n",
            "[CV 3/5; 336/448] END C=0.1, penalty=None, solver=saga, tol=1e-06;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 336/448] START C=0.1, penalty=None, solver=saga, tol=1e-06.............\n",
            "[CV 4/5; 336/448] END C=0.1, penalty=None, solver=saga, tol=1e-06;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 336/448] START C=0.1, penalty=None, solver=saga, tol=1e-06.............\n",
            "[CV 5/5; 336/448] END C=0.1, penalty=None, solver=saga, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 337/448] START C=1, penalty=l1, solver=saga, tol=0.001.................\n",
            "[CV 1/5; 337/448] END C=1, penalty=l1, solver=saga, tol=0.001;, score=0.852 total time=   0.0s\n",
            "[CV 2/5; 337/448] START C=1, penalty=l1, solver=saga, tol=0.001.................\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 337/448] END C=1, penalty=l1, solver=saga, tol=0.001;, score=0.784 total time=   0.0s\n",
            "[CV 3/5; 337/448] START C=1, penalty=l1, solver=saga, tol=0.001.................\n",
            "[CV 3/5; 337/448] END C=1, penalty=l1, solver=saga, tol=0.001;, score=0.816 total time=   0.0s\n",
            "[CV 4/5; 337/448] START C=1, penalty=l1, solver=saga, tol=0.001.................\n",
            "[CV 4/5; 337/448] END C=1, penalty=l1, solver=saga, tol=0.001;, score=0.832 total time=   0.0s\n",
            "[CV 5/5; 337/448] START C=1, penalty=l1, solver=saga, tol=0.001.................\n",
            "[CV 5/5; 337/448] END C=1, penalty=l1, solver=saga, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 338/448] START C=1, penalty=l1, solver=saga, tol=0.0001................\n",
            "[CV 1/5; 338/448] END C=1, penalty=l1, solver=saga, tol=0.0001;, score=0.852 total time=   0.0s\n",
            "[CV 2/5; 338/448] START C=1, penalty=l1, solver=saga, tol=0.0001................\n",
            "[CV 2/5; 338/448] END C=1, penalty=l1, solver=saga, tol=0.0001;, score=0.784 total time=   0.0s\n",
            "[CV 3/5; 338/448] START C=1, penalty=l1, solver=saga, tol=0.0001................\n",
            "[CV 3/5; 338/448] END C=1, penalty=l1, solver=saga, tol=0.0001;, score=0.816 total time=   0.0s\n",
            "[CV 4/5; 338/448] START C=1, penalty=l1, solver=saga, tol=0.0001................\n",
            "[CV 4/5; 338/448] END C=1, penalty=l1, solver=saga, tol=0.0001;, score=0.832 total time=   0.0s\n",
            "[CV 5/5; 338/448] START C=1, penalty=l1, solver=saga, tol=0.0001................\n",
            "[CV 5/5; 338/448] END C=1, penalty=l1, solver=saga, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 339/448] START C=1, penalty=l1, solver=saga, tol=1e-05.................\n",
            "[CV 1/5; 339/448] END C=1, penalty=l1, solver=saga, tol=1e-05;, score=0.852 total time=   0.0s\n",
            "[CV 2/5; 339/448] START C=1, penalty=l1, solver=saga, tol=1e-05.................\n",
            "[CV 2/5; 339/448] END C=1, penalty=l1, solver=saga, tol=1e-05;, score=0.784 total time=   0.0s\n",
            "[CV 3/5; 339/448] START C=1, penalty=l1, solver=saga, tol=1e-05.................\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 339/448] END C=1, penalty=l1, solver=saga, tol=1e-05;, score=0.816 total time=   0.0s\n",
            "[CV 4/5; 339/448] START C=1, penalty=l1, solver=saga, tol=1e-05.................\n",
            "[CV 4/5; 339/448] END C=1, penalty=l1, solver=saga, tol=1e-05;, score=0.832 total time=   0.0s\n",
            "[CV 5/5; 339/448] START C=1, penalty=l1, solver=saga, tol=1e-05.................\n",
            "[CV 5/5; 339/448] END C=1, penalty=l1, solver=saga, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 340/448] START C=1, penalty=l1, solver=saga, tol=1e-06.................\n",
            "[CV 1/5; 340/448] END C=1, penalty=l1, solver=saga, tol=1e-06;, score=0.852 total time=   0.0s\n",
            "[CV 2/5; 340/448] START C=1, penalty=l1, solver=saga, tol=1e-06.................\n",
            "[CV 2/5; 340/448] END C=1, penalty=l1, solver=saga, tol=1e-06;, score=0.784 total time=   0.0s\n",
            "[CV 3/5; 340/448] START C=1, penalty=l1, solver=saga, tol=1e-06.................\n",
            "[CV 3/5; 340/448] END C=1, penalty=l1, solver=saga, tol=1e-06;, score=0.816 total time=   0.0s\n",
            "[CV 4/5; 340/448] START C=1, penalty=l1, solver=saga, tol=1e-06.................\n",
            "[CV 4/5; 340/448] END C=1, penalty=l1, solver=saga, tol=1e-06;, score=0.832 total time=   0.0s\n",
            "[CV 5/5; 340/448] START C=1, penalty=l1, solver=saga, tol=1e-06.................\n",
            "[CV 5/5; 340/448] END C=1, penalty=l1, solver=saga, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 341/448] START C=1, penalty=l2, solver=saga, tol=0.001.................\n",
            "[CV 1/5; 341/448] END C=1, penalty=l2, solver=saga, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 341/448] START C=1, penalty=l2, solver=saga, tol=0.001.................\n",
            "[CV 2/5; 341/448] END C=1, penalty=l2, solver=saga, tol=0.001;, score=0.776 total time=   0.0s\n",
            "[CV 3/5; 341/448] START C=1, penalty=l2, solver=saga, tol=0.001.................\n",
            "[CV 3/5; 341/448] END C=1, penalty=l2, solver=saga, tol=0.001;, score=0.808 total time=   0.0s\n",
            "[CV 4/5; 341/448] START C=1, penalty=l2, solver=saga, tol=0.001.................\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 341/448] END C=1, penalty=l2, solver=saga, tol=0.001;, score=0.824 total time=   0.0s\n",
            "[CV 5/5; 341/448] START C=1, penalty=l2, solver=saga, tol=0.001.................\n",
            "[CV 5/5; 341/448] END C=1, penalty=l2, solver=saga, tol=0.001;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 342/448] START C=1, penalty=l2, solver=saga, tol=0.0001................\n",
            "[CV 1/5; 342/448] END C=1, penalty=l2, solver=saga, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 342/448] START C=1, penalty=l2, solver=saga, tol=0.0001................\n",
            "[CV 2/5; 342/448] END C=1, penalty=l2, solver=saga, tol=0.0001;, score=0.776 total time=   0.0s\n",
            "[CV 3/5; 342/448] START C=1, penalty=l2, solver=saga, tol=0.0001................\n",
            "[CV 3/5; 342/448] END C=1, penalty=l2, solver=saga, tol=0.0001;, score=0.808 total time=   0.0s\n",
            "[CV 4/5; 342/448] START C=1, penalty=l2, solver=saga, tol=0.0001................\n",
            "[CV 4/5; 342/448] END C=1, penalty=l2, solver=saga, tol=0.0001;, score=0.824 total time=   0.0s\n",
            "[CV 5/5; 342/448] START C=1, penalty=l2, solver=saga, tol=0.0001................\n",
            "[CV 5/5; 342/448] END C=1, penalty=l2, solver=saga, tol=0.0001;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 343/448] START C=1, penalty=l2, solver=saga, tol=1e-05.................\n",
            "[CV 1/5; 343/448] END C=1, penalty=l2, solver=saga, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 343/448] START C=1, penalty=l2, solver=saga, tol=1e-05.................\n",
            "[CV 2/5; 343/448] END C=1, penalty=l2, solver=saga, tol=1e-05;, score=0.776 total time=   0.0s\n",
            "[CV 3/5; 343/448] START C=1, penalty=l2, solver=saga, tol=1e-05.................\n",
            "[CV 3/5; 343/448] END C=1, penalty=l2, solver=saga, tol=1e-05;, score=0.808 total time=   0.0s\n",
            "[CV 4/5; 343/448] START C=1, penalty=l2, solver=saga, tol=1e-05.................\n",
            "[CV 4/5; 343/448] END C=1, penalty=l2, solver=saga, tol=1e-05;, score=0.824 total time=   0.0s\n",
            "[CV 5/5; 343/448] START C=1, penalty=l2, solver=saga, tol=1e-05.................\n",
            "[CV 5/5; 343/448] END C=1, penalty=l2, solver=saga, tol=1e-05;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 344/448] START C=1, penalty=l2, solver=saga, tol=1e-06.................\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 344/448] END C=1, penalty=l2, solver=saga, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 344/448] START C=1, penalty=l2, solver=saga, tol=1e-06.................\n",
            "[CV 2/5; 344/448] END C=1, penalty=l2, solver=saga, tol=1e-06;, score=0.776 total time=   0.0s\n",
            "[CV 3/5; 344/448] START C=1, penalty=l2, solver=saga, tol=1e-06.................\n",
            "[CV 3/5; 344/448] END C=1, penalty=l2, solver=saga, tol=1e-06;, score=0.808 total time=   0.0s\n",
            "[CV 4/5; 344/448] START C=1, penalty=l2, solver=saga, tol=1e-06.................\n",
            "[CV 4/5; 344/448] END C=1, penalty=l2, solver=saga, tol=1e-06;, score=0.824 total time=   0.0s\n",
            "[CV 5/5; 344/448] START C=1, penalty=l2, solver=saga, tol=1e-06.................\n",
            "[CV 5/5; 344/448] END C=1, penalty=l2, solver=saga, tol=1e-06;, score=0.928 total time=   0.0s\n",
            "[CV 1/5; 345/448] START C=1, penalty=elasticnet, solver=saga, tol=0.001.........\n",
            "[CV 1/5; 345/448] END C=1, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 2/5; 345/448] START C=1, penalty=elasticnet, solver=saga, tol=0.001.........\n",
            "[CV 2/5; 345/448] END C=1, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 3/5; 345/448] START C=1, penalty=elasticnet, solver=saga, tol=0.001.........\n",
            "[CV 3/5; 345/448] END C=1, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 4/5; 345/448] START C=1, penalty=elasticnet, solver=saga, tol=0.001.........\n",
            "[CV 4/5; 345/448] END C=1, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 5/5; 345/448] START C=1, penalty=elasticnet, solver=saga, tol=0.001.........\n",
            "[CV 5/5; 345/448] END C=1, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 1/5; 346/448] START C=1, penalty=elasticnet, solver=saga, tol=0.0001........\n",
            "[CV 1/5; 346/448] END C=1, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 2/5; 346/448] START C=1, penalty=elasticnet, solver=saga, tol=0.0001........\n",
            "[CV 2/5; 346/448] END C=1, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 3/5; 346/448] START C=1, penalty=elasticnet, solver=saga, tol=0.0001........\n",
            "[CV 3/5; 346/448] END C=1, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 4/5; 346/448] START C=1, penalty=elasticnet, solver=saga, tol=0.0001........\n",
            "[CV 4/5; 346/448] END C=1, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 5/5; 346/448] START C=1, penalty=elasticnet, solver=saga, tol=0.0001........\n",
            "[CV 5/5; 346/448] END C=1, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 1/5; 347/448] START C=1, penalty=elasticnet, solver=saga, tol=1e-05.........\n",
            "[CV 1/5; 347/448] END C=1, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 2/5; 347/448] START C=1, penalty=elasticnet, solver=saga, tol=1e-05.........\n",
            "[CV 2/5; 347/448] END C=1, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 3/5; 347/448] START C=1, penalty=elasticnet, solver=saga, tol=1e-05.........\n",
            "[CV 3/5; 347/448] END C=1, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 4/5; 347/448] START C=1, penalty=elasticnet, solver=saga, tol=1e-05.........\n",
            "[CV 4/5; 347/448] END C=1, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 5/5; 347/448] START C=1, penalty=elasticnet, solver=saga, tol=1e-05.........\n",
            "[CV 5/5; 347/448] END C=1, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 1/5; 348/448] START C=1, penalty=elasticnet, solver=saga, tol=1e-06.........\n",
            "[CV 1/5; 348/448] END C=1, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 2/5; 348/448] START C=1, penalty=elasticnet, solver=saga, tol=1e-06.........\n",
            "[CV 2/5; 348/448] END C=1, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 3/5; 348/448] START C=1, penalty=elasticnet, solver=saga, tol=1e-06.........\n",
            "[CV 3/5; 348/448] END C=1, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 4/5; 348/448] START C=1, penalty=elasticnet, solver=saga, tol=1e-06.........\n",
            "[CV 4/5; 348/448] END C=1, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 5/5; 348/448] START C=1, penalty=elasticnet, solver=saga, tol=1e-06.........\n",
            "[CV 5/5; 348/448] END C=1, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 1/5; 349/448] START C=1, penalty=None, solver=saga, tol=0.001...............\n",
            "[CV 1/5; 349/448] END C=1, penalty=None, solver=saga, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 349/448] START C=1, penalty=None, solver=saga, tol=0.001...............\n",
            "[CV 2/5; 349/448] END C=1, penalty=None, solver=saga, tol=0.001;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 349/448] START C=1, penalty=None, solver=saga, tol=0.001...............\n",
            "[CV 3/5; 349/448] END C=1, penalty=None, solver=saga, tol=0.001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 349/448] START C=1, penalty=None, solver=saga, tol=0.001...............\n",
            "[CV 4/5; 349/448] END C=1, penalty=None, solver=saga, tol=0.001;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 349/448] START C=1, penalty=None, solver=saga, tol=0.001...............\n",
            "[CV 5/5; 349/448] END C=1, penalty=None, solver=saga, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 350/448] START C=1, penalty=None, solver=saga, tol=0.0001..............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 350/448] END C=1, penalty=None, solver=saga, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 350/448] START C=1, penalty=None, solver=saga, tol=0.0001..............\n",
            "[CV 2/5; 350/448] END C=1, penalty=None, solver=saga, tol=0.0001;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 350/448] START C=1, penalty=None, solver=saga, tol=0.0001..............\n",
            "[CV 3/5; 350/448] END C=1, penalty=None, solver=saga, tol=0.0001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 350/448] START C=1, penalty=None, solver=saga, tol=0.0001..............\n",
            "[CV 4/5; 350/448] END C=1, penalty=None, solver=saga, tol=0.0001;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 350/448] START C=1, penalty=None, solver=saga, tol=0.0001..............\n",
            "[CV 5/5; 350/448] END C=1, penalty=None, solver=saga, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 351/448] START C=1, penalty=None, solver=saga, tol=1e-05...............\n",
            "[CV 1/5; 351/448] END C=1, penalty=None, solver=saga, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 351/448] START C=1, penalty=None, solver=saga, tol=1e-05...............\n",
            "[CV 2/5; 351/448] END C=1, penalty=None, solver=saga, tol=1e-05;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 351/448] START C=1, penalty=None, solver=saga, tol=1e-05...............\n",
            "[CV 3/5; 351/448] END C=1, penalty=None, solver=saga, tol=1e-05;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 351/448] START C=1, penalty=None, solver=saga, tol=1e-05...............\n",
            "[CV 4/5; 351/448] END C=1, penalty=None, solver=saga, tol=1e-05;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 351/448] START C=1, penalty=None, solver=saga, tol=1e-05...............\n",
            "[CV 5/5; 351/448] END C=1, penalty=None, solver=saga, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 352/448] START C=1, penalty=None, solver=saga, tol=1e-06...............\n",
            "[CV 1/5; 352/448] END C=1, penalty=None, solver=saga, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 352/448] START C=1, penalty=None, solver=saga, tol=1e-06...............\n",
            "[CV 2/5; 352/448] END C=1, penalty=None, solver=saga, tol=1e-06;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 352/448] START C=1, penalty=None, solver=saga, tol=1e-06...............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 352/448] END C=1, penalty=None, solver=saga, tol=1e-06;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 352/448] START C=1, penalty=None, solver=saga, tol=1e-06...............\n",
            "[CV 4/5; 352/448] END C=1, penalty=None, solver=saga, tol=1e-06;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 352/448] START C=1, penalty=None, solver=saga, tol=1e-06...............\n",
            "[CV 5/5; 352/448] END C=1, penalty=None, solver=saga, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 353/448] START C=10.0, penalty=l1, solver=saga, tol=0.001..............\n",
            "[CV 1/5; 353/448] END C=10.0, penalty=l1, solver=saga, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 353/448] START C=10.0, penalty=l1, solver=saga, tol=0.001..............\n",
            "[CV 2/5; 353/448] END C=10.0, penalty=l1, solver=saga, tol=0.001;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 353/448] START C=10.0, penalty=l1, solver=saga, tol=0.001..............\n",
            "[CV 3/5; 353/448] END C=10.0, penalty=l1, solver=saga, tol=0.001;, score=0.820 total time=   0.0s\n",
            "[CV 4/5; 353/448] START C=10.0, penalty=l1, solver=saga, tol=0.001..............\n",
            "[CV 4/5; 353/448] END C=10.0, penalty=l1, solver=saga, tol=0.001;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 353/448] START C=10.0, penalty=l1, solver=saga, tol=0.001..............\n",
            "[CV 5/5; 353/448] END C=10.0, penalty=l1, solver=saga, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 354/448] START C=10.0, penalty=l1, solver=saga, tol=0.0001.............\n",
            "[CV 1/5; 354/448] END C=10.0, penalty=l1, solver=saga, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 354/448] START C=10.0, penalty=l1, solver=saga, tol=0.0001.............\n",
            "[CV 2/5; 354/448] END C=10.0, penalty=l1, solver=saga, tol=0.0001;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 354/448] START C=10.0, penalty=l1, solver=saga, tol=0.0001.............\n",
            "[CV 3/5; 354/448] END C=10.0, penalty=l1, solver=saga, tol=0.0001;, score=0.820 total time=   0.0s\n",
            "[CV 4/5; 354/448] START C=10.0, penalty=l1, solver=saga, tol=0.0001.............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 354/448] END C=10.0, penalty=l1, solver=saga, tol=0.0001;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 354/448] START C=10.0, penalty=l1, solver=saga, tol=0.0001.............\n",
            "[CV 5/5; 354/448] END C=10.0, penalty=l1, solver=saga, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 355/448] START C=10.0, penalty=l1, solver=saga, tol=1e-05..............\n",
            "[CV 1/5; 355/448] END C=10.0, penalty=l1, solver=saga, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 355/448] START C=10.0, penalty=l1, solver=saga, tol=1e-05..............\n",
            "[CV 2/5; 355/448] END C=10.0, penalty=l1, solver=saga, tol=1e-05;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 355/448] START C=10.0, penalty=l1, solver=saga, tol=1e-05..............\n",
            "[CV 3/5; 355/448] END C=10.0, penalty=l1, solver=saga, tol=1e-05;, score=0.820 total time=   0.0s\n",
            "[CV 4/5; 355/448] START C=10.0, penalty=l1, solver=saga, tol=1e-05..............\n",
            "[CV 4/5; 355/448] END C=10.0, penalty=l1, solver=saga, tol=1e-05;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 355/448] START C=10.0, penalty=l1, solver=saga, tol=1e-05..............\n",
            "[CV 5/5; 355/448] END C=10.0, penalty=l1, solver=saga, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 356/448] START C=10.0, penalty=l1, solver=saga, tol=1e-06..............\n",
            "[CV 1/5; 356/448] END C=10.0, penalty=l1, solver=saga, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 356/448] START C=10.0, penalty=l1, solver=saga, tol=1e-06..............\n",
            "[CV 2/5; 356/448] END C=10.0, penalty=l1, solver=saga, tol=1e-06;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 356/448] START C=10.0, penalty=l1, solver=saga, tol=1e-06..............\n",
            "[CV 3/5; 356/448] END C=10.0, penalty=l1, solver=saga, tol=1e-06;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 356/448] START C=10.0, penalty=l1, solver=saga, tol=1e-06..............\n",
            "[CV 4/5; 356/448] END C=10.0, penalty=l1, solver=saga, tol=1e-06;, score=0.836 total time=   0.0s\n",
            "[CV 5/5; 356/448] START C=10.0, penalty=l1, solver=saga, tol=1e-06..............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 356/448] END C=10.0, penalty=l1, solver=saga, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 357/448] START C=10.0, penalty=l2, solver=saga, tol=0.001..............\n",
            "[CV 1/5; 357/448] END C=10.0, penalty=l2, solver=saga, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 357/448] START C=10.0, penalty=l2, solver=saga, tol=0.001..............\n",
            "[CV 2/5; 357/448] END C=10.0, penalty=l2, solver=saga, tol=0.001;, score=0.784 total time=   0.0s\n",
            "[CV 3/5; 357/448] START C=10.0, penalty=l2, solver=saga, tol=0.001..............\n",
            "[CV 3/5; 357/448] END C=10.0, penalty=l2, solver=saga, tol=0.001;, score=0.820 total time=   0.0s\n",
            "[CV 4/5; 357/448] START C=10.0, penalty=l2, solver=saga, tol=0.001..............\n",
            "[CV 4/5; 357/448] END C=10.0, penalty=l2, solver=saga, tol=0.001;, score=0.836 total time=   0.0s\n",
            "[CV 5/5; 357/448] START C=10.0, penalty=l2, solver=saga, tol=0.001..............\n",
            "[CV 5/5; 357/448] END C=10.0, penalty=l2, solver=saga, tol=0.001;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 358/448] START C=10.0, penalty=l2, solver=saga, tol=0.0001.............\n",
            "[CV 1/5; 358/448] END C=10.0, penalty=l2, solver=saga, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 358/448] START C=10.0, penalty=l2, solver=saga, tol=0.0001.............\n",
            "[CV 2/5; 358/448] END C=10.0, penalty=l2, solver=saga, tol=0.0001;, score=0.784 total time=   0.0s\n",
            "[CV 3/5; 358/448] START C=10.0, penalty=l2, solver=saga, tol=0.0001.............\n",
            "[CV 3/5; 358/448] END C=10.0, penalty=l2, solver=saga, tol=0.0001;, score=0.820 total time=   0.0s\n",
            "[CV 4/5; 358/448] START C=10.0, penalty=l2, solver=saga, tol=0.0001.............\n",
            "[CV 4/5; 358/448] END C=10.0, penalty=l2, solver=saga, tol=0.0001;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 358/448] START C=10.0, penalty=l2, solver=saga, tol=0.0001.............\n",
            "[CV 5/5; 358/448] END C=10.0, penalty=l2, solver=saga, tol=0.0001;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 359/448] START C=10.0, penalty=l2, solver=saga, tol=1e-05..............\n",
            "[CV 1/5; 359/448] END C=10.0, penalty=l2, solver=saga, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 359/448] START C=10.0, penalty=l2, solver=saga, tol=1e-05..............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 359/448] END C=10.0, penalty=l2, solver=saga, tol=1e-05;, score=0.784 total time=   0.0s\n",
            "[CV 3/5; 359/448] START C=10.0, penalty=l2, solver=saga, tol=1e-05..............\n",
            "[CV 3/5; 359/448] END C=10.0, penalty=l2, solver=saga, tol=1e-05;, score=0.820 total time=   0.0s\n",
            "[CV 4/5; 359/448] START C=10.0, penalty=l2, solver=saga, tol=1e-05..............\n",
            "[CV 4/5; 359/448] END C=10.0, penalty=l2, solver=saga, tol=1e-05;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 359/448] START C=10.0, penalty=l2, solver=saga, tol=1e-05..............\n",
            "[CV 5/5; 359/448] END C=10.0, penalty=l2, solver=saga, tol=1e-05;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 360/448] START C=10.0, penalty=l2, solver=saga, tol=1e-06..............\n",
            "[CV 1/5; 360/448] END C=10.0, penalty=l2, solver=saga, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 360/448] START C=10.0, penalty=l2, solver=saga, tol=1e-06..............\n",
            "[CV 2/5; 360/448] END C=10.0, penalty=l2, solver=saga, tol=1e-06;, score=0.784 total time=   0.0s\n",
            "[CV 3/5; 360/448] START C=10.0, penalty=l2, solver=saga, tol=1e-06..............\n",
            "[CV 3/5; 360/448] END C=10.0, penalty=l2, solver=saga, tol=1e-06;, score=0.820 total time=   0.0s\n",
            "[CV 4/5; 360/448] START C=10.0, penalty=l2, solver=saga, tol=1e-06..............\n",
            "[CV 4/5; 360/448] END C=10.0, penalty=l2, solver=saga, tol=1e-06;, score=0.836 total time=   0.0s\n",
            "[CV 5/5; 360/448] START C=10.0, penalty=l2, solver=saga, tol=1e-06..............\n",
            "[CV 5/5; 360/448] END C=10.0, penalty=l2, solver=saga, tol=1e-06;, score=0.960 total time=   0.0s\n",
            "[CV 1/5; 361/448] START C=10.0, penalty=elasticnet, solver=saga, tol=0.001......\n",
            "[CV 1/5; 361/448] END C=10.0, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 2/5; 361/448] START C=10.0, penalty=elasticnet, solver=saga, tol=0.001......\n",
            "[CV 2/5; 361/448] END C=10.0, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 3/5; 361/448] START C=10.0, penalty=elasticnet, solver=saga, tol=0.001......\n",
            "[CV 3/5; 361/448] END C=10.0, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 4/5; 361/448] START C=10.0, penalty=elasticnet, solver=saga, tol=0.001......\n",
            "[CV 4/5; 361/448] END C=10.0, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 5/5; 361/448] START C=10.0, penalty=elasticnet, solver=saga, tol=0.001......\n",
            "[CV 5/5; 361/448] END C=10.0, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 1/5; 362/448] START C=10.0, penalty=elasticnet, solver=saga, tol=0.0001.....\n",
            "[CV 1/5; 362/448] END C=10.0, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 2/5; 362/448] START C=10.0, penalty=elasticnet, solver=saga, tol=0.0001.....\n",
            "[CV 2/5; 362/448] END C=10.0, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 3/5; 362/448] START C=10.0, penalty=elasticnet, solver=saga, tol=0.0001.....\n",
            "[CV 3/5; 362/448] END C=10.0, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 4/5; 362/448] START C=10.0, penalty=elasticnet, solver=saga, tol=0.0001.....\n",
            "[CV 4/5; 362/448] END C=10.0, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 5/5; 362/448] START C=10.0, penalty=elasticnet, solver=saga, tol=0.0001.....\n",
            "[CV 5/5; 362/448] END C=10.0, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 1/5; 363/448] START C=10.0, penalty=elasticnet, solver=saga, tol=1e-05......\n",
            "[CV 1/5; 363/448] END C=10.0, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 2/5; 363/448] START C=10.0, penalty=elasticnet, solver=saga, tol=1e-05......\n",
            "[CV 2/5; 363/448] END C=10.0, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 3/5; 363/448] START C=10.0, penalty=elasticnet, solver=saga, tol=1e-05......\n",
            "[CV 3/5; 363/448] END C=10.0, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 4/5; 363/448] START C=10.0, penalty=elasticnet, solver=saga, tol=1e-05......\n",
            "[CV 4/5; 363/448] END C=10.0, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 5/5; 363/448] START C=10.0, penalty=elasticnet, solver=saga, tol=1e-05......\n",
            "[CV 5/5; 363/448] END C=10.0, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 1/5; 364/448] START C=10.0, penalty=elasticnet, solver=saga, tol=1e-06......\n",
            "[CV 1/5; 364/448] END C=10.0, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 2/5; 364/448] START C=10.0, penalty=elasticnet, solver=saga, tol=1e-06......\n",
            "[CV 2/5; 364/448] END C=10.0, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 3/5; 364/448] START C=10.0, penalty=elasticnet, solver=saga, tol=1e-06......\n",
            "[CV 3/5; 364/448] END C=10.0, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 4/5; 364/448] START C=10.0, penalty=elasticnet, solver=saga, tol=1e-06......\n",
            "[CV 4/5; 364/448] END C=10.0, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 5/5; 364/448] START C=10.0, penalty=elasticnet, solver=saga, tol=1e-06......\n",
            "[CV 5/5; 364/448] END C=10.0, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 1/5; 365/448] START C=10.0, penalty=None, solver=saga, tol=0.001............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 365/448] END C=10.0, penalty=None, solver=saga, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 365/448] START C=10.0, penalty=None, solver=saga, tol=0.001............\n",
            "[CV 2/5; 365/448] END C=10.0, penalty=None, solver=saga, tol=0.001;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 365/448] START C=10.0, penalty=None, solver=saga, tol=0.001............\n",
            "[CV 3/5; 365/448] END C=10.0, penalty=None, solver=saga, tol=0.001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 365/448] START C=10.0, penalty=None, solver=saga, tol=0.001............\n",
            "[CV 4/5; 365/448] END C=10.0, penalty=None, solver=saga, tol=0.001;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 365/448] START C=10.0, penalty=None, solver=saga, tol=0.001............\n",
            "[CV 5/5; 365/448] END C=10.0, penalty=None, solver=saga, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 366/448] START C=10.0, penalty=None, solver=saga, tol=0.0001...........\n",
            "[CV 1/5; 366/448] END C=10.0, penalty=None, solver=saga, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 366/448] START C=10.0, penalty=None, solver=saga, tol=0.0001...........\n",
            "[CV 2/5; 366/448] END C=10.0, penalty=None, solver=saga, tol=0.0001;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 366/448] START C=10.0, penalty=None, solver=saga, tol=0.0001...........\n",
            "[CV 3/5; 366/448] END C=10.0, penalty=None, solver=saga, tol=0.0001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 366/448] START C=10.0, penalty=None, solver=saga, tol=0.0001...........\n",
            "[CV 4/5; 366/448] END C=10.0, penalty=None, solver=saga, tol=0.0001;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 366/448] START C=10.0, penalty=None, solver=saga, tol=0.0001...........\n",
            "[CV 5/5; 366/448] END C=10.0, penalty=None, solver=saga, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 367/448] START C=10.0, penalty=None, solver=saga, tol=1e-05............\n",
            "[CV 1/5; 367/448] END C=10.0, penalty=None, solver=saga, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 367/448] START C=10.0, penalty=None, solver=saga, tol=1e-05............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 367/448] END C=10.0, penalty=None, solver=saga, tol=1e-05;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 367/448] START C=10.0, penalty=None, solver=saga, tol=1e-05............\n",
            "[CV 3/5; 367/448] END C=10.0, penalty=None, solver=saga, tol=1e-05;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 367/448] START C=10.0, penalty=None, solver=saga, tol=1e-05............\n",
            "[CV 4/5; 367/448] END C=10.0, penalty=None, solver=saga, tol=1e-05;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 367/448] START C=10.0, penalty=None, solver=saga, tol=1e-05............\n",
            "[CV 5/5; 367/448] END C=10.0, penalty=None, solver=saga, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 368/448] START C=10.0, penalty=None, solver=saga, tol=1e-06............\n",
            "[CV 1/5; 368/448] END C=10.0, penalty=None, solver=saga, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 368/448] START C=10.0, penalty=None, solver=saga, tol=1e-06............\n",
            "[CV 2/5; 368/448] END C=10.0, penalty=None, solver=saga, tol=1e-06;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 368/448] START C=10.0, penalty=None, solver=saga, tol=1e-06............\n",
            "[CV 3/5; 368/448] END C=10.0, penalty=None, solver=saga, tol=1e-06;, score=0.820 total time=   0.0s\n",
            "[CV 4/5; 368/448] START C=10.0, penalty=None, solver=saga, tol=1e-06............\n",
            "[CV 4/5; 368/448] END C=10.0, penalty=None, solver=saga, tol=1e-06;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 368/448] START C=10.0, penalty=None, solver=saga, tol=1e-06............\n",
            "[CV 5/5; 368/448] END C=10.0, penalty=None, solver=saga, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 369/448] START C=100.0, penalty=l1, solver=saga, tol=0.001.............\n",
            "[CV 1/5; 369/448] END C=100.0, penalty=l1, solver=saga, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 369/448] START C=100.0, penalty=l1, solver=saga, tol=0.001.............\n",
            "[CV 2/5; 369/448] END C=100.0, penalty=l1, solver=saga, tol=0.001;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 369/448] START C=100.0, penalty=l1, solver=saga, tol=0.001.............\n",
            "[CV 3/5; 369/448] END C=100.0, penalty=l1, solver=saga, tol=0.001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 369/448] START C=100.0, penalty=l1, solver=saga, tol=0.001.............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 369/448] END C=100.0, penalty=l1, solver=saga, tol=0.001;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 369/448] START C=100.0, penalty=l1, solver=saga, tol=0.001.............\n",
            "[CV 5/5; 369/448] END C=100.0, penalty=l1, solver=saga, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 370/448] START C=100.0, penalty=l1, solver=saga, tol=0.0001............\n",
            "[CV 1/5; 370/448] END C=100.0, penalty=l1, solver=saga, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 370/448] START C=100.0, penalty=l1, solver=saga, tol=0.0001............\n",
            "[CV 2/5; 370/448] END C=100.0, penalty=l1, solver=saga, tol=0.0001;, score=0.792 total time=   0.0s\n",
            "[CV 3/5; 370/448] START C=100.0, penalty=l1, solver=saga, tol=0.0001............\n",
            "[CV 3/5; 370/448] END C=100.0, penalty=l1, solver=saga, tol=0.0001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 370/448] START C=100.0, penalty=l1, solver=saga, tol=0.0001............\n",
            "[CV 4/5; 370/448] END C=100.0, penalty=l1, solver=saga, tol=0.0001;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 370/448] START C=100.0, penalty=l1, solver=saga, tol=0.0001............\n",
            "[CV 5/5; 370/448] END C=100.0, penalty=l1, solver=saga, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 371/448] START C=100.0, penalty=l1, solver=saga, tol=1e-05.............\n",
            "[CV 1/5; 371/448] END C=100.0, penalty=l1, solver=saga, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 371/448] START C=100.0, penalty=l1, solver=saga, tol=1e-05.............\n",
            "[CV 2/5; 371/448] END C=100.0, penalty=l1, solver=saga, tol=1e-05;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 371/448] START C=100.0, penalty=l1, solver=saga, tol=1e-05.............\n",
            "[CV 3/5; 371/448] END C=100.0, penalty=l1, solver=saga, tol=1e-05;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 371/448] START C=100.0, penalty=l1, solver=saga, tol=1e-05.............\n",
            "[CV 4/5; 371/448] END C=100.0, penalty=l1, solver=saga, tol=1e-05;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 371/448] START C=100.0, penalty=l1, solver=saga, tol=1e-05.............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 371/448] END C=100.0, penalty=l1, solver=saga, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 372/448] START C=100.0, penalty=l1, solver=saga, tol=1e-06.............\n",
            "[CV 1/5; 372/448] END C=100.0, penalty=l1, solver=saga, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 372/448] START C=100.0, penalty=l1, solver=saga, tol=1e-06.............\n",
            "[CV 2/5; 372/448] END C=100.0, penalty=l1, solver=saga, tol=1e-06;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 372/448] START C=100.0, penalty=l1, solver=saga, tol=1e-06.............\n",
            "[CV 3/5; 372/448] END C=100.0, penalty=l1, solver=saga, tol=1e-06;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 372/448] START C=100.0, penalty=l1, solver=saga, tol=1e-06.............\n",
            "[CV 4/5; 372/448] END C=100.0, penalty=l1, solver=saga, tol=1e-06;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 372/448] START C=100.0, penalty=l1, solver=saga, tol=1e-06.............\n",
            "[CV 5/5; 372/448] END C=100.0, penalty=l1, solver=saga, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 373/448] START C=100.0, penalty=l2, solver=saga, tol=0.001.............\n",
            "[CV 1/5; 373/448] END C=100.0, penalty=l2, solver=saga, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 373/448] START C=100.0, penalty=l2, solver=saga, tol=0.001.............\n",
            "[CV 2/5; 373/448] END C=100.0, penalty=l2, solver=saga, tol=0.001;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 373/448] START C=100.0, penalty=l2, solver=saga, tol=0.001.............\n",
            "[CV 3/5; 373/448] END C=100.0, penalty=l2, solver=saga, tol=0.001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 373/448] START C=100.0, penalty=l2, solver=saga, tol=0.001.............\n",
            "[CV 4/5; 373/448] END C=100.0, penalty=l2, solver=saga, tol=0.001;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 373/448] START C=100.0, penalty=l2, solver=saga, tol=0.001.............\n",
            "[CV 5/5; 373/448] END C=100.0, penalty=l2, solver=saga, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 374/448] START C=100.0, penalty=l2, solver=saga, tol=0.0001............\n",
            "[CV 1/5; 374/448] END C=100.0, penalty=l2, solver=saga, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 374/448] START C=100.0, penalty=l2, solver=saga, tol=0.0001............"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[CV 2/5; 374/448] END C=100.0, penalty=l2, solver=saga, tol=0.0001;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 374/448] START C=100.0, penalty=l2, solver=saga, tol=0.0001............\n",
            "[CV 3/5; 374/448] END C=100.0, penalty=l2, solver=saga, tol=0.0001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 374/448] START C=100.0, penalty=l2, solver=saga, tol=0.0001............\n",
            "[CV 4/5; 374/448] END C=100.0, penalty=l2, solver=saga, tol=0.0001;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 374/448] START C=100.0, penalty=l2, solver=saga, tol=0.0001............\n",
            "[CV 5/5; 374/448] END C=100.0, penalty=l2, solver=saga, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 375/448] START C=100.0, penalty=l2, solver=saga, tol=1e-05.............\n",
            "[CV 1/5; 375/448] END C=100.0, penalty=l2, solver=saga, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 375/448] START C=100.0, penalty=l2, solver=saga, tol=1e-05.............\n",
            "[CV 2/5; 375/448] END C=100.0, penalty=l2, solver=saga, tol=1e-05;, score=0.792 total time=   0.0s\n",
            "[CV 3/5; 375/448] START C=100.0, penalty=l2, solver=saga, tol=1e-05.............\n",
            "[CV 3/5; 375/448] END C=100.0, penalty=l2, solver=saga, tol=1e-05;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 375/448] START C=100.0, penalty=l2, solver=saga, tol=1e-05.............\n",
            "[CV 4/5; 375/448] END C=100.0, penalty=l2, solver=saga, tol=1e-05;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 375/448] START C=100.0, penalty=l2, solver=saga, tol=1e-05.............\n",
            "[CV 5/5; 375/448] END C=100.0, penalty=l2, solver=saga, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 376/448] START C=100.0, penalty=l2, solver=saga, tol=1e-06.............\n",
            "[CV 1/5; 376/448] END C=100.0, penalty=l2, solver=saga, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 376/448] START C=100.0, penalty=l2, solver=saga, tol=1e-06.............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 376/448] END C=100.0, penalty=l2, solver=saga, tol=1e-06;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 376/448] START C=100.0, penalty=l2, solver=saga, tol=1e-06.............\n",
            "[CV 3/5; 376/448] END C=100.0, penalty=l2, solver=saga, tol=1e-06;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 376/448] START C=100.0, penalty=l2, solver=saga, tol=1e-06.............\n",
            "[CV 4/5; 376/448] END C=100.0, penalty=l2, solver=saga, tol=1e-06;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 376/448] START C=100.0, penalty=l2, solver=saga, tol=1e-06.............\n",
            "[CV 5/5; 376/448] END C=100.0, penalty=l2, solver=saga, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 377/448] START C=100.0, penalty=elasticnet, solver=saga, tol=0.001.....\n",
            "[CV 1/5; 377/448] END C=100.0, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 2/5; 377/448] START C=100.0, penalty=elasticnet, solver=saga, tol=0.001.....\n",
            "[CV 2/5; 377/448] END C=100.0, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 3/5; 377/448] START C=100.0, penalty=elasticnet, solver=saga, tol=0.001.....\n",
            "[CV 3/5; 377/448] END C=100.0, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 4/5; 377/448] START C=100.0, penalty=elasticnet, solver=saga, tol=0.001.....\n",
            "[CV 4/5; 377/448] END C=100.0, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 5/5; 377/448] START C=100.0, penalty=elasticnet, solver=saga, tol=0.001.....\n",
            "[CV 5/5; 377/448] END C=100.0, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 1/5; 378/448] START C=100.0, penalty=elasticnet, solver=saga, tol=0.0001....\n",
            "[CV 1/5; 378/448] END C=100.0, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 2/5; 378/448] START C=100.0, penalty=elasticnet, solver=saga, tol=0.0001....\n",
            "[CV 2/5; 378/448] END C=100.0, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 3/5; 378/448] START C=100.0, penalty=elasticnet, solver=saga, tol=0.0001....\n",
            "[CV 3/5; 378/448] END C=100.0, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 4/5; 378/448] START C=100.0, penalty=elasticnet, solver=saga, tol=0.0001....\n",
            "[CV 4/5; 378/448] END C=100.0, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 5/5; 378/448] START C=100.0, penalty=elasticnet, solver=saga, tol=0.0001....\n",
            "[CV 5/5; 378/448] END C=100.0, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 1/5; 379/448] START C=100.0, penalty=elasticnet, solver=saga, tol=1e-05.....\n",
            "[CV 1/5; 379/448] END C=100.0, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 2/5; 379/448] START C=100.0, penalty=elasticnet, solver=saga, tol=1e-05.....\n",
            "[CV 2/5; 379/448] END C=100.0, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 3/5; 379/448] START C=100.0, penalty=elasticnet, solver=saga, tol=1e-05.....\n",
            "[CV 3/5; 379/448] END C=100.0, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 4/5; 379/448] START C=100.0, penalty=elasticnet, solver=saga, tol=1e-05.....\n",
            "[CV 4/5; 379/448] END C=100.0, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 5/5; 379/448] START C=100.0, penalty=elasticnet, solver=saga, tol=1e-05.....\n",
            "[CV 5/5; 379/448] END C=100.0, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 1/5; 380/448] START C=100.0, penalty=elasticnet, solver=saga, tol=1e-06.....\n",
            "[CV 1/5; 380/448] END C=100.0, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 2/5; 380/448] START C=100.0, penalty=elasticnet, solver=saga, tol=1e-06.....\n",
            "[CV 2/5; 380/448] END C=100.0, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 3/5; 380/448] START C=100.0, penalty=elasticnet, solver=saga, tol=1e-06.....\n",
            "[CV 3/5; 380/448] END C=100.0, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 4/5; 380/448] START C=100.0, penalty=elasticnet, solver=saga, tol=1e-06.....\n",
            "[CV 4/5; 380/448] END C=100.0, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 5/5; 380/448] START C=100.0, penalty=elasticnet, solver=saga, tol=1e-06.....\n",
            "[CV 5/5; 380/448] END C=100.0, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 1/5; 381/448] START C=100.0, penalty=None, solver=saga, tol=0.001...........\n",
            "[CV 1/5; 381/448] END C=100.0, penalty=None, solver=saga, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 381/448] START C=100.0, penalty=None, solver=saga, tol=0.001...........\n",
            "[CV 2/5; 381/448] END C=100.0, penalty=None, solver=saga, tol=0.001;, score=0.792 total time=   0.0s\n",
            "[CV 3/5; 381/448] START C=100.0, penalty=None, solver=saga, tol=0.001...........\n",
            "[CV 3/5; 381/448] END C=100.0, penalty=None, solver=saga, tol=0.001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 381/448] START C=100.0, penalty=None, solver=saga, tol=0.001...........\n",
            "[CV 4/5; 381/448] END C=100.0, penalty=None, solver=saga, tol=0.001;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 381/448] START C=100.0, penalty=None, solver=saga, tol=0.001...........\n",
            "[CV 5/5; 381/448] END C=100.0, penalty=None, solver=saga, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 382/448] START C=100.0, penalty=None, solver=saga, tol=0.0001..........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 382/448] END C=100.0, penalty=None, solver=saga, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 382/448] START C=100.0, penalty=None, solver=saga, tol=0.0001..........\n",
            "[CV 2/5; 382/448] END C=100.0, penalty=None, solver=saga, tol=0.0001;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 382/448] START C=100.0, penalty=None, solver=saga, tol=0.0001..........\n",
            "[CV 3/5; 382/448] END C=100.0, penalty=None, solver=saga, tol=0.0001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 382/448] START C=100.0, penalty=None, solver=saga, tol=0.0001..........\n",
            "[CV 4/5; 382/448] END C=100.0, penalty=None, solver=saga, tol=0.0001;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 382/448] START C=100.0, penalty=None, solver=saga, tol=0.0001..........\n",
            "[CV 5/5; 382/448] END C=100.0, penalty=None, solver=saga, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 383/448] START C=100.0, penalty=None, solver=saga, tol=1e-05...........\n",
            "[CV 1/5; 383/448] END C=100.0, penalty=None, solver=saga, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 383/448] START C=100.0, penalty=None, solver=saga, tol=1e-05...........\n",
            "[CV 2/5; 383/448] END C=100.0, penalty=None, solver=saga, tol=1e-05;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 383/448] START C=100.0, penalty=None, solver=saga, tol=1e-05...........\n",
            "[CV 3/5; 383/448] END C=100.0, penalty=None, solver=saga, tol=1e-05;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 383/448] START C=100.0, penalty=None, solver=saga, tol=1e-05...........\n",
            "[CV 4/5; 383/448] END C=100.0, penalty=None, solver=saga, tol=1e-05;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 383/448] START C=100.0, penalty=None, solver=saga, tol=1e-05...........\n",
            "[CV 5/5; 383/448] END C=100.0, penalty=None, solver=saga, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 384/448] START C=100.0, penalty=None, solver=saga, tol=1e-06...........\n",
            "[CV 1/5; 384/448] END C=100.0, penalty=None, solver=saga, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 384/448] START C=100.0, penalty=None, solver=saga, tol=1e-06...........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 384/448] END C=100.0, penalty=None, solver=saga, tol=1e-06;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 384/448] START C=100.0, penalty=None, solver=saga, tol=1e-06...........\n",
            "[CV 3/5; 384/448] END C=100.0, penalty=None, solver=saga, tol=1e-06;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 384/448] START C=100.0, penalty=None, solver=saga, tol=1e-06...........\n",
            "[CV 4/5; 384/448] END C=100.0, penalty=None, solver=saga, tol=1e-06;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 384/448] START C=100.0, penalty=None, solver=saga, tol=1e-06...........\n",
            "[CV 5/5; 384/448] END C=100.0, penalty=None, solver=saga, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 385/448] START C=1000.0, penalty=l1, solver=saga, tol=0.001............\n",
            "[CV 1/5; 385/448] END C=1000.0, penalty=l1, solver=saga, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 385/448] START C=1000.0, penalty=l1, solver=saga, tol=0.001............\n",
            "[CV 2/5; 385/448] END C=1000.0, penalty=l1, solver=saga, tol=0.001;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 385/448] START C=1000.0, penalty=l1, solver=saga, tol=0.001............\n",
            "[CV 3/5; 385/448] END C=1000.0, penalty=l1, solver=saga, tol=0.001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 385/448] START C=1000.0, penalty=l1, solver=saga, tol=0.001............\n",
            "[CV 4/5; 385/448] END C=1000.0, penalty=l1, solver=saga, tol=0.001;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 385/448] START C=1000.0, penalty=l1, solver=saga, tol=0.001............\n",
            "[CV 5/5; 385/448] END C=1000.0, penalty=l1, solver=saga, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 386/448] START C=1000.0, penalty=l1, solver=saga, tol=0.0001...........\n",
            "[CV 1/5; 386/448] END C=1000.0, penalty=l1, solver=saga, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 386/448] START C=1000.0, penalty=l1, solver=saga, tol=0.0001...........\n",
            "[CV 2/5; 386/448] END C=1000.0, penalty=l1, solver=saga, tol=0.0001;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 386/448] START C=1000.0, penalty=l1, solver=saga, tol=0.0001...........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 386/448] END C=1000.0, penalty=l1, solver=saga, tol=0.0001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 386/448] START C=1000.0, penalty=l1, solver=saga, tol=0.0001...........\n",
            "[CV 4/5; 386/448] END C=1000.0, penalty=l1, solver=saga, tol=0.0001;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 386/448] START C=1000.0, penalty=l1, solver=saga, tol=0.0001...........\n",
            "[CV 5/5; 386/448] END C=1000.0, penalty=l1, solver=saga, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 387/448] START C=1000.0, penalty=l1, solver=saga, tol=1e-05............\n",
            "[CV 1/5; 387/448] END C=1000.0, penalty=l1, solver=saga, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 387/448] START C=1000.0, penalty=l1, solver=saga, tol=1e-05............\n",
            "[CV 2/5; 387/448] END C=1000.0, penalty=l1, solver=saga, tol=1e-05;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 387/448] START C=1000.0, penalty=l1, solver=saga, tol=1e-05............\n",
            "[CV 3/5; 387/448] END C=1000.0, penalty=l1, solver=saga, tol=1e-05;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 387/448] START C=1000.0, penalty=l1, solver=saga, tol=1e-05............\n",
            "[CV 4/5; 387/448] END C=1000.0, penalty=l1, solver=saga, tol=1e-05;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 387/448] START C=1000.0, penalty=l1, solver=saga, tol=1e-05............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 387/448] END C=1000.0, penalty=l1, solver=saga, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 388/448] START C=1000.0, penalty=l1, solver=saga, tol=1e-06............\n",
            "[CV 1/5; 388/448] END C=1000.0, penalty=l1, solver=saga, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 388/448] START C=1000.0, penalty=l1, solver=saga, tol=1e-06............\n",
            "[CV 2/5; 388/448] END C=1000.0, penalty=l1, solver=saga, tol=1e-06;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 388/448] START C=1000.0, penalty=l1, solver=saga, tol=1e-06............\n",
            "[CV 3/5; 388/448] END C=1000.0, penalty=l1, solver=saga, tol=1e-06;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 388/448] START C=1000.0, penalty=l1, solver=saga, tol=1e-06............\n",
            "[CV 4/5; 388/448] END C=1000.0, penalty=l1, solver=saga, tol=1e-06;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 388/448] START C=1000.0, penalty=l1, solver=saga, tol=1e-06............\n",
            "[CV 5/5; 388/448] END C=1000.0, penalty=l1, solver=saga, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 389/448] START C=1000.0, penalty=l2, solver=saga, tol=0.001............\n",
            "[CV 1/5; 389/448] END C=1000.0, penalty=l2, solver=saga, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 389/448] START C=1000.0, penalty=l2, solver=saga, tol=0.001............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 389/448] END C=1000.0, penalty=l2, solver=saga, tol=0.001;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 389/448] START C=1000.0, penalty=l2, solver=saga, tol=0.001............\n",
            "[CV 3/5; 389/448] END C=1000.0, penalty=l2, solver=saga, tol=0.001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 389/448] START C=1000.0, penalty=l2, solver=saga, tol=0.001............\n",
            "[CV 4/5; 389/448] END C=1000.0, penalty=l2, solver=saga, tol=0.001;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 389/448] START C=1000.0, penalty=l2, solver=saga, tol=0.001............\n",
            "[CV 5/5; 389/448] END C=1000.0, penalty=l2, solver=saga, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 390/448] START C=1000.0, penalty=l2, solver=saga, tol=0.0001...........\n",
            "[CV 1/5; 390/448] END C=1000.0, penalty=l2, solver=saga, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 390/448] START C=1000.0, penalty=l2, solver=saga, tol=0.0001...........\n",
            "[CV 2/5; 390/448] END C=1000.0, penalty=l2, solver=saga, tol=0.0001;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 390/448] START C=1000.0, penalty=l2, solver=saga, tol=0.0001...........\n",
            "[CV 3/5; 390/448] END C=1000.0, penalty=l2, solver=saga, tol=0.0001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 390/448] START C=1000.0, penalty=l2, solver=saga, tol=0.0001...........\n",
            "[CV 4/5; 390/448] END C=1000.0, penalty=l2, solver=saga, tol=0.0001;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 390/448] START C=1000.0, penalty=l2, solver=saga, tol=0.0001...........\n",
            "[CV 5/5; 390/448] END C=1000.0, penalty=l2, solver=saga, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 391/448] START C=1000.0, penalty=l2, solver=saga, tol=1e-05............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 391/448] END C=1000.0, penalty=l2, solver=saga, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 391/448] START C=1000.0, penalty=l2, solver=saga, tol=1e-05............\n",
            "[CV 2/5; 391/448] END C=1000.0, penalty=l2, solver=saga, tol=1e-05;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 391/448] START C=1000.0, penalty=l2, solver=saga, tol=1e-05............\n",
            "[CV 3/5; 391/448] END C=1000.0, penalty=l2, solver=saga, tol=1e-05;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 391/448] START C=1000.0, penalty=l2, solver=saga, tol=1e-05............\n",
            "[CV 4/5; 391/448] END C=1000.0, penalty=l2, solver=saga, tol=1e-05;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 391/448] START C=1000.0, penalty=l2, solver=saga, tol=1e-05............\n",
            "[CV 5/5; 391/448] END C=1000.0, penalty=l2, solver=saga, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 392/448] START C=1000.0, penalty=l2, solver=saga, tol=1e-06............\n",
            "[CV 1/5; 392/448] END C=1000.0, penalty=l2, solver=saga, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 392/448] START C=1000.0, penalty=l2, solver=saga, tol=1e-06............\n",
            "[CV 2/5; 392/448] END C=1000.0, penalty=l2, solver=saga, tol=1e-06;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 392/448] START C=1000.0, penalty=l2, solver=saga, tol=1e-06............\n",
            "[CV 3/5; 392/448] END C=1000.0, penalty=l2, solver=saga, tol=1e-06;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 392/448] START C=1000.0, penalty=l2, solver=saga, tol=1e-06............\n",
            "[CV 4/5; 392/448] END C=1000.0, penalty=l2, solver=saga, tol=1e-06;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 392/448] START C=1000.0, penalty=l2, solver=saga, tol=1e-06............\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 392/448] END C=1000.0, penalty=l2, solver=saga, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 393/448] START C=1000.0, penalty=elasticnet, solver=saga, tol=0.001....\n",
            "[CV 1/5; 393/448] END C=1000.0, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 2/5; 393/448] START C=1000.0, penalty=elasticnet, solver=saga, tol=0.001....\n",
            "[CV 2/5; 393/448] END C=1000.0, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 3/5; 393/448] START C=1000.0, penalty=elasticnet, solver=saga, tol=0.001....\n",
            "[CV 3/5; 393/448] END C=1000.0, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 4/5; 393/448] START C=1000.0, penalty=elasticnet, solver=saga, tol=0.001....\n",
            "[CV 4/5; 393/448] END C=1000.0, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 5/5; 393/448] START C=1000.0, penalty=elasticnet, solver=saga, tol=0.001....\n",
            "[CV 5/5; 393/448] END C=1000.0, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 1/5; 394/448] START C=1000.0, penalty=elasticnet, solver=saga, tol=0.0001...\n",
            "[CV 1/5; 394/448] END C=1000.0, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 2/5; 394/448] START C=1000.0, penalty=elasticnet, solver=saga, tol=0.0001...\n",
            "[CV 2/5; 394/448] END C=1000.0, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 3/5; 394/448] START C=1000.0, penalty=elasticnet, solver=saga, tol=0.0001...\n",
            "[CV 3/5; 394/448] END C=1000.0, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 4/5; 394/448] START C=1000.0, penalty=elasticnet, solver=saga, tol=0.0001...\n",
            "[CV 4/5; 394/448] END C=1000.0, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 5/5; 394/448] START C=1000.0, penalty=elasticnet, solver=saga, tol=0.0001...\n",
            "[CV 5/5; 394/448] END C=1000.0, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 1/5; 395/448] START C=1000.0, penalty=elasticnet, solver=saga, tol=1e-05....\n",
            "[CV 1/5; 395/448] END C=1000.0, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 2/5; 395/448] START C=1000.0, penalty=elasticnet, solver=saga, tol=1e-05....\n",
            "[CV 2/5; 395/448] END C=1000.0, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 3/5; 395/448] START C=1000.0, penalty=elasticnet, solver=saga, tol=1e-05....\n",
            "[CV 3/5; 395/448] END C=1000.0, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 4/5; 395/448] START C=1000.0, penalty=elasticnet, solver=saga, tol=1e-05....\n",
            "[CV 4/5; 395/448] END C=1000.0, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 5/5; 395/448] START C=1000.0, penalty=elasticnet, solver=saga, tol=1e-05....\n",
            "[CV 5/5; 395/448] END C=1000.0, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 1/5; 396/448] START C=1000.0, penalty=elasticnet, solver=saga, tol=1e-06....\n",
            "[CV 1/5; 396/448] END C=1000.0, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 2/5; 396/448] START C=1000.0, penalty=elasticnet, solver=saga, tol=1e-06....\n",
            "[CV 2/5; 396/448] END C=1000.0, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 3/5; 396/448] START C=1000.0, penalty=elasticnet, solver=saga, tol=1e-06....\n",
            "[CV 3/5; 396/448] END C=1000.0, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 4/5; 396/448] START C=1000.0, penalty=elasticnet, solver=saga, tol=1e-06....\n",
            "[CV 4/5; 396/448] END C=1000.0, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 5/5; 396/448] START C=1000.0, penalty=elasticnet, solver=saga, tol=1e-06....\n",
            "[CV 5/5; 396/448] END C=1000.0, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 1/5; 397/448] START C=1000.0, penalty=None, solver=saga, tol=0.001..........\n",
            "[CV 1/5; 397/448] END C=1000.0, penalty=None, solver=saga, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 397/448] START C=1000.0, penalty=None, solver=saga, tol=0.001..........\n",
            "[CV 2/5; 397/448] END C=1000.0, penalty=None, solver=saga, tol=0.001;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 397/448] START C=1000.0, penalty=None, solver=saga, tol=0.001..........\n",
            "[CV 3/5; 397/448] END C=1000.0, penalty=None, solver=saga, tol=0.001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 397/448] START C=1000.0, penalty=None, solver=saga, tol=0.001..........\n",
            "[CV 4/5; 397/448] END C=1000.0, penalty=None, solver=saga, tol=0.001;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 397/448] START C=1000.0, penalty=None, solver=saga, tol=0.001..........\n",
            "[CV 5/5; 397/448] END C=1000.0, penalty=None, solver=saga, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 398/448] START C=1000.0, penalty=None, solver=saga, tol=0.0001.........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 398/448] END C=1000.0, penalty=None, solver=saga, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 398/448] START C=1000.0, penalty=None, solver=saga, tol=0.0001.........\n",
            "[CV 2/5; 398/448] END C=1000.0, penalty=None, solver=saga, tol=0.0001;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 398/448] START C=1000.0, penalty=None, solver=saga, tol=0.0001.........\n",
            "[CV 3/5; 398/448] END C=1000.0, penalty=None, solver=saga, tol=0.0001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 398/448] START C=1000.0, penalty=None, solver=saga, tol=0.0001.........\n",
            "[CV 4/5; 398/448] END C=1000.0, penalty=None, solver=saga, tol=0.0001;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 398/448] START C=1000.0, penalty=None, solver=saga, tol=0.0001.........\n",
            "[CV 5/5; 398/448] END C=1000.0, penalty=None, solver=saga, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 399/448] START C=1000.0, penalty=None, solver=saga, tol=1e-05..........\n",
            "[CV 1/5; 399/448] END C=1000.0, penalty=None, solver=saga, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 399/448] START C=1000.0, penalty=None, solver=saga, tol=1e-05..........\n",
            "[CV 2/5; 399/448] END C=1000.0, penalty=None, solver=saga, tol=1e-05;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 399/448] START C=1000.0, penalty=None, solver=saga, tol=1e-05..........\n",
            "[CV 3/5; 399/448] END C=1000.0, penalty=None, solver=saga, tol=1e-05;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 399/448] START C=1000.0, penalty=None, solver=saga, tol=1e-05..........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 399/448] END C=1000.0, penalty=None, solver=saga, tol=1e-05;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 399/448] START C=1000.0, penalty=None, solver=saga, tol=1e-05..........\n",
            "[CV 5/5; 399/448] END C=1000.0, penalty=None, solver=saga, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 400/448] START C=1000.0, penalty=None, solver=saga, tol=1e-06..........\n",
            "[CV 1/5; 400/448] END C=1000.0, penalty=None, solver=saga, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 400/448] START C=1000.0, penalty=None, solver=saga, tol=1e-06..........\n",
            "[CV 2/5; 400/448] END C=1000.0, penalty=None, solver=saga, tol=1e-06;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 400/448] START C=1000.0, penalty=None, solver=saga, tol=1e-06..........\n",
            "[CV 3/5; 400/448] END C=1000.0, penalty=None, solver=saga, tol=1e-06;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 400/448] START C=1000.0, penalty=None, solver=saga, tol=1e-06..........\n",
            "[CV 4/5; 400/448] END C=1000.0, penalty=None, solver=saga, tol=1e-06;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 400/448] START C=1000.0, penalty=None, solver=saga, tol=1e-06..........\n",
            "[CV 5/5; 400/448] END C=1000.0, penalty=None, solver=saga, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 401/448] START C=10000.0, penalty=l1, solver=saga, tol=0.001...........\n",
            "[CV 1/5; 401/448] END C=10000.0, penalty=l1, solver=saga, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 401/448] START C=10000.0, penalty=l1, solver=saga, tol=0.001...........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 401/448] END C=10000.0, penalty=l1, solver=saga, tol=0.001;, score=0.792 total time=   0.0s\n",
            "[CV 3/5; 401/448] START C=10000.0, penalty=l1, solver=saga, tol=0.001...........\n",
            "[CV 3/5; 401/448] END C=10000.0, penalty=l1, solver=saga, tol=0.001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 401/448] START C=10000.0, penalty=l1, solver=saga, tol=0.001...........\n",
            "[CV 4/5; 401/448] END C=10000.0, penalty=l1, solver=saga, tol=0.001;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 401/448] START C=10000.0, penalty=l1, solver=saga, tol=0.001...........\n",
            "[CV 5/5; 401/448] END C=10000.0, penalty=l1, solver=saga, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 402/448] START C=10000.0, penalty=l1, solver=saga, tol=0.0001..........\n",
            "[CV 1/5; 402/448] END C=10000.0, penalty=l1, solver=saga, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 402/448] START C=10000.0, penalty=l1, solver=saga, tol=0.0001..........\n",
            "[CV 2/5; 402/448] END C=10000.0, penalty=l1, solver=saga, tol=0.0001;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 402/448] START C=10000.0, penalty=l1, solver=saga, tol=0.0001..........\n",
            "[CV 3/5; 402/448] END C=10000.0, penalty=l1, solver=saga, tol=0.0001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 402/448] START C=10000.0, penalty=l1, solver=saga, tol=0.0001..........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 402/448] END C=10000.0, penalty=l1, solver=saga, tol=0.0001;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 402/448] START C=10000.0, penalty=l1, solver=saga, tol=0.0001..........\n",
            "[CV 5/5; 402/448] END C=10000.0, penalty=l1, solver=saga, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 403/448] START C=10000.0, penalty=l1, solver=saga, tol=1e-05...........\n",
            "[CV 1/5; 403/448] END C=10000.0, penalty=l1, solver=saga, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 403/448] START C=10000.0, penalty=l1, solver=saga, tol=1e-05...........\n",
            "[CV 2/5; 403/448] END C=10000.0, penalty=l1, solver=saga, tol=1e-05;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 403/448] START C=10000.0, penalty=l1, solver=saga, tol=1e-05...........\n",
            "[CV 3/5; 403/448] END C=10000.0, penalty=l1, solver=saga, tol=1e-05;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 403/448] START C=10000.0, penalty=l1, solver=saga, tol=1e-05...........\n",
            "[CV 4/5; 403/448] END C=10000.0, penalty=l1, solver=saga, tol=1e-05;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 403/448] START C=10000.0, penalty=l1, solver=saga, tol=1e-05...........\n",
            "[CV 5/5; 403/448] END C=10000.0, penalty=l1, solver=saga, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 404/448] START C=10000.0, penalty=l1, solver=saga, tol=1e-06...........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 404/448] END C=10000.0, penalty=l1, solver=saga, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 404/448] START C=10000.0, penalty=l1, solver=saga, tol=1e-06...........\n",
            "[CV 2/5; 404/448] END C=10000.0, penalty=l1, solver=saga, tol=1e-06;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 404/448] START C=10000.0, penalty=l1, solver=saga, tol=1e-06...........\n",
            "[CV 3/5; 404/448] END C=10000.0, penalty=l1, solver=saga, tol=1e-06;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 404/448] START C=10000.0, penalty=l1, solver=saga, tol=1e-06...........\n",
            "[CV 4/5; 404/448] END C=10000.0, penalty=l1, solver=saga, tol=1e-06;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 404/448] START C=10000.0, penalty=l1, solver=saga, tol=1e-06...........\n",
            "[CV 5/5; 404/448] END C=10000.0, penalty=l1, solver=saga, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 405/448] START C=10000.0, penalty=l2, solver=saga, tol=0.001...........\n",
            "[CV 1/5; 405/448] END C=10000.0, penalty=l2, solver=saga, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 405/448] START C=10000.0, penalty=l2, solver=saga, tol=0.001...........\n",
            "[CV 2/5; 405/448] END C=10000.0, penalty=l2, solver=saga, tol=0.001;, score=0.792 total time=   0.0s\n",
            "[CV 3/5; 405/448] START C=10000.0, penalty=l2, solver=saga, tol=0.001...........\n",
            "[CV 3/5; 405/448] END C=10000.0, penalty=l2, solver=saga, tol=0.001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 405/448] START C=10000.0, penalty=l2, solver=saga, tol=0.001...........\n",
            "[CV 4/5; 405/448] END C=10000.0, penalty=l2, solver=saga, tol=0.001;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 405/448] START C=10000.0, penalty=l2, solver=saga, tol=0.001...........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 405/448] END C=10000.0, penalty=l2, solver=saga, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 406/448] START C=10000.0, penalty=l2, solver=saga, tol=0.0001..........\n",
            "[CV 1/5; 406/448] END C=10000.0, penalty=l2, solver=saga, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 406/448] START C=10000.0, penalty=l2, solver=saga, tol=0.0001..........\n",
            "[CV 2/5; 406/448] END C=10000.0, penalty=l2, solver=saga, tol=0.0001;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 406/448] START C=10000.0, penalty=l2, solver=saga, tol=0.0001..........\n",
            "[CV 3/5; 406/448] END C=10000.0, penalty=l2, solver=saga, tol=0.0001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 406/448] START C=10000.0, penalty=l2, solver=saga, tol=0.0001..........\n",
            "[CV 4/5; 406/448] END C=10000.0, penalty=l2, solver=saga, tol=0.0001;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 406/448] START C=10000.0, penalty=l2, solver=saga, tol=0.0001..........\n",
            "[CV 5/5; 406/448] END C=10000.0, penalty=l2, solver=saga, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 407/448] START C=10000.0, penalty=l2, solver=saga, tol=1e-05...........\n",
            "[CV 1/5; 407/448] END C=10000.0, penalty=l2, solver=saga, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 407/448] START C=10000.0, penalty=l2, solver=saga, tol=1e-05...........\n",
            "[CV 2/5; 407/448] END C=10000.0, penalty=l2, solver=saga, tol=1e-05;, score=0.792 total time=   0.0s\n",
            "[CV 3/5; 407/448] START C=10000.0, penalty=l2, solver=saga, tol=1e-05...........\n",
            "[CV 3/5; 407/448] END C=10000.0, penalty=l2, solver=saga, tol=1e-05;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 407/448] START C=10000.0, penalty=l2, solver=saga, tol=1e-05...........\n",
            "[CV 4/5; 407/448] END C=10000.0, penalty=l2, solver=saga, tol=1e-05;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 407/448] START C=10000.0, penalty=l2, solver=saga, tol=1e-05...........\n",
            "[CV 5/5; 407/448] END C=10000.0, penalty=l2, solver=saga, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 408/448] START C=10000.0, penalty=l2, solver=saga, tol=1e-06...........\n",
            "[CV 1/5; 408/448] END C=10000.0, penalty=l2, solver=saga, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 408/448] START C=10000.0, penalty=l2, solver=saga, tol=1e-06...........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 408/448] END C=10000.0, penalty=l2, solver=saga, tol=1e-06;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 408/448] START C=10000.0, penalty=l2, solver=saga, tol=1e-06...........\n",
            "[CV 3/5; 408/448] END C=10000.0, penalty=l2, solver=saga, tol=1e-06;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 408/448] START C=10000.0, penalty=l2, solver=saga, tol=1e-06...........\n",
            "[CV 4/5; 408/448] END C=10000.0, penalty=l2, solver=saga, tol=1e-06;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 408/448] START C=10000.0, penalty=l2, solver=saga, tol=1e-06...........\n",
            "[CV 5/5; 408/448] END C=10000.0, penalty=l2, solver=saga, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 409/448] START C=10000.0, penalty=elasticnet, solver=saga, tol=0.001...\n",
            "[CV 1/5; 409/448] END C=10000.0, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 2/5; 409/448] START C=10000.0, penalty=elasticnet, solver=saga, tol=0.001...\n",
            "[CV 2/5; 409/448] END C=10000.0, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 3/5; 409/448] START C=10000.0, penalty=elasticnet, solver=saga, tol=0.001...\n",
            "[CV 3/5; 409/448] END C=10000.0, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 4/5; 409/448] START C=10000.0, penalty=elasticnet, solver=saga, tol=0.001...\n",
            "[CV 4/5; 409/448] END C=10000.0, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 5/5; 409/448] START C=10000.0, penalty=elasticnet, solver=saga, tol=0.001...\n",
            "[CV 5/5; 409/448] END C=10000.0, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 1/5; 410/448] START C=10000.0, penalty=elasticnet, solver=saga, tol=0.0001..\n",
            "[CV 1/5; 410/448] END C=10000.0, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 2/5; 410/448] START C=10000.0, penalty=elasticnet, solver=saga, tol=0.0001..\n",
            "[CV 2/5; 410/448] END C=10000.0, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 3/5; 410/448] START C=10000.0, penalty=elasticnet, solver=saga, tol=0.0001..\n",
            "[CV 3/5; 410/448] END C=10000.0, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 4/5; 410/448] START C=10000.0, penalty=elasticnet, solver=saga, tol=0.0001..\n",
            "[CV 4/5; 410/448] END C=10000.0, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 5/5; 410/448] START C=10000.0, penalty=elasticnet, solver=saga, tol=0.0001..\n",
            "[CV 5/5; 410/448] END C=10000.0, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 1/5; 411/448] START C=10000.0, penalty=elasticnet, solver=saga, tol=1e-05...\n",
            "[CV 1/5; 411/448] END C=10000.0, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 2/5; 411/448] START C=10000.0, penalty=elasticnet, solver=saga, tol=1e-05...\n",
            "[CV 2/5; 411/448] END C=10000.0, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 3/5; 411/448] START C=10000.0, penalty=elasticnet, solver=saga, tol=1e-05...\n",
            "[CV 3/5; 411/448] END C=10000.0, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 4/5; 411/448] START C=10000.0, penalty=elasticnet, solver=saga, tol=1e-05...\n",
            "[CV 4/5; 411/448] END C=10000.0, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 5/5; 411/448] START C=10000.0, penalty=elasticnet, solver=saga, tol=1e-05...\n",
            "[CV 5/5; 411/448] END C=10000.0, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 1/5; 412/448] START C=10000.0, penalty=elasticnet, solver=saga, tol=1e-06...\n",
            "[CV 1/5; 412/448] END C=10000.0, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 2/5; 412/448] START C=10000.0, penalty=elasticnet, solver=saga, tol=1e-06...\n",
            "[CV 2/5; 412/448] END C=10000.0, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 3/5; 412/448] START C=10000.0, penalty=elasticnet, solver=saga, tol=1e-06...\n",
            "[CV 3/5; 412/448] END C=10000.0, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 4/5; 412/448] START C=10000.0, penalty=elasticnet, solver=saga, tol=1e-06...\n",
            "[CV 4/5; 412/448] END C=10000.0, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 5/5; 412/448] START C=10000.0, penalty=elasticnet, solver=saga, tol=1e-06...\n",
            "[CV 5/5; 412/448] END C=10000.0, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 1/5; 413/448] START C=10000.0, penalty=None, solver=saga, tol=0.001.........\n",
            "[CV 1/5; 413/448] END C=10000.0, penalty=None, solver=saga, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 413/448] START C=10000.0, penalty=None, solver=saga, tol=0.001.........\n",
            "[CV 2/5; 413/448] END C=10000.0, penalty=None, solver=saga, tol=0.001;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 413/448] START C=10000.0, penalty=None, solver=saga, tol=0.001.........\n",
            "[CV 3/5; 413/448] END C=10000.0, penalty=None, solver=saga, tol=0.001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 413/448] START C=10000.0, penalty=None, solver=saga, tol=0.001.........\n",
            "[CV 4/5; 413/448] END C=10000.0, penalty=None, solver=saga, tol=0.001;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 413/448] START C=10000.0, penalty=None, solver=saga, tol=0.001.........\n",
            "[CV 5/5; 413/448] END C=10000.0, penalty=None, solver=saga, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 414/448] START C=10000.0, penalty=None, solver=saga, tol=0.0001........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 414/448] END C=10000.0, penalty=None, solver=saga, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 414/448] START C=10000.0, penalty=None, solver=saga, tol=0.0001........\n",
            "[CV 2/5; 414/448] END C=10000.0, penalty=None, solver=saga, tol=0.0001;, score=0.792 total time=   0.0s\n",
            "[CV 3/5; 414/448] START C=10000.0, penalty=None, solver=saga, tol=0.0001........\n",
            "[CV 3/5; 414/448] END C=10000.0, penalty=None, solver=saga, tol=0.0001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 414/448] START C=10000.0, penalty=None, solver=saga, tol=0.0001........\n",
            "[CV 4/5; 414/448] END C=10000.0, penalty=None, solver=saga, tol=0.0001;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 414/448] START C=10000.0, penalty=None, solver=saga, tol=0.0001........\n",
            "[CV 5/5; 414/448] END C=10000.0, penalty=None, solver=saga, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 415/448] START C=10000.0, penalty=None, solver=saga, tol=1e-05.........\n",
            "[CV 1/5; 415/448] END C=10000.0, penalty=None, solver=saga, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 415/448] START C=10000.0, penalty=None, solver=saga, tol=1e-05.........\n",
            "[CV 2/5; 415/448] END C=10000.0, penalty=None, solver=saga, tol=1e-05;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 415/448] START C=10000.0, penalty=None, solver=saga, tol=1e-05.........\n",
            "[CV 3/5; 415/448] END C=10000.0, penalty=None, solver=saga, tol=1e-05;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 415/448] START C=10000.0, penalty=None, solver=saga, tol=1e-05.........\n",
            "[CV 4/5; 415/448] END C=10000.0, penalty=None, solver=saga, tol=1e-05;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 415/448] START C=10000.0, penalty=None, solver=saga, tol=1e-05.........\n",
            "[CV 5/5; 415/448] END C=10000.0, penalty=None, solver=saga, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 416/448] START C=10000.0, penalty=None, solver=saga, tol=1e-06.........\n",
            "[CV 1/5; 416/448] END C=10000.0, penalty=None, solver=saga, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 416/448] START C=10000.0, penalty=None, solver=saga, tol=1e-06.........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 416/448] END C=10000.0, penalty=None, solver=saga, tol=1e-06;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 416/448] START C=10000.0, penalty=None, solver=saga, tol=1e-06.........\n",
            "[CV 3/5; 416/448] END C=10000.0, penalty=None, solver=saga, tol=1e-06;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 416/448] START C=10000.0, penalty=None, solver=saga, tol=1e-06.........\n",
            "[CV 4/5; 416/448] END C=10000.0, penalty=None, solver=saga, tol=1e-06;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 416/448] START C=10000.0, penalty=None, solver=saga, tol=1e-06.........\n",
            "[CV 5/5; 416/448] END C=10000.0, penalty=None, solver=saga, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 417/448] START C=100000.0, penalty=l1, solver=saga, tol=0.001..........\n",
            "[CV 1/5; 417/448] END C=100000.0, penalty=l1, solver=saga, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 417/448] START C=100000.0, penalty=l1, solver=saga, tol=0.001..........\n",
            "[CV 2/5; 417/448] END C=100000.0, penalty=l1, solver=saga, tol=0.001;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 417/448] START C=100000.0, penalty=l1, solver=saga, tol=0.001..........\n",
            "[CV 3/5; 417/448] END C=100000.0, penalty=l1, solver=saga, tol=0.001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 417/448] START C=100000.0, penalty=l1, solver=saga, tol=0.001..........\n",
            "[CV 4/5; 417/448] END C=100000.0, penalty=l1, solver=saga, tol=0.001;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 417/448] START C=100000.0, penalty=l1, solver=saga, tol=0.001..........\n",
            "[CV 5/5; 417/448] END C=100000.0, penalty=l1, solver=saga, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 418/448] START C=100000.0, penalty=l1, solver=saga, tol=0.0001.........\n",
            "[CV 1/5; 418/448] END C=100000.0, penalty=l1, solver=saga, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 418/448] START C=100000.0, penalty=l1, solver=saga, tol=0.0001.........\n",
            "[CV 2/5; 418/448] END C=100000.0, penalty=l1, solver=saga, tol=0.0001;, score=0.792 total time=   0.0s\n",
            "[CV 3/5; 418/448] START C=100000.0, penalty=l1, solver=saga, tol=0.0001.........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 418/448] END C=100000.0, penalty=l1, solver=saga, tol=0.0001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 418/448] START C=100000.0, penalty=l1, solver=saga, tol=0.0001.........\n",
            "[CV 4/5; 418/448] END C=100000.0, penalty=l1, solver=saga, tol=0.0001;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 418/448] START C=100000.0, penalty=l1, solver=saga, tol=0.0001.........\n",
            "[CV 5/5; 418/448] END C=100000.0, penalty=l1, solver=saga, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 419/448] START C=100000.0, penalty=l1, solver=saga, tol=1e-05..........\n",
            "[CV 1/5; 419/448] END C=100000.0, penalty=l1, solver=saga, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 419/448] START C=100000.0, penalty=l1, solver=saga, tol=1e-05..........\n",
            "[CV 2/5; 419/448] END C=100000.0, penalty=l1, solver=saga, tol=1e-05;, score=0.792 total time=   0.0s\n",
            "[CV 3/5; 419/448] START C=100000.0, penalty=l1, solver=saga, tol=1e-05..........\n",
            "[CV 3/5; 419/448] END C=100000.0, penalty=l1, solver=saga, tol=1e-05;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 419/448] START C=100000.0, penalty=l1, solver=saga, tol=1e-05..........\n",
            "[CV 4/5; 419/448] END C=100000.0, penalty=l1, solver=saga, tol=1e-05;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 419/448] START C=100000.0, penalty=l1, solver=saga, tol=1e-05..........\n",
            "[CV 5/5; 419/448] END C=100000.0, penalty=l1, solver=saga, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 420/448] START C=100000.0, penalty=l1, solver=saga, tol=1e-06..........\n",
            "[CV 1/5; 420/448] END C=100000.0, penalty=l1, solver=saga, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 420/448] START C=100000.0, penalty=l1, solver=saga, tol=1e-06..........\n",
            "[CV 2/5; 420/448] END C=100000.0, penalty=l1, solver=saga, tol=1e-06;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 420/448] START C=100000.0, penalty=l1, solver=saga, tol=1e-06..........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 420/448] END C=100000.0, penalty=l1, solver=saga, tol=1e-06;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 420/448] START C=100000.0, penalty=l1, solver=saga, tol=1e-06..........\n",
            "[CV 4/5; 420/448] END C=100000.0, penalty=l1, solver=saga, tol=1e-06;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 420/448] START C=100000.0, penalty=l1, solver=saga, tol=1e-06..........\n",
            "[CV 5/5; 420/448] END C=100000.0, penalty=l1, solver=saga, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 421/448] START C=100000.0, penalty=l2, solver=saga, tol=0.001..........\n",
            "[CV 1/5; 421/448] END C=100000.0, penalty=l2, solver=saga, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 421/448] START C=100000.0, penalty=l2, solver=saga, tol=0.001..........\n",
            "[CV 2/5; 421/448] END C=100000.0, penalty=l2, solver=saga, tol=0.001;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 421/448] START C=100000.0, penalty=l2, solver=saga, tol=0.001..........\n",
            "[CV 3/5; 421/448] END C=100000.0, penalty=l2, solver=saga, tol=0.001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 421/448] START C=100000.0, penalty=l2, solver=saga, tol=0.001..........\n",
            "[CV 4/5; 421/448] END C=100000.0, penalty=l2, solver=saga, tol=0.001;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 421/448] START C=100000.0, penalty=l2, solver=saga, tol=0.001..........\n",
            "[CV 5/5; 421/448] END C=100000.0, penalty=l2, solver=saga, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 422/448] START C=100000.0, penalty=l2, solver=saga, tol=0.0001.........\n",
            "[CV 1/5; 422/448] END C=100000.0, penalty=l2, solver=saga, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 422/448] START C=100000.0, penalty=l2, solver=saga, tol=0.0001.........\n",
            "[CV 2/5; 422/448] END C=100000.0, penalty=l2, solver=saga, tol=0.0001;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 422/448] START C=100000.0, penalty=l2, solver=saga, tol=0.0001.........\n",
            "[CV 3/5; 422/448] END C=100000.0, penalty=l2, solver=saga, tol=0.0001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 422/448] START C=100000.0, penalty=l2, solver=saga, tol=0.0001.........\n",
            "[CV 4/5; 422/448] END C=100000.0, penalty=l2, solver=saga, tol=0.0001;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 422/448] START C=100000.0, penalty=l2, solver=saga, tol=0.0001.........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 422/448] END C=100000.0, penalty=l2, solver=saga, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 423/448] START C=100000.0, penalty=l2, solver=saga, tol=1e-05..........\n",
            "[CV 1/5; 423/448] END C=100000.0, penalty=l2, solver=saga, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 423/448] START C=100000.0, penalty=l2, solver=saga, tol=1e-05..........\n",
            "[CV 2/5; 423/448] END C=100000.0, penalty=l2, solver=saga, tol=1e-05;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 423/448] START C=100000.0, penalty=l2, solver=saga, tol=1e-05..........\n",
            "[CV 3/5; 423/448] END C=100000.0, penalty=l2, solver=saga, tol=1e-05;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 423/448] START C=100000.0, penalty=l2, solver=saga, tol=1e-05..........\n",
            "[CV 4/5; 423/448] END C=100000.0, penalty=l2, solver=saga, tol=1e-05;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 423/448] START C=100000.0, penalty=l2, solver=saga, tol=1e-05..........\n",
            "[CV 5/5; 423/448] END C=100000.0, penalty=l2, solver=saga, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 424/448] START C=100000.0, penalty=l2, solver=saga, tol=1e-06..........\n",
            "[CV 1/5; 424/448] END C=100000.0, penalty=l2, solver=saga, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 424/448] START C=100000.0, penalty=l2, solver=saga, tol=1e-06..........\n",
            "[CV 2/5; 424/448] END C=100000.0, penalty=l2, solver=saga, tol=1e-06;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 424/448] START C=100000.0, penalty=l2, solver=saga, tol=1e-06..........\n",
            "[CV 3/5; 424/448] END C=100000.0, penalty=l2, solver=saga, tol=1e-06;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 424/448] START C=100000.0, penalty=l2, solver=saga, tol=1e-06..........\n",
            "[CV 4/5; 424/448] END C=100000.0, penalty=l2, solver=saga, tol=1e-06;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 424/448] START C=100000.0, penalty=l2, solver=saga, tol=1e-06..........\n",
            "[CV 5/5; 424/448] END C=100000.0, penalty=l2, solver=saga, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 425/448] START C=100000.0, penalty=elasticnet, solver=saga, tol=0.001..\n",
            "[CV 1/5; 425/448] END C=100000.0, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 2/5; 425/448] START C=100000.0, penalty=elasticnet, solver=saga, tol=0.001..\n",
            "[CV 2/5; 425/448] END C=100000.0, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 3/5; 425/448] START C=100000.0, penalty=elasticnet, solver=saga, tol=0.001..\n",
            "[CV 3/5; 425/448] END C=100000.0, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 4/5; 425/448] START C=100000.0, penalty=elasticnet, solver=saga, tol=0.001..\n",
            "[CV 4/5; 425/448] END C=100000.0, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 5/5; 425/448] START C=100000.0, penalty=elasticnet, solver=saga, tol=0.001..\n",
            "[CV 5/5; 425/448] END C=100000.0, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 1/5; 426/448] START C=100000.0, penalty=elasticnet, solver=saga, tol=0.0001.\n",
            "[CV 1/5; 426/448] END C=100000.0, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 2/5; 426/448] START C=100000.0, penalty=elasticnet, solver=saga, tol=0.0001.\n",
            "[CV 2/5; 426/448] END C=100000.0, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 3/5; 426/448] START C=100000.0, penalty=elasticnet, solver=saga, tol=0.0001.\n",
            "[CV 3/5; 426/448] END C=100000.0, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 4/5; 426/448] START C=100000.0, penalty=elasticnet, solver=saga, tol=0.0001.\n",
            "[CV 4/5; 426/448] END C=100000.0, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 5/5; 426/448] START C=100000.0, penalty=elasticnet, solver=saga, tol=0.0001.\n",
            "[CV 5/5; 426/448] END C=100000.0, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 1/5; 427/448] START C=100000.0, penalty=elasticnet, solver=saga, tol=1e-05..\n",
            "[CV 1/5; 427/448] END C=100000.0, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 2/5; 427/448] START C=100000.0, penalty=elasticnet, solver=saga, tol=1e-05..\n",
            "[CV 2/5; 427/448] END C=100000.0, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 3/5; 427/448] START C=100000.0, penalty=elasticnet, solver=saga, tol=1e-05..\n",
            "[CV 3/5; 427/448] END C=100000.0, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 4/5; 427/448] START C=100000.0, penalty=elasticnet, solver=saga, tol=1e-05..\n",
            "[CV 4/5; 427/448] END C=100000.0, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 5/5; 427/448] START C=100000.0, penalty=elasticnet, solver=saga, tol=1e-05..\n",
            "[CV 5/5; 427/448] END C=100000.0, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 1/5; 428/448] START C=100000.0, penalty=elasticnet, solver=saga, tol=1e-06..\n",
            "[CV 1/5; 428/448] END C=100000.0, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 2/5; 428/448] START C=100000.0, penalty=elasticnet, solver=saga, tol=1e-06..\n",
            "[CV 2/5; 428/448] END C=100000.0, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 3/5; 428/448] START C=100000.0, penalty=elasticnet, solver=saga, tol=1e-06..\n",
            "[CV 3/5; 428/448] END C=100000.0, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 4/5; 428/448] START C=100000.0, penalty=elasticnet, solver=saga, tol=1e-06..\n",
            "[CV 4/5; 428/448] END C=100000.0, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 5/5; 428/448] START C=100000.0, penalty=elasticnet, solver=saga, tol=1e-06..\n",
            "[CV 5/5; 428/448] END C=100000.0, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 1/5; 429/448] START C=100000.0, penalty=None, solver=saga, tol=0.001........\n",
            "[CV 1/5; 429/448] END C=100000.0, penalty=None, solver=saga, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 429/448] START C=100000.0, penalty=None, solver=saga, tol=0.001........\n",
            "[CV 2/5; 429/448] END C=100000.0, penalty=None, solver=saga, tol=0.001;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 429/448] START C=100000.0, penalty=None, solver=saga, tol=0.001........\n",
            "[CV 3/5; 429/448] END C=100000.0, penalty=None, solver=saga, tol=0.001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 429/448] START C=100000.0, penalty=None, solver=saga, tol=0.001........\n",
            "[CV 4/5; 429/448] END C=100000.0, penalty=None, solver=saga, tol=0.001;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 429/448] START C=100000.0, penalty=None, solver=saga, tol=0.001........\n",
            "[CV 5/5; 429/448] END C=100000.0, penalty=None, solver=saga, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 430/448] START C=100000.0, penalty=None, solver=saga, tol=0.0001.......\n",
            "[CV 1/5; 430/448] END C=100000.0, penalty=None, solver=saga, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 430/448] START C=100000.0, penalty=None, solver=saga, tol=0.0001.......\n",
            "[CV 2/5; 430/448] END C=100000.0, penalty=None, solver=saga, tol=0.0001;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 430/448] START C=100000.0, penalty=None, solver=saga, tol=0.0001.......\n",
            "[CV 3/5; 430/448] END C=100000.0, penalty=None, solver=saga, tol=0.0001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 430/448] START C=100000.0, penalty=None, solver=saga, tol=0.0001.......\n",
            "[CV 4/5; 430/448] END C=100000.0, penalty=None, solver=saga, tol=0.0001;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 430/448] START C=100000.0, penalty=None, solver=saga, tol=0.0001.......\n",
            "[CV 5/5; 430/448] END C=100000.0, penalty=None, solver=saga, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 431/448] START C=100000.0, penalty=None, solver=saga, tol=1e-05........\n",
            "[CV 1/5; 431/448] END C=100000.0, penalty=None, solver=saga, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 431/448] START C=100000.0, penalty=None, solver=saga, tol=1e-05........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 431/448] END C=100000.0, penalty=None, solver=saga, tol=1e-05;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 431/448] START C=100000.0, penalty=None, solver=saga, tol=1e-05........\n",
            "[CV 3/5; 431/448] END C=100000.0, penalty=None, solver=saga, tol=1e-05;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 431/448] START C=100000.0, penalty=None, solver=saga, tol=1e-05........\n",
            "[CV 4/5; 431/448] END C=100000.0, penalty=None, solver=saga, tol=1e-05;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 431/448] START C=100000.0, penalty=None, solver=saga, tol=1e-05........\n",
            "[CV 5/5; 431/448] END C=100000.0, penalty=None, solver=saga, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 432/448] START C=100000.0, penalty=None, solver=saga, tol=1e-06........\n",
            "[CV 1/5; 432/448] END C=100000.0, penalty=None, solver=saga, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 432/448] START C=100000.0, penalty=None, solver=saga, tol=1e-06........\n",
            "[CV 2/5; 432/448] END C=100000.0, penalty=None, solver=saga, tol=1e-06;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 432/448] START C=100000.0, penalty=None, solver=saga, tol=1e-06........\n",
            "[CV 3/5; 432/448] END C=100000.0, penalty=None, solver=saga, tol=1e-06;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 432/448] START C=100000.0, penalty=None, solver=saga, tol=1e-06........\n",
            "[CV 4/5; 432/448] END C=100000.0, penalty=None, solver=saga, tol=1e-06;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 432/448] START C=100000.0, penalty=None, solver=saga, tol=1e-06........\n",
            "[CV 5/5; 432/448] END C=100000.0, penalty=None, solver=saga, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 433/448] START C=1000000.0, penalty=l1, solver=saga, tol=0.001.........\n",
            "[CV 1/5; 433/448] END C=1000000.0, penalty=l1, solver=saga, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 433/448] START C=1000000.0, penalty=l1, solver=saga, tol=0.001.........\n",
            "[CV 2/5; 433/448] END C=1000000.0, penalty=l1, solver=saga, tol=0.001;, score=0.792 total time=   0.0s\n",
            "[CV 3/5; 433/448] START C=1000000.0, penalty=l1, solver=saga, tol=0.001.........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 433/448] END C=1000000.0, penalty=l1, solver=saga, tol=0.001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 433/448] START C=1000000.0, penalty=l1, solver=saga, tol=0.001.........\n",
            "[CV 4/5; 433/448] END C=1000000.0, penalty=l1, solver=saga, tol=0.001;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 433/448] START C=1000000.0, penalty=l1, solver=saga, tol=0.001.........\n",
            "[CV 5/5; 433/448] END C=1000000.0, penalty=l1, solver=saga, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 434/448] START C=1000000.0, penalty=l1, solver=saga, tol=0.0001........\n",
            "[CV 1/5; 434/448] END C=1000000.0, penalty=l1, solver=saga, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 434/448] START C=1000000.0, penalty=l1, solver=saga, tol=0.0001........\n",
            "[CV 2/5; 434/448] END C=1000000.0, penalty=l1, solver=saga, tol=0.0001;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 434/448] START C=1000000.0, penalty=l1, solver=saga, tol=0.0001........\n",
            "[CV 3/5; 434/448] END C=1000000.0, penalty=l1, solver=saga, tol=0.0001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 434/448] START C=1000000.0, penalty=l1, solver=saga, tol=0.0001........\n",
            "[CV 4/5; 434/448] END C=1000000.0, penalty=l1, solver=saga, tol=0.0001;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 434/448] START C=1000000.0, penalty=l1, solver=saga, tol=0.0001........\n",
            "[CV 5/5; 434/448] END C=1000000.0, penalty=l1, solver=saga, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 435/448] START C=1000000.0, penalty=l1, solver=saga, tol=1e-05.........\n",
            "[CV 1/5; 435/448] END C=1000000.0, penalty=l1, solver=saga, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 435/448] START C=1000000.0, penalty=l1, solver=saga, tol=1e-05.........\n",
            "[CV 2/5; 435/448] END C=1000000.0, penalty=l1, solver=saga, tol=1e-05;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 435/448] START C=1000000.0, penalty=l1, solver=saga, tol=1e-05.........\n",
            "[CV 3/5; 435/448] END C=1000000.0, penalty=l1, solver=saga, tol=1e-05;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 435/448] START C=1000000.0, penalty=l1, solver=saga, tol=1e-05.........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 435/448] END C=1000000.0, penalty=l1, solver=saga, tol=1e-05;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 435/448] START C=1000000.0, penalty=l1, solver=saga, tol=1e-05.........\n",
            "[CV 5/5; 435/448] END C=1000000.0, penalty=l1, solver=saga, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 436/448] START C=1000000.0, penalty=l1, solver=saga, tol=1e-06.........\n",
            "[CV 1/5; 436/448] END C=1000000.0, penalty=l1, solver=saga, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 436/448] START C=1000000.0, penalty=l1, solver=saga, tol=1e-06.........\n",
            "[CV 2/5; 436/448] END C=1000000.0, penalty=l1, solver=saga, tol=1e-06;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 436/448] START C=1000000.0, penalty=l1, solver=saga, tol=1e-06.........\n",
            "[CV 3/5; 436/448] END C=1000000.0, penalty=l1, solver=saga, tol=1e-06;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 436/448] START C=1000000.0, penalty=l1, solver=saga, tol=1e-06.........\n",
            "[CV 4/5; 436/448] END C=1000000.0, penalty=l1, solver=saga, tol=1e-06;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 436/448] START C=1000000.0, penalty=l1, solver=saga, tol=1e-06.........\n",
            "[CV 5/5; 436/448] END C=1000000.0, penalty=l1, solver=saga, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 437/448] START C=1000000.0, penalty=l2, solver=saga, tol=0.001.........\n",
            "[CV 1/5; 437/448] END C=1000000.0, penalty=l2, solver=saga, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 437/448] START C=1000000.0, penalty=l2, solver=saga, tol=0.001.........\n",
            "[CV 2/5; 437/448] END C=1000000.0, penalty=l2, solver=saga, tol=0.001;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 437/448] START C=1000000.0, penalty=l2, solver=saga, tol=0.001.........\n",
            "[CV 3/5; 437/448] END C=1000000.0, penalty=l2, solver=saga, tol=0.001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 437/448] START C=1000000.0, penalty=l2, solver=saga, tol=0.001.........\n",
            "[CV 4/5; 437/448] END C=1000000.0, penalty=l2, solver=saga, tol=0.001;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 437/448] START C=1000000.0, penalty=l2, solver=saga, tol=0.001.........\n",
            "[CV 5/5; 437/448] END C=1000000.0, penalty=l2, solver=saga, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 438/448] START C=1000000.0, penalty=l2, solver=saga, tol=0.0001........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 438/448] END C=1000000.0, penalty=l2, solver=saga, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 438/448] START C=1000000.0, penalty=l2, solver=saga, tol=0.0001........\n",
            "[CV 2/5; 438/448] END C=1000000.0, penalty=l2, solver=saga, tol=0.0001;, score=0.792 total time=   0.0s\n",
            "[CV 3/5; 438/448] START C=1000000.0, penalty=l2, solver=saga, tol=0.0001........\n",
            "[CV 3/5; 438/448] END C=1000000.0, penalty=l2, solver=saga, tol=0.0001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 438/448] START C=1000000.0, penalty=l2, solver=saga, tol=0.0001........\n",
            "[CV 4/5; 438/448] END C=1000000.0, penalty=l2, solver=saga, tol=0.0001;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 438/448] START C=1000000.0, penalty=l2, solver=saga, tol=0.0001........\n",
            "[CV 5/5; 438/448] END C=1000000.0, penalty=l2, solver=saga, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 439/448] START C=1000000.0, penalty=l2, solver=saga, tol=1e-05.........\n",
            "[CV 1/5; 439/448] END C=1000000.0, penalty=l2, solver=saga, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 439/448] START C=1000000.0, penalty=l2, solver=saga, tol=1e-05.........\n",
            "[CV 2/5; 439/448] END C=1000000.0, penalty=l2, solver=saga, tol=1e-05;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 439/448] START C=1000000.0, penalty=l2, solver=saga, tol=1e-05.........\n",
            "[CV 3/5; 439/448] END C=1000000.0, penalty=l2, solver=saga, tol=1e-05;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 439/448] START C=1000000.0, penalty=l2, solver=saga, tol=1e-05.........\n",
            "[CV 4/5; 439/448] END C=1000000.0, penalty=l2, solver=saga, tol=1e-05;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 439/448] START C=1000000.0, penalty=l2, solver=saga, tol=1e-05.........\n",
            "[CV 5/5; 439/448] END C=1000000.0, penalty=l2, solver=saga, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 440/448] START C=1000000.0, penalty=l2, solver=saga, tol=1e-06.........\n",
            "[CV 1/5; 440/448] END C=1000000.0, penalty=l2, solver=saga, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 440/448] START C=1000000.0, penalty=l2, solver=saga, tol=1e-06.........\n",
            "[CV 2/5; 440/448] END C=1000000.0, penalty=l2, solver=saga, tol=1e-06;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 440/448] START C=1000000.0, penalty=l2, solver=saga, tol=1e-06.........\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 440/448] END C=1000000.0, penalty=l2, solver=saga, tol=1e-06;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 440/448] START C=1000000.0, penalty=l2, solver=saga, tol=1e-06.........\n",
            "[CV 4/5; 440/448] END C=1000000.0, penalty=l2, solver=saga, tol=1e-06;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 440/448] START C=1000000.0, penalty=l2, solver=saga, tol=1e-06.........\n",
            "[CV 5/5; 440/448] END C=1000000.0, penalty=l2, solver=saga, tol=1e-06;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 441/448] START C=1000000.0, penalty=elasticnet, solver=saga, tol=0.001.\n",
            "[CV 1/5; 441/448] END C=1000000.0, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 2/5; 441/448] START C=1000000.0, penalty=elasticnet, solver=saga, tol=0.001.\n",
            "[CV 2/5; 441/448] END C=1000000.0, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 3/5; 441/448] START C=1000000.0, penalty=elasticnet, solver=saga, tol=0.001.\n",
            "[CV 3/5; 441/448] END C=1000000.0, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 4/5; 441/448] START C=1000000.0, penalty=elasticnet, solver=saga, tol=0.001.\n",
            "[CV 4/5; 441/448] END C=1000000.0, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 5/5; 441/448] START C=1000000.0, penalty=elasticnet, solver=saga, tol=0.001.\n",
            "[CV 5/5; 441/448] END C=1000000.0, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
            "[CV 1/5; 442/448] START C=1000000.0, penalty=elasticnet, solver=saga, tol=0.0001\n",
            "[CV 1/5; 442/448] END C=1000000.0, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 2/5; 442/448] START C=1000000.0, penalty=elasticnet, solver=saga, tol=0.0001\n",
            "[CV 2/5; 442/448] END C=1000000.0, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 3/5; 442/448] START C=1000000.0, penalty=elasticnet, solver=saga, tol=0.0001\n",
            "[CV 3/5; 442/448] END C=1000000.0, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 4/5; 442/448] START C=1000000.0, penalty=elasticnet, solver=saga, tol=0.0001\n",
            "[CV 4/5; 442/448] END C=1000000.0, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 5/5; 442/448] START C=1000000.0, penalty=elasticnet, solver=saga, tol=0.0001\n",
            "[CV 5/5; 442/448] END C=1000000.0, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
            "[CV 1/5; 443/448] START C=1000000.0, penalty=elasticnet, solver=saga, tol=1e-05.\n",
            "[CV 1/5; 443/448] END C=1000000.0, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 2/5; 443/448] START C=1000000.0, penalty=elasticnet, solver=saga, tol=1e-05.\n",
            "[CV 2/5; 443/448] END C=1000000.0, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 3/5; 443/448] START C=1000000.0, penalty=elasticnet, solver=saga, tol=1e-05.\n",
            "[CV 3/5; 443/448] END C=1000000.0, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 4/5; 443/448] START C=1000000.0, penalty=elasticnet, solver=saga, tol=1e-05.\n",
            "[CV 4/5; 443/448] END C=1000000.0, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 5/5; 443/448] START C=1000000.0, penalty=elasticnet, solver=saga, tol=1e-05.\n",
            "[CV 5/5; 443/448] END C=1000000.0, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
            "[CV 1/5; 444/448] START C=1000000.0, penalty=elasticnet, solver=saga, tol=1e-06.\n",
            "[CV 1/5; 444/448] END C=1000000.0, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 2/5; 444/448] START C=1000000.0, penalty=elasticnet, solver=saga, tol=1e-06.\n",
            "[CV 2/5; 444/448] END C=1000000.0, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 3/5; 444/448] START C=1000000.0, penalty=elasticnet, solver=saga, tol=1e-06.\n",
            "[CV 3/5; 444/448] END C=1000000.0, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 4/5; 444/448] START C=1000000.0, penalty=elasticnet, solver=saga, tol=1e-06.\n",
            "[CV 4/5; 444/448] END C=1000000.0, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 5/5; 444/448] START C=1000000.0, penalty=elasticnet, solver=saga, tol=1e-06.\n",
            "[CV 5/5; 444/448] END C=1000000.0, penalty=elasticnet, solver=saga, tol=1e-06;, score=nan total time=   0.0s\n",
            "[CV 1/5; 445/448] START C=1000000.0, penalty=None, solver=saga, tol=0.001.......\n",
            "[CV 1/5; 445/448] END C=1000000.0, penalty=None, solver=saga, tol=0.001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 445/448] START C=1000000.0, penalty=None, solver=saga, tol=0.001.......\n",
            "[CV 2/5; 445/448] END C=1000000.0, penalty=None, solver=saga, tol=0.001;, score=0.792 total time=   0.0s\n",
            "[CV 3/5; 445/448] START C=1000000.0, penalty=None, solver=saga, tol=0.001.......\n",
            "[CV 3/5; 445/448] END C=1000000.0, penalty=None, solver=saga, tol=0.001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 445/448] START C=1000000.0, penalty=None, solver=saga, tol=0.001.......\n",
            "[CV 4/5; 445/448] END C=1000000.0, penalty=None, solver=saga, tol=0.001;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 445/448] START C=1000000.0, penalty=None, solver=saga, tol=0.001.......\n",
            "[CV 5/5; 445/448] END C=1000000.0, penalty=None, solver=saga, tol=0.001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 446/448] START C=1000000.0, penalty=None, solver=saga, tol=0.0001......\n",
            "[CV 1/5; 446/448] END C=1000000.0, penalty=None, solver=saga, tol=0.0001;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 446/448] START C=1000000.0, penalty=None, solver=saga, tol=0.0001......\n",
            "[CV 2/5; 446/448] END C=1000000.0, penalty=None, solver=saga, tol=0.0001;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 446/448] START C=1000000.0, penalty=None, solver=saga, tol=0.0001......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 446/448] END C=1000000.0, penalty=None, solver=saga, tol=0.0001;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 446/448] START C=1000000.0, penalty=None, solver=saga, tol=0.0001......\n",
            "[CV 4/5; 446/448] END C=1000000.0, penalty=None, solver=saga, tol=0.0001;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 446/448] START C=1000000.0, penalty=None, solver=saga, tol=0.0001......\n",
            "[CV 5/5; 446/448] END C=1000000.0, penalty=None, solver=saga, tol=0.0001;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 447/448] START C=1000000.0, penalty=None, solver=saga, tol=1e-05.......\n",
            "[CV 1/5; 447/448] END C=1000000.0, penalty=None, solver=saga, tol=1e-05;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 447/448] START C=1000000.0, penalty=None, solver=saga, tol=1e-05.......\n",
            "[CV 2/5; 447/448] END C=1000000.0, penalty=None, solver=saga, tol=1e-05;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 447/448] START C=1000000.0, penalty=None, solver=saga, tol=1e-05.......\n",
            "[CV 3/5; 447/448] END C=1000000.0, penalty=None, solver=saga, tol=1e-05;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 447/448] START C=1000000.0, penalty=None, solver=saga, tol=1e-05.......\n",
            "[CV 4/5; 447/448] END C=1000000.0, penalty=None, solver=saga, tol=1e-05;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 447/448] START C=1000000.0, penalty=None, solver=saga, tol=1e-05.......\n",
            "[CV 5/5; 447/448] END C=1000000.0, penalty=None, solver=saga, tol=1e-05;, score=0.964 total time=   0.0s\n",
            "[CV 1/5; 448/448] START C=1000000.0, penalty=None, solver=saga, tol=1e-06.......\n",
            "[CV 1/5; 448/448] END C=1000000.0, penalty=None, solver=saga, tol=1e-06;, score=0.848 total time=   0.0s\n",
            "[CV 2/5; 448/448] START C=1000000.0, penalty=None, solver=saga, tol=1e-06.......\n",
            "[CV 2/5; 448/448] END C=1000000.0, penalty=None, solver=saga, tol=1e-06;, score=0.788 total time=   0.0s\n",
            "[CV 3/5; 448/448] START C=1000000.0, penalty=None, solver=saga, tol=1e-06.......\n",
            "[CV 3/5; 448/448] END C=1000000.0, penalty=None, solver=saga, tol=1e-06;, score=0.824 total time=   0.0s\n",
            "[CV 4/5; 448/448] START C=1000000.0, penalty=None, solver=saga, tol=1e-06.......\n",
            "[CV 4/5; 448/448] END C=1000000.0, penalty=None, solver=saga, tol=1e-06;, score=0.844 total time=   0.0s\n",
            "[CV 5/5; 448/448] START C=1000000.0, penalty=None, solver=saga, tol=1e-06.......\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "160 fits failed out of a total of 2240.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "160 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
            "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1863, in __call__\n",
            "    return output if self.return_generator else list(output)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1792, in _get_sequential_output\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
            "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
            "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.9048 0.9048 0.9048 0.9048 0.7336 0.7336 0.7336 0.7336 0.9808 0.9808\n",
            " 0.9808 0.9808 0.912  0.912  0.912  0.912  0.984  0.9848 0.984  0.984\n",
            " 0.9688 0.9688 0.9688 0.9688 0.984  0.984  0.9824 0.984  0.9808 0.9808\n",
            " 0.9808 0.9816 0.984  0.9832 0.984  0.9832 0.9848 0.9848 0.9848 0.9848\n",
            " 0.984  0.984  0.9832 0.984  0.9832 0.9832 0.9832 0.9832 0.9848 0.9832\n",
            " 0.984  0.984  0.9832 0.9824 0.9816 0.9816 0.984  0.9848 0.984  0.9832\n",
            " 0.9832 0.9808 0.9808 0.9808 0.7312 0.7312 0.7312 0.7312 0.9824 0.9824\n",
            " 0.9824 0.9824 0.9112 0.9112 0.9112 0.9112 0.9824 0.9824 0.9824 0.9824\n",
            " 0.9688 0.9688 0.9688 0.9688 0.9824 0.9824 0.9824 0.9824 0.9816 0.9816\n",
            " 0.9816 0.9816 0.9824 0.9824 0.9824 0.9824 0.9848 0.9848 0.9848 0.9848\n",
            " 0.9824 0.9824 0.9824 0.9824 0.9832 0.9832 0.9832 0.9832 0.9824 0.9824\n",
            " 0.9824 0.9824 0.9816 0.9816 0.9816 0.9816 0.9824 0.9824 0.9824 0.9824\n",
            " 0.9816 0.9816 0.9816 0.9816 0.9824 0.9824 0.9824 0.9824 0.732  0.732\n",
            " 0.732  0.732  0.7336 0.732  0.732  0.732  0.9808 0.9808 0.9808 0.9808\n",
            " 0.9696 0.984  0.984  0.9824 0.9112 0.9112 0.9112 0.9112 0.9096 0.9112\n",
            " 0.9112 0.9112 0.9808 0.9808 0.9808 0.9808 0.9696 0.984  0.984  0.9824\n",
            " 0.9688 0.9688 0.9688 0.9688 0.9688 0.9688 0.9688 0.9688 0.9808 0.9808\n",
            " 0.9808 0.9808 0.9696 0.984  0.984  0.9824 0.9816 0.9816 0.9816 0.9816\n",
            " 0.9816 0.9816 0.9816 0.9816 0.9808 0.9808 0.9808 0.9808 0.9696 0.984\n",
            " 0.984  0.9824 0.9848 0.9848 0.9848 0.9848 0.9848 0.9848 0.9848 0.9848\n",
            " 0.9808 0.9808 0.9808 0.9808 0.9696 0.984  0.984  0.9824 0.9832 0.9832\n",
            " 0.9832 0.9832 0.9832 0.9832 0.9832 0.9832 0.9808 0.9808 0.9808 0.9808\n",
            " 0.9696 0.984  0.984  0.9824 0.9816 0.9816 0.9816 0.9816 0.9808 0.9808\n",
            " 0.9816 0.9816 0.9808 0.9808 0.9808 0.9808 0.9696 0.984  0.984  0.9824\n",
            " 0.9808 0.9808 0.9808 0.9808 0.9808 0.9808 0.9808 0.9808 0.9808 0.9808\n",
            " 0.9808 0.9808 0.9696 0.984  0.984  0.9824 0.728  0.7312 0.7312 0.7312\n",
            " 0.896  0.896  0.896  0.8952 0.8776 0.8776 0.8776 0.8768 0.896  0.896\n",
            " 0.896  0.8952 0.8952 0.8952 0.8952 0.8952 0.896  0.8952 0.896  0.8952\n",
            " 0.896  0.896  0.8952 0.896  0.896  0.896  0.896  0.8952 0.896  0.896\n",
            " 0.896  0.896  0.8952 0.896  0.896  0.8952 0.896  0.896  0.896  0.896\n",
            " 0.896  0.896  0.896  0.896  0.896  0.8952 0.896  0.896  0.896  0.896\n",
            " 0.896  0.896  0.896  0.896  0.896  0.896  0.896  0.896  0.896  0.896\n",
            " 0.7888 0.7888 0.7888 0.7888 0.728  0.728  0.728  0.728     nan    nan\n",
            "    nan    nan 0.8536 0.8536 0.8544 0.8536 0.8496 0.8496 0.8496 0.8496\n",
            " 0.8368 0.8368 0.8368 0.8368    nan    nan    nan    nan 0.8536 0.8536\n",
            " 0.8536 0.8528 0.852  0.852  0.852  0.852  0.8496 0.8504 0.8504 0.8496\n",
            "    nan    nan    nan    nan 0.8536 0.8536 0.8536 0.8528 0.8528 0.8544\n",
            " 0.8528 0.8536 0.8536 0.8528 0.8536 0.8528    nan    nan    nan    nan\n",
            " 0.8536 0.8536 0.8528 0.8528 0.8536 0.8528 0.8528 0.8536 0.8536 0.8536\n",
            " 0.8536 0.8528    nan    nan    nan    nan 0.8528 0.8536 0.8528 0.8536\n",
            " 0.8544 0.8536 0.8536 0.8528 0.8544 0.8536 0.8536 0.8528    nan    nan\n",
            "    nan    nan 0.8536 0.8536 0.8536 0.8536 0.8536 0.8536 0.8544 0.8536\n",
            " 0.8536 0.8536 0.8536 0.8536    nan    nan    nan    nan 0.8528 0.8536\n",
            " 0.8536 0.8536 0.8544 0.8536 0.8536 0.8536 0.8536 0.8536 0.8536 0.8536\n",
            "    nan    nan    nan    nan 0.8544 0.8536 0.8536 0.8536]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 448/448] END C=1000000.0, penalty=None, solver=saga, tol=1e-06;, score=0.964 total time=   0.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;lr&#x27;,\n",
              "                 GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
              "                              param_grid=[{&#x27;C&#x27;: [0.1, 1, 10.0, 100.0, 1000.0,\n",
              "                                                 10000.0, 100000.0, 1000000.0],\n",
              "                                           &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
              "                                           &#x27;solver&#x27;: [&#x27;liblinear&#x27;],\n",
              "                                           &#x27;tol&#x27;: [0.001, 0.0001, 1e-05,\n",
              "                                                   1e-06]},\n",
              "                                          {&#x27;C&#x27;: [0.1, 1, 10.0, 100.0, 1000.0,\n",
              "                                                 10000.0, 100000.0, 1000000.0],\n",
              "                                           &#x27;penalty&#x27;: [&#x27;l2&#x27;, None],\n",
              "                                           &#x27;solver&#x27;: [&#x27;lbfgs&#x27;],\n",
              "                                           &#x27;to...\n",
              "                                           &#x27;solver&#x27;: [&#x27;newton-cg&#x27;,\n",
              "                                                      &#x27;newton-cholesky&#x27;],\n",
              "                                           &#x27;tol&#x27;: [0.001, 0.0001, 1e-05,\n",
              "                                                   1e-06]},\n",
              "                                          {&#x27;C&#x27;: [0.1, 1, 10.0, 100.0, 1000.0,\n",
              "                                                 10000.0, 100000.0, 1000000.0],\n",
              "                                           &#x27;penalty&#x27;: [&#x27;l2&#x27;, None],\n",
              "                                           &#x27;solver&#x27;: [&#x27;sag&#x27;],\n",
              "                                           &#x27;tol&#x27;: [0.001, 0.0001, 1e-05,\n",
              "                                                   1e-06]},\n",
              "                                          {&#x27;C&#x27;: [0.1, 1, 10.0, 100.0, 1000.0,\n",
              "                                                 10000.0, 100000.0, 1000000.0],\n",
              "                                           &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;,\n",
              "                                                       None],\n",
              "                                           &#x27;solver&#x27;: [&#x27;saga&#x27;],\n",
              "                                           &#x27;tol&#x27;: [0.001, 0.0001, 1e-05,\n",
              "                                                   1e-06]}],\n",
              "                              verbose=10))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;lr&#x27;,\n",
              "                 GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
              "                              param_grid=[{&#x27;C&#x27;: [0.1, 1, 10.0, 100.0, 1000.0,\n",
              "                                                 10000.0, 100000.0, 1000000.0],\n",
              "                                           &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
              "                                           &#x27;solver&#x27;: [&#x27;liblinear&#x27;],\n",
              "                                           &#x27;tol&#x27;: [0.001, 0.0001, 1e-05,\n",
              "                                                   1e-06]},\n",
              "                                          {&#x27;C&#x27;: [0.1, 1, 10.0, 100.0, 1000.0,\n",
              "                                                 10000.0, 100000.0, 1000000.0],\n",
              "                                           &#x27;penalty&#x27;: [&#x27;l2&#x27;, None],\n",
              "                                           &#x27;solver&#x27;: [&#x27;lbfgs&#x27;],\n",
              "                                           &#x27;to...\n",
              "                                           &#x27;solver&#x27;: [&#x27;newton-cg&#x27;,\n",
              "                                                      &#x27;newton-cholesky&#x27;],\n",
              "                                           &#x27;tol&#x27;: [0.001, 0.0001, 1e-05,\n",
              "                                                   1e-06]},\n",
              "                                          {&#x27;C&#x27;: [0.1, 1, 10.0, 100.0, 1000.0,\n",
              "                                                 10000.0, 100000.0, 1000000.0],\n",
              "                                           &#x27;penalty&#x27;: [&#x27;l2&#x27;, None],\n",
              "                                           &#x27;solver&#x27;: [&#x27;sag&#x27;],\n",
              "                                           &#x27;tol&#x27;: [0.001, 0.0001, 1e-05,\n",
              "                                                   1e-06]},\n",
              "                                          {&#x27;C&#x27;: [0.1, 1, 10.0, 100.0, 1000.0,\n",
              "                                                 10000.0, 100000.0, 1000000.0],\n",
              "                                           &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;,\n",
              "                                                       None],\n",
              "                                           &#x27;solver&#x27;: [&#x27;saga&#x27;],\n",
              "                                           &#x27;tol&#x27;: [0.001, 0.0001, 1e-05,\n",
              "                                                   1e-06]}],\n",
              "                              verbose=10))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">lr: GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
              "             param_grid=[{&#x27;C&#x27;: [0.1, 1, 10.0, 100.0, 1000.0, 10000.0, 100000.0,\n",
              "                                1000000.0],\n",
              "                          &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;], &#x27;solver&#x27;: [&#x27;liblinear&#x27;],\n",
              "                          &#x27;tol&#x27;: [0.001, 0.0001, 1e-05, 1e-06]},\n",
              "                         {&#x27;C&#x27;: [0.1, 1, 10.0, 100.0, 1000.0, 10000.0, 100000.0,\n",
              "                                1000000.0],\n",
              "                          &#x27;penalty&#x27;: [&#x27;l2&#x27;, None], &#x27;solver&#x27;: [&#x27;lbfgs&#x27;],\n",
              "                          &#x27;tol&#x27;: [0.001, 0.0001, 1e-05, 1e-06]},\n",
              "                         {&#x27;C&#x27;: [0.1, 1, 10.0, 10...\n",
              "                          &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;newton-cholesky&#x27;],\n",
              "                          &#x27;tol&#x27;: [0.001, 0.0001, 1e-05, 1e-06]},\n",
              "                         {&#x27;C&#x27;: [0.1, 1, 10.0, 100.0, 1000.0, 10000.0, 100000.0,\n",
              "                                1000000.0],\n",
              "                          &#x27;penalty&#x27;: [&#x27;l2&#x27;, None], &#x27;solver&#x27;: [&#x27;sag&#x27;],\n",
              "                          &#x27;tol&#x27;: [0.001, 0.0001, 1e-05, 1e-06]},\n",
              "                         {&#x27;C&#x27;: [0.1, 1, 10.0, 100.0, 1000.0, 10000.0, 100000.0,\n",
              "                                1000000.0],\n",
              "                          &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, None],\n",
              "                          &#x27;solver&#x27;: [&#x27;saga&#x27;],\n",
              "                          &#x27;tol&#x27;: [0.001, 0.0001, 1e-05, 1e-06]}],\n",
              "             verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                ('lr',\n",
              "                 GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
              "                              param_grid=[{'C': [0.1, 1, 10.0, 100.0, 1000.0,\n",
              "                                                 10000.0, 100000.0, 1000000.0],\n",
              "                                           'penalty': ['l1', 'l2'],\n",
              "                                           'solver': ['liblinear'],\n",
              "                                           'tol': [0.001, 0.0001, 1e-05,\n",
              "                                                   1e-06]},\n",
              "                                          {'C': [0.1, 1, 10.0, 100.0, 1000.0,\n",
              "                                                 10000.0, 100000.0, 1000000.0],\n",
              "                                           'penalty': ['l2', None],\n",
              "                                           'solver': ['lbfgs'],\n",
              "                                           'to...\n",
              "                                           'solver': ['newton-cg',\n",
              "                                                      'newton-cholesky'],\n",
              "                                           'tol': [0.001, 0.0001, 1e-05,\n",
              "                                                   1e-06]},\n",
              "                                          {'C': [0.1, 1, 10.0, 100.0, 1000.0,\n",
              "                                                 10000.0, 100000.0, 1000000.0],\n",
              "                                           'penalty': ['l2', None],\n",
              "                                           'solver': ['sag'],\n",
              "                                           'tol': [0.001, 0.0001, 1e-05,\n",
              "                                                   1e-06]},\n",
              "                                          {'C': [0.1, 1, 10.0, 100.0, 1000.0,\n",
              "                                                 10000.0, 100000.0, 1000000.0],\n",
              "                                           'penalty': ['l1', 'l2', 'elasticnet',\n",
              "                                                       None],\n",
              "                                           'solver': ['saga'],\n",
              "                                           'tol': [0.001, 0.0001, 1e-05,\n",
              "                                                   1e-06]}],\n",
              "                              verbose=10))])"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "param_grid = [\n",
        "    {'solver': ['liblinear'], 'penalty': ['l1', 'l2'], 'tol': [1e-3, 1e-4, 1e-5, 1e-6], 'C': [1e-1, 1, 1e1, 1e2, 1e3, 1e4, 1e5, 1e6]},\n",
        "    {'solver': ['lbfgs'], 'penalty': ['l2', None], 'tol': [1e-3, 1e-4, 1e-5, 1e-6], 'C': [1e-1, 1, 1e1, 1e2, 1e3, 1e4, 1e5, 1e6]},\n",
        "    {'solver': ['newton-cg', 'newton-cholesky'], 'penalty': ['l2', None], 'tol': [1e-3, 1e-4, 1e-5, 1e-6], 'C': [1e-1, 1, 1e1, 1e2, 1e3, 1e4, 1e5, 1e6]},\n",
        "    {'solver': ['sag'], 'penalty': ['l2', None], 'tol': [1e-3, 1e-4, 1e-5, 1e-6], 'C': [1e-1, 1, 1e1, 1e2, 1e3, 1e4, 1e5, 1e6]},\n",
        "    {'solver': ['saga'], 'penalty': ['l1', 'l2', 'elasticnet', None], 'tol': [1e-3, 1e-4, 1e-5, 1e-6], 'C': [1e-1, 1, 1e1, 1e2, 1e3, 1e4, 1e5, 1e6]}\n",
        "]\n",
        "\n",
        "clf = Pipeline([('scaler', StandardScaler()),\n",
        "                ('lr', GridSearchCV(LogisticRegression(),\n",
        "                              param_grid=param_grid,\n",
        "                              cv=5,\n",
        "                              refit=True,\n",
        "                              verbose=10))])\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "4pj_J8edpcT0",
        "outputId": "e1739763-8d30-4cb2-dcda-0eae5606fbc3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10.0, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" checked><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10.0, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(C=10.0, penalty='l1', solver='liblinear')"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf['lr'].best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojQ_coCCq0M3",
        "outputId": "5d4f5e81-86e6-4d27-e77f-d10c7a7e56ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9847999999999999"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf['lr'].best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8XMAVLvq2S8"
      },
      "source": [
        "#### Evaluating Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ah-OgVE7q6Lx",
        "outputId": "096ded2d-4113-449c-dd16-e8347f28d3f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation f1 Score:  0.9891304347826086\n",
            "Test f1 Score:  0.9685230024213075\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "y_valid_pred = clf.predict(X_valid)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Validation f1 Score: \", f1_score(y_valid, y_valid_pred))\n",
        "print(\"Test f1 Score: \", f1_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uUGsgINrBO0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Nf9auCTLMpsG",
        "nLcL45WjM8pS",
        "Zo4FCpPtNC5W",
        "VhzT0jqSB8kj",
        "sDtaQYinNbMw",
        "eNYzyI1Biki9",
        "B8UAlZ6qlFQk",
        "R5buC5sXm95s"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}