{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LgbiLl1ymLwk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "WRgSIbYwudYN",
        "outputId": "67b03d20-dcfd-4493-d00c-8f89377ff242"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>gold_open</th>\n",
              "      <th>gold_high</th>\n",
              "      <th>gold_low</th>\n",
              "      <th>gold_close</th>\n",
              "      <th>gold_adj_close</th>\n",
              "      <th>gold_volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000-08-30</td>\n",
              "      <td>273.899994</td>\n",
              "      <td>273.899994</td>\n",
              "      <td>273.899994</td>\n",
              "      <td>273.899994</td>\n",
              "      <td>273.899994</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000-08-31</td>\n",
              "      <td>274.799988</td>\n",
              "      <td>278.299988</td>\n",
              "      <td>274.799988</td>\n",
              "      <td>278.299988</td>\n",
              "      <td>278.299988</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2000-09-01</td>\n",
              "      <td>277.000000</td>\n",
              "      <td>277.000000</td>\n",
              "      <td>277.000000</td>\n",
              "      <td>277.000000</td>\n",
              "      <td>277.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2000-09-05</td>\n",
              "      <td>275.799988</td>\n",
              "      <td>275.799988</td>\n",
              "      <td>275.799988</td>\n",
              "      <td>275.799988</td>\n",
              "      <td>275.799988</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2000-09-06</td>\n",
              "      <td>274.200012</td>\n",
              "      <td>274.200012</td>\n",
              "      <td>274.200012</td>\n",
              "      <td>274.200012</td>\n",
              "      <td>274.200012</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date   gold_open   gold_high    gold_low  gold_close  gold_adj_close  \\\n",
              "0 2000-08-30  273.899994  273.899994  273.899994  273.899994      273.899994   \n",
              "1 2000-08-31  274.799988  278.299988  274.799988  278.299988      278.299988   \n",
              "2 2000-09-01  277.000000  277.000000  277.000000  277.000000      277.000000   \n",
              "3 2000-09-05  275.799988  275.799988  275.799988  275.799988      275.799988   \n",
              "4 2000-09-06  274.200012  274.200012  274.200012  274.200012      274.200012   \n",
              "\n",
              "   gold_volume  \n",
              "0            0  \n",
              "1            0  \n",
              "2            0  \n",
              "3            2  \n",
              "4            0  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gold = yf.download(tickers = 'GC=F',\n",
        "                     period = 'max',\n",
        "                     interval = '1d').reset_index()\n",
        "\n",
        "gold = gold.rename(columns = {'Open': 'gold_open', 'High': 'gold_high', 'Low': 'gold_low', 'Close': 'gold_close', 'Adj Close': 'gold_adj_close', 'Volume': 'gold_volume'})\n",
        "gold.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "II43oMhMTERM",
        "outputId": "577080dc-3d2b-43b6-a0b8-1b151df3adb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>euro_usd_open</th>\n",
              "      <th>euro_usd_high</th>\n",
              "      <th>euro_usd_low</th>\n",
              "      <th>euro_usd_close</th>\n",
              "      <th>euro_usd_adj_close</th>\n",
              "      <th>euro_usd_volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2003-12-01</td>\n",
              "      <td>1.203398</td>\n",
              "      <td>1.204007</td>\n",
              "      <td>1.194401</td>\n",
              "      <td>1.196501</td>\n",
              "      <td>1.196501</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2003-12-02</td>\n",
              "      <td>1.196101</td>\n",
              "      <td>1.210903</td>\n",
              "      <td>1.194600</td>\n",
              "      <td>1.208897</td>\n",
              "      <td>1.208897</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2003-12-03</td>\n",
              "      <td>1.209000</td>\n",
              "      <td>1.213003</td>\n",
              "      <td>1.207700</td>\n",
              "      <td>1.212298</td>\n",
              "      <td>1.212298</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2003-12-04</td>\n",
              "      <td>1.212004</td>\n",
              "      <td>1.214403</td>\n",
              "      <td>1.204398</td>\n",
              "      <td>1.208094</td>\n",
              "      <td>1.208094</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2003-12-05</td>\n",
              "      <td>1.207802</td>\n",
              "      <td>1.219096</td>\n",
              "      <td>1.206593</td>\n",
              "      <td>1.218695</td>\n",
              "      <td>1.218695</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date  euro_usd_open  euro_usd_high  euro_usd_low  euro_usd_close  \\\n",
              "0 2003-12-01       1.203398       1.204007      1.194401        1.196501   \n",
              "1 2003-12-02       1.196101       1.210903      1.194600        1.208897   \n",
              "2 2003-12-03       1.209000       1.213003      1.207700        1.212298   \n",
              "3 2003-12-04       1.212004       1.214403      1.204398        1.208094   \n",
              "4 2003-12-05       1.207802       1.219096      1.206593        1.218695   \n",
              "\n",
              "   euro_usd_adj_close  euro_usd_volume  \n",
              "0            1.196501                0  \n",
              "1            1.208897                0  \n",
              "2            1.212298                0  \n",
              "3            1.208094                0  \n",
              "4            1.218695                0  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "uero_usd = yf.download(tickers = 'EURUSD=X' , period = 'max' , interval = '1d').reset_index()\n",
        "uero_usd = uero_usd.rename(columns = {'Open': 'euro_usd_open' , 'High' : 'euro_usd_high' , 'Low': 'euro_usd_low' , 'Close':'euro_usd_close' , 'Adj Close':'euro_usd_adj_close' , 'Volume': 'euro_usd_volume'})\n",
        "uero_usd.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "zLjZGaKWTOM2",
        "outputId": "3d970a69-2b7f-414a-8d6a-f10559e38587"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>sp500_open</th>\n",
              "      <th>sp500_high</th>\n",
              "      <th>sp500_low</th>\n",
              "      <th>sp500_close</th>\n",
              "      <th>sp500_adj_close</th>\n",
              "      <th>sp500_volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1927-12-30</td>\n",
              "      <td>17.660000</td>\n",
              "      <td>17.660000</td>\n",
              "      <td>17.660000</td>\n",
              "      <td>17.660000</td>\n",
              "      <td>17.660000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1928-01-03</td>\n",
              "      <td>17.760000</td>\n",
              "      <td>17.760000</td>\n",
              "      <td>17.760000</td>\n",
              "      <td>17.760000</td>\n",
              "      <td>17.760000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1928-01-04</td>\n",
              "      <td>17.719999</td>\n",
              "      <td>17.719999</td>\n",
              "      <td>17.719999</td>\n",
              "      <td>17.719999</td>\n",
              "      <td>17.719999</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1928-01-05</td>\n",
              "      <td>17.549999</td>\n",
              "      <td>17.549999</td>\n",
              "      <td>17.549999</td>\n",
              "      <td>17.549999</td>\n",
              "      <td>17.549999</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1928-01-06</td>\n",
              "      <td>17.660000</td>\n",
              "      <td>17.660000</td>\n",
              "      <td>17.660000</td>\n",
              "      <td>17.660000</td>\n",
              "      <td>17.660000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date  sp500_open  sp500_high  sp500_low  sp500_close  sp500_adj_close  \\\n",
              "0 1927-12-30   17.660000   17.660000  17.660000    17.660000        17.660000   \n",
              "1 1928-01-03   17.760000   17.760000  17.760000    17.760000        17.760000   \n",
              "2 1928-01-04   17.719999   17.719999  17.719999    17.719999        17.719999   \n",
              "3 1928-01-05   17.549999   17.549999  17.549999    17.549999        17.549999   \n",
              "4 1928-01-06   17.660000   17.660000  17.660000    17.660000        17.660000   \n",
              "\n",
              "   sp500_volume  \n",
              "0             0  \n",
              "1             0  \n",
              "2             0  \n",
              "3             0  \n",
              "4             0  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sp500 = yf.download(tickers = \"^GSPC\",\n",
        "                     period = \"max\",\n",
        "                     interval = \"1d\").reset_index()\n",
        "sp500 = sp500.rename(columns={'Open': 'sp500_open', 'High': 'sp500_high', 'Low': 'sp500_low', 'Close': 'sp500_close', 'Adj Close': 'sp500_adj_close', 'Volume': 'sp500_volume'})\n",
        "sp500.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "buzyJFPMWVKd",
        "outputId": "baa293cd-30da-47df-fc23-ae73b783fd95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017-11-09</td>\n",
              "      <td>112.531998</td>\n",
              "      <td>123.404999</td>\n",
              "      <td>112.219002</td>\n",
              "      <td>120.779999</td>\n",
              "      <td>120.779999</td>\n",
              "      <td>86864600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017-11-10</td>\n",
              "      <td>121.344002</td>\n",
              "      <td>121.665001</td>\n",
              "      <td>101.757004</td>\n",
              "      <td>105.585999</td>\n",
              "      <td>105.585999</td>\n",
              "      <td>84614000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017-11-11</td>\n",
              "      <td>105.750000</td>\n",
              "      <td>127.106003</td>\n",
              "      <td>103.877998</td>\n",
              "      <td>119.615997</td>\n",
              "      <td>119.615997</td>\n",
              "      <td>107708000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017-11-12</td>\n",
              "      <td>119.597000</td>\n",
              "      <td>133.675003</td>\n",
              "      <td>110.617996</td>\n",
              "      <td>123.856003</td>\n",
              "      <td>123.856003</td>\n",
              "      <td>144948000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017-11-13</td>\n",
              "      <td>128.960007</td>\n",
              "      <td>136.528000</td>\n",
              "      <td>120.921997</td>\n",
              "      <td>123.402000</td>\n",
              "      <td>123.402000</td>\n",
              "      <td>116200000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date        Open        High         Low       Close   Adj Close  \\\n",
              "0 2017-11-09  112.531998  123.404999  112.219002  120.779999  120.779999   \n",
              "1 2017-11-10  121.344002  121.665001  101.757004  105.585999  105.585999   \n",
              "2 2017-11-11  105.750000  127.106003  103.877998  119.615997  119.615997   \n",
              "3 2017-11-12  119.597000  133.675003  110.617996  123.856003  123.856003   \n",
              "4 2017-11-13  128.960007  136.528000  120.921997  123.402000  123.402000   \n",
              "\n",
              "      Volume  \n",
              "0   86864600  \n",
              "1   84614000  \n",
              "2  107708000  \n",
              "3  144948000  \n",
              "4  116200000  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xmr = yf.Ticker(\"XMR-USD\")\n",
        "df = yf.download(tickers = 'XMR-USD' ,\n",
        "                 period = 'max',\n",
        "                 interval = '1d').reset_index()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "oFvtdSSUW2Vp",
        "outputId": "395744e4-1865-45fc-e6cb-573677309275"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>price_increase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017-11-09</td>\n",
              "      <td>112.531998</td>\n",
              "      <td>123.404999</td>\n",
              "      <td>112.219002</td>\n",
              "      <td>120.779999</td>\n",
              "      <td>120.779999</td>\n",
              "      <td>86864600</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017-11-10</td>\n",
              "      <td>121.344002</td>\n",
              "      <td>121.665001</td>\n",
              "      <td>101.757004</td>\n",
              "      <td>105.585999</td>\n",
              "      <td>105.585999</td>\n",
              "      <td>84614000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017-11-11</td>\n",
              "      <td>105.750000</td>\n",
              "      <td>127.106003</td>\n",
              "      <td>103.877998</td>\n",
              "      <td>119.615997</td>\n",
              "      <td>119.615997</td>\n",
              "      <td>107708000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017-11-12</td>\n",
              "      <td>119.597000</td>\n",
              "      <td>133.675003</td>\n",
              "      <td>110.617996</td>\n",
              "      <td>123.856003</td>\n",
              "      <td>123.856003</td>\n",
              "      <td>144948000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017-11-13</td>\n",
              "      <td>128.960007</td>\n",
              "      <td>136.528000</td>\n",
              "      <td>120.921997</td>\n",
              "      <td>123.402000</td>\n",
              "      <td>123.402000</td>\n",
              "      <td>116200000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date        Open        High         Low       Close   Adj Close  \\\n",
              "0 2017-11-09  112.531998  123.404999  112.219002  120.779999  120.779999   \n",
              "1 2017-11-10  121.344002  121.665001  101.757004  105.585999  105.585999   \n",
              "2 2017-11-11  105.750000  127.106003  103.877998  119.615997  119.615997   \n",
              "3 2017-11-12  119.597000  133.675003  110.617996  123.856003  123.856003   \n",
              "4 2017-11-13  128.960007  136.528000  120.921997  123.402000  123.402000   \n",
              "\n",
              "      Volume  price_increase  \n",
              "0   86864600             0.0  \n",
              "1   84614000             0.0  \n",
              "2  107708000             1.0  \n",
              "3  144948000             1.0  \n",
              "4  116200000             0.0  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.loc[0 , 'price_increase'] = 0\n",
        "for i in range(1, len(df)):\n",
        "  df.loc[i , 'price_increase'] = 1 if df.loc[i-1 , 'Close'] < df.loc[i , 'Close'] else 0\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "yb3A0BRKXbNC",
        "outputId": "92844b3e-7b69-4b4b-e79a-e9c50b9bb34c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>price_increase</th>\n",
              "      <th>gold_open</th>\n",
              "      <th>gold_high</th>\n",
              "      <th>...</th>\n",
              "      <th>euro_usd_low</th>\n",
              "      <th>euro_usd_close</th>\n",
              "      <th>euro_usd_adj_close</th>\n",
              "      <th>euro_usd_volume</th>\n",
              "      <th>sp500_open</th>\n",
              "      <th>sp500_high</th>\n",
              "      <th>sp500_low</th>\n",
              "      <th>sp500_close</th>\n",
              "      <th>sp500_adj_close</th>\n",
              "      <th>sp500_volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017-11-09</td>\n",
              "      <td>112.531998</td>\n",
              "      <td>123.404999</td>\n",
              "      <td>112.219002</td>\n",
              "      <td>120.779999</td>\n",
              "      <td>120.779999</td>\n",
              "      <td>86864600</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1279.699951</td>\n",
              "      <td>1286.900024</td>\n",
              "      <td>...</td>\n",
              "      <td>1.158641</td>\n",
              "      <td>1.159689</td>\n",
              "      <td>1.159689</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2584.000000</td>\n",
              "      <td>2586.500000</td>\n",
              "      <td>2566.330078</td>\n",
              "      <td>2584.620117</td>\n",
              "      <td>2584.620117</td>\n",
              "      <td>3.844100e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017-11-10</td>\n",
              "      <td>121.344002</td>\n",
              "      <td>121.665001</td>\n",
              "      <td>101.757004</td>\n",
              "      <td>105.585999</td>\n",
              "      <td>105.585999</td>\n",
              "      <td>84614000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1283.500000</td>\n",
              "      <td>1283.500000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.162399</td>\n",
              "      <td>1.164687</td>\n",
              "      <td>1.164687</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2580.179932</td>\n",
              "      <td>2583.810059</td>\n",
              "      <td>2575.570068</td>\n",
              "      <td>2582.300049</td>\n",
              "      <td>2582.300049</td>\n",
              "      <td>3.489740e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017-11-11</td>\n",
              "      <td>105.750000</td>\n",
              "      <td>127.106003</td>\n",
              "      <td>103.877998</td>\n",
              "      <td>119.615997</td>\n",
              "      <td>119.615997</td>\n",
              "      <td>107708000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017-11-12</td>\n",
              "      <td>119.597000</td>\n",
              "      <td>133.675003</td>\n",
              "      <td>110.617996</td>\n",
              "      <td>123.856003</td>\n",
              "      <td>123.856003</td>\n",
              "      <td>144948000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017-11-13</td>\n",
              "      <td>128.960007</td>\n",
              "      <td>136.528000</td>\n",
              "      <td>120.921997</td>\n",
              "      <td>123.402000</td>\n",
              "      <td>123.402000</td>\n",
              "      <td>116200000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1277.300049</td>\n",
              "      <td>1277.300049</td>\n",
              "      <td>...</td>\n",
              "      <td>1.163873</td>\n",
              "      <td>1.166113</td>\n",
              "      <td>1.166113</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2576.530029</td>\n",
              "      <td>2587.659912</td>\n",
              "      <td>2574.479980</td>\n",
              "      <td>2584.840088</td>\n",
              "      <td>2584.840088</td>\n",
              "      <td>3.405200e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 26 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date        Open        High         Low       Close   Adj Close  \\\n",
              "0 2017-11-09  112.531998  123.404999  112.219002  120.779999  120.779999   \n",
              "1 2017-11-10  121.344002  121.665001  101.757004  105.585999  105.585999   \n",
              "2 2017-11-11  105.750000  127.106003  103.877998  119.615997  119.615997   \n",
              "3 2017-11-12  119.597000  133.675003  110.617996  123.856003  123.856003   \n",
              "4 2017-11-13  128.960007  136.528000  120.921997  123.402000  123.402000   \n",
              "\n",
              "      Volume  price_increase    gold_open    gold_high  ...  euro_usd_low  \\\n",
              "0   86864600             0.0  1279.699951  1286.900024  ...      1.158641   \n",
              "1   84614000             0.0  1283.500000  1283.500000  ...      1.162399   \n",
              "2  107708000             1.0          NaN          NaN  ...           NaN   \n",
              "3  144948000             1.0          NaN          NaN  ...           NaN   \n",
              "4  116200000             0.0  1277.300049  1277.300049  ...      1.163873   \n",
              "\n",
              "   euro_usd_close  euro_usd_adj_close  euro_usd_volume   sp500_open  \\\n",
              "0        1.159689            1.159689              0.0  2584.000000   \n",
              "1        1.164687            1.164687              0.0  2580.179932   \n",
              "2             NaN                 NaN              NaN          NaN   \n",
              "3             NaN                 NaN              NaN          NaN   \n",
              "4        1.166113            1.166113              0.0  2576.530029   \n",
              "\n",
              "    sp500_high    sp500_low  sp500_close  sp500_adj_close  sp500_volume  \n",
              "0  2586.500000  2566.330078  2584.620117      2584.620117  3.844100e+09  \n",
              "1  2583.810059  2575.570068  2582.300049      2582.300049  3.489740e+09  \n",
              "2          NaN          NaN          NaN              NaN           NaN  \n",
              "3          NaN          NaN          NaN              NaN           NaN  \n",
              "4  2587.659912  2574.479980  2584.840088      2584.840088  3.405200e+09  \n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.merge(gold , on='Date' , how = 'left').merge(uero_usd , on ='Date' , how = 'left').merge(sp500 , on = 'Date' , how = 'left')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "jj7Wl0CzYqtH",
        "outputId": "73db693f-7ee0-4b80-dc96-6fcebcc6a91b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: ylabel='Frequency'>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df.plot(kind = 'hist')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0R9tVtaTZD4g",
        "outputId": "1740b6b4-312d-43ab-adf6-af0ad51b904d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'gdown' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'gdown' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!gdown 11NUjXNzuFnBd0MShJYq-RlrFeepMHUrA\n",
        "!gdown 1WUNRZJgU0f5NaC-6Z0n_mMvt6P9yNV1U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ypiz3Oj0ZTOY",
        "outputId": "42a4ba68-3389-40f1-dd5a-8622b975e34c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time_stamp</th>\n",
              "      <th>hash</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.442190e+12</td>\n",
              "      <td>12514082.15</td>\n",
              "      <td>2015-09-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.442280e+12</td>\n",
              "      <td>13361330.16</td>\n",
              "      <td>2015-09-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.442360e+12</td>\n",
              "      <td>13065948.13</td>\n",
              "      <td>2015-09-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.442450e+12</td>\n",
              "      <td>12663854.33</td>\n",
              "      <td>2015-09-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.442530e+12</td>\n",
              "      <td>12198340.44</td>\n",
              "      <td>2015-09-18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     time_stamp         hash       time\n",
              "0  1.442190e+12  12514082.15 2015-09-14\n",
              "1  1.442280e+12  13361330.16 2015-09-15\n",
              "2  1.442360e+12  13065948.13 2015-09-16\n",
              "3  1.442450e+12  12663854.33 2015-09-17\n",
              "4  1.442530e+12  12198340.44 2015-09-18"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "date_parser = lambda x: datetime.strptime(x , \"%Y-%m-%dT%H:%M:%SZ\").date()\\\n",
        "\n",
        "xmr_hash = pd.read_csv('./XMR_hash.csv' , index_col = 0 , parse_dates = [\"time\"] , date_parser = date_parser)\n",
        "xmr_difficulty = pd.read_csv('./XMR_difficulty.csv' , index_col = 0 , parse_dates = ['time'] , date_parser = date_parser)\n",
        "xmr_hash.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6KWmfdfcaaka",
        "outputId": "f22ab4cb-4385-4614-c1d8-8c388e341d4e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time_stamp</th>\n",
              "      <th>difficulty</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1442188800000</td>\n",
              "      <td>7.508450e+08</td>\n",
              "      <td>2015-09-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1442275200000</td>\n",
              "      <td>8.016798e+08</td>\n",
              "      <td>2015-09-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1442361600000</td>\n",
              "      <td>7.839569e+08</td>\n",
              "      <td>2015-09-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1442448000000</td>\n",
              "      <td>7.598313e+08</td>\n",
              "      <td>2015-09-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1442534400000</td>\n",
              "      <td>7.319005e+08</td>\n",
              "      <td>2015-09-18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      time_stamp    difficulty       time\n",
              "0  1442188800000  7.508450e+08 2015-09-14\n",
              "1  1442275200000  8.016798e+08 2015-09-15\n",
              "2  1442361600000  7.839569e+08 2015-09-16\n",
              "3  1442448000000  7.598313e+08 2015-09-17\n",
              "4  1442534400000  7.319005e+08 2015-09-18"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xmr_difficulty.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "egTUEARbaqjk",
        "outputId": "8ead5b8a-f13d-4beb-e2c9-7d988048b86f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time_stamp</th>\n",
              "      <th>hash</th>\n",
              "      <th>time</th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>...</th>\n",
              "      <th>euro_usd_low</th>\n",
              "      <th>euro_usd_close</th>\n",
              "      <th>euro_usd_adj_close</th>\n",
              "      <th>euro_usd_volume</th>\n",
              "      <th>sp500_open</th>\n",
              "      <th>sp500_high</th>\n",
              "      <th>sp500_low</th>\n",
              "      <th>sp500_close</th>\n",
              "      <th>sp500_adj_close</th>\n",
              "      <th>sp500_volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.510190e+12</td>\n",
              "      <td>233898872.2</td>\n",
              "      <td>2017-11-09</td>\n",
              "      <td>2017-11-09</td>\n",
              "      <td>112.531998</td>\n",
              "      <td>123.404999</td>\n",
              "      <td>112.219002</td>\n",
              "      <td>120.779999</td>\n",
              "      <td>120.779999</td>\n",
              "      <td>86864600</td>\n",
              "      <td>...</td>\n",
              "      <td>1.158641</td>\n",
              "      <td>1.159689</td>\n",
              "      <td>1.159689</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2584.000000</td>\n",
              "      <td>2586.500000</td>\n",
              "      <td>2566.330078</td>\n",
              "      <td>2584.620117</td>\n",
              "      <td>2584.620117</td>\n",
              "      <td>3.844100e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.510270e+12</td>\n",
              "      <td>233778227.0</td>\n",
              "      <td>2017-11-10</td>\n",
              "      <td>2017-11-10</td>\n",
              "      <td>121.344002</td>\n",
              "      <td>121.665001</td>\n",
              "      <td>101.757004</td>\n",
              "      <td>105.585999</td>\n",
              "      <td>105.585999</td>\n",
              "      <td>84614000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.162399</td>\n",
              "      <td>1.164687</td>\n",
              "      <td>1.164687</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2580.179932</td>\n",
              "      <td>2583.810059</td>\n",
              "      <td>2575.570068</td>\n",
              "      <td>2582.300049</td>\n",
              "      <td>2582.300049</td>\n",
              "      <td>3.489740e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.510360e+12</td>\n",
              "      <td>233778227.0</td>\n",
              "      <td>2017-11-11</td>\n",
              "      <td>2017-11-11</td>\n",
              "      <td>105.750000</td>\n",
              "      <td>127.106003</td>\n",
              "      <td>103.877998</td>\n",
              "      <td>119.615997</td>\n",
              "      <td>119.615997</td>\n",
              "      <td>107708000</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.510440e+12</td>\n",
              "      <td>233778227.0</td>\n",
              "      <td>2017-11-12</td>\n",
              "      <td>2017-11-12</td>\n",
              "      <td>119.597000</td>\n",
              "      <td>133.675003</td>\n",
              "      <td>110.617996</td>\n",
              "      <td>123.856003</td>\n",
              "      <td>123.856003</td>\n",
              "      <td>144948000</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.510530e+12</td>\n",
              "      <td>233778227.0</td>\n",
              "      <td>2017-11-13</td>\n",
              "      <td>2017-11-13</td>\n",
              "      <td>128.960007</td>\n",
              "      <td>136.528000</td>\n",
              "      <td>120.921997</td>\n",
              "      <td>123.402000</td>\n",
              "      <td>123.402000</td>\n",
              "      <td>116200000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.163873</td>\n",
              "      <td>1.166113</td>\n",
              "      <td>1.166113</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2576.530029</td>\n",
              "      <td>2587.659912</td>\n",
              "      <td>2574.479980</td>\n",
              "      <td>2584.840088</td>\n",
              "      <td>2584.840088</td>\n",
              "      <td>3.405200e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     time_stamp         hash       time       Date        Open        High  \\\n",
              "0  1.510190e+12  233898872.2 2017-11-09 2017-11-09  112.531998  123.404999   \n",
              "1  1.510270e+12  233778227.0 2017-11-10 2017-11-10  121.344002  121.665001   \n",
              "2  1.510360e+12  233778227.0 2017-11-11 2017-11-11  105.750000  127.106003   \n",
              "3  1.510440e+12  233778227.0 2017-11-12 2017-11-12  119.597000  133.675003   \n",
              "4  1.510530e+12  233778227.0 2017-11-13 2017-11-13  128.960007  136.528000   \n",
              "\n",
              "          Low       Close   Adj Close     Volume  ...  euro_usd_low  \\\n",
              "0  112.219002  120.779999  120.779999   86864600  ...      1.158641   \n",
              "1  101.757004  105.585999  105.585999   84614000  ...      1.162399   \n",
              "2  103.877998  119.615997  119.615997  107708000  ...           NaN   \n",
              "3  110.617996  123.856003  123.856003  144948000  ...           NaN   \n",
              "4  120.921997  123.402000  123.402000  116200000  ...      1.163873   \n",
              "\n",
              "   euro_usd_close  euro_usd_adj_close  euro_usd_volume   sp500_open  \\\n",
              "0        1.159689            1.159689              0.0  2584.000000   \n",
              "1        1.164687            1.164687              0.0  2580.179932   \n",
              "2             NaN                 NaN              NaN          NaN   \n",
              "3             NaN                 NaN              NaN          NaN   \n",
              "4        1.166113            1.166113              0.0  2576.530029   \n",
              "\n",
              "    sp500_high    sp500_low  sp500_close  sp500_adj_close  sp500_volume  \n",
              "0  2586.500000  2566.330078  2584.620117      2584.620117  3.844100e+09  \n",
              "1  2583.810059  2575.570068  2582.300049      2582.300049  3.489740e+09  \n",
              "2          NaN          NaN          NaN              NaN           NaN  \n",
              "3          NaN          NaN          NaN              NaN           NaN  \n",
              "4  2587.659912  2574.479980  2584.840088      2584.840088  3.405200e+09  \n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = xmr_hash.sort_values(by = ['time' , 'time_stamp']).drop_duplicates(subset='time' , keep = 'last').merge(df , left_on = 'time' , right_on = 'Date')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "cGaDp5ypbU2K",
        "outputId": "d47b0c8b-eca6-4627-d429-ca316d5b690b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time_stamp_x</th>\n",
              "      <th>difficulty</th>\n",
              "      <th>time</th>\n",
              "      <th>time_stamp_y</th>\n",
              "      <th>hash</th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>...</th>\n",
              "      <th>euro_usd_low</th>\n",
              "      <th>euro_usd_close</th>\n",
              "      <th>euro_usd_adj_close</th>\n",
              "      <th>euro_usd_volume</th>\n",
              "      <th>sp500_open</th>\n",
              "      <th>sp500_high</th>\n",
              "      <th>sp500_low</th>\n",
              "      <th>sp500_close</th>\n",
              "      <th>sp500_adj_close</th>\n",
              "      <th>sp500_volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1510185600000</td>\n",
              "      <td>2.806786e+10</td>\n",
              "      <td>2017-11-09</td>\n",
              "      <td>1.510190e+12</td>\n",
              "      <td>233898872.2</td>\n",
              "      <td>2017-11-09</td>\n",
              "      <td>112.531998</td>\n",
              "      <td>123.404999</td>\n",
              "      <td>112.219002</td>\n",
              "      <td>120.779999</td>\n",
              "      <td>...</td>\n",
              "      <td>1.158641</td>\n",
              "      <td>1.159689</td>\n",
              "      <td>1.159689</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2584.000000</td>\n",
              "      <td>2586.500000</td>\n",
              "      <td>2566.330078</td>\n",
              "      <td>2584.620117</td>\n",
              "      <td>2584.620117</td>\n",
              "      <td>3.844100e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1510272000000</td>\n",
              "      <td>2.805339e+10</td>\n",
              "      <td>2017-11-10</td>\n",
              "      <td>1.510270e+12</td>\n",
              "      <td>233778227.0</td>\n",
              "      <td>2017-11-10</td>\n",
              "      <td>121.344002</td>\n",
              "      <td>121.665001</td>\n",
              "      <td>101.757004</td>\n",
              "      <td>105.585999</td>\n",
              "      <td>...</td>\n",
              "      <td>1.162399</td>\n",
              "      <td>1.164687</td>\n",
              "      <td>1.164687</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2580.179932</td>\n",
              "      <td>2583.810059</td>\n",
              "      <td>2575.570068</td>\n",
              "      <td>2582.300049</td>\n",
              "      <td>2582.300049</td>\n",
              "      <td>3.489740e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1510358400000</td>\n",
              "      <td>2.805339e+10</td>\n",
              "      <td>2017-11-11</td>\n",
              "      <td>1.510360e+12</td>\n",
              "      <td>233778227.0</td>\n",
              "      <td>2017-11-11</td>\n",
              "      <td>105.750000</td>\n",
              "      <td>127.106003</td>\n",
              "      <td>103.877998</td>\n",
              "      <td>119.615997</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1510444800000</td>\n",
              "      <td>2.805339e+10</td>\n",
              "      <td>2017-11-12</td>\n",
              "      <td>1.510440e+12</td>\n",
              "      <td>233778227.0</td>\n",
              "      <td>2017-11-12</td>\n",
              "      <td>119.597000</td>\n",
              "      <td>133.675003</td>\n",
              "      <td>110.617996</td>\n",
              "      <td>123.856003</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1510531200000</td>\n",
              "      <td>2.805339e+10</td>\n",
              "      <td>2017-11-13</td>\n",
              "      <td>1.510530e+12</td>\n",
              "      <td>233778227.0</td>\n",
              "      <td>2017-11-13</td>\n",
              "      <td>128.960007</td>\n",
              "      <td>136.528000</td>\n",
              "      <td>120.921997</td>\n",
              "      <td>123.402000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.163873</td>\n",
              "      <td>1.166113</td>\n",
              "      <td>1.166113</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2576.530029</td>\n",
              "      <td>2587.659912</td>\n",
              "      <td>2574.479980</td>\n",
              "      <td>2584.840088</td>\n",
              "      <td>2584.840088</td>\n",
              "      <td>3.405200e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    time_stamp_x    difficulty       time  time_stamp_y         hash  \\\n",
              "0  1510185600000  2.806786e+10 2017-11-09  1.510190e+12  233898872.2   \n",
              "1  1510272000000  2.805339e+10 2017-11-10  1.510270e+12  233778227.0   \n",
              "2  1510358400000  2.805339e+10 2017-11-11  1.510360e+12  233778227.0   \n",
              "3  1510444800000  2.805339e+10 2017-11-12  1.510440e+12  233778227.0   \n",
              "4  1510531200000  2.805339e+10 2017-11-13  1.510530e+12  233778227.0   \n",
              "\n",
              "        Date        Open        High         Low       Close  ...  \\\n",
              "0 2017-11-09  112.531998  123.404999  112.219002  120.779999  ...   \n",
              "1 2017-11-10  121.344002  121.665001  101.757004  105.585999  ...   \n",
              "2 2017-11-11  105.750000  127.106003  103.877998  119.615997  ...   \n",
              "3 2017-11-12  119.597000  133.675003  110.617996  123.856003  ...   \n",
              "4 2017-11-13  128.960007  136.528000  120.921997  123.402000  ...   \n",
              "\n",
              "   euro_usd_low  euro_usd_close  euro_usd_adj_close  euro_usd_volume  \\\n",
              "0      1.158641        1.159689            1.159689              0.0   \n",
              "1      1.162399        1.164687            1.164687              0.0   \n",
              "2           NaN             NaN                 NaN              NaN   \n",
              "3           NaN             NaN                 NaN              NaN   \n",
              "4      1.163873        1.166113            1.166113              0.0   \n",
              "\n",
              "    sp500_open   sp500_high    sp500_low  sp500_close  sp500_adj_close  \\\n",
              "0  2584.000000  2586.500000  2566.330078  2584.620117      2584.620117   \n",
              "1  2580.179932  2583.810059  2575.570068  2582.300049      2582.300049   \n",
              "2          NaN          NaN          NaN          NaN              NaN   \n",
              "3          NaN          NaN          NaN          NaN              NaN   \n",
              "4  2576.530029  2587.659912  2574.479980  2584.840088      2584.840088   \n",
              "\n",
              "   sp500_volume  \n",
              "0  3.844100e+09  \n",
              "1  3.489740e+09  \n",
              "2           NaN  \n",
              "3           NaN  \n",
              "4  3.405200e+09  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = xmr_difficulty.sort_values(by = ['time' , 'time_stamp']).drop_duplicates(subset = 'time' , keep='last').merge(df , on = 'time')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfwdJsyobybW",
        "outputId": "f09c336f-12a9-4323-ba53-4bbc81a59b6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "time_stamp_x            0\n",
              "difficulty              0\n",
              "time                    0\n",
              "time_stamp_y            0\n",
              "hash                    0\n",
              "Date                    0\n",
              "Open                    0\n",
              "High                    0\n",
              "Low                     0\n",
              "Close                   0\n",
              "Adj Close               0\n",
              "Volume                  0\n",
              "price_increase          0\n",
              "gold_open             672\n",
              "gold_high             672\n",
              "gold_low              672\n",
              "gold_close            672\n",
              "gold_adj_close        672\n",
              "gold_volume           672\n",
              "euro_usd_open         619\n",
              "euro_usd_high         619\n",
              "euro_usd_low          619\n",
              "euro_usd_close        619\n",
              "euro_usd_adj_close    619\n",
              "euro_usd_volume       619\n",
              "sp500_open            671\n",
              "sp500_high            671\n",
              "sp500_low             671\n",
              "sp500_close           671\n",
              "sp500_adj_close       671\n",
              "sp500_volume          671\n",
              "dtype: int64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kptxbLoMWlXS",
        "outputId": "9270d5ca-86cd-42b2-ea29-b4a325e95984"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2151, 31)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nE2s3GlWcDC8",
        "outputId": "6fb3255e-39a8-445b-c907-38dfac367857"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "time_stamp_x            0\n",
              "difficulty              0\n",
              "time                    0\n",
              "time_stamp_y            0\n",
              "hash                    0\n",
              "Date                    0\n",
              "Open                    0\n",
              "High                    0\n",
              "Low                     0\n",
              "Close                   0\n",
              "Adj Close               0\n",
              "Volume                  0\n",
              "price_increase          0\n",
              "gold_open               0\n",
              "gold_high               0\n",
              "gold_low                0\n",
              "gold_close              0\n",
              "gold_adj_close          0\n",
              "gold_volume             0\n",
              "euro_usd_open         619\n",
              "euro_usd_high         619\n",
              "euro_usd_low          619\n",
              "euro_usd_close        619\n",
              "euro_usd_adj_close    619\n",
              "euro_usd_volume       619\n",
              "sp500_open            671\n",
              "sp500_high            671\n",
              "sp500_low             671\n",
              "sp500_close           671\n",
              "sp500_adj_close       671\n",
              "sp500_volume          671\n",
              "dtype: int64"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['gold_open'].fillna(0 , inplace = True)\n",
        "\n",
        "for i in range(len(df)) :\n",
        "  if df.loc[i , 'gold_open'] == 0 and i != df.shape[0] - 1:\n",
        "    df.loc[i , 'gold_open'] = df.loc[i-1 , 'gold_close']\n",
        "    df.loc[i , 'gold_high'] = df.loc[i-1 , 'gold_close']\n",
        "    df.loc[i , 'gold_low'] = df.loc[i-1 , 'gold_close']\n",
        "    df.loc[i , 'gold_close'] = df.loc[i+1 , 'gold_open']\n",
        "    df.loc[i , 'gold_adj_close'] = df.loc[i+1 , 'gold_open']\n",
        "    df.loc[i , 'gold_volume'] = df.loc[i-1 , 'gold_volume']\n",
        "  elif df.loc[i , 'gold_open'] == 0 and i != 0:\n",
        "    df.loc[i , 'gold_open'] = df.loc[i-1 , 'gold_close']\n",
        "    df.loc[i , 'gold_high'] = df.loc[i-1 , 'gold_close']\n",
        "    df.loc[i , 'gold_low'] = df.loc[i-1 , 'gold_close']\n",
        "    df.loc[i , 'gold_close'] = df.loc[i-1 , 'gold_close']\n",
        "    df.loc[i , 'gold_adj_close'] = df.loc[i-1 , 'gold_close']\n",
        "    df.loc[i , 'gold_volume'] = df.loc[i-1 , 'gold_volume']\n",
        "  elif df.loc[i , 'gold_open'] == 0 and i == 0:\n",
        "    df.loc[i , 'gold_open'] = df.loc[i+1 , 'gold_open']\n",
        "    df.loc[i , 'gold_high'] = df.loc[i+1 , 'gold_open']\n",
        "    df.loc[i , 'gold_low'] = df.loc[i+1 , 'gold_open']\n",
        "    df.loc[i , 'gold_close'] = df.loc[i+1 , 'gold_open']\n",
        "    df.loc[i , 'gold_adj_close'] = df.loc[i+1 , 'gold_open']\n",
        "    df.loc[i , 'gold_volume'] = df.loc[i+1 , 'gold_volume']\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9WDhEWeffaO",
        "outputId": "5f9888ad-2160-45ae-8489-b1eb601f8143"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "time_stamp_x            0\n",
              "difficulty              0\n",
              "time                    0\n",
              "time_stamp_y            0\n",
              "hash                    0\n",
              "Date                    0\n",
              "Open                    0\n",
              "High                    0\n",
              "Low                     0\n",
              "Close                   0\n",
              "Adj Close               0\n",
              "Volume                  0\n",
              "price_increase          0\n",
              "gold_open               0\n",
              "gold_high               0\n",
              "gold_low                0\n",
              "gold_close              0\n",
              "gold_adj_close          0\n",
              "gold_volume             0\n",
              "euro_usd_open           0\n",
              "euro_usd_high           0\n",
              "euro_usd_low            0\n",
              "euro_usd_close          0\n",
              "euro_usd_adj_close      0\n",
              "euro_usd_volume         0\n",
              "sp500_open            671\n",
              "sp500_high            671\n",
              "sp500_low             671\n",
              "sp500_close           671\n",
              "sp500_adj_close       671\n",
              "sp500_volume          671\n",
              "dtype: int64"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['euro_usd_open'].fillna(0 , inplace = True)\n",
        "for i in range(len(df)):\n",
        "  if df.loc[i , 'euro_usd_open'] == 0 and df.shape[0] -1 != i and i != 0:\n",
        "    df.loc[i , 'euro_usd_open'] = df.loc[i-1 , 'euro_usd_close']\n",
        "    df.loc[i , 'euro_usd_high'] = df.loc[i-1 , 'euro_usd_close']\n",
        "    df.loc[i , 'euro_usd_low'] = df.loc[i-1 , 'euro_usd_close']\n",
        "    df.loc[i , 'euro_usd_close'] = df.loc[i+1 , 'euro_usd_open']\n",
        "    df.loc[i , 'euro_usd_adj_close'] = df.loc[i+1 , 'euro_usd_open']\n",
        "    df.loc[i , 'euro_usd_volume'] = df.loc[i-1 ,  'euro_usd_volume']\n",
        "\n",
        "  elif df.loc[i , 'euro_usd_open'] == 0 and df.shape[0] -1 == i and i != 0:\n",
        "    df.loc[i , 'euro_usd_open'] = df.loc[i-1, 'euro_usd_close']\n",
        "    df.loc[i , 'euro_usd_high'] = df.loc[i-1, 'euro_usd_close']\n",
        "    df.loc[i , 'euro_usd_low']  = df.loc[i-1, 'euro_usd_close']\n",
        "    df.loc[i , 'euro_usd_close'] = df.loc[i-1, 'euro_usd_close']\n",
        "    df.loc[i , 'euro_usd_adj_close'] = df.loc[i-1 , 'euro_usd_close']\n",
        "    df.loc[i , 'euro_usd_volume'] = df.loc[i-1 , 'euro_usd_volume']\n",
        "\n",
        "  elif df.loc[i , 'euro_usd_open'] == 0 and i == 0:\n",
        "    df.loc[i , 'euro_usd_open'] = df.loc[i+1 ,'euro_usd_open']\n",
        "    df.loc[i , 'euro_usd_high'] = df.loc[i+1 ,'euro_usd_open']\n",
        "    df.loc[i , 'euro_usd_low'] = df.loc[i+1 , 'euro_usd_open']\n",
        "    df.loc[i , 'euro_usd_close'] = df.loc[i+1 , 'euro_usd_open']\n",
        "    df.loc[i , 'euro_usd_adj_close'] = df.loc[i+1 , 'euro_usd_open']\n",
        "    df.loc[i , 'euro_usd_volume'] = df.loc[i+1 , 'euro_usd_volume']\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W9_rG7zm_1e",
        "outputId": "bfd8197d-ebcf-4358-aa9e-3fb089e795f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "time_stamp_x          0\n",
              "difficulty            0\n",
              "time                  0\n",
              "time_stamp_y          0\n",
              "hash                  0\n",
              "Date                  0\n",
              "Open                  0\n",
              "High                  0\n",
              "Low                   0\n",
              "Close                 0\n",
              "Adj Close             0\n",
              "Volume                0\n",
              "price_increase        0\n",
              "gold_open             0\n",
              "gold_high             0\n",
              "gold_low              0\n",
              "gold_close            0\n",
              "gold_adj_close        0\n",
              "gold_volume           0\n",
              "euro_usd_open         0\n",
              "euro_usd_high         0\n",
              "euro_usd_low          0\n",
              "euro_usd_close        0\n",
              "euro_usd_adj_close    0\n",
              "euro_usd_volume       0\n",
              "sp500_open            0\n",
              "sp500_high            0\n",
              "sp500_low             0\n",
              "sp500_close           0\n",
              "sp500_adj_close       0\n",
              "sp500_volume          0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['sp500_open'].fillna(0 , inplace = True)\n",
        "for i in range(len(df)):\n",
        "  if df.loc[i , 'sp500_open'] == 0 and df.shape[0] -1 != i and i != 0:\n",
        "    df.loc[i , 'sp500_open'] = df.loc[i-1 , 'sp500_close']\n",
        "    df.loc[i , 'sp500_high'] = df.loc[i-1 , 'sp500_close']\n",
        "    df.loc[i , 'sp500_low'] = df.loc[i-1 , 'sp500_close']\n",
        "    df.loc[i , 'sp500_close'] = df.loc[i+1 , 'sp500_open']\n",
        "    df.loc[i , 'sp500_adj_close'] = df.loc[i+1 , 'sp500_open']\n",
        "    df.loc[i , 'sp500_volume'] = df.loc[i-1 ,  'sp500_volume']\n",
        "\n",
        "  elif df.loc[i , 'sp500_open'] == 0 and df.shape[0] -1 == i and i != 0:\n",
        "    df.loc[i , 'sp500_open'] = df.loc[i-1, 'sp500_close']\n",
        "    df.loc[i , 'sp500_high'] = df.loc[i-1, 'sp500_close']\n",
        "    df.loc[i , 'sp500_low']  = df.loc[i-1, 'sp500_close']\n",
        "    df.loc[i , 'sp500_close'] = df.loc[i-1, 'sp500_close']\n",
        "    df.loc[i , 'sp500_adj_close'] = df.loc[i-1 , 'sp500_close']\n",
        "    df.loc[i , 'sp500_volume'] = df.loc[i-1 , 'sp500_volume']\n",
        "\n",
        "  elif df.loc[i , 'sp500_open'] == 0 and i == 0:\n",
        "    df.loc[i , 'sp500_open'] = df.loc[i+1 ,'sp500_open']\n",
        "    df.loc[i , 'sp500_high'] = df.loc[i+1 ,'sp500_open']\n",
        "    df.loc[i , 'sp500_low'] = df.loc[i+1 , 'sp500_open']\n",
        "    df.loc[i , 'sp500_close'] = df.loc[i+1 , 'sp500_open']\n",
        "    df.loc[i , 'sp500_adj_close'] = df.loc[i+1 , 'sp500_open']\n",
        "    df.loc[i , 'sp500_volume'] = df.loc[i+1 , 'sp500_volume']\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "bSmEMLfEpOSx"
      },
      "outputs": [],
      "source": [
        "date_range = pd.date_range(start = '2022-09-08' , end = '2023-09-07' , freq = 'D')\n",
        "test = df[df['Date'].isin(date_range)]\n",
        "train = df.drop(index = test.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZekHGvmVp7uC",
        "outputId": "dcdc9fe3-6eeb-4126-95dd-0e86a1812c98"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1786, 31), (365, 31))"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.shape , test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "yyBNytixp-mQ",
        "outputId": "7e18fab1-a3fb-492c-cfb2-8953d82c82d6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time_stamp_x</th>\n",
              "      <th>difficulty</th>\n",
              "      <th>time</th>\n",
              "      <th>time_stamp_y</th>\n",
              "      <th>hash</th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>...</th>\n",
              "      <th>euro_usd_low</th>\n",
              "      <th>euro_usd_close</th>\n",
              "      <th>euro_usd_adj_close</th>\n",
              "      <th>euro_usd_volume</th>\n",
              "      <th>sp500_open</th>\n",
              "      <th>sp500_high</th>\n",
              "      <th>sp500_low</th>\n",
              "      <th>sp500_close</th>\n",
              "      <th>sp500_adj_close</th>\n",
              "      <th>sp500_volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1510185600000</td>\n",
              "      <td>2.806786e+10</td>\n",
              "      <td>2017-11-09</td>\n",
              "      <td>1.510190e+12</td>\n",
              "      <td>233898872.2</td>\n",
              "      <td>2017-11-09</td>\n",
              "      <td>112.531998</td>\n",
              "      <td>123.404999</td>\n",
              "      <td>112.219002</td>\n",
              "      <td>120.779999</td>\n",
              "      <td>...</td>\n",
              "      <td>1.158641</td>\n",
              "      <td>1.159689</td>\n",
              "      <td>1.159689</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2584.000000</td>\n",
              "      <td>2586.500000</td>\n",
              "      <td>2566.330078</td>\n",
              "      <td>2584.620117</td>\n",
              "      <td>2584.620117</td>\n",
              "      <td>3.844100e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1510272000000</td>\n",
              "      <td>2.805339e+10</td>\n",
              "      <td>2017-11-10</td>\n",
              "      <td>1.510270e+12</td>\n",
              "      <td>233778227.0</td>\n",
              "      <td>2017-11-10</td>\n",
              "      <td>121.344002</td>\n",
              "      <td>121.665001</td>\n",
              "      <td>101.757004</td>\n",
              "      <td>105.585999</td>\n",
              "      <td>...</td>\n",
              "      <td>1.162399</td>\n",
              "      <td>1.164687</td>\n",
              "      <td>1.164687</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2580.179932</td>\n",
              "      <td>2583.810059</td>\n",
              "      <td>2575.570068</td>\n",
              "      <td>2582.300049</td>\n",
              "      <td>2582.300049</td>\n",
              "      <td>3.489740e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1510358400000</td>\n",
              "      <td>2.805339e+10</td>\n",
              "      <td>2017-11-11</td>\n",
              "      <td>1.510360e+12</td>\n",
              "      <td>233778227.0</td>\n",
              "      <td>2017-11-11</td>\n",
              "      <td>105.750000</td>\n",
              "      <td>127.106003</td>\n",
              "      <td>103.877998</td>\n",
              "      <td>119.615997</td>\n",
              "      <td>...</td>\n",
              "      <td>1.164687</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2582.300049</td>\n",
              "      <td>2582.300049</td>\n",
              "      <td>2582.300049</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.489740e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1510444800000</td>\n",
              "      <td>2.805339e+10</td>\n",
              "      <td>2017-11-12</td>\n",
              "      <td>1.510440e+12</td>\n",
              "      <td>233778227.0</td>\n",
              "      <td>2017-11-12</td>\n",
              "      <td>119.597000</td>\n",
              "      <td>133.675003</td>\n",
              "      <td>110.617996</td>\n",
              "      <td>123.856003</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.166113</td>\n",
              "      <td>1.166113</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2576.530029</td>\n",
              "      <td>2576.530029</td>\n",
              "      <td>3.489740e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1510531200000</td>\n",
              "      <td>2.805339e+10</td>\n",
              "      <td>2017-11-13</td>\n",
              "      <td>1.510530e+12</td>\n",
              "      <td>233778227.0</td>\n",
              "      <td>2017-11-13</td>\n",
              "      <td>128.960007</td>\n",
              "      <td>136.528000</td>\n",
              "      <td>120.921997</td>\n",
              "      <td>123.402000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.163873</td>\n",
              "      <td>1.166113</td>\n",
              "      <td>1.166113</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2576.530029</td>\n",
              "      <td>2587.659912</td>\n",
              "      <td>2574.479980</td>\n",
              "      <td>2584.840088</td>\n",
              "      <td>2584.840088</td>\n",
              "      <td>3.405200e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    time_stamp_x    difficulty       time  time_stamp_y         hash  \\\n",
              "0  1510185600000  2.806786e+10 2017-11-09  1.510190e+12  233898872.2   \n",
              "1  1510272000000  2.805339e+10 2017-11-10  1.510270e+12  233778227.0   \n",
              "2  1510358400000  2.805339e+10 2017-11-11  1.510360e+12  233778227.0   \n",
              "3  1510444800000  2.805339e+10 2017-11-12  1.510440e+12  233778227.0   \n",
              "4  1510531200000  2.805339e+10 2017-11-13  1.510530e+12  233778227.0   \n",
              "\n",
              "        Date        Open        High         Low       Close  ...  \\\n",
              "0 2017-11-09  112.531998  123.404999  112.219002  120.779999  ...   \n",
              "1 2017-11-10  121.344002  121.665001  101.757004  105.585999  ...   \n",
              "2 2017-11-11  105.750000  127.106003  103.877998  119.615997  ...   \n",
              "3 2017-11-12  119.597000  133.675003  110.617996  123.856003  ...   \n",
              "4 2017-11-13  128.960007  136.528000  120.921997  123.402000  ...   \n",
              "\n",
              "   euro_usd_low  euro_usd_close  euro_usd_adj_close  euro_usd_volume  \\\n",
              "0      1.158641        1.159689            1.159689              0.0   \n",
              "1      1.162399        1.164687            1.164687              0.0   \n",
              "2      1.164687        0.000000            0.000000              0.0   \n",
              "3      0.000000        1.166113            1.166113              0.0   \n",
              "4      1.163873        1.166113            1.166113              0.0   \n",
              "\n",
              "    sp500_open   sp500_high    sp500_low  sp500_close  sp500_adj_close  \\\n",
              "0  2584.000000  2586.500000  2566.330078  2584.620117      2584.620117   \n",
              "1  2580.179932  2583.810059  2575.570068  2582.300049      2582.300049   \n",
              "2  2582.300049  2582.300049  2582.300049     0.000000         0.000000   \n",
              "3     0.000000     0.000000     0.000000  2576.530029      2576.530029   \n",
              "4  2576.530029  2587.659912  2574.479980  2584.840088      2584.840088   \n",
              "\n",
              "   sp500_volume  \n",
              "0  3.844100e+09  \n",
              "1  3.489740e+09  \n",
              "2  3.489740e+09  \n",
              "3  3.489740e+09  \n",
              "4  3.405200e+09  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "JajP8BNFqAy7",
        "outputId": "8f9a2a49-4293-443f-8035-1dd683244597"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time_stamp_x</th>\n",
              "      <th>difficulty</th>\n",
              "      <th>time</th>\n",
              "      <th>time_stamp_y</th>\n",
              "      <th>hash</th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>...</th>\n",
              "      <th>euro_usd_low</th>\n",
              "      <th>euro_usd_close</th>\n",
              "      <th>euro_usd_adj_close</th>\n",
              "      <th>euro_usd_volume</th>\n",
              "      <th>sp500_open</th>\n",
              "      <th>sp500_high</th>\n",
              "      <th>sp500_low</th>\n",
              "      <th>sp500_close</th>\n",
              "      <th>sp500_adj_close</th>\n",
              "      <th>sp500_volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1755</th>\n",
              "      <td>1662595200000</td>\n",
              "      <td>3.208107e+11</td>\n",
              "      <td>2022-09-08</td>\n",
              "      <td>1.662600e+12</td>\n",
              "      <td>2.673422e+09</td>\n",
              "      <td>2022-09-08</td>\n",
              "      <td>149.233353</td>\n",
              "      <td>152.426529</td>\n",
              "      <td>147.767471</td>\n",
              "      <td>152.175339</td>\n",
              "      <td>...</td>\n",
              "      <td>0.993345</td>\n",
              "      <td>0.999570</td>\n",
              "      <td>0.999570</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3959.939941</td>\n",
              "      <td>4010.500000</td>\n",
              "      <td>3944.810059</td>\n",
              "      <td>4006.179932</td>\n",
              "      <td>4006.179932</td>\n",
              "      <td>3.966850e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1756</th>\n",
              "      <td>1662681600000</td>\n",
              "      <td>3.191583e+11</td>\n",
              "      <td>2022-09-09</td>\n",
              "      <td>1.662680e+12</td>\n",
              "      <td>2.659653e+09</td>\n",
              "      <td>2022-09-09</td>\n",
              "      <td>152.175949</td>\n",
              "      <td>159.720169</td>\n",
              "      <td>151.765671</td>\n",
              "      <td>159.720169</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000931</td>\n",
              "      <td>1.001202</td>\n",
              "      <td>1.001202</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4022.939941</td>\n",
              "      <td>4076.810059</td>\n",
              "      <td>4022.939941</td>\n",
              "      <td>4067.360107</td>\n",
              "      <td>4067.360107</td>\n",
              "      <td>3.901940e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1757</th>\n",
              "      <td>1662768000000</td>\n",
              "      <td>3.376091e+11</td>\n",
              "      <td>2022-09-10</td>\n",
              "      <td>1.662770e+12</td>\n",
              "      <td>2.813409e+09</td>\n",
              "      <td>2022-09-10</td>\n",
              "      <td>160.002502</td>\n",
              "      <td>161.677124</td>\n",
              "      <td>157.358948</td>\n",
              "      <td>157.581055</td>\n",
              "      <td>...</td>\n",
              "      <td>1.001202</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4067.360107</td>\n",
              "      <td>4067.360107</td>\n",
              "      <td>4067.360107</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.901940e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1758</th>\n",
              "      <td>1662854400000</td>\n",
              "      <td>3.544228e+11</td>\n",
              "      <td>2022-09-11</td>\n",
              "      <td>1.662850e+12</td>\n",
              "      <td>2.953524e+09</td>\n",
              "      <td>2022-09-11</td>\n",
              "      <td>157.612946</td>\n",
              "      <td>159.213715</td>\n",
              "      <td>154.800797</td>\n",
              "      <td>158.860352</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.007141</td>\n",
              "      <td>1.007141</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4083.669922</td>\n",
              "      <td>4083.669922</td>\n",
              "      <td>3.901940e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1759</th>\n",
              "      <td>1662940800000</td>\n",
              "      <td>3.523094e+11</td>\n",
              "      <td>2022-09-12</td>\n",
              "      <td>1.662940e+12</td>\n",
              "      <td>2.935912e+09</td>\n",
              "      <td>2022-09-12</td>\n",
              "      <td>158.856659</td>\n",
              "      <td>164.834427</td>\n",
              "      <td>158.242157</td>\n",
              "      <td>163.911850</td>\n",
              "      <td>...</td>\n",
              "      <td>1.006472</td>\n",
              "      <td>1.007141</td>\n",
              "      <td>1.007141</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4083.669922</td>\n",
              "      <td>4119.279785</td>\n",
              "      <td>4083.669922</td>\n",
              "      <td>4110.410156</td>\n",
              "      <td>4110.410156</td>\n",
              "      <td>3.814200e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       time_stamp_x    difficulty       time  time_stamp_y          hash  \\\n",
              "1755  1662595200000  3.208107e+11 2022-09-08  1.662600e+12  2.673422e+09   \n",
              "1756  1662681600000  3.191583e+11 2022-09-09  1.662680e+12  2.659653e+09   \n",
              "1757  1662768000000  3.376091e+11 2022-09-10  1.662770e+12  2.813409e+09   \n",
              "1758  1662854400000  3.544228e+11 2022-09-11  1.662850e+12  2.953524e+09   \n",
              "1759  1662940800000  3.523094e+11 2022-09-12  1.662940e+12  2.935912e+09   \n",
              "\n",
              "           Date        Open        High         Low       Close  ...  \\\n",
              "1755 2022-09-08  149.233353  152.426529  147.767471  152.175339  ...   \n",
              "1756 2022-09-09  152.175949  159.720169  151.765671  159.720169  ...   \n",
              "1757 2022-09-10  160.002502  161.677124  157.358948  157.581055  ...   \n",
              "1758 2022-09-11  157.612946  159.213715  154.800797  158.860352  ...   \n",
              "1759 2022-09-12  158.856659  164.834427  158.242157  163.911850  ...   \n",
              "\n",
              "      euro_usd_low  euro_usd_close  euro_usd_adj_close  euro_usd_volume  \\\n",
              "1755      0.993345        0.999570            0.999570              0.0   \n",
              "1756      1.000931        1.001202            1.001202              0.0   \n",
              "1757      1.001202        0.000000            0.000000              0.0   \n",
              "1758      0.000000        1.007141            1.007141              0.0   \n",
              "1759      1.006472        1.007141            1.007141              0.0   \n",
              "\n",
              "       sp500_open   sp500_high    sp500_low  sp500_close  sp500_adj_close  \\\n",
              "1755  3959.939941  4010.500000  3944.810059  4006.179932      4006.179932   \n",
              "1756  4022.939941  4076.810059  4022.939941  4067.360107      4067.360107   \n",
              "1757  4067.360107  4067.360107  4067.360107     0.000000         0.000000   \n",
              "1758     0.000000     0.000000     0.000000  4083.669922      4083.669922   \n",
              "1759  4083.669922  4119.279785  4083.669922  4110.410156      4110.410156   \n",
              "\n",
              "      sp500_volume  \n",
              "1755  3.966850e+09  \n",
              "1756  3.901940e+09  \n",
              "1757  3.901940e+09  \n",
              "1758  3.901940e+09  \n",
              "1759  3.814200e+09  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Iy0ZMJFTqByZ"
      },
      "outputs": [],
      "source": [
        "X = train.drop(columns = [ 'price_increase' , 'time' , 'Date'])\n",
        "y = train['price_increase']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "Jkpri70qqXo5",
        "outputId": "51094cdf-9ba1-4aea-c579-e0005592d74f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time_stamp_x</th>\n",
              "      <th>difficulty</th>\n",
              "      <th>time_stamp_y</th>\n",
              "      <th>hash</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>...</th>\n",
              "      <th>euro_usd_low</th>\n",
              "      <th>euro_usd_close</th>\n",
              "      <th>euro_usd_adj_close</th>\n",
              "      <th>euro_usd_volume</th>\n",
              "      <th>sp500_open</th>\n",
              "      <th>sp500_high</th>\n",
              "      <th>sp500_low</th>\n",
              "      <th>sp500_close</th>\n",
              "      <th>sp500_adj_close</th>\n",
              "      <th>sp500_volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1510185600000</td>\n",
              "      <td>2.806786e+10</td>\n",
              "      <td>1.510190e+12</td>\n",
              "      <td>233898872.2</td>\n",
              "      <td>112.531998</td>\n",
              "      <td>123.404999</td>\n",
              "      <td>112.219002</td>\n",
              "      <td>120.779999</td>\n",
              "      <td>120.779999</td>\n",
              "      <td>86864600</td>\n",
              "      <td>...</td>\n",
              "      <td>1.158641</td>\n",
              "      <td>1.159689</td>\n",
              "      <td>1.159689</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2584.000000</td>\n",
              "      <td>2586.500000</td>\n",
              "      <td>2566.330078</td>\n",
              "      <td>2584.620117</td>\n",
              "      <td>2584.620117</td>\n",
              "      <td>3.844100e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1510272000000</td>\n",
              "      <td>2.805339e+10</td>\n",
              "      <td>1.510270e+12</td>\n",
              "      <td>233778227.0</td>\n",
              "      <td>121.344002</td>\n",
              "      <td>121.665001</td>\n",
              "      <td>101.757004</td>\n",
              "      <td>105.585999</td>\n",
              "      <td>105.585999</td>\n",
              "      <td>84614000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.162399</td>\n",
              "      <td>1.164687</td>\n",
              "      <td>1.164687</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2580.179932</td>\n",
              "      <td>2583.810059</td>\n",
              "      <td>2575.570068</td>\n",
              "      <td>2582.300049</td>\n",
              "      <td>2582.300049</td>\n",
              "      <td>3.489740e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1510358400000</td>\n",
              "      <td>2.805339e+10</td>\n",
              "      <td>1.510360e+12</td>\n",
              "      <td>233778227.0</td>\n",
              "      <td>105.750000</td>\n",
              "      <td>127.106003</td>\n",
              "      <td>103.877998</td>\n",
              "      <td>119.615997</td>\n",
              "      <td>119.615997</td>\n",
              "      <td>107708000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.164687</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2582.300049</td>\n",
              "      <td>2582.300049</td>\n",
              "      <td>2582.300049</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.489740e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1510444800000</td>\n",
              "      <td>2.805339e+10</td>\n",
              "      <td>1.510440e+12</td>\n",
              "      <td>233778227.0</td>\n",
              "      <td>119.597000</td>\n",
              "      <td>133.675003</td>\n",
              "      <td>110.617996</td>\n",
              "      <td>123.856003</td>\n",
              "      <td>123.856003</td>\n",
              "      <td>144948000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.166113</td>\n",
              "      <td>1.166113</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2576.530029</td>\n",
              "      <td>2576.530029</td>\n",
              "      <td>3.489740e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1510531200000</td>\n",
              "      <td>2.805339e+10</td>\n",
              "      <td>1.510530e+12</td>\n",
              "      <td>233778227.0</td>\n",
              "      <td>128.960007</td>\n",
              "      <td>136.528000</td>\n",
              "      <td>120.921997</td>\n",
              "      <td>123.402000</td>\n",
              "      <td>123.402000</td>\n",
              "      <td>116200000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.163873</td>\n",
              "      <td>1.166113</td>\n",
              "      <td>1.166113</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2576.530029</td>\n",
              "      <td>2587.659912</td>\n",
              "      <td>2574.479980</td>\n",
              "      <td>2584.840088</td>\n",
              "      <td>2584.840088</td>\n",
              "      <td>3.405200e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    time_stamp_x    difficulty  time_stamp_y         hash        Open  \\\n",
              "0  1510185600000  2.806786e+10  1.510190e+12  233898872.2  112.531998   \n",
              "1  1510272000000  2.805339e+10  1.510270e+12  233778227.0  121.344002   \n",
              "2  1510358400000  2.805339e+10  1.510360e+12  233778227.0  105.750000   \n",
              "3  1510444800000  2.805339e+10  1.510440e+12  233778227.0  119.597000   \n",
              "4  1510531200000  2.805339e+10  1.510530e+12  233778227.0  128.960007   \n",
              "\n",
              "         High         Low       Close   Adj Close     Volume  ...  \\\n",
              "0  123.404999  112.219002  120.779999  120.779999   86864600  ...   \n",
              "1  121.665001  101.757004  105.585999  105.585999   84614000  ...   \n",
              "2  127.106003  103.877998  119.615997  119.615997  107708000  ...   \n",
              "3  133.675003  110.617996  123.856003  123.856003  144948000  ...   \n",
              "4  136.528000  120.921997  123.402000  123.402000  116200000  ...   \n",
              "\n",
              "   euro_usd_low  euro_usd_close  euro_usd_adj_close  euro_usd_volume  \\\n",
              "0      1.158641        1.159689            1.159689              0.0   \n",
              "1      1.162399        1.164687            1.164687              0.0   \n",
              "2      1.164687        0.000000            0.000000              0.0   \n",
              "3      0.000000        1.166113            1.166113              0.0   \n",
              "4      1.163873        1.166113            1.166113              0.0   \n",
              "\n",
              "    sp500_open   sp500_high    sp500_low  sp500_close  sp500_adj_close  \\\n",
              "0  2584.000000  2586.500000  2566.330078  2584.620117      2584.620117   \n",
              "1  2580.179932  2583.810059  2575.570068  2582.300049      2582.300049   \n",
              "2  2582.300049  2582.300049  2582.300049     0.000000         0.000000   \n",
              "3     0.000000     0.000000     0.000000  2576.530029      2576.530029   \n",
              "4  2576.530029  2587.659912  2574.479980  2584.840088      2584.840088   \n",
              "\n",
              "   sp500_volume  \n",
              "0  3.844100e+09  \n",
              "1  3.489740e+09  \n",
              "2  3.489740e+09  \n",
              "3  3.489740e+09  \n",
              "4  3.405200e+09  \n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lh51Md12qdaF",
        "outputId": "eb96f6ea-c0af-4a47-e7af-f56bcdbe622b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    0.0\n",
              "1    0.0\n",
              "2    1.0\n",
              "3    1.0\n",
              "4    0.0\n",
              "Name: price_increase, dtype: float64"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "0rf0X3W2qeaX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1339 entries, 266 to 1126\n",
            "Data columns (total 28 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   time_stamp_x        1339 non-null   int64  \n",
            " 1   difficulty          1339 non-null   float64\n",
            " 2   time_stamp_y        1339 non-null   float64\n",
            " 3   hash                1339 non-null   float64\n",
            " 4   Open                1339 non-null   float64\n",
            " 5   High                1339 non-null   float64\n",
            " 6   Low                 1339 non-null   float64\n",
            " 7   Close               1339 non-null   float64\n",
            " 8   Adj Close           1339 non-null   float64\n",
            " 9   Volume              1339 non-null   int64  \n",
            " 10  gold_open           1339 non-null   float64\n",
            " 11  gold_high           1339 non-null   float64\n",
            " 12  gold_low            1339 non-null   float64\n",
            " 13  gold_close          1339 non-null   float64\n",
            " 14  gold_adj_close      1339 non-null   float64\n",
            " 15  gold_volume         1339 non-null   float64\n",
            " 16  euro_usd_open       1339 non-null   float64\n",
            " 17  euro_usd_high       1339 non-null   float64\n",
            " 18  euro_usd_low        1339 non-null   float64\n",
            " 19  euro_usd_close      1339 non-null   float64\n",
            " 20  euro_usd_adj_close  1339 non-null   float64\n",
            " 21  euro_usd_volume     1339 non-null   float64\n",
            " 22  sp500_open          1339 non-null   float64\n",
            " 23  sp500_high          1339 non-null   float64\n",
            " 24  sp500_low           1339 non-null   float64\n",
            " 25  sp500_close         1339 non-null   float64\n",
            " 26  sp500_adj_close     1339 non-null   float64\n",
            " 27  sp500_volume        1339 non-null   float64\n",
            "dtypes: float64(26), int64(2)\n",
            "memory usage: 303.4 KB\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train , X_validation , y_train , y_validation = train_test_split(X, y , test_size = 0.25 , random_state = 42)\n",
        "X_test = test.drop(columns = [ \"price_increase\" , 'time' , 'Date'])\n",
        "y_test = test['price_increase']\n",
        "X_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "Tk54ZExpq-Uo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 448 candidates, totalling 2240 fits\n",
            "[CV 1/5; 1/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 1/5; 1/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.862 total time=   0.0s\n",
            "[CV 2/5; 1/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 2/5; 1/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.847 total time=   0.0s\n",
            "[CV 3/5; 1/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 3/5; 1/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.817 total time=   0.0s\n",
            "[CV 4/5; 1/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 4/5; 1/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.896 total time=   0.0s\n",
            "[CV 5/5; 1/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 5/5; 1/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.700 total time=   0.0s\n",
            "[CV 1/5; 2/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 2/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.836 total time=   0.0s\n",
            "[CV 2/5; 2/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 2/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.724 total time=   0.0s\n",
            "[CV 3/5; 2/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 2/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.851 total time=   0.0s\n",
            "[CV 4/5; 2/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 2/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.832 total time=   0.0s\n",
            "[CV 5/5; 2/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 2/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.843 total time=   0.0s\n",
            "[CV 1/5; 3/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 3/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.813 total time=   0.0s\n",
            "[CV 2/5; 3/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 3/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.843 total time=   0.0s\n",
            "[CV 3/5; 3/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 3/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.854 total time=   0.0s\n",
            "[CV 4/5; 3/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 3/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.791 total time=   0.0s\n",
            "[CV 5/5; 3/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 3/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.846 total time=   0.0s\n",
            "[CV 1/5; 4/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 4/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 4/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 4/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.832 total time=   0.0s\n",
            "[CV 3/5; 4/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 4/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.802 total time=   0.0s\n",
            "[CV 4/5; 4/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 4/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.765 total time=   0.0s\n",
            "[CV 5/5; 4/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 4/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.835 total time=   0.0s\n",
            "[CV 1/5; 5/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 1/5; 5/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.705 total time=   0.0s\n",
            "[CV 2/5; 5/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 2/5; 5/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.739 total time=   0.0s\n",
            "[CV 3/5; 5/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 3/5; 5/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.757 total time=   0.0s\n",
            "[CV 4/5; 5/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 4/5; 5/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.772 total time=   0.0s\n",
            "[CV 5/5; 5/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 5/5; 5/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.760 total time=   0.0s\n",
            "[CV 1/5; 6/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 6/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.619 total time=   0.0s\n",
            "[CV 2/5; 6/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 6/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.791 total time=   0.0s\n",
            "[CV 3/5; 6/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 6/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.784 total time=   0.0s\n",
            "[CV 4/5; 6/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 6/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.854 total time=   0.0s\n",
            "[CV 5/5; 6/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 6/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 7/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 7/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.757 total time=   0.0s\n",
            "[CV 2/5; 7/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 7/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.776 total time=   0.0s\n",
            "[CV 3/5; 7/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 7/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.679 total time=   0.0s\n",
            "[CV 4/5; 7/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 7/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.724 total time=   0.0s\n",
            "[CV 5/5; 7/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 7/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.839 total time=   0.0s\n",
            "[CV 1/5; 8/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 8/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.743 total time=   0.0s\n",
            "[CV 2/5; 8/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 8/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.668 total time=   0.0s\n",
            "[CV 3/5; 8/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 8/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.746 total time=   0.0s\n",
            "[CV 4/5; 8/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 8/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.806 total time=   0.0s\n",
            "[CV 5/5; 8/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 8/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.768 total time=   0.0s\n",
            "[CV 1/5; 9/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 1/5; 9/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.795 total time=   0.0s\n",
            "[CV 2/5; 9/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 2/5; 9/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.910 total time=   0.0s\n",
            "[CV 3/5; 9/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 3/5; 9/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.821 total time=   0.0s\n",
            "[CV 4/5; 9/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 4/5; 9/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.825 total time=   0.0s\n",
            "[CV 5/5; 9/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 5/5; 9/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.652 total time=   0.0s\n",
            "[CV 1/5; 10/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 10/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.761 total time=   0.0s\n",
            "[CV 2/5; 10/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 10/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.869 total time=   0.0s\n",
            "[CV 3/5; 10/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 10/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.843 total time=   0.0s\n",
            "[CV 4/5; 10/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 10/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.772 total time=   0.0s\n",
            "[CV 5/5; 10/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 10/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.757 total time=   0.0s\n",
            "[CV 1/5; 11/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 11/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.825 total time=   0.0s\n",
            "[CV 2/5; 11/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 11/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.832 total time=   0.0s\n",
            "[CV 3/5; 11/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 11/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.757 total time=   0.0s\n",
            "[CV 4/5; 11/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 11/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.735 total time=   0.0s\n",
            "[CV 5/5; 11/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 11/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.753 total time=   0.0s\n",
            "[CV 1/5; 12/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 12/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.802 total time=   0.0s\n",
            "[CV 2/5; 12/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 12/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.862 total time=   0.0s\n",
            "[CV 3/5; 12/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 12/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.810 total time=   0.0s\n",
            "[CV 4/5; 12/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 12/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.817 total time=   0.0s\n",
            "[CV 5/5; 12/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 12/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.794 total time=   0.0s\n",
            "[CV 1/5; 13/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 1/5; 13/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.873 total time=   0.0s\n",
            "[CV 2/5; 13/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 2/5; 13/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.810 total time=   0.0s\n",
            "[CV 3/5; 13/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 3/5; 13/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.802 total time=   0.0s\n",
            "[CV 4/5; 13/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 4/5; 13/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.925 total time=   0.0s\n",
            "[CV 5/5; 13/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 5/5; 13/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.858 total time=   0.0s\n",
            "[CV 1/5; 14/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 14/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.877 total time=   0.0s\n",
            "[CV 2/5; 14/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 14/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.795 total time=   0.0s\n",
            "[CV 3/5; 14/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 14/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.754 total time=   0.0s\n",
            "[CV 4/5; 14/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 14/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.832 total time=   0.0s\n",
            "[CV 5/5; 14/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 14/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.918 total time=   0.0s\n",
            "[CV 1/5; 15/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 15/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.810 total time=   0.0s\n",
            "[CV 2/5; 15/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 15/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.854 total time=   0.0s\n",
            "[CV 3/5; 15/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 15/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.847 total time=   0.0s\n",
            "[CV 4/5; 15/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 15/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.802 total time=   0.0s\n",
            "[CV 5/5; 15/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 15/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.884 total time=   0.0s\n",
            "[CV 1/5; 16/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 16/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.851 total time=   0.0s\n",
            "[CV 2/5; 16/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 16/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.784 total time=   0.0s\n",
            "[CV 3/5; 16/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 16/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.799 total time=   0.0s\n",
            "[CV 4/5; 16/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 16/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.828 total time=   0.0s\n",
            "[CV 5/5; 16/448] START alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 16/448] END alpha=1e-06, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.861 total time=   0.0s\n",
            "[CV 1/5; 17/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 1/5; 17/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.813 total time=   0.0s\n",
            "[CV 2/5; 17/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 2/5; 17/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.877 total time=   0.0s\n",
            "[CV 3/5; 17/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 3/5; 17/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.851 total time=   0.0s\n",
            "[CV 4/5; 17/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 4/5; 17/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 17/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 5/5; 17/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.891 total time=   0.0s\n",
            "[CV 1/5; 18/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 18/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.858 total time=   0.0s\n",
            "[CV 2/5; 18/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 18/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.869 total time=   0.0s\n",
            "[CV 3/5; 18/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 18/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.896 total time=   0.0s\n",
            "[CV 4/5; 18/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 18/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 18/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 18/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.873 total time=   0.0s\n",
            "[CV 1/5; 19/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 19/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.881 total time=   0.0s\n",
            "[CV 2/5; 19/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 19/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.840 total time=   0.0s\n",
            "[CV 3/5; 19/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 19/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.769 total time=   0.0s\n",
            "[CV 4/5; 19/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 19/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 19/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 19/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.914 total time=   0.0s\n",
            "[CV 1/5; 20/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 20/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.772 total time=   0.0s\n",
            "[CV 2/5; 20/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 20/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.784 total time=   0.0s\n",
            "[CV 3/5; 20/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 20/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.690 total time=   0.0s\n",
            "[CV 4/5; 20/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 20/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.701 total time=   0.0s\n",
            "[CV 5/5; 20/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 20/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.730 total time=   0.0s\n",
            "[CV 1/5; 21/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 1/5; 21/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.754 total time=   0.0s\n",
            "[CV 2/5; 21/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 2/5; 21/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.746 total time=   0.0s\n",
            "[CV 3/5; 21/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 3/5; 21/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.791 total time=   0.0s\n",
            "[CV 4/5; 21/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 4/5; 21/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.780 total time=   0.0s\n",
            "[CV 5/5; 21/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 5/5; 21/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.727 total time=   0.0s\n",
            "[CV 1/5; 22/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 22/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.757 total time=   0.0s\n",
            "[CV 2/5; 22/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 22/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.698 total time=   0.0s\n",
            "[CV 3/5; 22/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 22/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.817 total time=   0.0s\n",
            "[CV 4/5; 22/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 22/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.832 total time=   0.0s\n",
            "[CV 5/5; 22/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 22/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.730 total time=   0.0s\n",
            "[CV 1/5; 23/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 23/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.858 total time=   0.0s\n",
            "[CV 2/5; 23/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 23/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.735 total time=   0.0s\n",
            "[CV 3/5; 23/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 23/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.817 total time=   0.0s\n",
            "[CV 4/5; 23/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 23/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.899 total time=   0.0s\n",
            "[CV 5/5; 23/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 23/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.757 total time=   0.0s\n",
            "[CV 1/5; 24/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 24/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.765 total time=   0.0s\n",
            "[CV 2/5; 24/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 24/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.660 total time=   0.0s\n",
            "[CV 3/5; 24/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 24/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.683 total time=   0.0s\n",
            "[CV 4/5; 24/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 24/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.769 total time=   0.0s\n",
            "[CV 5/5; 24/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 24/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.861 total time=   0.0s\n",
            "[CV 1/5; 25/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 1/5; 25/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.769 total time=   0.0s\n",
            "[CV 2/5; 25/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 2/5; 25/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.784 total time=   0.0s\n",
            "[CV 3/5; 25/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 3/5; 25/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.761 total time=   0.0s\n",
            "[CV 4/5; 25/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 4/5; 25/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.825 total time=   0.0s\n",
            "[CV 5/5; 25/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 5/5; 25/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.753 total time=   0.0s\n",
            "[CV 1/5; 26/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 26/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.791 total time=   0.0s\n",
            "[CV 2/5; 26/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 26/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.675 total time=   0.0s\n",
            "[CV 3/5; 26/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 26/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.866 total time=   0.0s\n",
            "[CV 4/5; 26/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 26/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.862 total time=   0.0s\n",
            "[CV 5/5; 26/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 26/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.768 total time=   0.0s\n",
            "[CV 1/5; 27/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 27/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.821 total time=   0.0s\n",
            "[CV 2/5; 27/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 27/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.776 total time=   0.0s\n",
            "[CV 3/5; 27/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 27/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.735 total time=   0.0s\n",
            "[CV 4/5; 27/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 27/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.810 total time=   0.0s\n",
            "[CV 5/5; 27/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 27/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 1/5; 28/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 28/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.784 total time=   0.0s\n",
            "[CV 2/5; 28/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 28/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.754 total time=   0.0s\n",
            "[CV 3/5; 28/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 28/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.866 total time=   0.0s\n",
            "[CV 4/5; 28/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 28/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.743 total time=   0.0s\n",
            "[CV 5/5; 28/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 28/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.813 total time=   0.0s\n",
            "[CV 1/5; 29/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 1/5; 29/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.843 total time=   0.0s\n",
            "[CV 2/5; 29/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 2/5; 29/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.787 total time=   0.0s\n",
            "[CV 3/5; 29/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 3/5; 29/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.884 total time=   0.0s\n",
            "[CV 4/5; 29/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 4/5; 29/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.709 total time=   0.0s\n",
            "[CV 5/5; 29/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 5/5; 29/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.858 total time=   0.0s\n",
            "[CV 1/5; 30/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 30/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.832 total time=   0.0s\n",
            "[CV 2/5; 30/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 30/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.735 total time=   0.0s\n",
            "[CV 3/5; 30/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 30/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.821 total time=   0.0s\n",
            "[CV 4/5; 30/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 30/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.847 total time=   0.0s\n",
            "[CV 5/5; 30/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 30/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 1/5; 31/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 31/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.847 total time=   0.0s\n",
            "[CV 2/5; 31/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 31/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.922 total time=   0.0s\n",
            "[CV 3/5; 31/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 31/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.832 total time=   0.0s\n",
            "[CV 4/5; 31/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 31/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.799 total time=   0.0s\n",
            "[CV 5/5; 31/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 31/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.809 total time=   0.0s\n",
            "[CV 1/5; 32/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 32/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.795 total time=   0.0s\n",
            "[CV 2/5; 32/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 32/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.780 total time=   0.0s\n",
            "[CV 3/5; 32/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 32/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.761 total time=   0.0s\n",
            "[CV 4/5; 32/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 32/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.802 total time=   0.0s\n",
            "[CV 5/5; 32/448] START alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 32/448] END alpha=1e-06, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.764 total time=   0.0s\n",
            "[CV 1/5; 33/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 1/5; 33/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.862 total time=   0.0s\n",
            "[CV 2/5; 33/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 2/5; 33/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.787 total time=   0.0s\n",
            "[CV 3/5; 33/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 3/5; 33/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.757 total time=   0.0s\n",
            "[CV 4/5; 33/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 4/5; 33/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.754 total time=   0.0s\n",
            "[CV 5/5; 33/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 5/5; 33/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.861 total time=   0.0s\n",
            "[CV 1/5; 34/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 34/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.918 total time=   0.0s\n",
            "[CV 2/5; 34/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 34/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.854 total time=   0.0s\n",
            "[CV 3/5; 34/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 34/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.739 total time=   0.0s\n",
            "[CV 4/5; 34/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 34/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.780 total time=   0.0s\n",
            "[CV 5/5; 34/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 34/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.835 total time=   0.0s\n",
            "[CV 1/5; 35/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 35/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.899 total time=   0.0s\n",
            "[CV 2/5; 35/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 35/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.675 total time=   0.0s\n",
            "[CV 3/5; 35/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 35/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.634 total time=   0.0s\n",
            "[CV 4/5; 35/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 35/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.817 total time=   0.0s\n",
            "[CV 5/5; 35/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 35/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.742 total time=   0.0s\n",
            "[CV 1/5; 36/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 36/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.914 total time=   0.0s\n",
            "[CV 2/5; 36/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 36/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.679 total time=   0.0s\n",
            "[CV 3/5; 36/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 36/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.836 total time=   0.0s\n",
            "[CV 4/5; 36/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 36/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.720 total time=   0.0s\n",
            "[CV 5/5; 36/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 36/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.787 total time=   0.0s\n",
            "[CV 1/5; 37/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 1/5; 37/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.869 total time=   0.0s\n",
            "[CV 2/5; 37/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 2/5; 37/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.646 total time=   0.0s\n",
            "[CV 3/5; 37/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 3/5; 37/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.791 total time=   0.0s\n",
            "[CV 4/5; 37/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 4/5; 37/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.754 total time=   0.0s\n",
            "[CV 5/5; 37/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 5/5; 37/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.719 total time=   0.0s\n",
            "[CV 1/5; 38/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 38/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.817 total time=   0.0s\n",
            "[CV 2/5; 38/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 38/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.631 total time=   0.0s\n",
            "[CV 3/5; 38/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 38/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.787 total time=   0.0s\n",
            "[CV 4/5; 38/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 38/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.769 total time=   0.0s\n",
            "[CV 5/5; 38/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 38/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.824 total time=   0.0s\n",
            "[CV 1/5; 39/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 39/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.799 total time=   0.0s\n",
            "[CV 2/5; 39/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 39/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.776 total time=   0.0s\n",
            "[CV 3/5; 39/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 39/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.731 total time=   0.0s\n",
            "[CV 4/5; 39/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 39/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.780 total time=   0.0s\n",
            "[CV 5/5; 39/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 39/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.674 total time=   0.0s\n",
            "[CV 1/5; 40/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 40/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.687 total time=   0.0s\n",
            "[CV 2/5; 40/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 40/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.735 total time=   0.0s\n",
            "[CV 3/5; 40/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 40/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.750 total time=   0.0s\n",
            "[CV 4/5; 40/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 40/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.713 total time=   0.0s\n",
            "[CV 5/5; 40/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 40/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.734 total time=   0.0s\n",
            "[CV 1/5; 41/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 1/5; 41/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.757 total time=   0.0s\n",
            "[CV 2/5; 41/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 2/5; 41/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.776 total time=   0.0s\n",
            "[CV 3/5; 41/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 3/5; 41/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.754 total time=   0.0s\n",
            "[CV 4/5; 41/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 4/5; 41/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.713 total time=   0.0s\n",
            "[CV 5/5; 41/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 5/5; 41/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.779 total time=   0.0s\n",
            "[CV 1/5; 42/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 42/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.817 total time=   0.0s\n",
            "[CV 2/5; 42/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 42/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.791 total time=   0.0s\n",
            "[CV 3/5; 42/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 42/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.672 total time=   0.0s\n",
            "[CV 4/5; 42/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 42/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.657 total time=   0.0s\n",
            "[CV 5/5; 42/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 42/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.828 total time=   0.0s\n",
            "[CV 1/5; 43/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 43/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.877 total time=   0.0s\n",
            "[CV 2/5; 43/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 43/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.735 total time=   0.0s\n",
            "[CV 3/5; 43/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 43/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.743 total time=   0.0s\n",
            "[CV 4/5; 43/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 43/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.713 total time=   0.0s\n",
            "[CV 5/5; 43/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 43/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.738 total time=   0.0s\n",
            "[CV 1/5; 44/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 44/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.840 total time=   0.0s\n",
            "[CV 2/5; 44/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 44/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.795 total time=   0.0s\n",
            "[CV 3/5; 44/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 44/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.791 total time=   0.0s\n",
            "[CV 4/5; 44/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 44/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.813 total time=   0.0s\n",
            "[CV 5/5; 44/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 44/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.801 total time=   0.0s\n",
            "[CV 1/5; 45/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 1/5; 45/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.784 total time=   0.0s\n",
            "[CV 2/5; 45/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 2/5; 45/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.851 total time=   0.0s\n",
            "[CV 3/5; 45/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 3/5; 45/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.810 total time=   0.0s\n",
            "[CV 4/5; 45/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 4/5; 45/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.832 total time=   0.0s\n",
            "[CV 5/5; 45/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 5/5; 45/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.738 total time=   0.0s\n",
            "[CV 1/5; 46/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 46/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.869 total time=   0.0s\n",
            "[CV 2/5; 46/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 46/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.720 total time=   0.0s\n",
            "[CV 3/5; 46/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 46/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.795 total time=   0.0s\n",
            "[CV 4/5; 46/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 46/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.761 total time=   0.0s\n",
            "[CV 5/5; 46/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 46/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.805 total time=   0.0s\n",
            "[CV 1/5; 47/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 47/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.862 total time=   0.0s\n",
            "[CV 2/5; 47/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 47/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.728 total time=   0.0s\n",
            "[CV 3/5; 47/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 47/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.836 total time=   0.0s\n",
            "[CV 4/5; 47/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 47/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.843 total time=   0.0s\n",
            "[CV 5/5; 47/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 47/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.712 total time=   0.0s\n",
            "[CV 1/5; 48/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 48/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.881 total time=   0.0s\n",
            "[CV 2/5; 48/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 48/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.810 total time=   0.0s\n",
            "[CV 3/5; 48/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 48/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.701 total time=   0.0s\n",
            "[CV 4/5; 48/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 48/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.806 total time=   0.0s\n",
            "[CV 5/5; 48/448] START alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 48/448] END alpha=1e-06, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.790 total time=   0.0s\n",
            "[CV 1/5; 49/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 1/5; 49/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.884 total time=   0.0s\n",
            "[CV 2/5; 49/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 2/5; 49/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.821 total time=   0.0s\n",
            "[CV 3/5; 49/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 3/5; 49/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.791 total time=   0.0s\n",
            "[CV 4/5; 49/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 4/5; 49/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.851 total time=   0.0s\n",
            "[CV 5/5; 49/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 5/5; 49/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.869 total time=   0.0s\n",
            "[CV 1/5; 50/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 50/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.896 total time=   0.0s\n",
            "[CV 2/5; 50/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 50/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.757 total time=   0.0s\n",
            "[CV 3/5; 50/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 50/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.862 total time=   0.0s\n",
            "[CV 4/5; 50/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 50/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.854 total time=   0.0s\n",
            "[CV 5/5; 50/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 50/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.884 total time=   0.0s\n",
            "[CV 1/5; 51/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 51/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.746 total time=   0.0s\n",
            "[CV 2/5; 51/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 51/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.705 total time=   0.0s\n",
            "[CV 3/5; 51/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 51/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.787 total time=   0.0s\n",
            "[CV 4/5; 51/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 51/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 5/5; 51/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 51/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.809 total time=   0.0s\n",
            "[CV 1/5; 52/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 52/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.914 total time=   0.0s\n",
            "[CV 2/5; 52/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 52/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.862 total time=   0.0s\n",
            "[CV 3/5; 52/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 52/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.772 total time=   0.0s\n",
            "[CV 4/5; 52/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 52/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 52/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 52/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.846 total time=   0.0s\n",
            "[CV 1/5; 53/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 1/5; 53/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.854 total time=   0.0s\n",
            "[CV 2/5; 53/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 2/5; 53/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.705 total time=   0.0s\n",
            "[CV 3/5; 53/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 3/5; 53/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.836 total time=   0.0s\n",
            "[CV 4/5; 53/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 4/5; 53/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.821 total time=   0.0s\n",
            "[CV 5/5; 53/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 5/5; 53/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.749 total time=   0.0s\n",
            "[CV 1/5; 54/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 54/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.679 total time=   0.0s\n",
            "[CV 2/5; 54/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 54/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.821 total time=   0.0s\n",
            "[CV 3/5; 54/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 54/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.713 total time=   0.0s\n",
            "[CV 4/5; 54/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 54/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.772 total time=   0.0s\n",
            "[CV 5/5; 54/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 54/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.798 total time=   0.0s\n",
            "[CV 1/5; 55/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 55/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.653 total time=   0.0s\n",
            "[CV 2/5; 55/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 55/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.832 total time=   0.0s\n",
            "[CV 3/5; 55/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 55/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.802 total time=   0.0s\n",
            "[CV 4/5; 55/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 55/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.720 total time=   0.0s\n",
            "[CV 5/5; 55/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 55/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.775 total time=   0.0s\n",
            "[CV 1/5; 56/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 56/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.802 total time=   0.0s\n",
            "[CV 2/5; 56/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 56/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.806 total time=   0.0s\n",
            "[CV 3/5; 56/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 56/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.817 total time=   0.0s\n",
            "[CV 4/5; 56/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 56/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.877 total time=   0.0s\n",
            "[CV 5/5; 56/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 56/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.760 total time=   0.0s\n",
            "[CV 1/5; 57/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 1/5; 57/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.627 total time=   0.0s\n",
            "[CV 2/5; 57/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 2/5; 57/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.690 total time=   0.0s\n",
            "[CV 3/5; 57/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 3/5; 57/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.806 total time=   0.0s\n",
            "[CV 4/5; 57/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 4/5; 57/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.772 total time=   0.0s\n",
            "[CV 5/5; 57/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 5/5; 57/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.861 total time=   0.0s\n",
            "[CV 1/5; 58/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 58/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.709 total time=   0.0s\n",
            "[CV 2/5; 58/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 58/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.619 total time=   0.0s\n",
            "[CV 3/5; 58/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 58/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.757 total time=   0.0s\n",
            "[CV 4/5; 58/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 58/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.799 total time=   0.0s\n",
            "[CV 5/5; 58/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 58/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 59/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 59/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.877 total time=   0.0s\n",
            "[CV 2/5; 59/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 59/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.813 total time=   0.0s\n",
            "[CV 3/5; 59/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 59/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.776 total time=   0.0s\n",
            "[CV 4/5; 59/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 59/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.757 total time=   0.0s\n",
            "[CV 5/5; 59/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 59/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.757 total time=   0.0s\n",
            "[CV 1/5; 60/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 60/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.884 total time=   0.0s\n",
            "[CV 2/5; 60/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 60/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.698 total time=   0.0s\n",
            "[CV 3/5; 60/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 60/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.754 total time=   0.0s\n",
            "[CV 4/5; 60/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 60/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.832 total time=   0.0s\n",
            "[CV 5/5; 60/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 60/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.764 total time=   0.0s\n",
            "[CV 1/5; 61/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 1/5; 61/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.784 total time=   0.0s\n",
            "[CV 2/5; 61/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 2/5; 61/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.772 total time=   0.0s\n",
            "[CV 3/5; 61/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 3/5; 61/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.795 total time=   0.0s\n",
            "[CV 4/5; 61/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 4/5; 61/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.813 total time=   0.0s\n",
            "[CV 5/5; 61/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 5/5; 61/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.801 total time=   0.0s\n",
            "[CV 1/5; 62/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 62/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.858 total time=   0.0s\n",
            "[CV 2/5; 62/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 62/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.754 total time=   0.0s\n",
            "[CV 3/5; 62/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 62/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.821 total time=   0.0s\n",
            "[CV 4/5; 62/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 62/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.929 total time=   0.0s\n",
            "[CV 5/5; 62/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 62/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.891 total time=   0.0s\n",
            "[CV 1/5; 63/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 63/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.836 total time=   0.0s\n",
            "[CV 2/5; 63/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 63/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.657 total time=   0.0s\n",
            "[CV 3/5; 63/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 63/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.761 total time=   0.0s\n",
            "[CV 4/5; 63/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 63/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.862 total time=   0.0s\n",
            "[CV 5/5; 63/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 63/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.742 total time=   0.0s\n",
            "[CV 1/5; 64/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 64/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.884 total time=   0.0s\n",
            "[CV 2/5; 64/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 64/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.836 total time=   0.0s\n",
            "[CV 3/5; 64/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 64/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.780 total time=   0.0s\n",
            "[CV 4/5; 64/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 64/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 64/448] START alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 64/448] END alpha=1e-06, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.873 total time=   0.0s\n",
            "[CV 1/5; 65/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 1/5; 65/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.933 total time=   0.0s\n",
            "[CV 2/5; 65/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 2/5; 65/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.910 total time=   0.0s\n",
            "[CV 3/5; 65/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 3/5; 65/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.951 total time=   0.0s\n",
            "[CV 4/5; 65/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 4/5; 65/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.925 total time=   0.0s\n",
            "[CV 5/5; 65/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 5/5; 65/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.918 total time=   0.0s\n",
            "[CV 1/5; 66/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 66/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.869 total time=   0.0s\n",
            "[CV 2/5; 66/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 66/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.925 total time=   0.0s\n",
            "[CV 3/5; 66/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 66/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.951 total time=   0.0s\n",
            "[CV 4/5; 66/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 66/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.869 total time=   0.0s\n",
            "[CV 5/5; 66/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 66/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.850 total time=   0.0s\n",
            "[CV 1/5; 67/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 67/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.933 total time=   0.0s\n",
            "[CV 2/5; 67/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 67/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.925 total time=   0.0s\n",
            "[CV 3/5; 67/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 67/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.925 total time=   0.0s\n",
            "[CV 4/5; 67/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 67/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.963 total time=   0.0s\n",
            "[CV 5/5; 67/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 67/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.895 total time=   0.0s\n",
            "[CV 1/5; 68/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 68/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.918 total time=   0.0s\n",
            "[CV 2/5; 68/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 68/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 3/5; 68/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 68/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.925 total time=   0.0s\n",
            "[CV 4/5; 68/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 68/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.903 total time=   0.0s\n",
            "[CV 5/5; 68/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 68/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.906 total time=   0.0s\n",
            "[CV 1/5; 69/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 1/5; 69/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.877 total time=   0.0s\n",
            "[CV 2/5; 69/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 2/5; 69/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.881 total time=   0.0s\n",
            "[CV 3/5; 69/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 3/5; 69/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.694 total time=   0.0s\n",
            "[CV 4/5; 69/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 4/5; 69/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.851 total time=   0.0s\n",
            "[CV 5/5; 69/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 5/5; 69/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.831 total time=   0.0s\n",
            "[CV 1/5; 70/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 70/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.828 total time=   0.0s\n",
            "[CV 2/5; 70/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 70/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.866 total time=   0.0s\n",
            "[CV 3/5; 70/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 70/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.687 total time=   0.0s\n",
            "[CV 4/5; 70/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 70/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.743 total time=   0.0s\n",
            "[CV 5/5; 70/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 70/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.779 total time=   0.0s\n",
            "[CV 1/5; 71/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 71/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.825 total time=   0.0s\n",
            "[CV 2/5; 71/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 71/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.899 total time=   0.0s\n",
            "[CV 3/5; 71/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 71/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.791 total time=   0.0s\n",
            "[CV 4/5; 71/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 71/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.825 total time=   0.0s\n",
            "[CV 5/5; 71/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 71/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.813 total time=   0.0s\n",
            "[CV 1/5; 72/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 72/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.828 total time=   0.0s\n",
            "[CV 2/5; 72/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 72/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.903 total time=   0.0s\n",
            "[CV 3/5; 72/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 72/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.769 total time=   0.0s\n",
            "[CV 4/5; 72/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 72/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.735 total time=   0.0s\n",
            "[CV 5/5; 72/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 72/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.861 total time=   0.0s\n",
            "[CV 1/5; 73/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 1/5; 73/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.754 total time=   0.0s\n",
            "[CV 2/5; 73/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 2/5; 73/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.862 total time=   0.0s\n",
            "[CV 3/5; 73/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 3/5; 73/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.769 total time=   0.0s\n",
            "[CV 4/5; 73/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 4/5; 73/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.810 total time=   0.0s\n",
            "[CV 5/5; 73/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 5/5; 73/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.869 total time=   0.0s\n",
            "[CV 1/5; 74/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 74/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.821 total time=   0.0s\n",
            "[CV 2/5; 74/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 74/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.825 total time=   0.0s\n",
            "[CV 3/5; 74/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 74/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.787 total time=   0.0s\n",
            "[CV 4/5; 74/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 74/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 5/5; 74/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 74/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.869 total time=   0.0s\n",
            "[CV 1/5; 75/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 75/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.881 total time=   0.0s\n",
            "[CV 2/5; 75/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 75/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.866 total time=   0.0s\n",
            "[CV 3/5; 75/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 75/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.884 total time=   0.0s\n",
            "[CV 4/5; 75/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 75/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.795 total time=   0.0s\n",
            "[CV 5/5; 75/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 75/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.839 total time=   0.0s\n",
            "[CV 1/5; 76/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 76/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.825 total time=   0.0s\n",
            "[CV 2/5; 76/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 76/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.746 total time=   0.0s\n",
            "[CV 3/5; 76/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 76/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.851 total time=   0.0s\n",
            "[CV 4/5; 76/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 76/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.825 total time=   0.0s\n",
            "[CV 5/5; 76/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 76/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.884 total time=   0.0s\n",
            "[CV 1/5; 77/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 1/5; 77/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.910 total time=   0.0s\n",
            "[CV 2/5; 77/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 2/5; 77/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.877 total time=   0.0s\n",
            "[CV 3/5; 77/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 3/5; 77/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.910 total time=   0.0s\n",
            "[CV 4/5; 77/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 4/5; 77/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.918 total time=   0.0s\n",
            "[CV 5/5; 77/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 5/5; 77/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.925 total time=   0.0s\n",
            "[CV 1/5; 78/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 78/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.873 total time=   0.0s\n",
            "[CV 2/5; 78/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 78/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.914 total time=   0.0s\n",
            "[CV 3/5; 78/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 78/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 78/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 78/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.922 total time=   0.0s\n",
            "[CV 5/5; 78/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 78/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.918 total time=   0.0s\n",
            "[CV 1/5; 79/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 79/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.910 total time=   0.0s\n",
            "[CV 2/5; 79/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 79/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.869 total time=   0.0s\n",
            "[CV 3/5; 79/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 79/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.896 total time=   0.0s\n",
            "[CV 4/5; 79/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 79/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.884 total time=   0.0s\n",
            "[CV 5/5; 79/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 79/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.925 total time=   0.0s\n",
            "[CV 1/5; 80/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 80/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.866 total time=   0.0s\n",
            "[CV 2/5; 80/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 80/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.843 total time=   0.0s\n",
            "[CV 3/5; 80/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 80/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.843 total time=   0.0s\n",
            "[CV 4/5; 80/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 80/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.922 total time=   0.0s\n",
            "[CV 5/5; 80/448] START alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 80/448] END alpha=1e-05, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.936 total time=   0.0s\n",
            "[CV 1/5; 81/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 1/5; 81/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.840 total time=   0.0s\n",
            "[CV 2/5; 81/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 2/5; 81/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.985 total time=   0.0s\n",
            "[CV 3/5; 81/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 3/5; 81/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.881 total time=   0.0s\n",
            "[CV 4/5; 81/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 4/5; 81/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.877 total time=   0.0s\n",
            "[CV 5/5; 81/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 5/5; 81/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.914 total time=   0.0s\n",
            "[CV 1/5; 82/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 82/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.896 total time=   0.0s\n",
            "[CV 2/5; 82/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 82/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 3/5; 82/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 82/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.918 total time=   0.0s\n",
            "[CV 4/5; 82/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 82/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.925 total time=   0.0s\n",
            "[CV 5/5; 82/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 82/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.929 total time=   0.0s\n",
            "[CV 1/5; 83/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 83/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.951 total time=   0.0s\n",
            "[CV 2/5; 83/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 83/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.907 total time=   0.0s\n",
            "[CV 3/5; 83/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 83/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.922 total time=   0.0s\n",
            "[CV 4/5; 83/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 83/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.922 total time=   0.0s\n",
            "[CV 5/5; 83/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 83/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.899 total time=   0.0s\n",
            "[CV 1/5; 84/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 84/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.963 total time=   0.0s\n",
            "[CV 2/5; 84/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 84/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.974 total time=   0.0s\n",
            "[CV 3/5; 84/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 84/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.892 total time=   0.0s\n",
            "[CV 4/5; 84/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 84/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.981 total time=   0.0s\n",
            "[CV 5/5; 84/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 84/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.921 total time=   0.0s\n",
            "[CV 1/5; 85/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 1/5; 85/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.787 total time=   0.0s\n",
            "[CV 2/5; 85/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 2/5; 85/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.810 total time=   0.0s\n",
            "[CV 3/5; 85/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 3/5; 85/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.787 total time=   0.0s\n",
            "[CV 4/5; 85/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 4/5; 85/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.825 total time=   0.0s\n",
            "[CV 5/5; 85/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 5/5; 85/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.775 total time=   0.0s\n",
            "[CV 1/5; 86/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 86/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.881 total time=   0.0s\n",
            "[CV 2/5; 86/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 86/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.784 total time=   0.0s\n",
            "[CV 3/5; 86/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 86/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.892 total time=   0.0s\n",
            "[CV 4/5; 86/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 86/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 86/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 86/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.839 total time=   0.0s\n",
            "[CV 1/5; 87/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 87/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.836 total time=   0.0s\n",
            "[CV 2/5; 87/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 87/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.791 total time=   0.0s\n",
            "[CV 3/5; 87/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 87/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.780 total time=   0.0s\n",
            "[CV 4/5; 87/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 87/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.709 total time=   0.0s\n",
            "[CV 5/5; 87/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 87/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.779 total time=   0.0s\n",
            "[CV 1/5; 88/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 88/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.858 total time=   0.0s\n",
            "[CV 2/5; 88/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 88/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.716 total time=   0.0s\n",
            "[CV 3/5; 88/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 88/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.851 total time=   0.0s\n",
            "[CV 4/5; 88/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 88/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.810 total time=   0.0s\n",
            "[CV 5/5; 88/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 88/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.820 total time=   0.0s\n",
            "[CV 1/5; 89/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 1/5; 89/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.761 total time=   0.0s\n",
            "[CV 2/5; 89/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 2/5; 89/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.784 total time=   0.0s\n",
            "[CV 3/5; 89/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 3/5; 89/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 89/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 4/5; 89/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.817 total time=   0.0s\n",
            "[CV 5/5; 89/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 5/5; 89/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.798 total time=   0.0s\n",
            "[CV 1/5; 90/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 90/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.892 total time=   0.0s\n",
            "[CV 2/5; 90/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 90/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.761 total time=   0.0s\n",
            "[CV 3/5; 90/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 90/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.854 total time=   0.0s\n",
            "[CV 4/5; 90/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 90/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.847 total time=   0.0s\n",
            "[CV 5/5; 90/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 90/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.809 total time=   0.0s\n",
            "[CV 1/5; 91/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 91/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.813 total time=   0.0s\n",
            "[CV 2/5; 91/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 91/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.772 total time=   0.0s\n",
            "[CV 3/5; 91/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 91/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.802 total time=   0.0s\n",
            "[CV 4/5; 91/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 91/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.836 total time=   0.0s\n",
            "[CV 5/5; 91/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 91/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.712 total time=   0.0s\n",
            "[CV 1/5; 92/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 92/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.918 total time=   0.0s\n",
            "[CV 2/5; 92/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 92/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.765 total time=   0.0s\n",
            "[CV 3/5; 92/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 92/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.828 total time=   0.0s\n",
            "[CV 4/5; 92/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 92/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.832 total time=   0.0s\n",
            "[CV 5/5; 92/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 92/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.850 total time=   0.0s\n",
            "[CV 1/5; 93/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 1/5; 93/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.914 total time=   0.0s\n",
            "[CV 2/5; 93/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 2/5; 93/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.862 total time=   0.0s\n",
            "[CV 3/5; 93/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 3/5; 93/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.825 total time=   0.0s\n",
            "[CV 4/5; 93/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 4/5; 93/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.881 total time=   0.0s\n",
            "[CV 5/5; 93/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 5/5; 93/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.921 total time=   0.0s\n",
            "[CV 1/5; 94/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 94/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.951 total time=   0.0s\n",
            "[CV 2/5; 94/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 94/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.828 total time=   0.0s\n",
            "[CV 3/5; 94/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 94/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.854 total time=   0.0s\n",
            "[CV 4/5; 94/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 94/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.910 total time=   0.0s\n",
            "[CV 5/5; 94/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 94/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.839 total time=   0.0s\n",
            "[CV 1/5; 95/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 95/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.881 total time=   0.0s\n",
            "[CV 2/5; 95/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 95/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.896 total time=   0.0s\n",
            "[CV 3/5; 95/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 95/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.813 total time=   0.0s\n",
            "[CV 4/5; 95/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 95/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.929 total time=   0.0s\n",
            "[CV 5/5; 95/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 95/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 1/5; 96/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 96/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.877 total time=   0.0s\n",
            "[CV 2/5; 96/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 96/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.862 total time=   0.0s\n",
            "[CV 3/5; 96/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 96/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.896 total time=   0.0s\n",
            "[CV 4/5; 96/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 96/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.910 total time=   0.0s\n",
            "[CV 5/5; 96/448] START alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 96/448] END alpha=1e-05, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.921 total time=   0.0s\n",
            "[CV 1/5; 97/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 1/5; 97/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.866 total time=   0.0s\n",
            "[CV 2/5; 97/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 2/5; 97/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.854 total time=   0.0s\n",
            "[CV 3/5; 97/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 3/5; 97/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.813 total time=   0.0s\n",
            "[CV 4/5; 97/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 4/5; 97/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.862 total time=   0.0s\n",
            "[CV 5/5; 97/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 5/5; 97/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.888 total time=   0.0s\n",
            "[CV 1/5; 98/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 98/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.929 total time=   0.0s\n",
            "[CV 2/5; 98/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 98/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.769 total time=   0.0s\n",
            "[CV 3/5; 98/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 98/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.869 total time=   0.0s\n",
            "[CV 4/5; 98/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 98/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.836 total time=   0.0s\n",
            "[CV 5/5; 98/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 98/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.873 total time=   0.0s\n",
            "[CV 1/5; 99/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 99/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.903 total time=   0.0s\n",
            "[CV 2/5; 99/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 99/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.903 total time=   0.0s\n",
            "[CV 3/5; 99/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 99/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.925 total time=   0.0s\n",
            "[CV 4/5; 99/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 99/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.847 total time=   0.0s\n",
            "[CV 5/5; 99/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 99/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.884 total time=   0.0s\n",
            "[CV 1/5; 100/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 100/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.903 total time=   0.0s\n",
            "[CV 2/5; 100/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 100/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 3/5; 100/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 100/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.851 total time=   0.0s\n",
            "[CV 4/5; 100/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 100/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.896 total time=   0.0s\n",
            "[CV 5/5; 100/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 100/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.891 total time=   0.0s\n",
            "[CV 1/5; 101/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 1/5; 101/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.757 total time=   0.0s\n",
            "[CV 2/5; 101/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 2/5; 101/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.776 total time=   0.0s\n",
            "[CV 3/5; 101/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 3/5; 101/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.840 total time=   0.0s\n",
            "[CV 4/5; 101/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 4/5; 101/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.776 total time=   0.0s\n",
            "[CV 5/5; 101/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 5/5; 101/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.734 total time=   0.0s\n",
            "[CV 1/5; 102/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 102/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.765 total time=   0.0s\n",
            "[CV 2/5; 102/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 102/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.780 total time=   0.0s\n",
            "[CV 3/5; 102/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 102/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.724 total time=   0.0s\n",
            "[CV 4/5; 102/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 102/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.769 total time=   0.0s\n",
            "[CV 5/5; 102/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 102/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.805 total time=   0.0s\n",
            "[CV 1/5; 103/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 103/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.795 total time=   0.0s\n",
            "[CV 2/5; 103/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 103/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.716 total time=   0.0s\n",
            "[CV 3/5; 103/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 103/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.854 total time=   0.0s\n",
            "[CV 4/5; 103/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 103/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.810 total time=   0.0s\n",
            "[CV 5/5; 103/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 103/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.738 total time=   0.0s\n",
            "[CV 1/5; 104/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 104/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.828 total time=   0.0s\n",
            "[CV 2/5; 104/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 104/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.765 total time=   0.0s\n",
            "[CV 3/5; 104/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 104/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.821 total time=   0.0s\n",
            "[CV 4/5; 104/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 104/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.668 total time=   0.0s\n",
            "[CV 5/5; 104/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 104/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.869 total time=   0.0s\n",
            "[CV 1/5; 105/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 1/5; 105/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.724 total time=   0.0s\n",
            "[CV 2/5; 105/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 2/5; 105/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.780 total time=   0.0s\n",
            "[CV 3/5; 105/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 3/5; 105/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.709 total time=   0.0s\n",
            "[CV 4/5; 105/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 4/5; 105/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.784 total time=   0.0s\n",
            "[CV 5/5; 105/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 5/5; 105/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.835 total time=   0.0s\n",
            "[CV 1/5; 106/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 106/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.862 total time=   0.0s\n",
            "[CV 2/5; 106/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 106/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.813 total time=   0.0s\n",
            "[CV 3/5; 106/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 106/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.772 total time=   0.0s\n",
            "[CV 4/5; 106/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 106/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 106/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 106/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.801 total time=   0.0s\n",
            "[CV 1/5; 107/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 107/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.840 total time=   0.0s\n",
            "[CV 2/5; 107/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 107/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.728 total time=   0.0s\n",
            "[CV 3/5; 107/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 107/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.791 total time=   0.0s\n",
            "[CV 4/5; 107/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 107/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.772 total time=   0.0s\n",
            "[CV 5/5; 107/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 107/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.828 total time=   0.0s\n",
            "[CV 1/5; 108/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 108/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.799 total time=   0.0s\n",
            "[CV 2/5; 108/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 108/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.746 total time=   0.0s\n",
            "[CV 3/5; 108/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 108/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.832 total time=   0.0s\n",
            "[CV 4/5; 108/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 108/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.739 total time=   0.0s\n",
            "[CV 5/5; 108/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 108/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.790 total time=   0.0s\n",
            "[CV 1/5; 109/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 1/5; 109/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.877 total time=   0.0s\n",
            "[CV 2/5; 109/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 2/5; 109/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.892 total time=   0.0s\n",
            "[CV 3/5; 109/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 3/5; 109/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.750 total time=   0.0s\n",
            "[CV 4/5; 109/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 4/5; 109/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.925 total time=   0.0s\n",
            "[CV 5/5; 109/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 5/5; 109/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.876 total time=   0.0s\n",
            "[CV 1/5; 110/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 110/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.877 total time=   0.0s\n",
            "[CV 2/5; 110/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 110/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.873 total time=   0.0s\n",
            "[CV 3/5; 110/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 110/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.817 total time=   0.0s\n",
            "[CV 4/5; 110/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 110/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 5/5; 110/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 110/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.824 total time=   0.0s\n",
            "[CV 1/5; 111/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 111/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.877 total time=   0.0s\n",
            "[CV 2/5; 111/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 111/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 3/5; 111/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 111/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.847 total time=   0.0s\n",
            "[CV 4/5; 111/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 111/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.832 total time=   0.0s\n",
            "[CV 5/5; 111/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 111/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.910 total time=   0.0s\n",
            "[CV 1/5; 112/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 112/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.910 total time=   0.0s\n",
            "[CV 2/5; 112/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 112/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.799 total time=   0.0s\n",
            "[CV 3/5; 112/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 112/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.866 total time=   0.0s\n",
            "[CV 4/5; 112/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 112/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.828 total time=   0.0s\n",
            "[CV 5/5; 112/448] START alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 112/448] END alpha=1e-05, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.891 total time=   0.0s\n",
            "[CV 1/5; 113/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 1/5; 113/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.933 total time=   0.0s\n",
            "[CV 2/5; 113/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 2/5; 113/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.925 total time=   0.0s\n",
            "[CV 3/5; 113/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 3/5; 113/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.903 total time=   0.0s\n",
            "[CV 4/5; 113/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 4/5; 113/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.929 total time=   0.0s\n",
            "[CV 5/5; 113/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 5/5; 113/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.914 total time=   0.0s\n",
            "[CV 1/5; 114/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 114/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.840 total time=   0.0s\n",
            "[CV 2/5; 114/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 114/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 3/5; 114/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 114/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.881 total time=   0.0s\n",
            "[CV 4/5; 114/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 114/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.918 total time=   0.0s\n",
            "[CV 5/5; 114/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 114/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.921 total time=   0.0s\n",
            "[CV 1/5; 115/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 115/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.899 total time=   0.0s\n",
            "[CV 2/5; 115/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 115/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.925 total time=   0.0s\n",
            "[CV 3/5; 115/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 115/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.896 total time=   0.0s\n",
            "[CV 4/5; 115/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 115/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.929 total time=   0.0s\n",
            "[CV 5/5; 115/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 115/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.951 total time=   0.0s\n",
            "[CV 1/5; 116/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 116/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 2/5; 116/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 116/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.959 total time=   0.0s\n",
            "[CV 3/5; 116/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 116/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.910 total time=   0.0s\n",
            "[CV 4/5; 116/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 116/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.937 total time=   0.0s\n",
            "[CV 5/5; 116/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 116/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.876 total time=   0.0s\n",
            "[CV 1/5; 117/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 1/5; 117/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 117/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 2/5; 117/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.813 total time=   0.0s\n",
            "[CV 3/5; 117/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 3/5; 117/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.765 total time=   0.0s\n",
            "[CV 4/5; 117/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 4/5; 117/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.851 total time=   0.0s\n",
            "[CV 5/5; 117/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 5/5; 117/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.693 total time=   0.0s\n",
            "[CV 1/5; 118/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 118/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.750 total time=   0.0s\n",
            "[CV 2/5; 118/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 118/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.720 total time=   0.0s\n",
            "[CV 3/5; 118/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 118/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.881 total time=   0.0s\n",
            "[CV 4/5; 118/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 118/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.847 total time=   0.0s\n",
            "[CV 5/5; 118/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 118/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.764 total time=   0.0s\n",
            "[CV 1/5; 119/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 119/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.806 total time=   0.0s\n",
            "[CV 2/5; 119/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 119/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.784 total time=   0.0s\n",
            "[CV 3/5; 119/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 119/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.866 total time=   0.0s\n",
            "[CV 4/5; 119/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 119/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.802 total time=   0.0s\n",
            "[CV 5/5; 119/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 119/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.742 total time=   0.0s\n",
            "[CV 1/5; 120/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 120/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.799 total time=   0.0s\n",
            "[CV 2/5; 120/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 120/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.813 total time=   0.0s\n",
            "[CV 3/5; 120/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 120/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.877 total time=   0.0s\n",
            "[CV 4/5; 120/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 120/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.866 total time=   0.0s\n",
            "[CV 5/5; 120/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 120/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.921 total time=   0.0s\n",
            "[CV 1/5; 121/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 1/5; 121/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.869 total time=   0.0s\n",
            "[CV 2/5; 121/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 2/5; 121/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.884 total time=   0.0s\n",
            "[CV 3/5; 121/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 3/5; 121/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.892 total time=   0.0s\n",
            "[CV 4/5; 121/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 4/5; 121/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.854 total time=   0.0s\n",
            "[CV 5/5; 121/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 5/5; 121/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.783 total time=   0.0s\n",
            "[CV 1/5; 122/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 122/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.832 total time=   0.0s\n",
            "[CV 2/5; 122/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 122/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.832 total time=   0.0s\n",
            "[CV 3/5; 122/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 122/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.840 total time=   0.0s\n",
            "[CV 4/5; 122/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 122/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 122/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 122/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.790 total time=   0.0s\n",
            "[CV 1/5; 123/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 123/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.776 total time=   0.0s\n",
            "[CV 2/5; 123/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 123/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.866 total time=   0.0s\n",
            "[CV 3/5; 123/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 123/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.791 total time=   0.0s\n",
            "[CV 4/5; 123/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 123/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.907 total time=   0.0s\n",
            "[CV 5/5; 123/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 123/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.809 total time=   0.0s\n",
            "[CV 1/5; 124/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 124/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.769 total time=   0.0s\n",
            "[CV 2/5; 124/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 124/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.813 total time=   0.0s\n",
            "[CV 3/5; 124/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 124/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.851 total time=   0.0s\n",
            "[CV 4/5; 124/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 124/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.821 total time=   0.0s\n",
            "[CV 5/5; 124/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 124/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.861 total time=   0.0s\n",
            "[CV 1/5; 125/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 1/5; 125/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.854 total time=   0.0s\n",
            "[CV 2/5; 125/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 2/5; 125/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.896 total time=   0.0s\n",
            "[CV 3/5; 125/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 3/5; 125/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.918 total time=   0.0s\n",
            "[CV 4/5; 125/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 4/5; 125/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.922 total time=   0.0s\n",
            "[CV 5/5; 125/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 5/5; 125/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.880 total time=   0.0s\n",
            "[CV 1/5; 126/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 126/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 2/5; 126/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 126/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.817 total time=   0.0s\n",
            "[CV 3/5; 126/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 126/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.899 total time=   0.0s\n",
            "[CV 4/5; 126/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 126/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.929 total time=   0.0s\n",
            "[CV 5/5; 126/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 126/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.891 total time=   0.0s\n",
            "[CV 1/5; 127/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 127/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.963 total time=   0.0s\n",
            "[CV 2/5; 127/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 127/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.892 total time=   0.0s\n",
            "[CV 3/5; 127/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 127/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.881 total time=   0.0s\n",
            "[CV 4/5; 127/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 127/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.851 total time=   0.0s\n",
            "[CV 5/5; 127/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 127/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 1/5; 128/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 128/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.884 total time=   0.0s\n",
            "[CV 2/5; 128/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 128/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.925 total time=   0.0s\n",
            "[CV 3/5; 128/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 128/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.847 total time=   0.0s\n",
            "[CV 4/5; 128/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 128/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.832 total time=   0.0s\n",
            "[CV 5/5; 128/448] START alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 128/448] END alpha=1e-05, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.876 total time=   0.0s\n",
            "[CV 1/5; 129/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 1/5; 129/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.978 total time=   0.0s\n",
            "[CV 2/5; 129/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 2/5; 129/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.922 total time=   0.0s\n",
            "[CV 3/5; 129/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 3/5; 129/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 129/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 4/5; 129/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.925 total time=   0.0s\n",
            "[CV 5/5; 129/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 5/5; 129/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.910 total time=   0.0s\n",
            "[CV 1/5; 130/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 130/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.933 total time=   0.0s\n",
            "[CV 2/5; 130/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 130/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.981 total time=   0.0s\n",
            "[CV 3/5; 130/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 130/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.918 total time=   0.0s\n",
            "[CV 4/5; 130/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 130/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 5/5; 130/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 130/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.828 total time=   0.0s\n",
            "[CV 1/5; 131/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 131/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.907 total time=   0.0s\n",
            "[CV 2/5; 131/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 131/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.955 total time=   0.0s\n",
            "[CV 3/5; 131/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 131/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.951 total time=   0.0s\n",
            "[CV 4/5; 131/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 131/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 5/5; 131/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 131/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.914 total time=   0.0s\n",
            "[CV 1/5; 132/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 132/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.959 total time=   0.0s\n",
            "[CV 2/5; 132/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 132/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.974 total time=   0.0s\n",
            "[CV 3/5; 132/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 132/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.910 total time=   0.0s\n",
            "[CV 4/5; 132/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 132/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.907 total time=   0.0s\n",
            "[CV 5/5; 132/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 132/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.876 total time=   0.0s\n",
            "[CV 1/5; 133/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 1/5; 133/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.810 total time=   0.0s\n",
            "[CV 2/5; 133/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 2/5; 133/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.765 total time=   0.0s\n",
            "[CV 3/5; 133/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 3/5; 133/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.772 total time=   0.0s\n",
            "[CV 4/5; 133/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 4/5; 133/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.705 total time=   0.0s\n",
            "[CV 5/5; 133/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 5/5; 133/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.824 total time=   0.0s\n",
            "[CV 1/5; 134/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 134/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.892 total time=   0.0s\n",
            "[CV 2/5; 134/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 134/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.802 total time=   0.0s\n",
            "[CV 3/5; 134/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 134/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.840 total time=   0.0s\n",
            "[CV 4/5; 134/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 134/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.731 total time=   0.0s\n",
            "[CV 5/5; 134/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 134/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.764 total time=   0.0s\n",
            "[CV 1/5; 135/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 135/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.813 total time=   0.0s\n",
            "[CV 2/5; 135/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 135/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.743 total time=   0.0s\n",
            "[CV 3/5; 135/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 135/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.765 total time=   0.0s\n",
            "[CV 4/5; 135/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 135/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.784 total time=   0.0s\n",
            "[CV 5/5; 135/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 135/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.749 total time=   0.0s\n",
            "[CV 1/5; 136/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 136/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.817 total time=   0.0s\n",
            "[CV 2/5; 136/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 136/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.765 total time=   0.0s\n",
            "[CV 3/5; 136/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 136/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.806 total time=   0.0s\n",
            "[CV 4/5; 136/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 136/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.828 total time=   0.0s\n",
            "[CV 5/5; 136/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 136/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.854 total time=   0.0s\n",
            "[CV 1/5; 137/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 1/5; 137/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.802 total time=   0.0s\n",
            "[CV 2/5; 137/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 2/5; 137/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.810 total time=   0.0s\n",
            "[CV 3/5; 137/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 3/5; 137/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.840 total time=   0.0s\n",
            "[CV 4/5; 137/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 4/5; 137/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.896 total time=   0.0s\n",
            "[CV 5/5; 137/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 5/5; 137/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.801 total time=   0.0s\n",
            "[CV 1/5; 138/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 138/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.810 total time=   0.0s\n",
            "[CV 2/5; 138/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 138/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.780 total time=   0.0s\n",
            "[CV 3/5; 138/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 138/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.832 total time=   0.0s\n",
            "[CV 4/5; 138/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 138/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.795 total time=   0.0s\n",
            "[CV 5/5; 138/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 138/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.757 total time=   0.0s\n",
            "[CV 1/5; 139/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 139/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.836 total time=   0.0s\n",
            "[CV 2/5; 139/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 139/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.791 total time=   0.0s\n",
            "[CV 3/5; 139/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 139/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.806 total time=   0.0s\n",
            "[CV 4/5; 139/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 139/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.851 total time=   0.0s\n",
            "[CV 5/5; 139/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 139/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.813 total time=   0.0s\n",
            "[CV 1/5; 140/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 140/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.869 total time=   0.0s\n",
            "[CV 2/5; 140/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 140/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.810 total time=   0.0s\n",
            "[CV 3/5; 140/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 140/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.802 total time=   0.0s\n",
            "[CV 4/5; 140/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 140/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.832 total time=   0.0s\n",
            "[CV 5/5; 140/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 140/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.783 total time=   0.0s\n",
            "[CV 1/5; 141/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 1/5; 141/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.907 total time=   0.0s\n",
            "[CV 2/5; 141/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 2/5; 141/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.933 total time=   0.0s\n",
            "[CV 3/5; 141/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 3/5; 141/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.888 total time=   0.0s\n",
            "[CV 4/5; 141/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 4/5; 141/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.881 total time=   0.0s\n",
            "[CV 5/5; 141/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 5/5; 141/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.884 total time=   0.0s\n",
            "[CV 1/5; 142/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 142/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.903 total time=   0.0s\n",
            "[CV 2/5; 142/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 142/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.966 total time=   0.0s\n",
            "[CV 3/5; 142/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 142/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 142/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 142/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.896 total time=   0.0s\n",
            "[CV 5/5; 142/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 142/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.929 total time=   0.0s\n",
            "[CV 1/5; 143/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 143/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.959 total time=   0.0s\n",
            "[CV 2/5; 143/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 143/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.955 total time=   0.0s\n",
            "[CV 3/5; 143/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 143/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.922 total time=   0.0s\n",
            "[CV 4/5; 143/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 143/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.925 total time=   0.0s\n",
            "[CV 5/5; 143/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 143/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.933 total time=   0.0s\n",
            "[CV 1/5; 144/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 144/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.907 total time=   0.0s\n",
            "[CV 2/5; 144/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 144/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 3/5; 144/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 144/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.925 total time=   0.0s\n",
            "[CV 4/5; 144/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 144/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.937 total time=   0.0s\n",
            "[CV 5/5; 144/448] START alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 144/448] END alpha=0.0001, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.906 total time=   0.0s\n",
            "[CV 1/5; 145/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 1/5; 145/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.940 total time=   0.0s\n",
            "[CV 2/5; 145/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 2/5; 145/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.963 total time=   0.0s\n",
            "[CV 3/5; 145/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 3/5; 145/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.951 total time=   0.0s\n",
            "[CV 4/5; 145/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 4/5; 145/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 145/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 5/5; 145/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.966 total time=   0.0s\n",
            "[CV 1/5; 146/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 146/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 2/5; 146/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 146/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.974 total time=   0.0s\n",
            "[CV 3/5; 146/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 146/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 146/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 146/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.955 total time=   0.0s\n",
            "[CV 5/5; 146/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 146/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.966 total time=   0.0s\n",
            "[CV 1/5; 147/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 147/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.959 total time=   0.0s\n",
            "[CV 2/5; 147/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 147/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.966 total time=   0.0s\n",
            "[CV 3/5; 147/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 147/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 4/5; 147/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 147/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.966 total time=   0.0s\n",
            "[CV 5/5; 147/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 147/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.936 total time=   0.0s\n",
            "[CV 1/5; 148/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 148/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.966 total time=   0.0s\n",
            "[CV 2/5; 148/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 148/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.966 total time=   0.0s\n",
            "[CV 3/5; 148/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 148/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 4/5; 148/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 148/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 148/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 148/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.955 total time=   0.0s\n",
            "[CV 1/5; 149/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 1/5; 149/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.769 total time=   0.0s\n",
            "[CV 2/5; 149/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 2/5; 149/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.828 total time=   0.0s\n",
            "[CV 3/5; 149/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 3/5; 149/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.832 total time=   0.0s\n",
            "[CV 4/5; 149/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 4/5; 149/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.881 total time=   0.0s\n",
            "[CV 5/5; 149/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 5/5; 149/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.820 total time=   0.0s\n",
            "[CV 1/5; 150/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 150/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.847 total time=   0.0s\n",
            "[CV 2/5; 150/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 150/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.787 total time=   0.0s\n",
            "[CV 3/5; 150/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 150/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.739 total time=   0.0s\n",
            "[CV 4/5; 150/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 150/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.866 total time=   0.0s\n",
            "[CV 5/5; 150/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 150/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.869 total time=   0.0s\n",
            "[CV 1/5; 151/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 151/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.810 total time=   0.0s\n",
            "[CV 2/5; 151/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 151/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.787 total time=   0.0s\n",
            "[CV 3/5; 151/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 151/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.769 total time=   0.0s\n",
            "[CV 4/5; 151/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 151/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.825 total time=   0.0s\n",
            "[CV 5/5; 151/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 151/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.869 total time=   0.0s\n",
            "[CV 1/5; 152/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 152/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.731 total time=   0.0s\n",
            "[CV 2/5; 152/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 152/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.836 total time=   0.0s\n",
            "[CV 3/5; 152/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 152/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.799 total time=   0.0s\n",
            "[CV 4/5; 152/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 152/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 152/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 152/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.708 total time=   0.0s\n",
            "[CV 1/5; 153/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 1/5; 153/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.836 total time=   0.0s\n",
            "[CV 2/5; 153/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 2/5; 153/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.884 total time=   0.0s\n",
            "[CV 3/5; 153/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 3/5; 153/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.802 total time=   0.0s\n",
            "[CV 4/5; 153/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 4/5; 153/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.817 total time=   0.0s\n",
            "[CV 5/5; 153/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 5/5; 153/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.790 total time=   0.0s\n",
            "[CV 1/5; 154/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 154/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.858 total time=   0.0s\n",
            "[CV 2/5; 154/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 154/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.862 total time=   0.0s\n",
            "[CV 3/5; 154/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 154/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.806 total time=   0.0s\n",
            "[CV 4/5; 154/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 154/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.854 total time=   0.0s\n",
            "[CV 5/5; 154/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 154/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.809 total time=   0.0s\n",
            "[CV 1/5; 155/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 155/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.866 total time=   0.0s\n",
            "[CV 2/5; 155/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 155/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.840 total time=   0.0s\n",
            "[CV 3/5; 155/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 155/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.784 total time=   0.0s\n",
            "[CV 4/5; 155/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 155/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.858 total time=   0.0s\n",
            "[CV 5/5; 155/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 155/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.790 total time=   0.0s\n",
            "[CV 1/5; 156/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 156/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.799 total time=   0.0s\n",
            "[CV 2/5; 156/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 156/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 3/5; 156/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 156/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.847 total time=   0.0s\n",
            "[CV 4/5; 156/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 156/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.922 total time=   0.0s\n",
            "[CV 5/5; 156/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 156/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.884 total time=   0.0s\n",
            "[CV 1/5; 157/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 1/5; 157/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.914 total time=   0.0s\n",
            "[CV 2/5; 157/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 2/5; 157/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.951 total time=   0.0s\n",
            "[CV 3/5; 157/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 3/5; 157/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.914 total time=   0.0s\n",
            "[CV 4/5; 157/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 4/5; 157/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.955 total time=   0.0s\n",
            "[CV 5/5; 157/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 5/5; 157/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.921 total time=   0.0s\n",
            "[CV 1/5; 158/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 158/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.907 total time=   0.0s\n",
            "[CV 2/5; 158/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 158/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.970 total time=   0.0s\n",
            "[CV 3/5; 158/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 158/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.937 total time=   0.0s\n",
            "[CV 4/5; 158/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 158/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.959 total time=   0.0s\n",
            "[CV 5/5; 158/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 158/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.955 total time=   0.0s\n",
            "[CV 1/5; 159/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 159/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 2/5; 159/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 159/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.951 total time=   0.0s\n",
            "[CV 3/5; 159/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 159/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.910 total time=   0.0s\n",
            "[CV 4/5; 159/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 159/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.937 total time=   0.0s\n",
            "[CV 5/5; 159/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 159/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.925 total time=   0.0s\n",
            "[CV 1/5; 160/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 160/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.929 total time=   0.0s\n",
            "[CV 2/5; 160/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 160/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.963 total time=   0.0s\n",
            "[CV 3/5; 160/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 160/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.925 total time=   0.0s\n",
            "[CV 4/5; 160/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 160/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.963 total time=   0.0s\n",
            "[CV 5/5; 160/448] START alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 160/448] END alpha=0.0001, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 1/5; 161/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 1/5; 161/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.929 total time=   0.0s\n",
            "[CV 2/5; 161/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 2/5; 161/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.925 total time=   0.0s\n",
            "[CV 3/5; 161/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 3/5; 161/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.914 total time=   0.0s\n",
            "[CV 4/5; 161/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 4/5; 161/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.899 total time=   0.0s\n",
            "[CV 5/5; 161/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 5/5; 161/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.914 total time=   0.0s\n",
            "[CV 1/5; 162/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 162/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.899 total time=   0.0s\n",
            "[CV 2/5; 162/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 162/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.843 total time=   0.0s\n",
            "[CV 3/5; 162/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 162/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.933 total time=   0.0s\n",
            "[CV 4/5; 162/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 162/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.922 total time=   0.0s\n",
            "[CV 5/5; 162/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 162/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.925 total time=   0.0s\n",
            "[CV 1/5; 163/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 163/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.963 total time=   0.0s\n",
            "[CV 2/5; 163/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 163/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.910 total time=   0.0s\n",
            "[CV 3/5; 163/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 163/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.884 total time=   0.0s\n",
            "[CV 4/5; 163/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 163/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.881 total time=   0.0s\n",
            "[CV 5/5; 163/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 163/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.880 total time=   0.0s\n",
            "[CV 1/5; 164/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 164/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.869 total time=   0.0s\n",
            "[CV 2/5; 164/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 164/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.810 total time=   0.0s\n",
            "[CV 3/5; 164/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 164/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.866 total time=   0.0s\n",
            "[CV 4/5; 164/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 164/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.966 total time=   0.0s\n",
            "[CV 5/5; 164/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 164/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.914 total time=   0.0s\n",
            "[CV 1/5; 165/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 1/5; 165/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.836 total time=   0.0s\n",
            "[CV 2/5; 165/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 2/5; 165/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.862 total time=   0.0s\n",
            "[CV 3/5; 165/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 3/5; 165/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.728 total time=   0.0s\n",
            "[CV 4/5; 165/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 4/5; 165/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.713 total time=   0.0s\n",
            "[CV 5/5; 165/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 5/5; 165/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.820 total time=   0.0s\n",
            "[CV 1/5; 166/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 166/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.802 total time=   0.0s\n",
            "[CV 2/5; 166/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 166/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.720 total time=   0.0s\n",
            "[CV 3/5; 166/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 166/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.776 total time=   0.0s\n",
            "[CV 4/5; 166/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 166/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.854 total time=   0.0s\n",
            "[CV 5/5; 166/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 166/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.805 total time=   0.0s\n",
            "[CV 1/5; 167/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 167/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.728 total time=   0.0s\n",
            "[CV 2/5; 167/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 167/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.776 total time=   0.0s\n",
            "[CV 3/5; 167/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 167/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.746 total time=   0.0s\n",
            "[CV 4/5; 167/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 167/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.743 total time=   0.0s\n",
            "[CV 5/5; 167/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 167/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.824 total time=   0.0s\n",
            "[CV 1/5; 168/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 168/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.843 total time=   0.0s\n",
            "[CV 2/5; 168/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 168/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.858 total time=   0.0s\n",
            "[CV 3/5; 168/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 168/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.784 total time=   0.0s\n",
            "[CV 4/5; 168/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 168/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.836 total time=   0.0s\n",
            "[CV 5/5; 168/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 168/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.876 total time=   0.0s\n",
            "[CV 1/5; 169/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 1/5; 169/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.832 total time=   0.0s\n",
            "[CV 2/5; 169/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 2/5; 169/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.854 total time=   0.0s\n",
            "[CV 3/5; 169/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 3/5; 169/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.776 total time=   0.0s\n",
            "[CV 4/5; 169/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 4/5; 169/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.731 total time=   0.0s\n",
            "[CV 5/5; 169/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 5/5; 169/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.760 total time=   0.0s\n",
            "[CV 1/5; 170/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 170/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.877 total time=   0.0s\n",
            "[CV 2/5; 170/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 170/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.739 total time=   0.0s\n",
            "[CV 3/5; 170/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 170/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.765 total time=   0.0s\n",
            "[CV 4/5; 170/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 170/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.750 total time=   0.0s\n",
            "[CV 5/5; 170/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 170/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.779 total time=   0.0s\n",
            "[CV 1/5; 171/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 171/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.836 total time=   0.0s\n",
            "[CV 2/5; 171/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 171/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.728 total time=   0.0s\n",
            "[CV 3/5; 171/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 171/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.761 total time=   0.0s\n",
            "[CV 4/5; 171/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 171/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.772 total time=   0.0s\n",
            "[CV 5/5; 171/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 171/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.764 total time=   0.0s\n",
            "[CV 1/5; 172/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 172/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.799 total time=   0.0s\n",
            "[CV 2/5; 172/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 172/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.765 total time=   0.0s\n",
            "[CV 3/5; 172/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 172/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.799 total time=   0.0s\n",
            "[CV 4/5; 172/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 172/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.780 total time=   0.0s\n",
            "[CV 5/5; 172/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 172/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.858 total time=   0.0s\n",
            "[CV 1/5; 173/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 1/5; 173/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.914 total time=   0.0s\n",
            "[CV 2/5; 173/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 2/5; 173/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.877 total time=   0.0s\n",
            "[CV 3/5; 173/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 3/5; 173/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.840 total time=   0.0s\n",
            "[CV 4/5; 173/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 4/5; 173/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.970 total time=   0.0s\n",
            "[CV 5/5; 173/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 5/5; 173/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.861 total time=   0.0s\n",
            "[CV 1/5; 174/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 174/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.955 total time=   0.0s\n",
            "[CV 2/5; 174/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 174/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 3/5; 174/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 174/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.925 total time=   0.0s\n",
            "[CV 4/5; 174/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 174/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.892 total time=   0.0s\n",
            "[CV 5/5; 174/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 174/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.914 total time=   0.0s\n",
            "[CV 1/5; 175/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 175/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 2/5; 175/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 175/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.914 total time=   0.0s\n",
            "[CV 3/5; 175/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 175/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.799 total time=   0.0s\n",
            "[CV 4/5; 175/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 175/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.903 total time=   0.0s\n",
            "[CV 5/5; 175/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 175/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 1/5; 176/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 176/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 2/5; 176/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 176/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.802 total time=   0.0s\n",
            "[CV 3/5; 176/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 176/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.918 total time=   0.0s\n",
            "[CV 4/5; 176/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 176/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.907 total time=   0.0s\n",
            "[CV 5/5; 176/448] START alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 176/448] END alpha=0.0001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.910 total time=   0.0s\n",
            "[CV 1/5; 177/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 1/5; 177/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.933 total time=   0.0s\n",
            "[CV 2/5; 177/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 2/5; 177/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.959 total time=   0.0s\n",
            "[CV 3/5; 177/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 3/5; 177/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.929 total time=   0.0s\n",
            "[CV 4/5; 177/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 4/5; 177/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.955 total time=   0.0s\n",
            "[CV 5/5; 177/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 5/5; 177/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.929 total time=   0.0s\n",
            "[CV 1/5; 178/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 178/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.963 total time=   0.0s\n",
            "[CV 2/5; 178/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 178/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.963 total time=   0.0s\n",
            "[CV 3/5; 178/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 178/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.910 total time=   0.0s\n",
            "[CV 4/5; 178/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 178/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.978 total time=   0.0s\n",
            "[CV 5/5; 178/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 178/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.940 total time=   0.0s\n",
            "[CV 1/5; 179/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 179/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.851 total time=   0.0s\n",
            "[CV 2/5; 179/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 179/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.970 total time=   0.0s\n",
            "[CV 3/5; 179/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 179/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.918 total time=   0.0s\n",
            "[CV 4/5; 179/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 179/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 179/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 179/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.944 total time=   0.0s\n",
            "[CV 1/5; 180/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 180/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.963 total time=   0.0s\n",
            "[CV 2/5; 180/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 180/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.937 total time=   0.0s\n",
            "[CV 3/5; 180/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 180/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 180/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 180/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.959 total time=   0.0s\n",
            "[CV 5/5; 180/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 180/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.903 total time=   0.0s\n",
            "[CV 1/5; 181/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 1/5; 181/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.780 total time=   0.0s\n",
            "[CV 2/5; 181/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 2/5; 181/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.746 total time=   0.0s\n",
            "[CV 3/5; 181/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 3/5; 181/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.806 total time=   0.0s\n",
            "[CV 4/5; 181/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 4/5; 181/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.791 total time=   0.0s\n",
            "[CV 5/5; 181/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 5/5; 181/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.801 total time=   0.0s\n",
            "[CV 1/5; 182/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 182/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.776 total time=   0.0s\n",
            "[CV 2/5; 182/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 182/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.795 total time=   0.0s\n",
            "[CV 3/5; 182/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 182/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.802 total time=   0.0s\n",
            "[CV 4/5; 182/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 182/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.806 total time=   0.0s\n",
            "[CV 5/5; 182/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 182/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.787 total time=   0.0s\n",
            "[CV 1/5; 183/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 183/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.810 total time=   0.0s\n",
            "[CV 2/5; 183/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 183/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.795 total time=   0.0s\n",
            "[CV 3/5; 183/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 183/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.754 total time=   0.0s\n",
            "[CV 4/5; 183/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 183/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.825 total time=   0.0s\n",
            "[CV 5/5; 183/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 183/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.846 total time=   0.0s\n",
            "[CV 1/5; 184/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 184/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.720 total time=   0.0s\n",
            "[CV 2/5; 184/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 184/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.776 total time=   0.0s\n",
            "[CV 3/5; 184/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 184/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.746 total time=   0.0s\n",
            "[CV 4/5; 184/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 184/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.772 total time=   0.0s\n",
            "[CV 5/5; 184/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 184/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.839 total time=   0.0s\n",
            "[CV 1/5; 185/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 1/5; 185/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.866 total time=   0.0s\n",
            "[CV 2/5; 185/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 2/5; 185/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.907 total time=   0.0s\n",
            "[CV 3/5; 185/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 3/5; 185/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.881 total time=   0.0s\n",
            "[CV 4/5; 185/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 4/5; 185/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.832 total time=   0.0s\n",
            "[CV 5/5; 185/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 5/5; 185/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.929 total time=   0.0s\n",
            "[CV 1/5; 186/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 186/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.907 total time=   0.0s\n",
            "[CV 2/5; 186/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 186/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.776 total time=   0.0s\n",
            "[CV 3/5; 186/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 186/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.754 total time=   0.0s\n",
            "[CV 4/5; 186/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 186/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.825 total time=   0.0s\n",
            "[CV 5/5; 186/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 186/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.933 total time=   0.0s\n",
            "[CV 1/5; 187/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 187/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.806 total time=   0.0s\n",
            "[CV 2/5; 187/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 187/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.724 total time=   0.0s\n",
            "[CV 3/5; 187/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 187/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.806 total time=   0.0s\n",
            "[CV 4/5; 187/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 187/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.851 total time=   0.0s\n",
            "[CV 5/5; 187/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 187/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.768 total time=   0.0s\n",
            "[CV 1/5; 188/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 188/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.716 total time=   0.0s\n",
            "[CV 2/5; 188/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 188/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.836 total time=   0.0s\n",
            "[CV 3/5; 188/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 188/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.757 total time=   0.0s\n",
            "[CV 4/5; 188/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 188/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.761 total time=   0.0s\n",
            "[CV 5/5; 188/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 188/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.854 total time=   0.0s\n",
            "[CV 1/5; 189/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 1/5; 189/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.966 total time=   0.0s\n",
            "[CV 2/5; 189/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 2/5; 189/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.896 total time=   0.0s\n",
            "[CV 3/5; 189/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 3/5; 189/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.896 total time=   0.0s\n",
            "[CV 4/5; 189/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 4/5; 189/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.940 total time=   0.0s\n",
            "[CV 5/5; 189/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 5/5; 189/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.884 total time=   0.0s\n",
            "[CV 1/5; 190/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 190/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 2/5; 190/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 190/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.940 total time=   0.0s\n",
            "[CV 3/5; 190/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 190/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.903 total time=   0.0s\n",
            "[CV 4/5; 190/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 190/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.884 total time=   0.0s\n",
            "[CV 5/5; 190/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 190/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.921 total time=   0.0s\n",
            "[CV 1/5; 191/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 191/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.914 total time=   0.0s\n",
            "[CV 2/5; 191/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 191/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.944 total time=   0.0s\n",
            "[CV 3/5; 191/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 191/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 4/5; 191/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 191/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.929 total time=   0.0s\n",
            "[CV 5/5; 191/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 191/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.921 total time=   0.0s\n",
            "[CV 1/5; 192/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 192/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.951 total time=   0.0s\n",
            "[CV 2/5; 192/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 192/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.970 total time=   0.0s\n",
            "[CV 3/5; 192/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 192/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 192/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 192/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.918 total time=   0.0s\n",
            "[CV 5/5; 192/448] START alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 192/448] END alpha=0.0001, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.899 total time=   0.0s\n",
            "[CV 1/5; 193/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 1/5; 193/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.922 total time=   0.0s\n",
            "[CV 2/5; 193/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 2/5; 193/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.888 total time=   0.0s\n",
            "[CV 3/5; 193/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 3/5; 193/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.851 total time=   0.0s\n",
            "[CV 4/5; 193/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 4/5; 193/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 193/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 5/5; 193/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.970 total time=   0.0s\n",
            "[CV 1/5; 194/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 194/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.955 total time=   0.0s\n",
            "[CV 2/5; 194/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 194/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.937 total time=   0.0s\n",
            "[CV 3/5; 194/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 194/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.951 total time=   0.0s\n",
            "[CV 4/5; 194/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 194/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 194/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 194/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.921 total time=   0.0s\n",
            "[CV 1/5; 195/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 195/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.955 total time=   0.0s\n",
            "[CV 2/5; 195/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 195/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.914 total time=   0.0s\n",
            "[CV 3/5; 195/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 195/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.899 total time=   0.0s\n",
            "[CV 4/5; 195/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 195/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.925 total time=   0.0s\n",
            "[CV 5/5; 195/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 195/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.944 total time=   0.0s\n",
            "[CV 1/5; 196/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 196/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.959 total time=   0.0s\n",
            "[CV 2/5; 196/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 196/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.963 total time=   0.0s\n",
            "[CV 3/5; 196/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 196/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 196/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 196/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.918 total time=   0.0s\n",
            "[CV 5/5; 196/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 196/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.951 total time=   0.0s\n",
            "[CV 1/5; 197/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 1/5; 197/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.840 total time=   0.0s\n",
            "[CV 2/5; 197/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 2/5; 197/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.832 total time=   0.0s\n",
            "[CV 3/5; 197/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 3/5; 197/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.802 total time=   0.0s\n",
            "[CV 4/5; 197/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 4/5; 197/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.735 total time=   0.0s\n",
            "[CV 5/5; 197/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 5/5; 197/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.757 total time=   0.0s\n",
            "[CV 1/5; 198/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 198/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.776 total time=   0.0s\n",
            "[CV 2/5; 198/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 198/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.757 total time=   0.0s\n",
            "[CV 3/5; 198/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 198/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.675 total time=   0.0s\n",
            "[CV 4/5; 198/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 198/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.750 total time=   0.0s\n",
            "[CV 5/5; 198/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 198/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.760 total time=   0.0s\n",
            "[CV 1/5; 199/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 199/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.817 total time=   0.0s\n",
            "[CV 2/5; 199/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 199/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.720 total time=   0.0s\n",
            "[CV 3/5; 199/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 199/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.720 total time=   0.0s\n",
            "[CV 4/5; 199/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 199/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.832 total time=   0.0s\n",
            "[CV 5/5; 199/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 199/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.813 total time=   0.0s\n",
            "[CV 1/5; 200/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 200/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.780 total time=   0.0s\n",
            "[CV 2/5; 200/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 200/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.731 total time=   0.0s\n",
            "[CV 3/5; 200/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 200/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.828 total time=   0.0s\n",
            "[CV 4/5; 200/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 200/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.795 total time=   0.0s\n",
            "[CV 5/5; 200/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 200/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.775 total time=   0.0s\n",
            "[CV 1/5; 201/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 1/5; 201/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.761 total time=   0.0s\n",
            "[CV 2/5; 201/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 2/5; 201/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.840 total time=   0.0s\n",
            "[CV 3/5; 201/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 3/5; 201/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.847 total time=   0.0s\n",
            "[CV 4/5; 201/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 4/5; 201/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.817 total time=   0.0s\n",
            "[CV 5/5; 201/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 5/5; 201/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.880 total time=   0.0s\n",
            "[CV 1/5; 202/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 202/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.787 total time=   0.0s\n",
            "[CV 2/5; 202/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 202/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.750 total time=   0.0s\n",
            "[CV 3/5; 202/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 202/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.731 total time=   0.0s\n",
            "[CV 4/5; 202/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 202/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.806 total time=   0.0s\n",
            "[CV 5/5; 202/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 202/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.824 total time=   0.0s\n",
            "[CV 1/5; 203/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 203/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.784 total time=   0.0s\n",
            "[CV 2/5; 203/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 203/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.799 total time=   0.0s\n",
            "[CV 3/5; 203/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 203/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.854 total time=   0.0s\n",
            "[CV 4/5; 203/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 203/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.828 total time=   0.0s\n",
            "[CV 5/5; 203/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 203/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.805 total time=   0.0s\n",
            "[CV 1/5; 204/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 204/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.836 total time=   0.0s\n",
            "[CV 2/5; 204/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 204/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.750 total time=   0.0s\n",
            "[CV 3/5; 204/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 204/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.813 total time=   0.0s\n",
            "[CV 4/5; 204/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 204/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.791 total time=   0.0s\n",
            "[CV 5/5; 204/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 204/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.839 total time=   0.0s\n",
            "[CV 1/5; 205/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 1/5; 205/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.929 total time=   0.0s\n",
            "[CV 2/5; 205/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 2/5; 205/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.933 total time=   0.0s\n",
            "[CV 3/5; 205/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 3/5; 205/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.918 total time=   0.0s\n",
            "[CV 4/5; 205/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 4/5; 205/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.955 total time=   0.0s\n",
            "[CV 5/5; 205/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 5/5; 205/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.921 total time=   0.0s\n",
            "[CV 1/5; 206/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 206/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.907 total time=   0.0s\n",
            "[CV 2/5; 206/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 206/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.955 total time=   0.0s\n",
            "[CV 3/5; 206/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 206/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.907 total time=   0.0s\n",
            "[CV 4/5; 206/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 206/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.910 total time=   0.0s\n",
            "[CV 5/5; 206/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 206/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.918 total time=   0.0s\n",
            "[CV 1/5; 207/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 207/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.955 total time=   0.0s\n",
            "[CV 2/5; 207/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 207/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 3/5; 207/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 207/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.910 total time=   0.0s\n",
            "[CV 4/5; 207/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 207/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.929 total time=   0.0s\n",
            "[CV 5/5; 207/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 207/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.888 total time=   0.0s\n",
            "[CV 1/5; 208/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 208/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.869 total time=   0.0s\n",
            "[CV 2/5; 208/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 208/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.959 total time=   0.0s\n",
            "[CV 3/5; 208/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 208/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.914 total time=   0.0s\n",
            "[CV 4/5; 208/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 208/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.929 total time=   0.0s\n",
            "[CV 5/5; 208/448] START alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 208/448] END alpha=0.001, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.929 total time=   0.0s\n",
            "[CV 1/5; 209/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 1/5; 209/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.948 total time=   0.0s\n",
            "[CV 2/5; 209/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 2/5; 209/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.963 total time=   0.0s\n",
            "[CV 3/5; 209/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 3/5; 209/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 209/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 4/5; 209/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.940 total time=   0.0s\n",
            "[CV 5/5; 209/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 5/5; 209/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.921 total time=   0.0s\n",
            "[CV 1/5; 210/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 210/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 2/5; 210/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 210/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.959 total time=   0.0s\n",
            "[CV 3/5; 210/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 210/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.937 total time=   0.0s\n",
            "[CV 4/5; 210/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 210/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 5/5; 210/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 210/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.910 total time=   0.0s\n",
            "[CV 1/5; 211/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 211/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 2/5; 211/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 211/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.978 total time=   0.0s\n",
            "[CV 3/5; 211/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 211/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.963 total time=   0.0s\n",
            "[CV 4/5; 211/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 211/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.951 total time=   0.0s\n",
            "[CV 5/5; 211/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 211/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.921 total time=   0.0s\n",
            "[CV 1/5; 212/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 212/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.970 total time=   0.0s\n",
            "[CV 2/5; 212/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 212/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 3/5; 212/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 212/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.929 total time=   0.0s\n",
            "[CV 4/5; 212/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 212/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 5/5; 212/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 212/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 1/5; 213/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 1/5; 213/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.866 total time=   0.0s\n",
            "[CV 2/5; 213/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 2/5; 213/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.772 total time=   0.0s\n",
            "[CV 3/5; 213/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 3/5; 213/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.847 total time=   0.0s\n",
            "[CV 4/5; 213/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 4/5; 213/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.799 total time=   0.0s\n",
            "[CV 5/5; 213/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 5/5; 213/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 214/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 214/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.825 total time=   0.0s\n",
            "[CV 2/5; 214/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 214/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.802 total time=   0.0s\n",
            "[CV 3/5; 214/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 214/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.832 total time=   0.0s\n",
            "[CV 4/5; 214/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 214/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.757 total time=   0.0s\n",
            "[CV 5/5; 214/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 214/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.764 total time=   0.0s\n",
            "[CV 1/5; 215/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 215/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.817 total time=   0.0s\n",
            "[CV 2/5; 215/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 215/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.761 total time=   0.0s\n",
            "[CV 3/5; 215/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 215/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.795 total time=   0.0s\n",
            "[CV 4/5; 215/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 215/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.780 total time=   0.0s\n",
            "[CV 5/5; 215/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 215/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.749 total time=   0.0s\n",
            "[CV 1/5; 216/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 216/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.750 total time=   0.0s\n",
            "[CV 2/5; 216/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 216/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.784 total time=   0.0s\n",
            "[CV 3/5; 216/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 216/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.746 total time=   0.0s\n",
            "[CV 4/5; 216/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 216/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.825 total time=   0.0s\n",
            "[CV 5/5; 216/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 216/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.854 total time=   0.0s\n",
            "[CV 1/5; 217/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 1/5; 217/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.806 total time=   0.0s\n",
            "[CV 2/5; 217/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 2/5; 217/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.795 total time=   0.0s\n",
            "[CV 3/5; 217/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 3/5; 217/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.787 total time=   0.0s\n",
            "[CV 4/5; 217/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 4/5; 217/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.769 total time=   0.0s\n",
            "[CV 5/5; 217/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 5/5; 217/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.794 total time=   0.0s\n",
            "[CV 1/5; 218/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 218/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.851 total time=   0.0s\n",
            "[CV 2/5; 218/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 218/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.817 total time=   0.0s\n",
            "[CV 3/5; 218/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 218/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.757 total time=   0.0s\n",
            "[CV 4/5; 218/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 218/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.821 total time=   0.0s\n",
            "[CV 5/5; 218/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 218/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.805 total time=   0.0s\n",
            "[CV 1/5; 219/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 219/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.761 total time=   0.0s\n",
            "[CV 2/5; 219/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 219/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.795 total time=   0.0s\n",
            "[CV 3/5; 219/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 219/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.873 total time=   0.0s\n",
            "[CV 4/5; 219/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 219/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.854 total time=   0.0s\n",
            "[CV 5/5; 219/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 219/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.884 total time=   0.0s\n",
            "[CV 1/5; 220/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 220/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.840 total time=   0.0s\n",
            "[CV 2/5; 220/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 220/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.799 total time=   0.0s\n",
            "[CV 3/5; 220/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 220/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.795 total time=   0.0s\n",
            "[CV 4/5; 220/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 220/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.743 total time=   0.0s\n",
            "[CV 5/5; 220/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 220/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.813 total time=   0.0s\n",
            "[CV 1/5; 221/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 1/5; 221/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.955 total time=   0.0s\n",
            "[CV 2/5; 221/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 2/5; 221/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.959 total time=   0.0s\n",
            "[CV 3/5; 221/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 3/5; 221/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.918 total time=   0.0s\n",
            "[CV 4/5; 221/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 4/5; 221/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.944 total time=   0.0s\n",
            "[CV 5/5; 221/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 5/5; 221/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.906 total time=   0.0s\n",
            "[CV 1/5; 222/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 222/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.951 total time=   0.0s\n",
            "[CV 2/5; 222/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 222/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.966 total time=   0.0s\n",
            "[CV 3/5; 222/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 222/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 222/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 222/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 5/5; 222/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 222/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.914 total time=   0.0s\n",
            "[CV 1/5; 223/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 223/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.959 total time=   0.0s\n",
            "[CV 2/5; 223/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 223/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.951 total time=   0.0s\n",
            "[CV 3/5; 223/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 223/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 4/5; 223/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 223/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.925 total time=   0.0s\n",
            "[CV 5/5; 223/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 223/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.944 total time=   0.0s\n",
            "[CV 1/5; 224/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 224/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.978 total time=   0.0s\n",
            "[CV 2/5; 224/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 224/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.951 total time=   0.0s\n",
            "[CV 3/5; 224/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 224/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 224/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 224/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.933 total time=   0.0s\n",
            "[CV 5/5; 224/448] START alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 224/448] END alpha=0.001, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.933 total time=   0.0s\n",
            "[CV 1/5; 225/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 1/5; 225/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.970 total time=   0.0s\n",
            "[CV 2/5; 225/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 2/5; 225/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.963 total time=   0.0s\n",
            "[CV 3/5; 225/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 3/5; 225/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.951 total time=   0.0s\n",
            "[CV 4/5; 225/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 4/5; 225/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 225/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 5/5; 225/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.910 total time=   0.0s\n",
            "[CV 1/5; 226/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 226/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.955 total time=   0.0s\n",
            "[CV 2/5; 226/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 226/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.970 total time=   0.0s\n",
            "[CV 3/5; 226/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 226/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.925 total time=   0.0s\n",
            "[CV 4/5; 226/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 226/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.907 total time=   0.0s\n",
            "[CV 5/5; 226/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 226/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 1/5; 227/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 227/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 2/5; 227/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 227/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.970 total time=   0.0s\n",
            "[CV 3/5; 227/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 227/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 227/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 227/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.959 total time=   0.0s\n",
            "[CV 5/5; 227/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 227/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 228/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 228/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 2/5; 228/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 228/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.981 total time=   0.0s\n",
            "[CV 3/5; 228/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 228/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.918 total time=   0.0s\n",
            "[CV 4/5; 228/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 228/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 228/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 228/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.921 total time=   0.0s\n",
            "[CV 1/5; 229/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 1/5; 229/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.828 total time=   0.0s\n",
            "[CV 2/5; 229/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 2/5; 229/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.679 total time=   0.0s\n",
            "[CV 3/5; 229/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 3/5; 229/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.806 total time=   0.0s\n",
            "[CV 4/5; 229/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 4/5; 229/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 229/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 5/5; 229/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.876 total time=   0.0s\n",
            "[CV 1/5; 230/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 230/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.951 total time=   0.0s\n",
            "[CV 2/5; 230/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 230/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.791 total time=   0.0s\n",
            "[CV 3/5; 230/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 230/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.851 total time=   0.0s\n",
            "[CV 4/5; 230/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 230/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.784 total time=   0.0s\n",
            "[CV 5/5; 230/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 230/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.712 total time=   0.0s\n",
            "[CV 1/5; 231/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 231/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.955 total time=   0.0s\n",
            "[CV 2/5; 231/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 231/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.776 total time=   0.0s\n",
            "[CV 3/5; 231/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 231/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.854 total time=   0.0s\n",
            "[CV 4/5; 231/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 231/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.847 total time=   0.0s\n",
            "[CV 5/5; 231/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 231/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.693 total time=   0.0s\n",
            "[CV 1/5; 232/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 232/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.903 total time=   0.0s\n",
            "[CV 2/5; 232/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 232/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.821 total time=   0.0s\n",
            "[CV 3/5; 232/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 232/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.769 total time=   0.0s\n",
            "[CV 4/5; 232/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 232/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.884 total time=   0.0s\n",
            "[CV 5/5; 232/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 232/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.884 total time=   0.0s\n",
            "[CV 1/5; 233/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 1/5; 233/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.918 total time=   0.0s\n",
            "[CV 2/5; 233/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 2/5; 233/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.799 total time=   0.0s\n",
            "[CV 3/5; 233/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 3/5; 233/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.907 total time=   0.0s\n",
            "[CV 4/5; 233/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 4/5; 233/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.825 total time=   0.0s\n",
            "[CV 5/5; 233/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 5/5; 233/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.712 total time=   0.0s\n",
            "[CV 1/5; 234/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 234/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.966 total time=   0.0s\n",
            "[CV 2/5; 234/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 234/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.646 total time=   0.0s\n",
            "[CV 3/5; 234/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 234/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.761 total time=   0.0s\n",
            "[CV 4/5; 234/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 234/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.757 total time=   0.0s\n",
            "[CV 5/5; 234/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 234/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.873 total time=   0.0s\n",
            "[CV 1/5; 235/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 235/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.937 total time=   0.0s\n",
            "[CV 2/5; 235/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 235/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.746 total time=   0.0s\n",
            "[CV 3/5; 235/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 235/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.828 total time=   0.0s\n",
            "[CV 4/5; 235/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 235/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.784 total time=   0.0s\n",
            "[CV 5/5; 235/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 235/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.865 total time=   0.0s\n",
            "[CV 1/5; 236/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 236/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 2/5; 236/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 236/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.821 total time=   0.0s\n",
            "[CV 3/5; 236/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 236/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.769 total time=   0.0s\n",
            "[CV 4/5; 236/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 236/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.813 total time=   0.0s\n",
            "[CV 5/5; 236/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 236/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.820 total time=   0.0s\n",
            "[CV 1/5; 237/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 1/5; 237/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.948 total time=   0.0s\n",
            "[CV 2/5; 237/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 2/5; 237/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.918 total time=   0.0s\n",
            "[CV 3/5; 237/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 3/5; 237/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.884 total time=   0.0s\n",
            "[CV 4/5; 237/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 4/5; 237/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.963 total time=   0.0s\n",
            "[CV 5/5; 237/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 5/5; 237/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.933 total time=   0.0s\n",
            "[CV 1/5; 238/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 238/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.959 total time=   0.0s\n",
            "[CV 2/5; 238/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 238/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.963 total time=   0.0s\n",
            "[CV 3/5; 238/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 238/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.877 total time=   0.0s\n",
            "[CV 4/5; 238/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 238/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.903 total time=   0.0s\n",
            "[CV 5/5; 238/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 238/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.925 total time=   0.0s\n",
            "[CV 1/5; 239/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 239/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.951 total time=   0.0s\n",
            "[CV 2/5; 239/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 239/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.963 total time=   0.0s\n",
            "[CV 3/5; 239/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 239/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 239/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 239/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.959 total time=   0.0s\n",
            "[CV 5/5; 239/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 239/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.936 total time=   0.0s\n",
            "[CV 1/5; 240/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 240/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.963 total time=   0.0s\n",
            "[CV 2/5; 240/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 240/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.970 total time=   0.0s\n",
            "[CV 3/5; 240/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 240/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 240/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 240/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.959 total time=   0.0s\n",
            "[CV 5/5; 240/448] START alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 240/448] END alpha=0.001, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.888 total time=   0.0s\n",
            "[CV 1/5; 241/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 1/5; 241/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.978 total time=   0.0s\n",
            "[CV 2/5; 241/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 2/5; 241/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.981 total time=   0.0s\n",
            "[CV 3/5; 241/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 3/5; 241/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.963 total time=   0.0s\n",
            "[CV 4/5; 241/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 4/5; 241/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.951 total time=   0.0s\n",
            "[CV 5/5; 241/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 5/5; 241/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.966 total time=   0.0s\n",
            "[CV 1/5; 242/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 242/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.996 total time=   0.0s\n",
            "[CV 2/5; 242/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 242/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.985 total time=   0.0s\n",
            "[CV 3/5; 242/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 242/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.925 total time=   0.0s\n",
            "[CV 4/5; 242/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 242/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.974 total time=   0.0s\n",
            "[CV 5/5; 242/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 242/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.978 total time=   0.0s\n",
            "[CV 1/5; 243/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 243/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.974 total time=   0.0s\n",
            "[CV 2/5; 243/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 243/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.985 total time=   0.0s\n",
            "[CV 3/5; 243/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 243/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 4/5; 243/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 243/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.929 total time=   0.0s\n",
            "[CV 5/5; 243/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 243/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.955 total time=   0.0s\n",
            "[CV 1/5; 244/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 244/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.963 total time=   0.0s\n",
            "[CV 2/5; 244/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 244/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.985 total time=   0.0s\n",
            "[CV 3/5; 244/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 244/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.963 total time=   0.0s\n",
            "[CV 4/5; 244/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 244/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.981 total time=   0.0s\n",
            "[CV 5/5; 244/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 244/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.970 total time=   0.0s\n",
            "[CV 1/5; 245/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 1/5; 245/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.828 total time=   0.0s\n",
            "[CV 2/5; 245/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 2/5; 245/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.675 total time=   0.0s\n",
            "[CV 3/5; 245/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 3/5; 245/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.754 total time=   0.0s\n",
            "[CV 4/5; 245/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 4/5; 245/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.836 total time=   0.0s\n",
            "[CV 5/5; 245/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 5/5; 245/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.891 total time=   0.0s\n",
            "[CV 1/5; 246/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 246/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.709 total time=   0.0s\n",
            "[CV 2/5; 246/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 246/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.869 total time=   0.0s\n",
            "[CV 3/5; 246/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 246/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.836 total time=   0.0s\n",
            "[CV 4/5; 246/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 246/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.910 total time=   0.0s\n",
            "[CV 5/5; 246/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 246/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.831 total time=   0.0s\n",
            "[CV 1/5; 247/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 247/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.869 total time=   0.0s\n",
            "[CV 2/5; 247/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 247/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.806 total time=   0.0s\n",
            "[CV 3/5; 247/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 247/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.813 total time=   0.0s\n",
            "[CV 4/5; 247/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 247/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.825 total time=   0.0s\n",
            "[CV 5/5; 247/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 247/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.689 total time=   0.0s\n",
            "[CV 1/5; 248/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 248/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.806 total time=   0.0s\n",
            "[CV 2/5; 248/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 248/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.854 total time=   0.0s\n",
            "[CV 3/5; 248/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 248/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.787 total time=   0.0s\n",
            "[CV 4/5; 248/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 248/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.802 total time=   0.0s\n",
            "[CV 5/5; 248/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 248/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 249/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 1/5; 249/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.817 total time=   0.0s\n",
            "[CV 2/5; 249/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 2/5; 249/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.810 total time=   0.0s\n",
            "[CV 3/5; 249/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 3/5; 249/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.862 total time=   0.0s\n",
            "[CV 4/5; 249/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 4/5; 249/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.866 total time=   0.0s\n",
            "[CV 5/5; 249/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 5/5; 249/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.783 total time=   0.0s\n",
            "[CV 1/5; 250/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 250/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 250/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 250/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.810 total time=   0.0s\n",
            "[CV 3/5; 250/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 250/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.858 total time=   0.0s\n",
            "[CV 4/5; 250/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 250/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.951 total time=   0.0s\n",
            "[CV 5/5; 250/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 250/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.850 total time=   0.0s\n",
            "[CV 1/5; 251/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 251/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.899 total time=   0.0s\n",
            "[CV 2/5; 251/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 251/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.817 total time=   0.0s\n",
            "[CV 3/5; 251/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 251/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.828 total time=   0.0s\n",
            "[CV 4/5; 251/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 251/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.866 total time=   0.0s\n",
            "[CV 5/5; 251/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 251/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.850 total time=   0.0s\n",
            "[CV 1/5; 252/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 252/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.866 total time=   0.0s\n",
            "[CV 2/5; 252/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 252/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.910 total time=   0.0s\n",
            "[CV 3/5; 252/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 252/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.896 total time=   0.0s\n",
            "[CV 4/5; 252/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 252/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.821 total time=   0.0s\n",
            "[CV 5/5; 252/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 252/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.835 total time=   0.0s\n",
            "[CV 1/5; 253/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 1/5; 253/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.966 total time=   0.0s\n",
            "[CV 2/5; 253/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 2/5; 253/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.944 total time=   0.0s\n",
            "[CV 3/5; 253/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 3/5; 253/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.970 total time=   0.0s\n",
            "[CV 4/5; 253/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 4/5; 253/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.951 total time=   0.0s\n",
            "[CV 5/5; 253/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 5/5; 253/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.921 total time=   0.0s\n",
            "[CV 1/5; 254/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 254/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.959 total time=   0.0s\n",
            "[CV 2/5; 254/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 254/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.955 total time=   0.0s\n",
            "[CV 3/5; 254/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 254/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 254/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 254/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.951 total time=   0.0s\n",
            "[CV 5/5; 254/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 254/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.944 total time=   0.0s\n",
            "[CV 1/5; 255/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 255/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 2/5; 255/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 255/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.937 total time=   0.0s\n",
            "[CV 3/5; 255/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 255/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.937 total time=   0.0s\n",
            "[CV 4/5; 255/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 255/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.933 total time=   0.0s\n",
            "[CV 5/5; 255/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 255/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.936 total time=   0.0s\n",
            "[CV 1/5; 256/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 256/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.933 total time=   0.0s\n",
            "[CV 2/5; 256/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 256/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.963 total time=   0.0s\n",
            "[CV 3/5; 256/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 256/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.929 total time=   0.0s\n",
            "[CV 4/5; 256/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 256/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.959 total time=   0.0s\n",
            "[CV 5/5; 256/448] START alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 256/448] END alpha=0.001, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.936 total time=   0.0s\n",
            "[CV 1/5; 257/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 1/5; 257/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.780 total time=   0.0s\n",
            "[CV 2/5; 257/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 2/5; 257/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.735 total time=   0.0s\n",
            "[CV 3/5; 257/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 3/5; 257/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.772 total time=   0.0s\n",
            "[CV 4/5; 257/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 4/5; 257/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.791 total time=   0.0s\n",
            "[CV 5/5; 257/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 5/5; 257/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.760 total time=   0.0s\n",
            "[CV 1/5; 258/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 258/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.817 total time=   0.0s\n",
            "[CV 2/5; 258/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 258/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.716 total time=   0.0s\n",
            "[CV 3/5; 258/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 258/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.784 total time=   0.0s\n",
            "[CV 4/5; 258/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 258/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.802 total time=   0.0s\n",
            "[CV 5/5; 258/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 258/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.779 total time=   0.0s\n",
            "[CV 1/5; 259/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 259/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.791 total time=   0.0s\n",
            "[CV 2/5; 259/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 259/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.743 total time=   0.0s\n",
            "[CV 3/5; 259/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 259/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.780 total time=   0.0s\n",
            "[CV 4/5; 259/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 259/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.799 total time=   0.0s\n",
            "[CV 5/5; 259/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 259/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.779 total time=   0.0s\n",
            "[CV 1/5; 260/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 260/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.765 total time=   0.0s\n",
            "[CV 2/5; 260/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 260/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.754 total time=   0.0s\n",
            "[CV 3/5; 260/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 260/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.784 total time=   0.0s\n",
            "[CV 4/5; 260/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 260/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.817 total time=   0.0s\n",
            "[CV 5/5; 260/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 260/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.764 total time=   0.0s\n",
            "[CV 1/5; 261/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 1/5; 261/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.664 total time=   0.0s\n",
            "[CV 2/5; 261/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 2/5; 261/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.634 total time=   0.0s\n",
            "[CV 3/5; 261/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 3/5; 261/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.649 total time=   0.0s\n",
            "[CV 4/5; 261/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 4/5; 261/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.634 total time=   0.0s\n",
            "[CV 5/5; 261/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 5/5; 261/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.693 total time=   0.0s\n",
            "[CV 1/5; 262/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 262/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.634 total time=   0.0s\n",
            "[CV 2/5; 262/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 262/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.604 total time=   0.0s\n",
            "[CV 3/5; 262/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 262/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.694 total time=   0.0s\n",
            "[CV 4/5; 262/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 262/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.698 total time=   0.0s\n",
            "[CV 5/5; 262/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 262/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.723 total time=   0.0s\n",
            "[CV 1/5; 263/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 263/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.619 total time=   0.0s\n",
            "[CV 2/5; 263/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 263/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.672 total time=   0.0s\n",
            "[CV 3/5; 263/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 263/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.728 total time=   0.0s\n",
            "[CV 4/5; 263/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 263/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.653 total time=   0.0s\n",
            "[CV 5/5; 263/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 263/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.685 total time=   0.0s\n",
            "[CV 1/5; 264/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 264/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.631 total time=   0.0s\n",
            "[CV 2/5; 264/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 264/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.646 total time=   0.0s\n",
            "[CV 3/5; 264/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 264/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.683 total time=   0.0s\n",
            "[CV 4/5; 264/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 264/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.631 total time=   0.0s\n",
            "[CV 5/5; 264/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 264/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.734 total time=   0.0s\n",
            "[CV 1/5; 265/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 1/5; 265/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.660 total time=   0.0s\n",
            "[CV 2/5; 265/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 2/5; 265/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.660 total time=   0.0s\n",
            "[CV 3/5; 265/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 3/5; 265/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.690 total time=   0.0s\n",
            "[CV 4/5; 265/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 4/5; 265/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.660 total time=   0.0s\n",
            "[CV 5/5; 265/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 5/5; 265/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.659 total time=   0.0s\n",
            "[CV 1/5; 266/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 266/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.675 total time=   0.0s\n",
            "[CV 2/5; 266/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 266/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.627 total time=   0.0s\n",
            "[CV 3/5; 266/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 266/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.660 total time=   0.0s\n",
            "[CV 4/5; 266/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 266/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.660 total time=   0.0s\n",
            "[CV 5/5; 266/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 266/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.704 total time=   0.0s\n",
            "[CV 1/5; 267/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 267/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.705 total time=   0.0s\n",
            "[CV 2/5; 267/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 267/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.653 total time=   0.0s\n",
            "[CV 3/5; 267/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 267/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.698 total time=   0.0s\n",
            "[CV 4/5; 267/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 267/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.657 total time=   0.0s\n",
            "[CV 5/5; 267/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 267/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.742 total time=   0.0s\n",
            "[CV 1/5; 268/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 268/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.687 total time=   0.0s\n",
            "[CV 2/5; 268/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 268/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.612 total time=   0.0s\n",
            "[CV 3/5; 268/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 268/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.709 total time=   0.0s\n",
            "[CV 4/5; 268/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 268/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.653 total time=   0.0s\n",
            "[CV 5/5; 268/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 268/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.670 total time=   0.0s\n",
            "[CV 1/5; 269/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 1/5; 269/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.877 total time=   0.0s\n",
            "[CV 2/5; 269/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 2/5; 269/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.877 total time=   0.0s\n",
            "[CV 3/5; 269/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 3/5; 269/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.858 total time=   0.0s\n",
            "[CV 4/5; 269/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 4/5; 269/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.843 total time=   0.0s\n",
            "[CV 5/5; 269/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 5/5; 269/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.839 total time=   0.0s\n",
            "[CV 1/5; 270/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 270/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.888 total time=   0.0s\n",
            "[CV 2/5; 270/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 270/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.881 total time=   0.0s\n",
            "[CV 3/5; 270/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 270/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.858 total time=   0.0s\n",
            "[CV 4/5; 270/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 270/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.832 total time=   0.0s\n",
            "[CV 5/5; 270/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 270/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.873 total time=   0.0s\n",
            "[CV 1/5; 271/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 271/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.884 total time=   0.0s\n",
            "[CV 2/5; 271/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 271/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.843 total time=   0.0s\n",
            "[CV 3/5; 271/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 271/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.854 total time=   0.0s\n",
            "[CV 4/5; 271/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 271/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.858 total time=   0.0s\n",
            "[CV 5/5; 271/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 271/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.861 total time=   0.0s\n",
            "[CV 1/5; 272/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 272/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.881 total time=   0.0s\n",
            "[CV 2/5; 272/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 272/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.854 total time=   0.0s\n",
            "[CV 3/5; 272/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 272/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.858 total time=   0.0s\n",
            "[CV 4/5; 272/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 272/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.836 total time=   0.0s\n",
            "[CV 5/5; 272/448] START alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 272/448] END alpha=0.01, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.861 total time=   0.0s\n",
            "[CV 1/5; 273/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 1/5; 273/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.869 total time=   0.0s\n",
            "[CV 2/5; 273/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 2/5; 273/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.821 total time=   0.0s\n",
            "[CV 3/5; 273/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 3/5; 273/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.862 total time=   0.0s\n",
            "[CV 4/5; 273/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 4/5; 273/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.877 total time=   0.0s\n",
            "[CV 5/5; 273/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 5/5; 273/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.861 total time=   0.0s\n",
            "[CV 1/5; 274/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 274/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.858 total time=   0.0s\n",
            "[CV 2/5; 274/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 274/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.817 total time=   0.0s\n",
            "[CV 3/5; 274/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 274/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.821 total time=   0.0s\n",
            "[CV 4/5; 274/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 274/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.881 total time=   0.0s\n",
            "[CV 5/5; 274/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 274/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.865 total time=   0.0s\n",
            "[CV 1/5; 275/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 275/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.869 total time=   0.0s\n",
            "[CV 2/5; 275/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 275/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.825 total time=   0.0s\n",
            "[CV 3/5; 275/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 275/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.851 total time=   0.0s\n",
            "[CV 4/5; 275/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 275/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.899 total time=   0.0s\n",
            "[CV 5/5; 275/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 275/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.861 total time=   0.0s\n",
            "[CV 1/5; 276/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 276/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.858 total time=   0.0s\n",
            "[CV 2/5; 276/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 276/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.817 total time=   0.0s\n",
            "[CV 3/5; 276/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 276/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.840 total time=   0.0s\n",
            "[CV 4/5; 276/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 276/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.899 total time=   0.0s\n",
            "[CV 5/5; 276/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 276/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.854 total time=   0.0s\n",
            "[CV 1/5; 277/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 1/5; 277/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.724 total time=   0.0s\n",
            "[CV 2/5; 277/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 2/5; 277/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.664 total time=   0.0s\n",
            "[CV 3/5; 277/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 3/5; 277/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.657 total time=   0.0s\n",
            "[CV 4/5; 277/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 4/5; 277/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.668 total time=   0.0s\n",
            "[CV 5/5; 277/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 5/5; 277/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.712 total time=   0.0s\n",
            "[CV 1/5; 278/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 278/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.716 total time=   0.0s\n",
            "[CV 2/5; 278/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 278/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.683 total time=   0.0s\n",
            "[CV 3/5; 278/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 278/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.638 total time=   0.0s\n",
            "[CV 4/5; 278/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 278/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.701 total time=   0.0s\n",
            "[CV 5/5; 278/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 278/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.678 total time=   0.0s\n",
            "[CV 1/5; 279/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 279/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.690 total time=   0.0s\n",
            "[CV 2/5; 279/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 279/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.664 total time=   0.0s\n",
            "[CV 3/5; 279/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 279/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.724 total time=   0.0s\n",
            "[CV 4/5; 279/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 279/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.679 total time=   0.0s\n",
            "[CV 5/5; 279/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 279/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.674 total time=   0.0s\n",
            "[CV 1/5; 280/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 280/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.679 total time=   0.0s\n",
            "[CV 2/5; 280/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 280/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.672 total time=   0.0s\n",
            "[CV 3/5; 280/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 280/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.687 total time=   0.0s\n",
            "[CV 4/5; 280/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 280/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.657 total time=   0.0s\n",
            "[CV 5/5; 280/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 280/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.693 total time=   0.0s\n",
            "[CV 1/5; 281/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 1/5; 281/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.660 total time=   0.0s\n",
            "[CV 2/5; 281/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 2/5; 281/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.664 total time=   0.0s\n",
            "[CV 3/5; 281/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 3/5; 281/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.728 total time=   0.0s\n",
            "[CV 4/5; 281/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 4/5; 281/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.709 total time=   0.0s\n",
            "[CV 5/5; 281/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 5/5; 281/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.730 total time=   0.0s\n",
            "[CV 1/5; 282/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 282/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.649 total time=   0.0s\n",
            "[CV 2/5; 282/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 282/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.720 total time=   0.0s\n",
            "[CV 3/5; 282/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 282/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.672 total time=   0.0s\n",
            "[CV 4/5; 282/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 282/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.750 total time=   0.0s\n",
            "[CV 5/5; 282/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 282/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.700 total time=   0.0s\n",
            "[CV 1/5; 283/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 283/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.750 total time=   0.0s\n",
            "[CV 2/5; 283/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 283/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.672 total time=   0.0s\n",
            "[CV 3/5; 283/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 283/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.664 total time=   0.0s\n",
            "[CV 4/5; 283/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 283/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.694 total time=   0.0s\n",
            "[CV 5/5; 283/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 283/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.734 total time=   0.0s\n",
            "[CV 1/5; 284/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 284/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.690 total time=   0.0s\n",
            "[CV 2/5; 284/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 284/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.679 total time=   0.0s\n",
            "[CV 3/5; 284/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 284/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.739 total time=   0.0s\n",
            "[CV 4/5; 284/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 284/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.683 total time=   0.0s\n",
            "[CV 5/5; 284/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 284/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.775 total time=   0.0s\n",
            "[CV 1/5; 285/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 1/5; 285/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.918 total time=   8.7s\n",
            "[CV 2/5; 285/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 2/5; 285/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.873 total time=   0.0s\n",
            "[CV 3/5; 285/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 3/5; 285/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.896 total time=   8.2s\n",
            "[CV 4/5; 285/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 4/5; 285/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.910 total time=   8.3s\n",
            "[CV 5/5; 285/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 5/5; 285/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.895 total time=   8.6s\n",
            "[CV 1/5; 286/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 286/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.907 total time=   0.9s\n",
            "[CV 2/5; 286/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 286/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.892 total time=   0.0s\n",
            "[CV 3/5; 286/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 286/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.847 total time=   0.0s\n",
            "[CV 4/5; 286/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 286/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.903 total time=   0.8s\n",
            "[CV 5/5; 286/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 286/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.891 total time=   0.0s\n",
            "[CV 1/5; 287/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 287/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.884 total time=   0.0s\n",
            "[CV 2/5; 287/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 287/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.910 total time=   0.0s\n",
            "[CV 3/5; 287/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 287/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.858 total time=   0.0s\n",
            "[CV 4/5; 287/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 287/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.910 total time=   0.0s\n",
            "[CV 5/5; 287/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 287/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.861 total time=   0.0s\n",
            "[CV 1/5; 288/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 288/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.877 total time=   0.0s\n",
            "[CV 2/5; 288/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 288/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.899 total time=   0.0s\n",
            "[CV 3/5; 288/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 288/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.881 total time=   0.0s\n",
            "[CV 4/5; 288/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 288/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.873 total time=   0.0s\n",
            "[CV 5/5; 288/448] START alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 288/448] END alpha=0.01, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.876 total time=   0.0s\n",
            "[CV 1/5; 289/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 1/5; 289/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.944 total time=   0.0s\n",
            "[CV 2/5; 289/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 2/5; 289/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.974 total time=   0.0s\n",
            "[CV 3/5; 289/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 3/5; 289/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.937 total time=   0.0s\n",
            "[CV 4/5; 289/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 4/5; 289/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.937 total time=   0.0s\n",
            "[CV 5/5; 289/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 5/5; 289/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.914 total time=   0.0s\n",
            "[CV 1/5; 290/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 290/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.940 total time=   0.0s\n",
            "[CV 2/5; 290/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 290/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 3/5; 290/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 290/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 290/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 290/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.933 total time=   0.0s\n",
            "[CV 5/5; 290/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 290/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.925 total time=   0.0s\n",
            "[CV 1/5; 291/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 291/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.933 total time=   0.0s\n",
            "[CV 2/5; 291/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 291/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.951 total time=   0.0s\n",
            "[CV 3/5; 291/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 291/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.951 total time=   0.0s\n",
            "[CV 4/5; 291/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 291/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 5/5; 291/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 291/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.918 total time=   0.0s\n",
            "[CV 1/5; 292/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 292/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.922 total time=   0.0s\n",
            "[CV 2/5; 292/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 292/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.970 total time=   0.0s\n",
            "[CV 3/5; 292/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 292/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.937 total time=   0.0s\n",
            "[CV 4/5; 292/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 292/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.918 total time=   0.0s\n",
            "[CV 5/5; 292/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 292/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.910 total time=   0.0s\n",
            "[CV 1/5; 293/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 293/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.937 total time= 1.4min\n",
            "[CV 2/5; 293/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 2/5; 293/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.787 total time=   0.0s\n",
            "[CV 3/5; 293/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 3/5; 293/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.817 total time=   0.0s\n",
            "[CV 4/5; 293/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 4/5; 293/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.851 total time=   0.0s\n",
            "[CV 5/5; 293/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 5/5; 293/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.805 total time=   0.0s\n",
            "[CV 1/5; 294/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 294/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.940 total time= 1.6min\n",
            "[CV 2/5; 294/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 294/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.851 total time=   0.0s\n",
            "[CV 3/5; 294/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 294/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.873 total time=   0.0s\n",
            "[CV 4/5; 294/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 294/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.765 total time=   0.0s\n",
            "[CV 5/5; 294/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 294/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.801 total time=   0.0s\n",
            "[CV 1/5; 295/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 295/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.937 total time= 1.6min\n",
            "[CV 2/5; 295/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 295/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.802 total time=   0.0s\n",
            "[CV 3/5; 295/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 295/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.810 total time=   0.0s\n",
            "[CV 4/5; 295/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 295/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.869 total time=   0.0s\n",
            "[CV 5/5; 295/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 295/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.794 total time=   0.0s\n",
            "[CV 1/5; 296/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 296/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.940 total time= 1.5min\n",
            "[CV 2/5; 296/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 296/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.705 total time=   0.0s\n",
            "[CV 3/5; 296/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 296/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.776 total time=   0.0s\n",
            "[CV 4/5; 296/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 296/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.884 total time=   0.0s\n",
            "[CV 5/5; 296/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 296/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.775 total time=   0.0s\n",
            "[CV 1/5; 297/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 297/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.940 total time= 3.3min\n",
            "[CV 2/5; 297/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 2/5; 297/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.743 total time=   0.0s\n",
            "[CV 3/5; 297/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 3/5; 297/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.847 total time=   0.0s\n",
            "[CV 4/5; 297/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 4/5; 297/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.925 total time=   0.0s\n",
            "[CV 5/5; 297/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 5/5; 297/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.798 total time=   0.0s\n",
            "[CV 1/5; 298/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 298/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.940 total time= 3.3min\n",
            "[CV 2/5; 298/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 298/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.963 total time= 3.4min\n",
            "[CV 3/5; 298/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 298/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.851 total time=   0.0s\n",
            "[CV 4/5; 298/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 298/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.914 total time=   0.0s\n",
            "[CV 5/5; 298/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 298/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.760 total time=   0.0s\n",
            "[CV 1/5; 299/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 299/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.940 total time= 3.2min\n",
            "[CV 2/5; 299/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 299/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.840 total time=   0.0s\n",
            "[CV 3/5; 299/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 299/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.963 total time= 2.6min\n",
            "[CV 4/5; 299/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 299/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.840 total time=   0.0s\n",
            "[CV 5/5; 299/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 299/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.828 total time=   0.0s\n",
            "[CV 1/5; 300/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 300/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.944 total time= 2.2min\n",
            "[CV 2/5; 300/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 300/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 3/5; 300/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 300/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.765 total time=   0.0s\n",
            "[CV 4/5; 300/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 300/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.858 total time=   0.0s\n",
            "[CV 5/5; 300/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 300/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.757 total time=   0.0s\n",
            "[CV 1/5; 301/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 1/5; 301/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.937 total time=   0.0s\n",
            "[CV 2/5; 301/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 2/5; 301/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.966 total time=   0.0s\n",
            "[CV 3/5; 301/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 3/5; 301/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.951 total time=   0.0s\n",
            "[CV 4/5; 301/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 4/5; 301/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.944 total time=   0.0s\n",
            "[CV 5/5; 301/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 5/5; 301/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.940 total time=   0.0s\n",
            "[CV 1/5; 302/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 302/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.933 total time=   0.0s\n",
            "[CV 2/5; 302/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 302/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.951 total time=   0.0s\n",
            "[CV 3/5; 302/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 302/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.955 total time=   0.0s\n",
            "[CV 4/5; 302/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 302/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.933 total time=   0.0s\n",
            "[CV 5/5; 302/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 302/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.940 total time=   0.0s\n",
            "[CV 1/5; 303/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 303/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.918 total time=   0.0s\n",
            "[CV 2/5; 303/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 303/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.963 total time=   0.0s\n",
            "[CV 3/5; 303/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 303/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.944 total time=  58.4s\n",
            "[CV 4/5; 303/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 303/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.933 total time=   0.0s\n",
            "[CV 5/5; 303/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 303/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.925 total time=   0.0s\n",
            "[CV 1/5; 304/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 304/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.937 total time=   0.0s\n",
            "[CV 2/5; 304/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 304/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.955 total time=   0.0s\n",
            "[CV 3/5; 304/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 304/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 304/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 304/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 5/5; 304/448] START alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 304/448] END alpha=0.01, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 1/5; 305/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 1/5; 305/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.929 total time=   0.0s\n",
            "[CV 2/5; 305/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 2/5; 305/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.679 total time=   0.0s\n",
            "[CV 3/5; 305/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 3/5; 305/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.549 total time=   0.0s\n",
            "[CV 4/5; 305/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 4/5; 305/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.597 total time=   0.0s\n",
            "[CV 5/5; 305/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 5/5; 305/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.558 total time=   0.0s\n",
            "[CV 1/5; 306/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 306/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.739 total time=   0.0s\n",
            "[CV 2/5; 306/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 306/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.597 total time=   0.0s\n",
            "[CV 3/5; 306/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 306/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.836 total time=   0.0s\n",
            "[CV 4/5; 306/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 306/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.701 total time=   0.0s\n",
            "[CV 5/5; 306/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 306/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.760 total time=   0.0s\n",
            "[CV 1/5; 307/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 307/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.799 total time=   0.0s\n",
            "[CV 2/5; 307/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 307/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.601 total time=   0.0s\n",
            "[CV 3/5; 307/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 307/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.619 total time=   0.0s\n",
            "[CV 4/5; 307/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 307/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.653 total time=   0.0s\n",
            "[CV 5/5; 307/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 307/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.757 total time=   0.0s\n",
            "[CV 1/5; 308/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 308/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.515 total time=   0.0s\n",
            "[CV 2/5; 308/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 308/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.578 total time=   0.0s\n",
            "[CV 3/5; 308/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 308/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.586 total time=   0.0s\n",
            "[CV 4/5; 308/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 308/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.552 total time=   0.0s\n",
            "[CV 5/5; 308/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 308/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.884 total time=   0.0s\n",
            "[CV 1/5; 309/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 1/5; 309/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.869 total time=   0.0s\n",
            "[CV 2/5; 309/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 2/5; 309/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.769 total time=   0.0s\n",
            "[CV 3/5; 309/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 3/5; 309/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.750 total time=   0.0s\n",
            "[CV 4/5; 309/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 4/5; 309/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.810 total time=   0.0s\n",
            "[CV 5/5; 309/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 5/5; 309/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.779 total time=   0.0s\n",
            "[CV 1/5; 310/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 310/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.772 total time=   0.0s\n",
            "[CV 2/5; 310/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 310/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.668 total time=   0.0s\n",
            "[CV 3/5; 310/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 310/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.784 total time=   0.0s\n",
            "[CV 4/5; 310/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 310/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.754 total time=   0.0s\n",
            "[CV 5/5; 310/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 310/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.760 total time=   0.0s\n",
            "[CV 1/5; 311/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 311/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.795 total time=   0.0s\n",
            "[CV 2/5; 311/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 311/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.724 total time=   0.0s\n",
            "[CV 3/5; 311/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 311/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.728 total time=   0.0s\n",
            "[CV 4/5; 311/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 311/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.813 total time=   0.0s\n",
            "[CV 5/5; 311/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 311/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.757 total time=   0.0s\n",
            "[CV 1/5; 312/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 312/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.810 total time=   0.0s\n",
            "[CV 2/5; 312/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 312/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.728 total time=   0.0s\n",
            "[CV 3/5; 312/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 312/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.866 total time=   0.0s\n",
            "[CV 4/5; 312/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 312/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.847 total time=   0.0s\n",
            "[CV 5/5; 312/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 312/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.824 total time=   0.0s\n",
            "[CV 1/5; 313/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 1/5; 313/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.724 total time=   0.0s\n",
            "[CV 2/5; 313/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 2/5; 313/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.746 total time=   0.0s\n",
            "[CV 3/5; 313/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 3/5; 313/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.791 total time=   0.0s\n",
            "[CV 4/5; 313/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 4/5; 313/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.731 total time=   0.0s\n",
            "[CV 5/5; 313/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 5/5; 313/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.925 total time=   0.0s\n",
            "[CV 1/5; 314/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 314/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.907 total time=   0.0s\n",
            "[CV 2/5; 314/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 314/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.750 total time=   0.0s\n",
            "[CV 3/5; 314/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 314/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.802 total time=   0.0s\n",
            "[CV 4/5; 314/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 314/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.933 total time=   0.0s\n",
            "[CV 5/5; 314/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 314/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 315/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 315/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.653 total time=   0.0s\n",
            "[CV 2/5; 315/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 315/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.664 total time=   0.0s\n",
            "[CV 3/5; 315/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 315/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.843 total time=   0.0s\n",
            "[CV 4/5; 315/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 315/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.873 total time=   0.0s\n",
            "[CV 5/5; 315/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 315/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.858 total time=   0.0s\n",
            "[CV 1/5; 316/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 316/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.989 total time=   0.0s\n",
            "[CV 2/5; 316/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 316/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.914 total time=   0.0s\n",
            "[CV 3/5; 316/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 316/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.825 total time=   0.0s\n",
            "[CV 4/5; 316/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 316/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.847 total time=   0.0s\n",
            "[CV 5/5; 316/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 316/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.906 total time=   0.0s\n",
            "[CV 1/5; 317/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 1/5; 317/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.951 total time=   0.0s\n",
            "[CV 2/5; 317/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 2/5; 317/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.981 total time=   0.0s\n",
            "[CV 3/5; 317/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 3/5; 317/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.955 total time=   0.0s\n",
            "[CV 4/5; 317/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 4/5; 317/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.963 total time=   0.0s\n",
            "[CV 5/5; 317/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 5/5; 317/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.940 total time=   0.0s\n",
            "[CV 1/5; 318/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 318/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.955 total time=   0.0s\n",
            "[CV 2/5; 318/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 318/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.985 total time=   0.0s\n",
            "[CV 3/5; 318/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 318/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.933 total time=   0.0s\n",
            "[CV 4/5; 318/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 318/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.922 total time=   0.0s\n",
            "[CV 5/5; 318/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 318/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.910 total time=   0.0s\n",
            "[CV 1/5; 319/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 319/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.970 total time=   0.0s\n",
            "[CV 2/5; 319/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 319/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.985 total time=   0.0s\n",
            "[CV 3/5; 319/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 319/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.963 total time=   0.0s\n",
            "[CV 4/5; 319/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 319/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.951 total time=   0.0s\n",
            "[CV 5/5; 319/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 319/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.951 total time=   0.0s\n",
            "[CV 1/5; 320/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 320/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.951 total time=   0.0s\n",
            "[CV 2/5; 320/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 320/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.974 total time=   0.0s\n",
            "[CV 3/5; 320/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 320/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.955 total time=   0.0s\n",
            "[CV 4/5; 320/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 320/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.966 total time=   0.0s\n",
            "[CV 5/5; 320/448] START alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 320/448] END alpha=0.01, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.955 total time=   0.0s\n",
            "[CV 1/5; 321/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 1/5; 321/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 321/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 2/5; 321/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 321/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 3/5; 321/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 321/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 4/5; 321/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 321/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 5/5; 321/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 322/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 322/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 322/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 322/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 322/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 322/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 322/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 322/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 322/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 322/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 323/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 323/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 323/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 323/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 323/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 323/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 323/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 323/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 323/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 323/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 324/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 324/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 324/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 324/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 324/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 324/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 324/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 324/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 324/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 324/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 325/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 1/5; 325/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.507 total time=   0.0s\n",
            "[CV 2/5; 325/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 2/5; 325/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.530 total time=   0.0s\n",
            "[CV 3/5; 325/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 3/5; 325/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.534 total time=   0.0s\n",
            "[CV 4/5; 325/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 4/5; 325/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.534 total time=   0.0s\n",
            "[CV 5/5; 325/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 5/5; 325/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 326/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 326/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.575 total time=   0.0s\n",
            "[CV 2/5; 326/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 326/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.534 total time=   0.0s\n",
            "[CV 3/5; 326/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 326/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.541 total time=   0.0s\n",
            "[CV 4/5; 326/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 326/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.549 total time=   0.0s\n",
            "[CV 5/5; 326/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 326/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 327/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 327/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.560 total time=   0.0s\n",
            "[CV 2/5; 327/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 327/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.526 total time=   0.0s\n",
            "[CV 3/5; 327/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 327/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.545 total time=   0.0s\n",
            "[CV 4/5; 327/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 327/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.530 total time=   0.0s\n",
            "[CV 5/5; 327/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 327/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 328/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 328/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.541 total time=   0.0s\n",
            "[CV 2/5; 328/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 328/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.534 total time=   0.0s\n",
            "[CV 3/5; 328/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 328/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.530 total time=   0.0s\n",
            "[CV 4/5; 328/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 328/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.537 total time=   0.0s\n",
            "[CV 5/5; 328/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 328/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.517 total time=   0.0s\n",
            "[CV 1/5; 329/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 1/5; 329/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 329/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 2/5; 329/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 329/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 3/5; 329/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 329/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 4/5; 329/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 329/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 5/5; 329/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 330/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 330/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 330/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 330/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 330/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 330/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 330/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 330/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 330/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 330/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 331/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 331/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 331/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 331/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 331/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 331/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 331/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 331/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 331/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 331/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 332/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 332/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 332/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 332/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 332/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 332/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 332/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 332/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 332/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 332/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 333/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 1/5; 333/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.720 total time=   9.0s\n",
            "[CV 2/5; 333/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 2/5; 333/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.694 total time=   9.1s\n",
            "[CV 3/5; 333/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 3/5; 333/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.728 total time=  11.5s\n",
            "[CV 4/5; 333/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 4/5; 333/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.728 total time=   9.6s\n",
            "[CV 5/5; 333/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 5/5; 333/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.764 total time=   8.6s\n",
            "[CV 1/5; 334/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 334/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.709 total time=   1.0s\n",
            "[CV 2/5; 334/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 334/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.687 total time=   1.2s\n",
            "[CV 3/5; 334/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 334/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.709 total time=   1.1s\n",
            "[CV 4/5; 334/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 334/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.720 total time=   1.1s\n",
            "[CV 5/5; 334/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 334/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.753 total time=   1.0s\n",
            "[CV 1/5; 335/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 335/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.675 total time=   0.0s\n",
            "[CV 2/5; 335/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 335/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.653 total time=   0.1s\n",
            "[CV 3/5; 335/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 335/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.679 total time=   0.0s\n",
            "[CV 4/5; 335/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 335/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.701 total time=   0.0s\n",
            "[CV 5/5; 335/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 335/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.742 total time=   0.0s\n",
            "[CV 1/5; 336/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 336/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.638 total time=   0.0s\n",
            "[CV 2/5; 336/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 336/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.653 total time=   0.0s\n",
            "[CV 3/5; 336/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 336/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.694 total time=   0.0s\n",
            "[CV 4/5; 336/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 336/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.694 total time=   0.0s\n",
            "[CV 5/5; 336/448] START alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 336/448] END alpha=0.1, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.697 total time=   0.0s\n",
            "[CV 1/5; 337/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 1/5; 337/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 337/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 2/5; 337/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 337/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 3/5; 337/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 337/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 4/5; 337/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 337/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 5/5; 337/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 338/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 338/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 338/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 338/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 338/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 338/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 338/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 338/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 338/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 338/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 339/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 339/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 339/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 339/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 339/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 339/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 339/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 339/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 339/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 339/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 340/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 340/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 340/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 340/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 340/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 340/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 340/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 340/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 340/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 340/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 341/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 1/5; 341/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.552 total time=   0.0s\n",
            "[CV 2/5; 341/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 2/5; 341/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.545 total time=   0.0s\n",
            "[CV 3/5; 341/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 3/5; 341/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.545 total time=   0.0s\n",
            "[CV 4/5; 341/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 4/5; 341/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.537 total time=   0.0s\n",
            "[CV 5/5; 341/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 5/5; 341/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.607 total time=   0.0s\n",
            "[CV 1/5; 342/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 342/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.545 total time=   0.0s\n",
            "[CV 2/5; 342/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 342/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.545 total time=   0.0s\n",
            "[CV 3/5; 342/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 342/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.541 total time=   0.0s\n",
            "[CV 4/5; 342/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 342/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.537 total time=   0.0s\n",
            "[CV 5/5; 342/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 342/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.599 total time=   0.0s\n",
            "[CV 1/5; 343/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 343/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.549 total time=   0.0s\n",
            "[CV 2/5; 343/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 343/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.545 total time=   0.0s\n",
            "[CV 3/5; 343/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 343/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.552 total time=   0.0s\n",
            "[CV 4/5; 343/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 343/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.537 total time=   0.0s\n",
            "[CV 5/5; 343/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 343/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.577 total time=   0.0s\n",
            "[CV 1/5; 344/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 344/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.552 total time=   0.0s\n",
            "[CV 2/5; 344/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 344/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.541 total time=   0.0s\n",
            "[CV 3/5; 344/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 344/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.549 total time=   0.0s\n",
            "[CV 4/5; 344/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 344/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.552 total time=   0.0s\n",
            "[CV 5/5; 344/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 344/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.588 total time=   0.0s\n",
            "[CV 1/5; 345/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 1/5; 345/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 345/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 2/5; 345/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 345/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 3/5; 345/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.526 total time=   0.0s\n",
            "[CV 4/5; 345/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 4/5; 345/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.526 total time=   0.0s\n",
            "[CV 5/5; 345/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 5/5; 345/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 346/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 346/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.519 total time=   0.0s\n",
            "[CV 2/5; 346/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 346/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 346/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 346/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.493 total time=   0.0s\n",
            "[CV 4/5; 346/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 346/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.526 total time=   0.0s\n",
            "[CV 5/5; 346/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 346/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 347/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 347/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.537 total time=   0.0s\n",
            "[CV 2/5; 347/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 347/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 347/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 347/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.500 total time=   0.0s\n",
            "[CV 4/5; 347/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 347/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.549 total time=   0.0s\n",
            "[CV 5/5; 347/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 347/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 348/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 348/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.526 total time=   0.0s\n",
            "[CV 2/5; 348/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 348/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 348/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 348/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.496 total time=   0.0s\n",
            "[CV 4/5; 348/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 348/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.537 total time=   0.0s\n",
            "[CV 5/5; 348/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 348/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 349/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 1/5; 349/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.716 total time=   7.9s\n",
            "[CV 2/5; 349/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 2/5; 349/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.716 total time=   6.2s\n",
            "[CV 3/5; 349/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 3/5; 349/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.735 total time=   6.1s\n",
            "[CV 4/5; 349/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 4/5; 349/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.728 total time=   6.0s\n",
            "[CV 5/5; 349/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 5/5; 349/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.764 total time=   6.1s\n",
            "[CV 1/5; 350/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 350/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.728 total time=   0.6s\n",
            "[CV 2/5; 350/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 350/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.713 total time=   0.6s\n",
            "[CV 3/5; 350/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 350/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.720 total time=   0.6s\n",
            "[CV 4/5; 350/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 350/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.728 total time=   0.6s\n",
            "[CV 5/5; 350/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 350/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.760 total time=   0.6s\n",
            "[CV 1/5; 351/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 351/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.698 total time=   0.0s\n",
            "[CV 2/5; 351/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 351/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.698 total time=   0.0s\n",
            "[CV 3/5; 351/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 351/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.705 total time=   0.0s\n",
            "[CV 4/5; 351/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 351/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.705 total time=   0.0s\n",
            "[CV 5/5; 351/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 351/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.678 total time=   0.1s\n",
            "[CV 1/5; 352/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 352/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.701 total time=   0.0s\n",
            "[CV 2/5; 352/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 352/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.675 total time=   0.0s\n",
            "[CV 3/5; 352/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 352/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.679 total time=   0.0s\n",
            "[CV 4/5; 352/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 352/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.705 total time=   0.0s\n",
            "[CV 5/5; 352/448] START alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 352/448] END alpha=0.1, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.734 total time=   0.0s\n",
            "[CV 1/5; 353/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 353/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.869 total time= 2.3min\n",
            "[CV 2/5; 353/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 353/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.959 total time= 2.2min\n",
            "[CV 3/5; 353/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 353/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.929 total time= 2.3min\n",
            "[CV 4/5; 353/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 353/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.929 total time= 2.3min\n",
            "[CV 5/5; 353/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 353/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.914 total time= 2.3min\n",
            "[CV 1/5; 354/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 354/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.877 total time= 2.4min\n",
            "[CV 2/5; 354/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 354/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.948 total time= 2.3min\n",
            "[CV 3/5; 354/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 354/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.910 total time= 2.2min\n",
            "[CV 4/5; 354/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 354/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.896 total time= 2.3min\n",
            "[CV 5/5; 354/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 354/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.933 total time= 2.2min\n",
            "[CV 1/5; 355/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 355/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.903 total time= 2.2min\n",
            "[CV 2/5; 355/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 355/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.940 total time= 2.2min\n",
            "[CV 3/5; 355/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 355/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.884 total time= 2.3min\n",
            "[CV 4/5; 355/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 355/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.929 total time= 2.2min\n",
            "[CV 5/5; 355/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 355/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.914 total time= 2.2min\n",
            "[CV 1/5; 356/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 356/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.892 total time= 2.3min\n",
            "[CV 2/5; 356/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 356/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.937 total time= 2.2min\n",
            "[CV 3/5; 356/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 356/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.869 total time= 2.2min\n",
            "[CV 4/5; 356/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 356/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.933 total time= 2.2min\n",
            "[CV 5/5; 356/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 356/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.888 total time= 2.3min\n",
            "[CV 1/5; 357/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 357/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.899 total time= 1.1min\n",
            "[CV 2/5; 357/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 357/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.884 total time= 1.2min\n",
            "[CV 3/5; 357/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 357/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.847 total time= 1.7min\n",
            "[CV 4/5; 357/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 357/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.955 total time= 1.5min\n",
            "[CV 5/5; 357/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 357/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.921 total time= 1.6min\n",
            "[CV 1/5; 358/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 358/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.910 total time= 1.7min\n",
            "[CV 2/5; 358/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 358/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.937 total time= 1.5min\n",
            "[CV 3/5; 358/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 358/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.851 total time= 1.2min\n",
            "[CV 4/5; 358/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 358/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.896 total time= 1.3min\n",
            "[CV 5/5; 358/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 358/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.884 total time= 1.3min\n",
            "[CV 1/5; 359/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 359/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.899 total time= 1.3min\n",
            "[CV 2/5; 359/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 359/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.918 total time= 1.2min\n",
            "[CV 3/5; 359/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 359/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.929 total time= 1.2min\n",
            "[CV 4/5; 359/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 359/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.922 total time= 1.4min\n",
            "[CV 5/5; 359/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 359/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.876 total time= 1.7min\n",
            "[CV 1/5; 360/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 360/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.881 total time= 1.6min\n",
            "[CV 2/5; 360/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 360/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.903 total time= 1.6min\n",
            "[CV 3/5; 360/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 360/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.866 total time= 1.7min\n",
            "[CV 4/5; 360/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 360/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.929 total time= 1.6min\n",
            "[CV 5/5; 360/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 360/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.861 total time= 1.7min\n",
            "[CV 1/5; 361/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 361/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.862 total time= 3.5min\n",
            "[CV 2/5; 361/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 361/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.933 total time= 3.4min\n",
            "[CV 3/5; 361/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 361/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.884 total time= 3.5min\n",
            "[CV 4/5; 361/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 361/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.884 total time= 3.5min\n",
            "[CV 5/5; 361/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 361/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.876 total time= 3.6min\n",
            "[CV 1/5; 362/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 362/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.896 total time= 2.5min\n",
            "[CV 2/5; 362/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 362/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.944 total time= 2.4min\n",
            "[CV 3/5; 362/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 362/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.888 total time= 2.4min\n",
            "[CV 4/5; 362/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 362/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.896 total time= 2.4min\n",
            "[CV 5/5; 362/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 362/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.899 total time= 2.4min\n",
            "[CV 1/5; 363/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 363/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.940 total time= 2.3min\n",
            "[CV 2/5; 363/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 363/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.892 total time= 2.7min\n",
            "[CV 3/5; 363/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 363/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.858 total time= 2.8min\n",
            "[CV 4/5; 363/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 363/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.929 total time= 2.5min\n",
            "[CV 5/5; 363/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 363/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.895 total time= 2.6min\n",
            "[CV 1/5; 364/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 364/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.869 total time= 2.4min\n",
            "[CV 2/5; 364/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 364/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.937 total time= 2.4min\n",
            "[CV 3/5; 364/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 364/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.881 total time= 2.5min\n",
            "[CV 4/5; 364/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 364/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.918 total time= 2.4min\n",
            "[CV 5/5; 364/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 364/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.918 total time= 2.4min\n",
            "[CV 1/5; 365/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 365/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.922 total time= 1.1min\n",
            "[CV 2/5; 365/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 365/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.877 total time= 1.0min\n",
            "[CV 3/5; 365/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 365/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.922 total time= 1.0min\n",
            "[CV 4/5; 365/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 365/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.933 total time= 1.0min\n",
            "[CV 5/5; 365/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 365/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.910 total time=  59.1s\n",
            "[CV 1/5; 366/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 366/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.881 total time= 1.0min\n",
            "[CV 2/5; 366/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 366/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.966 total time= 1.0min\n",
            "[CV 3/5; 366/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 366/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.899 total time= 1.7min\n",
            "[CV 4/5; 366/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 366/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.907 total time= 1.8min\n",
            "[CV 5/5; 366/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 366/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.918 total time= 1.7min\n",
            "[CV 1/5; 367/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 367/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.884 total time= 1.7min\n",
            "[CV 2/5; 367/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 367/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.937 total time= 1.7min\n",
            "[CV 3/5; 367/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 367/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.884 total time= 1.3min\n",
            "[CV 4/5; 367/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 367/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.929 total time= 1.4min\n",
            "[CV 5/5; 367/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 367/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.933 total time= 1.4min\n",
            "[CV 1/5; 368/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 368/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.910 total time= 1.4min\n",
            "[CV 2/5; 368/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 368/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.951 total time= 1.5min\n",
            "[CV 3/5; 368/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 368/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.940 total time= 1.7min\n",
            "[CV 4/5; 368/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 368/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.948 total time= 1.5min\n",
            "[CV 5/5; 368/448] START alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 368/448] END alpha=0.1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.921 total time= 1.6min\n",
            "[CV 1/5; 369/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 1/5; 369/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.478 total time=   0.0s\n",
            "[CV 2/5; 369/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 2/5; 369/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.478 total time=   0.0s\n",
            "[CV 3/5; 369/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 3/5; 369/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 369/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 4/5; 369/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.478 total time=   0.0s\n",
            "[CV 5/5; 369/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 5/5; 369/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.479 total time=   0.0s\n",
            "[CV 1/5; 370/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 370/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 370/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 370/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.478 total time=   0.0s\n",
            "[CV 3/5; 370/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 370/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.478 total time=   0.0s\n",
            "[CV 4/5; 370/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 370/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.478 total time=   0.0s\n",
            "[CV 5/5; 370/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 370/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.479 total time=   0.0s\n",
            "[CV 1/5; 371/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 371/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.478 total time=   0.0s\n",
            "[CV 2/5; 371/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 371/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.478 total time=   0.0s\n",
            "[CV 3/5; 371/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 371/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.478 total time=   0.0s\n",
            "[CV 4/5; 371/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 371/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 371/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 371/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 372/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 372/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.478 total time=   0.0s\n",
            "[CV 2/5; 372/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 372/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.478 total time=   0.0s\n",
            "[CV 3/5; 372/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 372/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 372/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 372/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 372/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 372/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 373/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 1/5; 373/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.843 total time=   0.0s\n",
            "[CV 2/5; 373/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 2/5; 373/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.851 total time=   0.0s\n",
            "[CV 3/5; 373/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 3/5; 373/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.843 total time=   0.0s\n",
            "[CV 4/5; 373/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 4/5; 373/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.776 total time=   0.0s\n",
            "[CV 5/5; 373/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 5/5; 373/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.876 total time=   0.0s\n",
            "[CV 1/5; 374/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 374/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.795 total time=   0.0s\n",
            "[CV 2/5; 374/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 374/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.825 total time=   0.0s\n",
            "[CV 3/5; 374/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 374/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.810 total time=   0.0s\n",
            "[CV 4/5; 374/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 374/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.806 total time=   0.0s\n",
            "[CV 5/5; 374/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 374/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 375/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 375/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.810 total time=   0.0s\n",
            "[CV 2/5; 375/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 375/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.817 total time=   0.0s\n",
            "[CV 3/5; 375/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 375/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.761 total time=   0.0s\n",
            "[CV 4/5; 375/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 375/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.929 total time=   0.0s\n",
            "[CV 5/5; 375/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 375/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.858 total time=   0.0s\n",
            "[CV 1/5; 376/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 376/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.802 total time=   0.0s\n",
            "[CV 2/5; 376/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 376/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.720 total time=   0.0s\n",
            "[CV 3/5; 376/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 376/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.780 total time=   0.0s\n",
            "[CV 4/5; 376/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 376/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.795 total time=   0.0s\n",
            "[CV 5/5; 376/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 376/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.828 total time=   0.0s\n",
            "[CV 1/5; 377/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 1/5; 377/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.534 total time=   0.0s\n",
            "[CV 2/5; 377/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 2/5; 377/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.772 total time=   0.0s\n",
            "[CV 3/5; 377/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 3/5; 377/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.478 total time=   0.0s\n",
            "[CV 4/5; 377/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 4/5; 377/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.519 total time=   0.0s\n",
            "[CV 5/5; 377/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 5/5; 377/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 378/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 378/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.571 total time=   0.0s\n",
            "[CV 2/5; 378/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 378/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.552 total time=   0.0s\n",
            "[CV 3/5; 378/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 378/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 378/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 378/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.489 total time=   0.0s\n",
            "[CV 5/5; 378/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 378/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 379/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 379/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 379/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 379/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.478 total time=   0.0s\n",
            "[CV 3/5; 379/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 379/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.507 total time=   0.0s\n",
            "[CV 4/5; 379/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 379/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 379/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 379/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 380/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 380/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 380/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 380/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 380/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 380/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 380/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 380/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.545 total time=   0.0s\n",
            "[CV 5/5; 380/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 380/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.528 total time=   0.0s\n",
            "[CV 1/5; 381/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 1/5; 381/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.925 total time=   0.0s\n",
            "[CV 2/5; 381/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 2/5; 381/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.959 total time=   0.0s\n",
            "[CV 3/5; 381/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 3/5; 381/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 381/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 4/5; 381/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.948 total time=   0.0s\n",
            "[CV 5/5; 381/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 5/5; 381/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.918 total time=   0.0s\n",
            "[CV 1/5; 382/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 382/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.918 total time=   0.0s\n",
            "[CV 2/5; 382/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 382/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.981 total time=   0.0s\n",
            "[CV 3/5; 382/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 382/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.929 total time=   0.0s\n",
            "[CV 4/5; 382/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 382/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.970 total time=   0.0s\n",
            "[CV 5/5; 382/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 382/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.936 total time=   0.0s\n",
            "[CV 1/5; 383/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 383/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.959 total time=   0.0s\n",
            "[CV 2/5; 383/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 383/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.966 total time=   0.0s\n",
            "[CV 3/5; 383/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 383/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 4/5; 383/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 383/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.970 total time=   0.0s\n",
            "[CV 5/5; 383/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 383/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 1/5; 384/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 384/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.955 total time=   0.0s\n",
            "[CV 2/5; 384/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 384/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 3/5; 384/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 384/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.914 total time=   0.0s\n",
            "[CV 4/5; 384/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 384/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.951 total time=   0.0s\n",
            "[CV 5/5; 384/448] START alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 384/448] END alpha=0.1, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.914 total time=   0.0s\n",
            "[CV 1/5; 385/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 1/5; 385/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 385/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 2/5; 385/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.478 total time=   6.3s\n",
            "[CV 3/5; 385/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 3/5; 385/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 385/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 4/5; 385/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.478 total time=   6.4s\n",
            "[CV 5/5; 385/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 5/5; 385/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.479 total time=   6.6s\n",
            "[CV 1/5; 386/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 386/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.522 total time=   0.6s\n",
            "[CV 2/5; 386/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 386/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 386/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 386/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 386/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 386/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.522 total time=   0.7s\n",
            "[CV 5/5; 386/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 386/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 387/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 387/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 387/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 387/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 387/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 387/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 387/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 387/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 387/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 387/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 388/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 388/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 388/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 388/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 388/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 388/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 388/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 388/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 388/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 388/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 389/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 1/5; 389/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.493 total time=   0.0s\n",
            "[CV 2/5; 389/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 2/5; 389/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.493 total time=   0.0s\n",
            "[CV 3/5; 389/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 3/5; 389/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 389/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 4/5; 389/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.448 total time=   0.0s\n",
            "[CV 5/5; 389/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 5/5; 389/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.521 total time=   0.3s\n",
            "[CV 1/5; 390/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 390/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 390/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 390/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.530 total time=   0.0s\n",
            "[CV 3/5; 390/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 390/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 390/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 390/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.515 total time=   0.0s\n",
            "[CV 5/5; 390/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 390/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 391/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 391/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 391/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 391/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 391/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 391/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.493 total time=   0.0s\n",
            "[CV 4/5; 391/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 391/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.541 total time=   0.0s\n",
            "[CV 5/5; 391/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 391/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.506 total time=   0.0s\n",
            "[CV 1/5; 392/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 392/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 392/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 392/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.519 total time=   0.0s\n",
            "[CV 3/5; 392/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 392/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.519 total time=   0.0s\n",
            "[CV 4/5; 392/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 392/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 392/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 392/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.509 total time=   0.0s\n",
            "[CV 1/5; 393/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 1/5; 393/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 393/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 2/5; 393/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 393/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 3/5; 393/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 393/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 4/5; 393/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.522 total time=   6.3s\n",
            "[CV 5/5; 393/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 5/5; 393/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 394/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 394/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.522 total time=   0.4s\n",
            "[CV 2/5; 394/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 394/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 394/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 394/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 394/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 394/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.522 total time=   0.5s\n",
            "[CV 5/5; 394/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 394/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 395/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 395/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 395/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 395/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 395/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 395/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 395/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 395/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 395/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 395/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.479 total time=   0.0s\n",
            "[CV 1/5; 396/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 396/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 396/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 396/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.478 total time=   0.0s\n",
            "[CV 3/5; 396/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 396/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 396/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 396/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 396/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 396/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 397/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 1/5; 397/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.522 total time=   6.9s\n",
            "[CV 2/5; 397/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 2/5; 397/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.500 total time=  17.5s\n",
            "[CV 3/5; 397/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 3/5; 397/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.526 total time=   7.8s\n",
            "[CV 4/5; 397/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 4/5; 397/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.552 total time=   5.0s\n",
            "[CV 5/5; 397/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 5/5; 397/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.498 total time=  10.3s\n",
            "[CV 1/5; 398/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 398/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.526 total time=   1.3s\n",
            "[CV 2/5; 398/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 398/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.530 total time=   0.8s\n",
            "[CV 3/5; 398/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 398/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.493 total time=   1.3s\n",
            "[CV 4/5; 398/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 398/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.530 total time=   2.9s\n",
            "[CV 5/5; 398/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 398/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.547 total time=   0.6s\n",
            "[CV 1/5; 399/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 399/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.511 total time=   0.0s\n",
            "[CV 2/5; 399/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 399/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.552 total time=   0.0s\n",
            "[CV 3/5; 399/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 399/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.522 total time=   0.3s\n",
            "[CV 4/5; 399/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 399/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.549 total time=   0.1s\n",
            "[CV 5/5; 399/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 399/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.521 total time=   1.5s\n",
            "[CV 1/5; 400/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 400/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.504 total time=   0.0s\n",
            "[CV 2/5; 400/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 400/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.474 total time=   0.1s\n",
            "[CV 3/5; 400/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 400/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.511 total time=   0.0s\n",
            "[CV 4/5; 400/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 400/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.530 total time=   0.0s\n",
            "[CV 5/5; 400/448] START alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 400/448] END alpha=1, loss=hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.528 total time=   0.0s\n",
            "[CV 1/5; 401/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 1/5; 401/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.522 total time=   0.1s\n",
            "[CV 2/5; 401/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 2/5; 401/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.522 total time=   0.2s\n",
            "[CV 3/5; 401/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 3/5; 401/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.522 total time=   0.1s\n",
            "[CV 4/5; 401/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 4/5; 401/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.522 total time=   0.3s\n",
            "[CV 5/5; 401/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 5/5; 401/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.521 total time=   0.1s\n",
            "[CV 1/5; 402/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 402/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 402/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 402/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 402/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 402/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 402/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 402/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 402/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 402/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 403/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 403/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 403/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 403/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 403/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 403/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 403/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 403/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 403/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 403/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 404/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 404/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 404/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 404/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 404/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 404/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.478 total time=   0.0s\n",
            "[CV 4/5; 404/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 404/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 404/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 404/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 405/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 1/5; 405/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.500 total time=   0.0s\n",
            "[CV 2/5; 405/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 2/5; 405/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.530 total time=   0.0s\n",
            "[CV 3/5; 405/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 3/5; 405/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.526 total time=   0.0s\n",
            "[CV 4/5; 405/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 4/5; 405/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.496 total time=   0.0s\n",
            "[CV 5/5; 405/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 5/5; 405/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.506 total time=   0.1s\n",
            "[CV 1/5; 406/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 406/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.537 total time=   0.0s\n",
            "[CV 2/5; 406/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 406/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.530 total time=   0.0s\n",
            "[CV 3/5; 406/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 406/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.496 total time=   0.0s\n",
            "[CV 4/5; 406/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 406/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.534 total time=   0.0s\n",
            "[CV 5/5; 406/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 406/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 407/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 407/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.526 total time=   0.0s\n",
            "[CV 2/5; 407/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 407/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.478 total time=   0.0s\n",
            "[CV 3/5; 407/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 407/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 407/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 407/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.526 total time=   0.0s\n",
            "[CV 5/5; 407/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 407/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.487 total time=   0.0s\n",
            "[CV 1/5; 408/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 408/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.496 total time=   0.0s\n",
            "[CV 2/5; 408/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 408/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 408/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 408/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.519 total time=   0.0s\n",
            "[CV 4/5; 408/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 408/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.530 total time=   0.0s\n",
            "[CV 5/5; 408/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 408/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.528 total time=   0.0s\n",
            "[CV 1/5; 409/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 1/5; 409/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 409/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 2/5; 409/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 409/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 3/5; 409/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.522 total time=   0.2s\n",
            "[CV 4/5; 409/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 4/5; 409/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.522 total time=   0.1s\n",
            "[CV 5/5; 409/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 5/5; 409/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.521 total time=   0.2s\n",
            "[CV 1/5; 410/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 410/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 410/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 410/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 410/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 410/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 410/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 410/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 410/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 410/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 411/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 411/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 411/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 411/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 411/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 411/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 411/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 411/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 411/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 411/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 412/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 412/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 412/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 412/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.478 total time=   0.0s\n",
            "[CV 3/5; 412/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 412/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 412/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 412/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.478 total time=   0.0s\n",
            "[CV 5/5; 412/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 412/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 413/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 1/5; 413/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.619 total time=   2.8s\n",
            "[CV 2/5; 413/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 2/5; 413/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.586 total time=   2.5s\n",
            "[CV 3/5; 413/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 3/5; 413/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.549 total time=   2.6s\n",
            "[CV 4/5; 413/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 4/5; 413/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.537 total time=   2.2s\n",
            "[CV 5/5; 413/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 5/5; 413/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-07;, score=0.562 total time=   2.9s\n",
            "[CV 1/5; 414/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 414/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.534 total time=   0.3s\n",
            "[CV 2/5; 414/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 414/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.545 total time=   0.3s\n",
            "[CV 3/5; 414/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 414/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.563 total time=   0.9s\n",
            "[CV 4/5; 414/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 414/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.575 total time=   0.4s\n",
            "[CV 5/5; 414/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 414/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-06;, score=0.596 total time=   0.8s\n",
            "[CV 1/5; 415/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 415/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.526 total time=   0.0s\n",
            "[CV 2/5; 415/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 415/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.563 total time=   0.0s\n",
            "[CV 3/5; 415/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 415/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.560 total time=   0.1s\n",
            "[CV 4/5; 415/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 415/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.582 total time=   0.0s\n",
            "[CV 5/5; 415/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 415/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=1e-05;, score=0.543 total time=   0.0s\n",
            "[CV 1/5; 416/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 416/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.530 total time=   0.0s\n",
            "[CV 2/5; 416/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 416/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.537 total time=   0.0s\n",
            "[CV 3/5; 416/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 416/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.597 total time=   0.0s\n",
            "[CV 4/5; 416/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 416/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.519 total time=   0.0s\n",
            "[CV 5/5; 416/448] START alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 416/448] END alpha=1, loss=log_loss, max_iter=1000000, penalty=None, tol=0.0001;, score=0.543 total time=   0.0s\n",
            "[CV 1/5; 417/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 1/5; 417/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 417/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 417/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.780 total time= 3.9min\n",
            "[CV 3/5; 417/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 3/5; 417/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.858 total time=   1.9s\n",
            "[CV 4/5; 417/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 4/5; 417/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 417/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 5/5; 417/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 418/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 418/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.694 total time= 3.9min\n",
            "[CV 2/5; 418/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 418/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 418/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 418/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.668 total time= 3.2min\n",
            "[CV 4/5; 418/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 418/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.660 total time= 2.8min\n",
            "[CV 5/5; 418/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 418/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 419/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 419/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.754 total time= 2.8min\n",
            "[CV 2/5; 419/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 419/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.966 total time=   0.0s\n",
            "[CV 3/5; 419/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 419/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.705 total time= 2.8min\n",
            "[CV 4/5; 419/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 419/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.642 total time= 3.1min\n",
            "[CV 5/5; 419/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 419/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 420/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 420/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.653 total time= 3.4min\n",
            "[CV 2/5; 420/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 420/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.642 total time= 3.1min\n",
            "[CV 3/5; 420/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 420/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.765 total time= 1.2min\n",
            "[CV 4/5; 420/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 420/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 420/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 420/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.685 total time= 2.6min\n",
            "[CV 1/5; 421/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 1/5; 421/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.545 total time=   0.0s\n",
            "[CV 2/5; 421/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 2/5; 421/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.567 total time=   0.0s\n",
            "[CV 3/5; 421/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 3/5; 421/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.545 total time=   0.0s\n",
            "[CV 4/5; 421/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 4/5; 421/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.582 total time=   0.0s\n",
            "[CV 5/5; 421/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 5/5; 421/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.625 total time=   0.0s\n",
            "[CV 1/5; 422/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 422/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.586 total time=   0.0s\n",
            "[CV 2/5; 422/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 422/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.541 total time=   0.0s\n",
            "[CV 3/5; 422/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 422/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.563 total time=   0.0s\n",
            "[CV 4/5; 422/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 422/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.571 total time=   0.0s\n",
            "[CV 5/5; 422/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 422/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.655 total time=   0.0s\n",
            "[CV 1/5; 423/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 423/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.556 total time=   0.0s\n",
            "[CV 2/5; 423/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 423/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.586 total time=   0.0s\n",
            "[CV 3/5; 423/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 423/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.563 total time=   0.0s\n",
            "[CV 4/5; 423/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 423/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.642 total time=   0.0s\n",
            "[CV 5/5; 423/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 423/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.584 total time=   0.0s\n",
            "[CV 1/5; 424/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 424/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.597 total time=   0.0s\n",
            "[CV 2/5; 424/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 424/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.541 total time=   0.0s\n",
            "[CV 3/5; 424/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 424/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.597 total time=   0.0s\n",
            "[CV 4/5; 424/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 424/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.522 total time=   0.7s\n",
            "[CV 5/5; 424/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 424/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.547 total time=   0.0s\n",
            "[CV 1/5; 425/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 1/5; 425/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 425/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 2/5; 425/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.530 total time=   0.0s\n",
            "[CV 3/5; 425/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 3/5; 425/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 425/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 4/5; 425/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.541 total time=   0.0s\n",
            "[CV 5/5; 425/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 5/5; 425/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.532 total time=   0.0s\n",
            "[CV 1/5; 426/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 426/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 426/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 426/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 426/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 426/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.507 total time=   0.0s\n",
            "[CV 4/5; 426/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 426/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.646 total time=   0.0s\n",
            "[CV 5/5; 426/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 426/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 427/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 427/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 427/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 427/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 427/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 427/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.530 total time=   0.0s\n",
            "[CV 4/5; 427/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 427/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 427/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 427/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.562 total time=   0.0s\n",
            "[CV 1/5; 428/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 428/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 428/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 428/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.530 total time=   0.1s\n",
            "[CV 3/5; 428/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 428/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 428/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 428/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.560 total time=   0.0s\n",
            "[CV 5/5; 428/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 428/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 429/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 429/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.672 total time= 1.7min\n",
            "[CV 2/5; 429/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 429/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.679 total time= 1.6min\n",
            "[CV 3/5; 429/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 429/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.657 total time= 1.4min\n",
            "[CV 4/5; 429/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 429/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.698 total time= 1.4min\n",
            "[CV 5/5; 429/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 429/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-07;, score=0.637 total time= 1.6min\n",
            "[CV 1/5; 430/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 430/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.728 total time= 1.4min\n",
            "[CV 2/5; 430/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 430/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.716 total time= 1.3min\n",
            "[CV 3/5; 430/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 430/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.627 total time= 1.5min\n",
            "[CV 4/5; 430/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 430/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.709 total time= 1.4min\n",
            "[CV 5/5; 430/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 430/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-06;, score=0.648 total time= 1.5min\n",
            "[CV 1/5; 431/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 431/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.616 total time= 1.4min\n",
            "[CV 2/5; 431/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 431/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.679 total time= 1.4min\n",
            "[CV 3/5; 431/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 431/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.642 total time= 1.5min\n",
            "[CV 4/5; 431/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 431/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.638 total time= 1.4min\n",
            "[CV 5/5; 431/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 431/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=1e-05;, score=0.682 total time= 1.4min\n",
            "[CV 1/5; 432/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 432/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.619 total time= 1.4min\n",
            "[CV 2/5; 432/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 432/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.664 total time= 1.4min\n",
            "[CV 3/5; 432/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 432/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.720 total time= 1.4min\n",
            "[CV 4/5; 432/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5; 432/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.638 total time= 1.4min\n",
            "[CV 5/5; 432/448] START alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 432/448] END alpha=1, loss=squared_hinge, max_iter=1000000, penalty=None, tol=0.0001;, score=0.730 total time= 1.4min\n",
            "[CV 1/5; 433/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 1/5; 433/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.478 total time=   0.0s\n",
            "[CV 2/5; 433/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 2/5; 433/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 433/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 3/5; 433/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 433/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 4/5; 433/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 433/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07\n",
            "[CV 5/5; 433/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-07;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 434/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 1/5; 434/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.478 total time=   0.0s\n",
            "[CV 2/5; 434/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 2/5; 434/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.478 total time=   0.0s\n",
            "[CV 3/5; 434/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 3/5; 434/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.478 total time=   0.0s\n",
            "[CV 4/5; 434/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 4/5; 434/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 434/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06\n",
            "[CV 5/5; 434/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-06;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 435/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 1/5; 435/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 435/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 2/5; 435/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.478 total time=   0.0s\n",
            "[CV 3/5; 435/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 3/5; 435/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 435/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 4/5; 435/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 435/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05\n",
            "[CV 5/5; 435/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=1e-05;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 436/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 1/5; 436/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.478 total time=   0.0s\n",
            "[CV 2/5; 436/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 2/5; 436/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.478 total time=   0.0s\n",
            "[CV 3/5; 436/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 3/5; 436/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.478 total time=   0.0s\n",
            "[CV 4/5; 436/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 4/5; 436/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 436/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001\n",
            "[CV 5/5; 436/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l1, tol=0.0001;, score=0.479 total time=   0.0s\n",
            "[CV 1/5; 437/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 1/5; 437/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.821 total time=   0.0s\n",
            "[CV 2/5; 437/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 2/5; 437/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.914 total time=   0.0s\n",
            "[CV 3/5; 437/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 3/5; 437/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.791 total time=   0.0s\n",
            "[CV 4/5; 437/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 4/5; 437/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.754 total time=   0.0s\n",
            "[CV 5/5; 437/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07\n",
            "[CV 5/5; 437/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-07;, score=0.869 total time=   0.0s\n",
            "[CV 1/5; 438/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 1/5; 438/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.802 total time=   0.0s\n",
            "[CV 2/5; 438/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 2/5; 438/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.784 total time=   0.0s\n",
            "[CV 3/5; 438/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 3/5; 438/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.772 total time=   0.0s\n",
            "[CV 4/5; 438/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 4/5; 438/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.873 total time=   0.0s\n",
            "[CV 5/5; 438/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06\n",
            "[CV 5/5; 438/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-06;, score=0.775 total time=   0.0s\n",
            "[CV 1/5; 439/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 1/5; 439/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.776 total time=   0.0s\n",
            "[CV 2/5; 439/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 2/5; 439/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.836 total time=   0.0s\n",
            "[CV 3/5; 439/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 3/5; 439/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.854 total time=   0.0s\n",
            "[CV 4/5; 439/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 4/5; 439/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.817 total time=   0.0s\n",
            "[CV 5/5; 439/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05\n",
            "[CV 5/5; 439/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=1e-05;, score=0.768 total time=   0.0s\n",
            "[CV 1/5; 440/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 1/5; 440/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.817 total time=   0.0s\n",
            "[CV 2/5; 440/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 2/5; 440/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.716 total time=   0.0s\n",
            "[CV 3/5; 440/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 3/5; 440/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.649 total time=   0.0s\n",
            "[CV 4/5; 440/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 4/5; 440/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.739 total time=   0.0s\n",
            "[CV 5/5; 440/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001\n",
            "[CV 5/5; 440/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=l2, tol=0.0001;, score=0.682 total time=   0.0s\n",
            "[CV 1/5; 441/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 1/5; 441/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 441/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 2/5; 441/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 441/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 3/5; 441/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 441/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 4/5; 441/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.478 total time=   0.0s\n",
            "[CV 5/5; 441/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07\n",
            "[CV 5/5; 441/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-07;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 442/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 1/5; 442/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.478 total time=   0.0s\n",
            "[CV 2/5; 442/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 2/5; 442/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 442/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 3/5; 442/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.478 total time=   0.0s\n",
            "[CV 4/5; 442/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 4/5; 442/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 442/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06\n",
            "[CV 5/5; 442/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-06;, score=0.479 total time=   0.0s\n",
            "[CV 1/5; 443/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 1/5; 443/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 443/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 2/5; 443/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 443/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 3/5; 443/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.478 total time=   0.0s\n",
            "[CV 4/5; 443/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 4/5; 443/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 443/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05\n",
            "[CV 5/5; 443/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=1e-05;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 444/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 1/5; 444/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 444/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 2/5; 444/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.478 total time=   0.0s\n",
            "[CV 3/5; 444/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 3/5; 444/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 444/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 4/5; 444/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.478 total time=   0.0s\n",
            "[CV 5/5; 444/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001\n",
            "[CV 5/5; 444/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=elasticnet, tol=0.0001;, score=0.479 total time=   0.0s\n",
            "[CV 1/5; 445/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 1/5; 445/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.679 total time=  17.7s\n",
            "[CV 2/5; 445/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 2/5; 445/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.959 total time=   0.0s\n",
            "[CV 3/5; 445/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 3/5; 445/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.903 total time=   0.0s\n",
            "[CV 4/5; 445/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 4/5; 445/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.963 total time=   0.0s\n",
            "[CV 5/5; 445/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07\n",
            "[CV 5/5; 445/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-07;, score=0.652 total time=   7.3s\n",
            "[CV 1/5; 446/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 1/5; 446/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.657 total time=   1.7s\n",
            "[CV 2/5; 446/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 2/5; 446/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.914 total time=   0.1s\n",
            "[CV 3/5; 446/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 3/5; 446/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.892 total time=   0.0s\n",
            "[CV 4/5; 446/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 4/5; 446/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.813 total time=   0.2s\n",
            "[CV 5/5; 446/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06\n",
            "[CV 5/5; 446/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-06;, score=0.914 total time=   0.0s\n",
            "[CV 1/5; 447/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 1/5; 447/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.925 total time=   0.0s\n",
            "[CV 2/5; 447/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 2/5; 447/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.716 total time=   0.0s\n",
            "[CV 3/5; 447/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 3/5; 447/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.802 total time=   0.0s\n",
            "[CV 4/5; 447/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 4/5; 447/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.851 total time=   0.0s\n",
            "[CV 5/5; 447/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05\n",
            "[CV 5/5; 447/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=1e-05;, score=0.543 total time=   0.7s\n",
            "[CV 1/5; 448/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 1/5; 448/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.586 total time=   0.0s\n",
            "[CV 2/5; 448/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 2/5; 448/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.571 total time=   0.0s\n",
            "[CV 3/5; 448/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 3/5; 448/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.910 total time=   0.0s\n",
            "[CV 4/5; 448/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 4/5; 448/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.884 total time=   0.0s\n",
            "[CV 5/5; 448/448] START alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001\n",
            "[CV 5/5; 448/448] END alpha=1, loss=perceptron, max_iter=1000000, penalty=None, tol=0.0001;, score=0.644 total time=   0.0s\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;sgdc&#x27;,\n",
              "                 GridSearchCV(cv=5, estimator=SGDClassifier(),\n",
              "                              param_grid={&#x27;alpha&#x27;: [1e-06, 1e-05, 0.0001, 0.001,\n",
              "                                                    0.01, 0.1, 1],\n",
              "                                          &#x27;loss&#x27;: [&#x27;hinge&#x27;, &#x27;log_loss&#x27;,\n",
              "                                                   &#x27;squared_hinge&#x27;,\n",
              "                                                   &#x27;perceptron&#x27;],\n",
              "                                          &#x27;max_iter&#x27;: [1000000],\n",
              "                                          &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;,\n",
              "                                                      None],\n",
              "                                          &#x27;tol&#x27;: [1e-07, 1e-06, 1e-05, 0.0001]},\n",
              "                              verbose=10))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;sgdc&#x27;,\n",
              "                 GridSearchCV(cv=5, estimator=SGDClassifier(),\n",
              "                              param_grid={&#x27;alpha&#x27;: [1e-06, 1e-05, 0.0001, 0.001,\n",
              "                                                    0.01, 0.1, 1],\n",
              "                                          &#x27;loss&#x27;: [&#x27;hinge&#x27;, &#x27;log_loss&#x27;,\n",
              "                                                   &#x27;squared_hinge&#x27;,\n",
              "                                                   &#x27;perceptron&#x27;],\n",
              "                                          &#x27;max_iter&#x27;: [1000000],\n",
              "                                          &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;,\n",
              "                                                      None],\n",
              "                                          &#x27;tol&#x27;: [1e-07, 1e-06, 1e-05, 0.0001]},\n",
              "                              verbose=10))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" ><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">sgdc: GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SGDClassifier(),\n",
              "             param_grid={&#x27;alpha&#x27;: [1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1],\n",
              "                         &#x27;loss&#x27;: [&#x27;hinge&#x27;, &#x27;log_loss&#x27;, &#x27;squared_hinge&#x27;,\n",
              "                                  &#x27;perceptron&#x27;],\n",
              "                         &#x27;max_iter&#x27;: [1000000],\n",
              "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, None],\n",
              "                         &#x27;tol&#x27;: [1e-07, 1e-06, 1e-05, 0.0001]},\n",
              "             verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" ><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" ><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                ('sgdc',\n",
              "                 GridSearchCV(cv=5, estimator=SGDClassifier(),\n",
              "                              param_grid={'alpha': [1e-06, 1e-05, 0.0001, 0.001,\n",
              "                                                    0.01, 0.1, 1],\n",
              "                                          'loss': ['hinge', 'log_loss',\n",
              "                                                   'squared_hinge',\n",
              "                                                   'perceptron'],\n",
              "                                          'max_iter': [1000000],\n",
              "                                          'penalty': ['l1', 'l2', 'elasticnet',\n",
              "                                                      None],\n",
              "                                          'tol': [1e-07, 1e-06, 1e-05, 0.0001]},\n",
              "                              verbose=10))])"
            ]
          },
          "execution_count": 152,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "param_grid = {'loss': ['hinge' , 'log_loss' , 'squared_hinge' , 'perceptron'],\n",
        "            'penalty':['l1' , 'l2' , 'elasticnet' , None],\n",
        "            'alpha': [1e-6 , 1e-5 , 1e-4 ,1e-3 , 1e-2 , 1e-1 , 1],\n",
        "            'max_iter': [int(1e6)],\n",
        "            'tol': [1e-7 ,1e-6 , 1e-5 ,1e-4 ]}\n",
        "clf = Pipeline([('scaler' , StandardScaler()),\n",
        "                ('sgdc' , GridSearchCV(SGDClassifier(),\n",
        "                param_grid = param_grid,\n",
        "                cv = 5,\n",
        "                refit = True,\n",
        "                verbose = 10))])\n",
        "clf.fit(X_train , y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(alpha=0.001, loss=&#x27;perceptron&#x27;, max_iter=1000000, penalty=&#x27;l1&#x27;,\n",
              "              tol=0.0001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-48\" type=\"checkbox\" checked><label for=\"sk-estimator-id-48\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(alpha=0.001, loss=&#x27;perceptron&#x27;, max_iter=1000000, penalty=&#x27;l1&#x27;,\n",
              "              tol=0.0001)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "SGDClassifier(alpha=0.001, loss='perceptron', max_iter=1000000, penalty='l1',\n",
              "              tol=0.0001)"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf['sgdc'].best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9723656995919281"
            ]
          },
          "execution_count": 154,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf['sgdc'].best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_val_prediction = clf.predict(X_validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9955947136563876"
            ]
          },
          "execution_count": 156,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_validation ,y_val_prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_prediction = clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9975186104218362"
            ]
          },
          "execution_count": 158,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f1_score(y_test , y_prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 143 candidates, totalling 715 fits\n",
            "[CV 1/5; 1/143] START C=0.001, kernel=linear, tol=0.01..........................\n",
            "[CV 1/5; 1/143] END C=0.001, kernel=linear, tol=0.01;, score=0.522 total time=   0.6s\n",
            "[CV 2/5; 1/143] START C=0.001, kernel=linear, tol=0.01..........................\n",
            "[CV 2/5; 1/143] END C=0.001, kernel=linear, tol=0.01;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 1/143] START C=0.001, kernel=linear, tol=0.01..........................\n",
            "[CV 3/5; 1/143] END C=0.001, kernel=linear, tol=0.01;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 1/143] START C=0.001, kernel=linear, tol=0.01..........................\n",
            "[CV 4/5; 1/143] END C=0.001, kernel=linear, tol=0.01;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 1/143] START C=0.001, kernel=linear, tol=0.01..........................\n",
            "[CV 5/5; 1/143] END C=0.001, kernel=linear, tol=0.01;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 2/143] START C=0.001, kernel=linear, tol=0.001.........................\n",
            "[CV 1/5; 2/143] END C=0.001, kernel=linear, tol=0.001;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 2/143] START C=0.001, kernel=linear, tol=0.001.........................\n",
            "[CV 2/5; 2/143] END C=0.001, kernel=linear, tol=0.001;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 2/143] START C=0.001, kernel=linear, tol=0.001.........................\n",
            "[CV 3/5; 2/143] END C=0.001, kernel=linear, tol=0.001;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 2/143] START C=0.001, kernel=linear, tol=0.001.........................\n",
            "[CV 4/5; 2/143] END C=0.001, kernel=linear, tol=0.001;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 2/143] START C=0.001, kernel=linear, tol=0.001.........................\n",
            "[CV 5/5; 2/143] END C=0.001, kernel=linear, tol=0.001;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 3/143] START C=0.001, kernel=linear, tol=0.0001........................\n",
            "[CV 1/5; 3/143] END C=0.001, kernel=linear, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 3/143] START C=0.001, kernel=linear, tol=0.0001........................\n",
            "[CV 2/5; 3/143] END C=0.001, kernel=linear, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 3/143] START C=0.001, kernel=linear, tol=0.0001........................\n",
            "[CV 3/5; 3/143] END C=0.001, kernel=linear, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 3/143] START C=0.001, kernel=linear, tol=0.0001........................\n",
            "[CV 4/5; 3/143] END C=0.001, kernel=linear, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 3/143] START C=0.001, kernel=linear, tol=0.0001........................\n",
            "[CV 5/5; 3/143] END C=0.001, kernel=linear, tol=0.0001;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 4/143] START C=0.001, kernel=linear, tol=1e-05.........................\n",
            "[CV 1/5; 4/143] END C=0.001, kernel=linear, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 4/143] START C=0.001, kernel=linear, tol=1e-05.........................\n",
            "[CV 2/5; 4/143] END C=0.001, kernel=linear, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 4/143] START C=0.001, kernel=linear, tol=1e-05.........................\n",
            "[CV 3/5; 4/143] END C=0.001, kernel=linear, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 4/143] START C=0.001, kernel=linear, tol=1e-05.........................\n",
            "[CV 4/5; 4/143] END C=0.001, kernel=linear, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 4/143] START C=0.001, kernel=linear, tol=1e-05.........................\n",
            "[CV 5/5; 4/143] END C=0.001, kernel=linear, tol=1e-05;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 5/143] START C=0.01, kernel=linear, tol=0.01...........................\n",
            "[CV 1/5; 5/143] END C=0.01, kernel=linear, tol=0.01;, score=0.519 total time=   0.0s\n",
            "[CV 2/5; 5/143] START C=0.01, kernel=linear, tol=0.01...........................\n",
            "[CV 2/5; 5/143] END C=0.01, kernel=linear, tol=0.01;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 5/143] START C=0.01, kernel=linear, tol=0.01...........................\n",
            "[CV 3/5; 5/143] END C=0.01, kernel=linear, tol=0.01;, score=0.526 total time=   0.0s\n",
            "[CV 4/5; 5/143] START C=0.01, kernel=linear, tol=0.01...........................\n",
            "[CV 4/5; 5/143] END C=0.01, kernel=linear, tol=0.01;, score=0.530 total time=   0.0s\n",
            "[CV 5/5; 5/143] START C=0.01, kernel=linear, tol=0.01...........................\n",
            "[CV 5/5; 5/143] END C=0.01, kernel=linear, tol=0.01;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 6/143] START C=0.01, kernel=linear, tol=0.001..........................\n",
            "[CV 1/5; 6/143] END C=0.01, kernel=linear, tol=0.001;, score=0.519 total time=   0.0s\n",
            "[CV 2/5; 6/143] START C=0.01, kernel=linear, tol=0.001..........................\n",
            "[CV 2/5; 6/143] END C=0.01, kernel=linear, tol=0.001;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 6/143] START C=0.01, kernel=linear, tol=0.001..........................\n",
            "[CV 3/5; 6/143] END C=0.01, kernel=linear, tol=0.001;, score=0.526 total time=   0.0s\n",
            "[CV 4/5; 6/143] START C=0.01, kernel=linear, tol=0.001..........................\n",
            "[CV 4/5; 6/143] END C=0.01, kernel=linear, tol=0.001;, score=0.530 total time=   0.0s\n",
            "[CV 5/5; 6/143] START C=0.01, kernel=linear, tol=0.001..........................\n",
            "[CV 5/5; 6/143] END C=0.01, kernel=linear, tol=0.001;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 7/143] START C=0.01, kernel=linear, tol=0.0001.........................\n",
            "[CV 1/5; 7/143] END C=0.01, kernel=linear, tol=0.0001;, score=0.519 total time=   0.0s\n",
            "[CV 2/5; 7/143] START C=0.01, kernel=linear, tol=0.0001.........................\n",
            "[CV 2/5; 7/143] END C=0.01, kernel=linear, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 7/143] START C=0.01, kernel=linear, tol=0.0001.........................\n",
            "[CV 3/5; 7/143] END C=0.01, kernel=linear, tol=0.0001;, score=0.526 total time=   0.0s\n",
            "[CV 4/5; 7/143] START C=0.01, kernel=linear, tol=0.0001.........................\n",
            "[CV 4/5; 7/143] END C=0.01, kernel=linear, tol=0.0001;, score=0.530 total time=   0.0s\n",
            "[CV 5/5; 7/143] START C=0.01, kernel=linear, tol=0.0001.........................\n",
            "[CV 5/5; 7/143] END C=0.01, kernel=linear, tol=0.0001;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 8/143] START C=0.01, kernel=linear, tol=1e-05..........................\n",
            "[CV 1/5; 8/143] END C=0.01, kernel=linear, tol=1e-05;, score=0.519 total time=   0.0s\n",
            "[CV 2/5; 8/143] START C=0.01, kernel=linear, tol=1e-05..........................\n",
            "[CV 2/5; 8/143] END C=0.01, kernel=linear, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 8/143] START C=0.01, kernel=linear, tol=1e-05..........................\n",
            "[CV 3/5; 8/143] END C=0.01, kernel=linear, tol=1e-05;, score=0.526 total time=   0.0s\n",
            "[CV 4/5; 8/143] START C=0.01, kernel=linear, tol=1e-05..........................\n",
            "[CV 4/5; 8/143] END C=0.01, kernel=linear, tol=1e-05;, score=0.530 total time=   0.0s\n",
            "[CV 5/5; 8/143] START C=0.01, kernel=linear, tol=1e-05..........................\n",
            "[CV 5/5; 8/143] END C=0.01, kernel=linear, tol=1e-05;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 9/143] START C=0.1, kernel=linear, tol=0.01............................\n",
            "[CV 1/5; 9/143] END C=0.1, kernel=linear, tol=0.01;, score=0.660 total time=   0.0s\n",
            "[CV 2/5; 9/143] START C=0.1, kernel=linear, tol=0.01............................\n",
            "[CV 2/5; 9/143] END C=0.1, kernel=linear, tol=0.01;, score=0.668 total time=   0.0s\n",
            "[CV 3/5; 9/143] START C=0.1, kernel=linear, tol=0.01............................\n",
            "[CV 3/5; 9/143] END C=0.1, kernel=linear, tol=0.01;, score=0.701 total time=   0.0s\n",
            "[CV 4/5; 9/143] START C=0.1, kernel=linear, tol=0.01............................\n",
            "[CV 4/5; 9/143] END C=0.1, kernel=linear, tol=0.01;, score=0.675 total time=   0.0s\n",
            "[CV 5/5; 9/143] START C=0.1, kernel=linear, tol=0.01............................\n",
            "[CV 5/5; 9/143] END C=0.1, kernel=linear, tol=0.01;, score=0.727 total time=   0.0s\n",
            "[CV 1/5; 10/143] START C=0.1, kernel=linear, tol=0.001..........................\n",
            "[CV 1/5; 10/143] END C=0.1, kernel=linear, tol=0.001;, score=0.660 total time=   0.0s\n",
            "[CV 2/5; 10/143] START C=0.1, kernel=linear, tol=0.001..........................\n",
            "[CV 2/5; 10/143] END C=0.1, kernel=linear, tol=0.001;, score=0.668 total time=   0.0s\n",
            "[CV 3/5; 10/143] START C=0.1, kernel=linear, tol=0.001..........................\n",
            "[CV 3/5; 10/143] END C=0.1, kernel=linear, tol=0.001;, score=0.701 total time=   0.0s\n",
            "[CV 4/5; 10/143] START C=0.1, kernel=linear, tol=0.001..........................\n",
            "[CV 4/5; 10/143] END C=0.1, kernel=linear, tol=0.001;, score=0.679 total time=   0.0s\n",
            "[CV 5/5; 10/143] START C=0.1, kernel=linear, tol=0.001..........................\n",
            "[CV 5/5; 10/143] END C=0.1, kernel=linear, tol=0.001;, score=0.723 total time=   0.0s\n",
            "[CV 1/5; 11/143] START C=0.1, kernel=linear, tol=0.0001.........................\n",
            "[CV 1/5; 11/143] END C=0.1, kernel=linear, tol=0.0001;, score=0.660 total time=   0.0s\n",
            "[CV 2/5; 11/143] START C=0.1, kernel=linear, tol=0.0001.........................\n",
            "[CV 2/5; 11/143] END C=0.1, kernel=linear, tol=0.0001;, score=0.668 total time=   0.0s\n",
            "[CV 3/5; 11/143] START C=0.1, kernel=linear, tol=0.0001.........................\n",
            "[CV 3/5; 11/143] END C=0.1, kernel=linear, tol=0.0001;, score=0.698 total time=   0.0s\n",
            "[CV 4/5; 11/143] START C=0.1, kernel=linear, tol=0.0001.........................\n",
            "[CV 4/5; 11/143] END C=0.1, kernel=linear, tol=0.0001;, score=0.679 total time=   0.0s\n",
            "[CV 5/5; 11/143] START C=0.1, kernel=linear, tol=0.0001.........................\n",
            "[CV 5/5; 11/143] END C=0.1, kernel=linear, tol=0.0001;, score=0.723 total time=   0.0s\n",
            "[CV 1/5; 12/143] START C=0.1, kernel=linear, tol=1e-05..........................\n",
            "[CV 1/5; 12/143] END C=0.1, kernel=linear, tol=1e-05;, score=0.660 total time=   0.0s\n",
            "[CV 2/5; 12/143] START C=0.1, kernel=linear, tol=1e-05..........................\n",
            "[CV 2/5; 12/143] END C=0.1, kernel=linear, tol=1e-05;, score=0.668 total time=   0.0s\n",
            "[CV 3/5; 12/143] START C=0.1, kernel=linear, tol=1e-05..........................\n",
            "[CV 3/5; 12/143] END C=0.1, kernel=linear, tol=1e-05;, score=0.698 total time=   0.0s\n",
            "[CV 4/5; 12/143] START C=0.1, kernel=linear, tol=1e-05..........................\n",
            "[CV 4/5; 12/143] END C=0.1, kernel=linear, tol=1e-05;, score=0.679 total time=   0.0s\n",
            "[CV 5/5; 12/143] START C=0.1, kernel=linear, tol=1e-05..........................\n",
            "[CV 5/5; 12/143] END C=0.1, kernel=linear, tol=1e-05;, score=0.723 total time=   0.0s\n",
            "[CV 1/5; 13/143] START C=1, kernel=linear, tol=0.01.............................\n",
            "[CV 1/5; 13/143] END C=1, kernel=linear, tol=0.01;, score=0.873 total time=   0.0s\n",
            "[CV 2/5; 13/143] START C=1, kernel=linear, tol=0.01.............................\n",
            "[CV 2/5; 13/143] END C=1, kernel=linear, tol=0.01;, score=0.899 total time=   0.0s\n",
            "[CV 3/5; 13/143] START C=1, kernel=linear, tol=0.01.............................\n",
            "[CV 3/5; 13/143] END C=1, kernel=linear, tol=0.01;, score=0.866 total time=   0.0s\n",
            "[CV 4/5; 13/143] START C=1, kernel=linear, tol=0.01.............................\n",
            "[CV 4/5; 13/143] END C=1, kernel=linear, tol=0.01;, score=0.828 total time=   0.0s\n",
            "[CV 5/5; 13/143] START C=1, kernel=linear, tol=0.01.............................\n",
            "[CV 5/5; 13/143] END C=1, kernel=linear, tol=0.01;, score=0.861 total time=   0.0s\n",
            "[CV 1/5; 14/143] START C=1, kernel=linear, tol=0.001............................\n",
            "[CV 1/5; 14/143] END C=1, kernel=linear, tol=0.001;, score=0.877 total time=   0.0s\n",
            "[CV 2/5; 14/143] START C=1, kernel=linear, tol=0.001............................\n",
            "[CV 2/5; 14/143] END C=1, kernel=linear, tol=0.001;, score=0.899 total time=   0.0s\n",
            "[CV 3/5; 14/143] START C=1, kernel=linear, tol=0.001............................\n",
            "[CV 3/5; 14/143] END C=1, kernel=linear, tol=0.001;, score=0.866 total time=   0.0s\n",
            "[CV 4/5; 14/143] START C=1, kernel=linear, tol=0.001............................\n",
            "[CV 4/5; 14/143] END C=1, kernel=linear, tol=0.001;, score=0.832 total time=   0.0s\n",
            "[CV 5/5; 14/143] START C=1, kernel=linear, tol=0.001............................\n",
            "[CV 5/5; 14/143] END C=1, kernel=linear, tol=0.001;, score=0.861 total time=   0.0s\n",
            "[CV 1/5; 15/143] START C=1, kernel=linear, tol=0.0001...........................\n",
            "[CV 1/5; 15/143] END C=1, kernel=linear, tol=0.0001;, score=0.881 total time=   0.0s\n",
            "[CV 2/5; 15/143] START C=1, kernel=linear, tol=0.0001...........................\n",
            "[CV 2/5; 15/143] END C=1, kernel=linear, tol=0.0001;, score=0.899 total time=   0.0s\n",
            "[CV 3/5; 15/143] START C=1, kernel=linear, tol=0.0001...........................\n",
            "[CV 3/5; 15/143] END C=1, kernel=linear, tol=0.0001;, score=0.866 total time=   0.0s\n",
            "[CV 4/5; 15/143] START C=1, kernel=linear, tol=0.0001...........................\n",
            "[CV 4/5; 15/143] END C=1, kernel=linear, tol=0.0001;, score=0.832 total time=   0.0s\n",
            "[CV 5/5; 15/143] START C=1, kernel=linear, tol=0.0001...........................\n",
            "[CV 5/5; 15/143] END C=1, kernel=linear, tol=0.0001;, score=0.861 total time=   0.0s\n",
            "[CV 1/5; 16/143] START C=1, kernel=linear, tol=1e-05............................\n",
            "[CV 1/5; 16/143] END C=1, kernel=linear, tol=1e-05;, score=0.877 total time=   0.0s\n",
            "[CV 2/5; 16/143] START C=1, kernel=linear, tol=1e-05............................\n",
            "[CV 2/5; 16/143] END C=1, kernel=linear, tol=1e-05;, score=0.899 total time=   0.0s\n",
            "[CV 3/5; 16/143] START C=1, kernel=linear, tol=1e-05............................\n",
            "[CV 3/5; 16/143] END C=1, kernel=linear, tol=1e-05;, score=0.866 total time=   0.0s\n",
            "[CV 4/5; 16/143] START C=1, kernel=linear, tol=1e-05............................\n",
            "[CV 4/5; 16/143] END C=1, kernel=linear, tol=1e-05;, score=0.832 total time=   0.0s\n",
            "[CV 5/5; 16/143] START C=1, kernel=linear, tol=1e-05............................\n",
            "[CV 5/5; 16/143] END C=1, kernel=linear, tol=1e-05;, score=0.861 total time=   0.0s\n",
            "[CV 1/5; 17/143] START C=10, kernel=linear, tol=0.01............................\n",
            "[CV 1/5; 17/143] END C=10, kernel=linear, tol=0.01;, score=0.978 total time=   0.0s\n",
            "[CV 2/5; 17/143] START C=10, kernel=linear, tol=0.01............................\n",
            "[CV 2/5; 17/143] END C=10, kernel=linear, tol=0.01;, score=0.963 total time=   0.0s\n",
            "[CV 3/5; 17/143] START C=10, kernel=linear, tol=0.01............................\n",
            "[CV 3/5; 17/143] END C=10, kernel=linear, tol=0.01;, score=0.955 total time=   0.0s\n",
            "[CV 4/5; 17/143] START C=10, kernel=linear, tol=0.01............................\n",
            "[CV 4/5; 17/143] END C=10, kernel=linear, tol=0.01;, score=0.955 total time=   0.0s\n",
            "[CV 5/5; 17/143] START C=10, kernel=linear, tol=0.01............................\n",
            "[CV 5/5; 17/143] END C=10, kernel=linear, tol=0.01;, score=0.955 total time=   0.0s\n",
            "[CV 1/5; 18/143] START C=10, kernel=linear, tol=0.001...........................\n",
            "[CV 1/5; 18/143] END C=10, kernel=linear, tol=0.001;, score=0.978 total time=   0.0s\n",
            "[CV 2/5; 18/143] START C=10, kernel=linear, tol=0.001...........................\n",
            "[CV 2/5; 18/143] END C=10, kernel=linear, tol=0.001;, score=0.966 total time=   0.0s\n",
            "[CV 3/5; 18/143] START C=10, kernel=linear, tol=0.001...........................\n",
            "[CV 3/5; 18/143] END C=10, kernel=linear, tol=0.001;, score=0.955 total time=   0.0s\n",
            "[CV 4/5; 18/143] START C=10, kernel=linear, tol=0.001...........................\n",
            "[CV 4/5; 18/143] END C=10, kernel=linear, tol=0.001;, score=0.955 total time=   0.0s\n",
            "[CV 5/5; 18/143] START C=10, kernel=linear, tol=0.001...........................\n",
            "[CV 5/5; 18/143] END C=10, kernel=linear, tol=0.001;, score=0.951 total time=   0.0s\n",
            "[CV 1/5; 19/143] START C=10, kernel=linear, tol=0.0001..........................\n",
            "[CV 1/5; 19/143] END C=10, kernel=linear, tol=0.0001;, score=0.978 total time=   0.1s\n",
            "[CV 2/5; 19/143] START C=10, kernel=linear, tol=0.0001..........................\n",
            "[CV 2/5; 19/143] END C=10, kernel=linear, tol=0.0001;, score=0.966 total time=   0.0s\n",
            "[CV 3/5; 19/143] START C=10, kernel=linear, tol=0.0001..........................\n",
            "[CV 3/5; 19/143] END C=10, kernel=linear, tol=0.0001;, score=0.955 total time=   0.0s\n",
            "[CV 4/5; 19/143] START C=10, kernel=linear, tol=0.0001..........................\n",
            "[CV 4/5; 19/143] END C=10, kernel=linear, tol=0.0001;, score=0.955 total time=   0.0s\n",
            "[CV 5/5; 19/143] START C=10, kernel=linear, tol=0.0001..........................\n",
            "[CV 5/5; 19/143] END C=10, kernel=linear, tol=0.0001;, score=0.951 total time=   0.1s\n",
            "[CV 1/5; 20/143] START C=10, kernel=linear, tol=1e-05...........................\n",
            "[CV 1/5; 20/143] END C=10, kernel=linear, tol=1e-05;, score=0.978 total time=   0.0s\n",
            "[CV 2/5; 20/143] START C=10, kernel=linear, tol=1e-05...........................\n",
            "[CV 2/5; 20/143] END C=10, kernel=linear, tol=1e-05;, score=0.966 total time=   0.0s\n",
            "[CV 3/5; 20/143] START C=10, kernel=linear, tol=1e-05...........................\n",
            "[CV 3/5; 20/143] END C=10, kernel=linear, tol=1e-05;, score=0.955 total time=   0.1s\n",
            "[CV 4/5; 20/143] START C=10, kernel=linear, tol=1e-05...........................\n",
            "[CV 4/5; 20/143] END C=10, kernel=linear, tol=1e-05;, score=0.955 total time=   0.0s\n",
            "[CV 5/5; 20/143] START C=10, kernel=linear, tol=1e-05...........................\n",
            "[CV 5/5; 20/143] END C=10, kernel=linear, tol=1e-05;, score=0.951 total time=   0.1s\n",
            "[CV 1/5; 21/143] START C=100.0, kernel=linear, tol=0.01.........................\n",
            "[CV 1/5; 21/143] END C=100.0, kernel=linear, tol=0.01;, score=0.981 total time=   0.2s\n",
            "[CV 2/5; 21/143] START C=100.0, kernel=linear, tol=0.01.........................\n",
            "[CV 2/5; 21/143] END C=100.0, kernel=linear, tol=0.01;, score=0.993 total time=   0.2s\n",
            "[CV 3/5; 21/143] START C=100.0, kernel=linear, tol=0.01.........................\n",
            "[CV 3/5; 21/143] END C=100.0, kernel=linear, tol=0.01;, score=0.963 total time=   0.1s\n",
            "[CV 4/5; 21/143] START C=100.0, kernel=linear, tol=0.01.........................\n",
            "[CV 4/5; 21/143] END C=100.0, kernel=linear, tol=0.01;, score=0.970 total time=   0.1s\n",
            "[CV 5/5; 21/143] START C=100.0, kernel=linear, tol=0.01.........................\n",
            "[CV 5/5; 21/143] END C=100.0, kernel=linear, tol=0.01;, score=0.978 total time=   0.2s\n",
            "[CV 1/5; 22/143] START C=100.0, kernel=linear, tol=0.001........................\n",
            "[CV 1/5; 22/143] END C=100.0, kernel=linear, tol=0.001;, score=0.981 total time=   0.4s\n",
            "[CV 2/5; 22/143] START C=100.0, kernel=linear, tol=0.001........................\n",
            "[CV 2/5; 22/143] END C=100.0, kernel=linear, tol=0.001;, score=0.993 total time=   0.3s\n",
            "[CV 3/5; 22/143] START C=100.0, kernel=linear, tol=0.001........................\n",
            "[CV 3/5; 22/143] END C=100.0, kernel=linear, tol=0.001;, score=0.963 total time=   0.3s\n",
            "[CV 4/5; 22/143] START C=100.0, kernel=linear, tol=0.001........................\n",
            "[CV 4/5; 22/143] END C=100.0, kernel=linear, tol=0.001;, score=0.970 total time=   0.2s\n",
            "[CV 5/5; 22/143] START C=100.0, kernel=linear, tol=0.001........................\n",
            "[CV 5/5; 22/143] END C=100.0, kernel=linear, tol=0.001;, score=0.978 total time=   0.3s\n",
            "[CV 1/5; 23/143] START C=100.0, kernel=linear, tol=0.0001.......................\n",
            "[CV 1/5; 23/143] END C=100.0, kernel=linear, tol=0.0001;, score=0.981 total time=   0.7s\n",
            "[CV 2/5; 23/143] START C=100.0, kernel=linear, tol=0.0001.......................\n",
            "[CV 2/5; 23/143] END C=100.0, kernel=linear, tol=0.0001;, score=0.993 total time=   0.4s\n",
            "[CV 3/5; 23/143] START C=100.0, kernel=linear, tol=0.0001.......................\n",
            "[CV 3/5; 23/143] END C=100.0, kernel=linear, tol=0.0001;, score=0.963 total time=   0.7s\n",
            "[CV 4/5; 23/143] START C=100.0, kernel=linear, tol=0.0001.......................\n",
            "[CV 4/5; 23/143] END C=100.0, kernel=linear, tol=0.0001;, score=0.970 total time=   0.2s\n",
            "[CV 5/5; 23/143] START C=100.0, kernel=linear, tol=0.0001.......................\n",
            "[CV 5/5; 23/143] END C=100.0, kernel=linear, tol=0.0001;, score=0.978 total time=   1.0s\n",
            "[CV 1/5; 24/143] START C=100.0, kernel=linear, tol=1e-05........................\n",
            "[CV 1/5; 24/143] END C=100.0, kernel=linear, tol=1e-05;, score=0.981 total time=   0.9s\n",
            "[CV 2/5; 24/143] START C=100.0, kernel=linear, tol=1e-05........................\n",
            "[CV 2/5; 24/143] END C=100.0, kernel=linear, tol=1e-05;, score=0.993 total time=   0.6s\n",
            "[CV 3/5; 24/143] START C=100.0, kernel=linear, tol=1e-05........................\n",
            "[CV 3/5; 24/143] END C=100.0, kernel=linear, tol=1e-05;, score=0.963 total time=   1.6s\n",
            "[CV 4/5; 24/143] START C=100.0, kernel=linear, tol=1e-05........................\n",
            "[CV 4/5; 24/143] END C=100.0, kernel=linear, tol=1e-05;, score=0.970 total time=   0.3s\n",
            "[CV 5/5; 24/143] START C=100.0, kernel=linear, tol=1e-05........................\n",
            "[CV 5/5; 24/143] END C=100.0, kernel=linear, tol=1e-05;, score=0.978 total time=   1.5s\n",
            "[CV 1/5; 25/143] START C=1000.0, kernel=linear, tol=0.01........................\n",
            "[CV 1/5; 25/143] END C=1000.0, kernel=linear, tol=0.01;, score=0.978 total time=   1.7s\n",
            "[CV 2/5; 25/143] START C=1000.0, kernel=linear, tol=0.01........................\n",
            "[CV 2/5; 25/143] END C=1000.0, kernel=linear, tol=0.01;, score=0.985 total time=   1.7s\n",
            "[CV 3/5; 25/143] START C=1000.0, kernel=linear, tol=0.01........................\n",
            "[CV 3/5; 25/143] END C=1000.0, kernel=linear, tol=0.01;, score=0.974 total time=   1.0s\n",
            "[CV 4/5; 25/143] START C=1000.0, kernel=linear, tol=0.01........................\n",
            "[CV 4/5; 25/143] END C=1000.0, kernel=linear, tol=0.01;, score=0.978 total time=   1.4s\n",
            "[CV 5/5; 25/143] START C=1000.0, kernel=linear, tol=0.01........................\n",
            "[CV 5/5; 25/143] END C=1000.0, kernel=linear, tol=0.01;, score=0.978 total time=   1.1s\n",
            "[CV 1/5; 26/143] START C=1000.0, kernel=linear, tol=0.001.......................\n",
            "[CV 1/5; 26/143] END C=1000.0, kernel=linear, tol=0.001;, score=0.978 total time=   9.4s\n",
            "[CV 2/5; 26/143] START C=1000.0, kernel=linear, tol=0.001.......................\n",
            "[CV 2/5; 26/143] END C=1000.0, kernel=linear, tol=0.001;, score=0.985 total time=   3.5s\n",
            "[CV 3/5; 26/143] START C=1000.0, kernel=linear, tol=0.001.......................\n",
            "[CV 3/5; 26/143] END C=1000.0, kernel=linear, tol=0.001;, score=0.974 total time=   4.0s\n",
            "[CV 4/5; 26/143] START C=1000.0, kernel=linear, tol=0.001.......................\n",
            "[CV 4/5; 26/143] END C=1000.0, kernel=linear, tol=0.001;, score=0.978 total time=   5.4s\n",
            "[CV 5/5; 26/143] START C=1000.0, kernel=linear, tol=0.001.......................\n",
            "[CV 5/5; 26/143] END C=1000.0, kernel=linear, tol=0.001;, score=0.978 total time=   2.6s\n",
            "[CV 1/5; 27/143] START C=1000.0, kernel=linear, tol=0.0001......................\n",
            "[CV 1/5; 27/143] END C=1000.0, kernel=linear, tol=0.0001;, score=0.978 total time=  29.3s\n",
            "[CV 2/5; 27/143] START C=1000.0, kernel=linear, tol=0.0001......................\n",
            "[CV 2/5; 27/143] END C=1000.0, kernel=linear, tol=0.0001;, score=0.985 total time=   7.0s\n",
            "[CV 3/5; 27/143] START C=1000.0, kernel=linear, tol=0.0001......................\n",
            "[CV 3/5; 27/143] END C=1000.0, kernel=linear, tol=0.0001;, score=0.974 total time=   6.9s\n",
            "[CV 4/5; 27/143] START C=1000.0, kernel=linear, tol=0.0001......................\n",
            "[CV 4/5; 27/143] END C=1000.0, kernel=linear, tol=0.0001;, score=0.978 total time=   7.0s\n",
            "[CV 5/5; 27/143] START C=1000.0, kernel=linear, tol=0.0001......................\n",
            "[CV 5/5; 27/143] END C=1000.0, kernel=linear, tol=0.0001;, score=0.978 total time=   3.4s\n",
            "[CV 1/5; 28/143] START C=1000.0, kernel=linear, tol=1e-05.......................\n",
            "[CV 1/5; 28/143] END C=1000.0, kernel=linear, tol=1e-05;, score=0.978 total time=  36.4s\n",
            "[CV 2/5; 28/143] START C=1000.0, kernel=linear, tol=1e-05.......................\n",
            "[CV 2/5; 28/143] END C=1000.0, kernel=linear, tol=1e-05;, score=0.985 total time=   9.5s\n",
            "[CV 3/5; 28/143] START C=1000.0, kernel=linear, tol=1e-05.......................\n",
            "[CV 3/5; 28/143] END C=1000.0, kernel=linear, tol=1e-05;, score=0.974 total time=   9.5s\n",
            "[CV 4/5; 28/143] START C=1000.0, kernel=linear, tol=1e-05.......................\n",
            "[CV 4/5; 28/143] END C=1000.0, kernel=linear, tol=1e-05;, score=0.978 total time=   7.7s\n",
            "[CV 5/5; 28/143] START C=1000.0, kernel=linear, tol=1e-05.......................\n",
            "[CV 5/5; 28/143] END C=1000.0, kernel=linear, tol=1e-05;, score=0.978 total time=   4.4s\n",
            "[CV 1/5; 29/143] START C=10000.0, kernel=linear, tol=0.01.......................\n",
            "[CV 1/5; 29/143] END C=10000.0, kernel=linear, tol=0.01;, score=0.981 total time=  15.1s\n",
            "[CV 2/5; 29/143] START C=10000.0, kernel=linear, tol=0.01.......................\n",
            "[CV 2/5; 29/143] END C=10000.0, kernel=linear, tol=0.01;, score=0.989 total time=  18.6s\n",
            "[CV 3/5; 29/143] START C=10000.0, kernel=linear, tol=0.01.......................\n",
            "[CV 3/5; 29/143] END C=10000.0, kernel=linear, tol=0.01;, score=0.963 total time=   4.7s\n",
            "[CV 4/5; 29/143] START C=10000.0, kernel=linear, tol=0.01.......................\n",
            "[CV 4/5; 29/143] END C=10000.0, kernel=linear, tol=0.01;, score=0.974 total time=  13.4s\n",
            "[CV 5/5; 29/143] START C=10000.0, kernel=linear, tol=0.01.......................\n",
            "[CV 5/5; 29/143] END C=10000.0, kernel=linear, tol=0.01;, score=0.981 total time=   9.1s\n",
            "[CV 1/5; 30/143] START C=10000.0, kernel=linear, tol=0.001......................\n",
            "[CV 1/5; 30/143] END C=10000.0, kernel=linear, tol=0.001;, score=0.985 total time=  23.1s\n",
            "[CV 2/5; 30/143] START C=10000.0, kernel=linear, tol=0.001......................\n",
            "[CV 2/5; 30/143] END C=10000.0, kernel=linear, tol=0.001;, score=0.989 total time=  26.5s\n",
            "[CV 3/5; 30/143] START C=10000.0, kernel=linear, tol=0.001......................\n",
            "[CV 3/5; 30/143] END C=10000.0, kernel=linear, tol=0.001;, score=0.963 total time=  15.6s\n",
            "[CV 4/5; 30/143] START C=10000.0, kernel=linear, tol=0.001......................\n",
            "[CV 4/5; 30/143] END C=10000.0, kernel=linear, tol=0.001;, score=0.974 total time=  19.8s\n",
            "[CV 5/5; 30/143] START C=10000.0, kernel=linear, tol=0.001......................\n",
            "[CV 5/5; 30/143] END C=10000.0, kernel=linear, tol=0.001;, score=0.981 total time=  27.0s\n",
            "[CV 1/5; 31/143] START C=10000.0, kernel=linear, tol=0.0001.....................\n",
            "[CV 1/5; 31/143] END C=10000.0, kernel=linear, tol=0.0001;, score=0.985 total time=  37.7s\n",
            "[CV 2/5; 31/143] START C=10000.0, kernel=linear, tol=0.0001.....................\n",
            "[CV 2/5; 31/143] END C=10000.0, kernel=linear, tol=0.0001;, score=0.989 total time= 1.5min\n",
            "[CV 3/5; 31/143] START C=10000.0, kernel=linear, tol=0.0001.....................\n",
            "[CV 3/5; 31/143] END C=10000.0, kernel=linear, tol=0.0001;, score=0.963 total time=  28.6s\n",
            "[CV 4/5; 31/143] START C=10000.0, kernel=linear, tol=0.0001.....................\n",
            "[CV 4/5; 31/143] END C=10000.0, kernel=linear, tol=0.0001;, score=0.978 total time=  31.9s\n",
            "[CV 5/5; 31/143] START C=10000.0, kernel=linear, tol=0.0001.....................\n",
            "[CV 5/5; 31/143] END C=10000.0, kernel=linear, tol=0.0001;, score=0.981 total time=  25.1s\n",
            "[CV 1/5; 32/143] START C=10000.0, kernel=linear, tol=1e-05......................\n",
            "[CV 1/5; 32/143] END C=10000.0, kernel=linear, tol=1e-05;, score=0.985 total time=  37.0s\n",
            "[CV 2/5; 32/143] START C=10000.0, kernel=linear, tol=1e-05......................\n",
            "[CV 2/5; 32/143] END C=10000.0, kernel=linear, tol=1e-05;, score=0.989 total time= 1.2min\n",
            "[CV 3/5; 32/143] START C=10000.0, kernel=linear, tol=1e-05......................\n",
            "[CV 3/5; 32/143] END C=10000.0, kernel=linear, tol=1e-05;, score=0.963 total time=  47.4s\n",
            "[CV 4/5; 32/143] START C=10000.0, kernel=linear, tol=1e-05......................\n",
            "[CV 4/5; 32/143] END C=10000.0, kernel=linear, tol=1e-05;, score=0.978 total time= 1.2min\n",
            "[CV 5/5; 32/143] START C=10000.0, kernel=linear, tol=1e-05......................\n",
            "[CV 5/5; 32/143] END C=10000.0, kernel=linear, tol=1e-05;, score=0.981 total time=  51.1s\n",
            "[CV 1/5; 33/143] START C=1, kernel=rbf, tol=0.1.................................\n",
            "[CV 1/5; 33/143] END ..C=1, kernel=rbf, tol=0.1;, score=0.552 total time=   0.0s\n",
            "[CV 2/5; 33/143] START C=1, kernel=rbf, tol=0.1.................................\n",
            "[CV 2/5; 33/143] END ..C=1, kernel=rbf, tol=0.1;, score=0.545 total time=   0.0s\n",
            "[CV 3/5; 33/143] START C=1, kernel=rbf, tol=0.1.................................\n",
            "[CV 3/5; 33/143] END ..C=1, kernel=rbf, tol=0.1;, score=0.511 total time=   0.0s\n",
            "[CV 4/5; 33/143] START C=1, kernel=rbf, tol=0.1.................................\n",
            "[CV 4/5; 33/143] END ..C=1, kernel=rbf, tol=0.1;, score=0.530 total time=   0.0s\n",
            "[CV 5/5; 33/143] START C=1, kernel=rbf, tol=0.1.................................\n",
            "[CV 5/5; 33/143] END ..C=1, kernel=rbf, tol=0.1;, score=0.547 total time=   0.0s\n",
            "[CV 1/5; 34/143] START C=1, kernel=rbf, tol=0.01................................\n",
            "[CV 1/5; 34/143] END .C=1, kernel=rbf, tol=0.01;, score=0.552 total time=   0.0s\n",
            "[CV 2/5; 34/143] START C=1, kernel=rbf, tol=0.01................................\n",
            "[CV 2/5; 34/143] END .C=1, kernel=rbf, tol=0.01;, score=0.534 total time=   0.0s\n",
            "[CV 3/5; 34/143] START C=1, kernel=rbf, tol=0.01................................\n",
            "[CV 3/5; 34/143] END .C=1, kernel=rbf, tol=0.01;, score=0.504 total time=   0.0s\n",
            "[CV 4/5; 34/143] START C=1, kernel=rbf, tol=0.01................................\n",
            "[CV 4/5; 34/143] END .C=1, kernel=rbf, tol=0.01;, score=0.530 total time=   0.0s\n",
            "[CV 5/5; 34/143] START C=1, kernel=rbf, tol=0.01................................\n",
            "[CV 5/5; 34/143] END .C=1, kernel=rbf, tol=0.01;, score=0.547 total time=   0.1s\n",
            "[CV 1/5; 35/143] START C=1, kernel=rbf, tol=0.001...............................\n",
            "[CV 1/5; 35/143] END C=1, kernel=rbf, tol=0.001;, score=0.552 total time=   0.0s\n",
            "[CV 2/5; 35/143] START C=1, kernel=rbf, tol=0.001...............................\n",
            "[CV 2/5; 35/143] END C=1, kernel=rbf, tol=0.001;, score=0.534 total time=   0.0s\n",
            "[CV 3/5; 35/143] START C=1, kernel=rbf, tol=0.001...............................\n",
            "[CV 3/5; 35/143] END C=1, kernel=rbf, tol=0.001;, score=0.504 total time=   0.0s\n",
            "[CV 4/5; 35/143] START C=1, kernel=rbf, tol=0.001...............................\n",
            "[CV 4/5; 35/143] END C=1, kernel=rbf, tol=0.001;, score=0.534 total time=   0.0s\n",
            "[CV 5/5; 35/143] START C=1, kernel=rbf, tol=0.001...............................\n",
            "[CV 5/5; 35/143] END C=1, kernel=rbf, tol=0.001;, score=0.547 total time=   0.0s\n",
            "[CV 1/5; 36/143] START C=1, kernel=rbf, tol=0.0001..............................\n",
            "[CV 1/5; 36/143] END C=1, kernel=rbf, tol=0.0001;, score=0.552 total time=   0.0s\n",
            "[CV 2/5; 36/143] START C=1, kernel=rbf, tol=0.0001..............................\n",
            "[CV 2/5; 36/143] END C=1, kernel=rbf, tol=0.0001;, score=0.534 total time=   0.0s\n",
            "[CV 3/5; 36/143] START C=1, kernel=rbf, tol=0.0001..............................\n",
            "[CV 3/5; 36/143] END C=1, kernel=rbf, tol=0.0001;, score=0.504 total time=   0.0s\n",
            "[CV 4/5; 36/143] START C=1, kernel=rbf, tol=0.0001..............................\n",
            "[CV 4/5; 36/143] END C=1, kernel=rbf, tol=0.0001;, score=0.534 total time=   0.0s\n",
            "[CV 5/5; 36/143] START C=1, kernel=rbf, tol=0.0001..............................\n",
            "[CV 5/5; 36/143] END C=1, kernel=rbf, tol=0.0001;, score=0.547 total time=   0.0s\n",
            "[CV 1/5; 37/143] START C=1, kernel=rbf, tol=1e-05...............................\n",
            "[CV 1/5; 37/143] END C=1, kernel=rbf, tol=1e-05;, score=0.552 total time=   0.0s\n",
            "[CV 2/5; 37/143] START C=1, kernel=rbf, tol=1e-05...............................\n",
            "[CV 2/5; 37/143] END C=1, kernel=rbf, tol=1e-05;, score=0.534 total time=   0.0s\n",
            "[CV 3/5; 37/143] START C=1, kernel=rbf, tol=1e-05...............................\n",
            "[CV 3/5; 37/143] END C=1, kernel=rbf, tol=1e-05;, score=0.504 total time=   0.0s\n",
            "[CV 4/5; 37/143] START C=1, kernel=rbf, tol=1e-05...............................\n",
            "[CV 4/5; 37/143] END C=1, kernel=rbf, tol=1e-05;, score=0.534 total time=   0.1s\n",
            "[CV 5/5; 37/143] START C=1, kernel=rbf, tol=1e-05...............................\n",
            "[CV 5/5; 37/143] END C=1, kernel=rbf, tol=1e-05;, score=0.547 total time=   0.0s\n",
            "[CV 1/5; 38/143] START C=1, kernel=rbf, tol=scale...............................\n",
            "[CV 1/5; 38/143] END ..C=1, kernel=rbf, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 2/5; 38/143] START C=1, kernel=rbf, tol=scale...............................\n",
            "[CV 2/5; 38/143] END ..C=1, kernel=rbf, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 3/5; 38/143] START C=1, kernel=rbf, tol=scale...............................\n",
            "[CV 3/5; 38/143] END ..C=1, kernel=rbf, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 4/5; 38/143] START C=1, kernel=rbf, tol=scale...............................\n",
            "[CV 4/5; 38/143] END ..C=1, kernel=rbf, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 5/5; 38/143] START C=1, kernel=rbf, tol=scale...............................\n",
            "[CV 5/5; 38/143] END ..C=1, kernel=rbf, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 1/5; 39/143] START C=10, kernel=rbf, tol=0.1................................\n",
            "[CV 1/5; 39/143] END .C=10, kernel=rbf, tol=0.1;, score=0.672 total time=   0.1s\n",
            "[CV 2/5; 39/143] START C=10, kernel=rbf, tol=0.1................................\n",
            "[CV 2/5; 39/143] END .C=10, kernel=rbf, tol=0.1;, score=0.660 total time=   0.0s\n",
            "[CV 3/5; 39/143] START C=10, kernel=rbf, tol=0.1................................\n",
            "[CV 3/5; 39/143] END .C=10, kernel=rbf, tol=0.1;, score=0.653 total time=   0.0s\n",
            "[CV 4/5; 39/143] START C=10, kernel=rbf, tol=0.1................................\n",
            "[CV 4/5; 39/143] END .C=10, kernel=rbf, tol=0.1;, score=0.657 total time=   0.0s\n",
            "[CV 5/5; 39/143] START C=10, kernel=rbf, tol=0.1................................\n",
            "[CV 5/5; 39/143] END .C=10, kernel=rbf, tol=0.1;, score=0.685 total time=   0.1s\n",
            "[CV 1/5; 40/143] START C=10, kernel=rbf, tol=0.01...............................\n",
            "[CV 1/5; 40/143] END C=10, kernel=rbf, tol=0.01;, score=0.668 total time=   0.0s\n",
            "[CV 2/5; 40/143] START C=10, kernel=rbf, tol=0.01...............................\n",
            "[CV 2/5; 40/143] END C=10, kernel=rbf, tol=0.01;, score=0.660 total time=   0.0s\n",
            "[CV 3/5; 40/143] START C=10, kernel=rbf, tol=0.01...............................\n",
            "[CV 3/5; 40/143] END C=10, kernel=rbf, tol=0.01;, score=0.657 total time=   0.0s\n",
            "[CV 4/5; 40/143] START C=10, kernel=rbf, tol=0.01...............................\n",
            "[CV 4/5; 40/143] END C=10, kernel=rbf, tol=0.01;, score=0.660 total time=   0.0s\n",
            "[CV 5/5; 40/143] START C=10, kernel=rbf, tol=0.01...............................\n",
            "[CV 5/5; 40/143] END C=10, kernel=rbf, tol=0.01;, score=0.700 total time=   0.0s\n",
            "[CV 1/5; 41/143] START C=10, kernel=rbf, tol=0.001..............................\n",
            "[CV 1/5; 41/143] END C=10, kernel=rbf, tol=0.001;, score=0.668 total time=   0.1s\n",
            "[CV 2/5; 41/143] START C=10, kernel=rbf, tol=0.001..............................\n",
            "[CV 2/5; 41/143] END C=10, kernel=rbf, tol=0.001;, score=0.660 total time=   0.0s\n",
            "[CV 3/5; 41/143] START C=10, kernel=rbf, tol=0.001..............................\n",
            "[CV 3/5; 41/143] END C=10, kernel=rbf, tol=0.001;, score=0.657 total time=   0.1s\n",
            "[CV 4/5; 41/143] START C=10, kernel=rbf, tol=0.001..............................\n",
            "[CV 4/5; 41/143] END C=10, kernel=rbf, tol=0.001;, score=0.660 total time=   0.0s\n",
            "[CV 5/5; 41/143] START C=10, kernel=rbf, tol=0.001..............................\n",
            "[CV 5/5; 41/143] END C=10, kernel=rbf, tol=0.001;, score=0.697 total time=   0.0s\n",
            "[CV 1/5; 42/143] START C=10, kernel=rbf, tol=0.0001.............................\n",
            "[CV 1/5; 42/143] END C=10, kernel=rbf, tol=0.0001;, score=0.668 total time=   0.0s\n",
            "[CV 2/5; 42/143] START C=10, kernel=rbf, tol=0.0001.............................\n",
            "[CV 2/5; 42/143] END C=10, kernel=rbf, tol=0.0001;, score=0.660 total time=   0.0s\n",
            "[CV 3/5; 42/143] START C=10, kernel=rbf, tol=0.0001.............................\n",
            "[CV 3/5; 42/143] END C=10, kernel=rbf, tol=0.0001;, score=0.657 total time=   0.0s\n",
            "[CV 4/5; 42/143] START C=10, kernel=rbf, tol=0.0001.............................\n",
            "[CV 4/5; 42/143] END C=10, kernel=rbf, tol=0.0001;, score=0.660 total time=   0.1s\n",
            "[CV 5/5; 42/143] START C=10, kernel=rbf, tol=0.0001.............................\n",
            "[CV 5/5; 42/143] END C=10, kernel=rbf, tol=0.0001;, score=0.697 total time=   0.0s\n",
            "[CV 1/5; 43/143] START C=10, kernel=rbf, tol=1e-05..............................\n",
            "[CV 1/5; 43/143] END C=10, kernel=rbf, tol=1e-05;, score=0.668 total time=   0.0s\n",
            "[CV 2/5; 43/143] START C=10, kernel=rbf, tol=1e-05..............................\n",
            "[CV 2/5; 43/143] END C=10, kernel=rbf, tol=1e-05;, score=0.660 total time=   0.0s\n",
            "[CV 3/5; 43/143] START C=10, kernel=rbf, tol=1e-05..............................\n",
            "[CV 3/5; 43/143] END C=10, kernel=rbf, tol=1e-05;, score=0.657 total time=   0.0s\n",
            "[CV 4/5; 43/143] START C=10, kernel=rbf, tol=1e-05..............................\n",
            "[CV 4/5; 43/143] END C=10, kernel=rbf, tol=1e-05;, score=0.660 total time=   0.0s\n",
            "[CV 5/5; 43/143] START C=10, kernel=rbf, tol=1e-05..............................\n",
            "[CV 5/5; 43/143] END C=10, kernel=rbf, tol=1e-05;, score=0.697 total time=   0.1s\n",
            "[CV 1/5; 44/143] START C=10, kernel=rbf, tol=scale..............................\n",
            "[CV 1/5; 44/143] END .C=10, kernel=rbf, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 2/5; 44/143] START C=10, kernel=rbf, tol=scale..............................\n",
            "[CV 2/5; 44/143] END .C=10, kernel=rbf, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 3/5; 44/143] START C=10, kernel=rbf, tol=scale..............................\n",
            "[CV 3/5; 44/143] END .C=10, kernel=rbf, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 4/5; 44/143] START C=10, kernel=rbf, tol=scale..............................\n",
            "[CV 4/5; 44/143] END .C=10, kernel=rbf, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 5/5; 44/143] START C=10, kernel=rbf, tol=scale..............................\n",
            "[CV 5/5; 44/143] END .C=10, kernel=rbf, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 1/5; 45/143] START C=100.0, kernel=rbf, tol=0.1.............................\n",
            "[CV 1/5; 45/143] END C=100.0, kernel=rbf, tol=0.1;, score=0.828 total time=   0.0s\n",
            "[CV 2/5; 45/143] START C=100.0, kernel=rbf, tol=0.1.............................\n",
            "[CV 2/5; 45/143] END C=100.0, kernel=rbf, tol=0.1;, score=0.772 total time=   0.1s\n",
            "[CV 3/5; 45/143] START C=100.0, kernel=rbf, tol=0.1.............................\n",
            "[CV 3/5; 45/143] END C=100.0, kernel=rbf, tol=0.1;, score=0.757 total time=   0.0s\n",
            "[CV 4/5; 45/143] START C=100.0, kernel=rbf, tol=0.1.............................\n",
            "[CV 4/5; 45/143] END C=100.0, kernel=rbf, tol=0.1;, score=0.806 total time=   0.0s\n",
            "[CV 5/5; 45/143] START C=100.0, kernel=rbf, tol=0.1.............................\n",
            "[CV 5/5; 45/143] END C=100.0, kernel=rbf, tol=0.1;, score=0.809 total time=   0.0s\n",
            "[CV 1/5; 46/143] START C=100.0, kernel=rbf, tol=0.01............................\n",
            "[CV 1/5; 46/143] END C=100.0, kernel=rbf, tol=0.01;, score=0.821 total time=   0.0s\n",
            "[CV 2/5; 46/143] START C=100.0, kernel=rbf, tol=0.01............................\n",
            "[CV 2/5; 46/143] END C=100.0, kernel=rbf, tol=0.01;, score=0.784 total time=   0.0s\n",
            "[CV 3/5; 46/143] START C=100.0, kernel=rbf, tol=0.01............................\n",
            "[CV 3/5; 46/143] END C=100.0, kernel=rbf, tol=0.01;, score=0.761 total time=   0.0s\n",
            "[CV 4/5; 46/143] START C=100.0, kernel=rbf, tol=0.01............................\n",
            "[CV 4/5; 46/143] END C=100.0, kernel=rbf, tol=0.01;, score=0.810 total time=   0.0s\n",
            "[CV 5/5; 46/143] START C=100.0, kernel=rbf, tol=0.01............................\n",
            "[CV 5/5; 46/143] END C=100.0, kernel=rbf, tol=0.01;, score=0.809 total time=   0.0s\n",
            "[CV 1/5; 47/143] START C=100.0, kernel=rbf, tol=0.001...........................\n",
            "[CV 1/5; 47/143] END C=100.0, kernel=rbf, tol=0.001;, score=0.821 total time=   0.0s\n",
            "[CV 2/5; 47/143] START C=100.0, kernel=rbf, tol=0.001...........................\n",
            "[CV 2/5; 47/143] END C=100.0, kernel=rbf, tol=0.001;, score=0.780 total time=   0.0s\n",
            "[CV 3/5; 47/143] START C=100.0, kernel=rbf, tol=0.001...........................\n",
            "[CV 3/5; 47/143] END C=100.0, kernel=rbf, tol=0.001;, score=0.761 total time=   0.0s\n",
            "[CV 4/5; 47/143] START C=100.0, kernel=rbf, tol=0.001...........................\n",
            "[CV 4/5; 47/143] END C=100.0, kernel=rbf, tol=0.001;, score=0.810 total time=   0.0s\n",
            "[CV 5/5; 47/143] START C=100.0, kernel=rbf, tol=0.001...........................\n",
            "[CV 5/5; 47/143] END C=100.0, kernel=rbf, tol=0.001;, score=0.809 total time=   0.0s\n",
            "[CV 1/5; 48/143] START C=100.0, kernel=rbf, tol=0.0001..........................\n",
            "[CV 1/5; 48/143] END C=100.0, kernel=rbf, tol=0.0001;, score=0.821 total time=   0.0s\n",
            "[CV 2/5; 48/143] START C=100.0, kernel=rbf, tol=0.0001..........................\n",
            "[CV 2/5; 48/143] END C=100.0, kernel=rbf, tol=0.0001;, score=0.780 total time=   0.1s\n",
            "[CV 3/5; 48/143] START C=100.0, kernel=rbf, tol=0.0001..........................\n",
            "[CV 3/5; 48/143] END C=100.0, kernel=rbf, tol=0.0001;, score=0.761 total time=   0.0s\n",
            "[CV 4/5; 48/143] START C=100.0, kernel=rbf, tol=0.0001..........................\n",
            "[CV 4/5; 48/143] END C=100.0, kernel=rbf, tol=0.0001;, score=0.813 total time=   0.0s\n",
            "[CV 5/5; 48/143] START C=100.0, kernel=rbf, tol=0.0001..........................\n",
            "[CV 5/5; 48/143] END C=100.0, kernel=rbf, tol=0.0001;, score=0.809 total time=   0.1s\n",
            "[CV 1/5; 49/143] START C=100.0, kernel=rbf, tol=1e-05...........................\n",
            "[CV 1/5; 49/143] END C=100.0, kernel=rbf, tol=1e-05;, score=0.821 total time=   0.1s\n",
            "[CV 2/5; 49/143] START C=100.0, kernel=rbf, tol=1e-05...........................\n",
            "[CV 2/5; 49/143] END C=100.0, kernel=rbf, tol=1e-05;, score=0.780 total time=   0.0s\n",
            "[CV 3/5; 49/143] START C=100.0, kernel=rbf, tol=1e-05...........................\n",
            "[CV 3/5; 49/143] END C=100.0, kernel=rbf, tol=1e-05;, score=0.761 total time=   0.1s\n",
            "[CV 4/5; 49/143] START C=100.0, kernel=rbf, tol=1e-05...........................\n",
            "[CV 4/5; 49/143] END C=100.0, kernel=rbf, tol=1e-05;, score=0.813 total time=   0.1s\n",
            "[CV 5/5; 49/143] START C=100.0, kernel=rbf, tol=1e-05...........................\n",
            "[CV 5/5; 49/143] END C=100.0, kernel=rbf, tol=1e-05;, score=0.809 total time=   0.0s\n",
            "[CV 1/5; 50/143] START C=100.0, kernel=rbf, tol=scale...........................\n",
            "[CV 1/5; 50/143] END C=100.0, kernel=rbf, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 2/5; 50/143] START C=100.0, kernel=rbf, tol=scale...........................\n",
            "[CV 2/5; 50/143] END C=100.0, kernel=rbf, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 3/5; 50/143] START C=100.0, kernel=rbf, tol=scale...........................\n",
            "[CV 3/5; 50/143] END C=100.0, kernel=rbf, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 4/5; 50/143] START C=100.0, kernel=rbf, tol=scale...........................\n",
            "[CV 4/5; 50/143] END C=100.0, kernel=rbf, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 5/5; 50/143] START C=100.0, kernel=rbf, tol=scale...........................\n",
            "[CV 5/5; 50/143] END C=100.0, kernel=rbf, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 1/5; 51/143] START C=1000.0, kernel=rbf, tol=0.1............................\n",
            "[CV 1/5; 51/143] END C=1000.0, kernel=rbf, tol=0.1;, score=0.862 total time=   0.0s\n",
            "[CV 2/5; 51/143] START C=1000.0, kernel=rbf, tol=0.1............................\n",
            "[CV 2/5; 51/143] END C=1000.0, kernel=rbf, tol=0.1;, score=0.836 total time=   0.0s\n",
            "[CV 3/5; 51/143] START C=1000.0, kernel=rbf, tol=0.1............................\n",
            "[CV 3/5; 51/143] END C=1000.0, kernel=rbf, tol=0.1;, score=0.840 total time=   0.1s\n",
            "[CV 4/5; 51/143] START C=1000.0, kernel=rbf, tol=0.1............................\n",
            "[CV 4/5; 51/143] END C=1000.0, kernel=rbf, tol=0.1;, score=0.884 total time=   0.0s\n",
            "[CV 5/5; 51/143] START C=1000.0, kernel=rbf, tol=0.1............................\n",
            "[CV 5/5; 51/143] END C=1000.0, kernel=rbf, tol=0.1;, score=0.846 total time=   0.1s\n",
            "[CV 1/5; 52/143] START C=1000.0, kernel=rbf, tol=0.01...........................\n",
            "[CV 1/5; 52/143] END C=1000.0, kernel=rbf, tol=0.01;, score=0.862 total time=   0.1s\n",
            "[CV 2/5; 52/143] START C=1000.0, kernel=rbf, tol=0.01...........................\n",
            "[CV 2/5; 52/143] END C=1000.0, kernel=rbf, tol=0.01;, score=0.847 total time=   0.1s\n",
            "[CV 3/5; 52/143] START C=1000.0, kernel=rbf, tol=0.01...........................\n",
            "[CV 3/5; 52/143] END C=1000.0, kernel=rbf, tol=0.01;, score=0.836 total time=   0.1s\n",
            "[CV 4/5; 52/143] START C=1000.0, kernel=rbf, tol=0.01...........................\n",
            "[CV 4/5; 52/143] END C=1000.0, kernel=rbf, tol=0.01;, score=0.881 total time=   0.1s\n",
            "[CV 5/5; 52/143] START C=1000.0, kernel=rbf, tol=0.01...........................\n",
            "[CV 5/5; 52/143] END C=1000.0, kernel=rbf, tol=0.01;, score=0.846 total time=   0.1s\n",
            "[CV 1/5; 53/143] START C=1000.0, kernel=rbf, tol=0.001..........................\n",
            "[CV 1/5; 53/143] END C=1000.0, kernel=rbf, tol=0.001;, score=0.862 total time=   0.2s\n",
            "[CV 2/5; 53/143] START C=1000.0, kernel=rbf, tol=0.001..........................\n",
            "[CV 2/5; 53/143] END C=1000.0, kernel=rbf, tol=0.001;, score=0.847 total time=   0.1s\n",
            "[CV 3/5; 53/143] START C=1000.0, kernel=rbf, tol=0.001..........................\n",
            "[CV 3/5; 53/143] END C=1000.0, kernel=rbf, tol=0.001;, score=0.836 total time=   0.1s\n",
            "[CV 4/5; 53/143] START C=1000.0, kernel=rbf, tol=0.001..........................\n",
            "[CV 4/5; 53/143] END C=1000.0, kernel=rbf, tol=0.001;, score=0.884 total time=   0.1s\n",
            "[CV 5/5; 53/143] START C=1000.0, kernel=rbf, tol=0.001..........................\n",
            "[CV 5/5; 53/143] END C=1000.0, kernel=rbf, tol=0.001;, score=0.846 total time=   0.1s\n",
            "[CV 1/5; 54/143] START C=1000.0, kernel=rbf, tol=0.0001.........................\n",
            "[CV 1/5; 54/143] END C=1000.0, kernel=rbf, tol=0.0001;, score=0.862 total time=   0.2s\n",
            "[CV 2/5; 54/143] START C=1000.0, kernel=rbf, tol=0.0001.........................\n",
            "[CV 2/5; 54/143] END C=1000.0, kernel=rbf, tol=0.0001;, score=0.847 total time=   0.3s\n",
            "[CV 3/5; 54/143] START C=1000.0, kernel=rbf, tol=0.0001.........................\n",
            "[CV 3/5; 54/143] END C=1000.0, kernel=rbf, tol=0.0001;, score=0.836 total time=   0.2s\n",
            "[CV 4/5; 54/143] START C=1000.0, kernel=rbf, tol=0.0001.........................\n",
            "[CV 4/5; 54/143] END C=1000.0, kernel=rbf, tol=0.0001;, score=0.884 total time=   0.2s\n",
            "[CV 5/5; 54/143] START C=1000.0, kernel=rbf, tol=0.0001.........................\n",
            "[CV 5/5; 54/143] END C=1000.0, kernel=rbf, tol=0.0001;, score=0.846 total time=   0.2s\n",
            "[CV 1/5; 55/143] START C=1000.0, kernel=rbf, tol=1e-05..........................\n",
            "[CV 1/5; 55/143] END C=1000.0, kernel=rbf, tol=1e-05;, score=0.862 total time=   0.4s\n",
            "[CV 2/5; 55/143] START C=1000.0, kernel=rbf, tol=1e-05..........................\n",
            "[CV 2/5; 55/143] END C=1000.0, kernel=rbf, tol=1e-05;, score=0.847 total time=   0.3s\n",
            "[CV 3/5; 55/143] START C=1000.0, kernel=rbf, tol=1e-05..........................\n",
            "[CV 3/5; 55/143] END C=1000.0, kernel=rbf, tol=1e-05;, score=0.836 total time=   0.2s\n",
            "[CV 4/5; 55/143] START C=1000.0, kernel=rbf, tol=1e-05..........................\n",
            "[CV 4/5; 55/143] END C=1000.0, kernel=rbf, tol=1e-05;, score=0.884 total time=   0.2s\n",
            "[CV 5/5; 55/143] START C=1000.0, kernel=rbf, tol=1e-05..........................\n",
            "[CV 5/5; 55/143] END C=1000.0, kernel=rbf, tol=1e-05;, score=0.846 total time=   0.3s\n",
            "[CV 1/5; 56/143] START C=1000.0, kernel=rbf, tol=scale..........................\n",
            "[CV 1/5; 56/143] END C=1000.0, kernel=rbf, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 2/5; 56/143] START C=1000.0, kernel=rbf, tol=scale..........................\n",
            "[CV 2/5; 56/143] END C=1000.0, kernel=rbf, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 3/5; 56/143] START C=1000.0, kernel=rbf, tol=scale..........................\n",
            "[CV 3/5; 56/143] END C=1000.0, kernel=rbf, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 4/5; 56/143] START C=1000.0, kernel=rbf, tol=scale..........................\n",
            "[CV 4/5; 56/143] END C=1000.0, kernel=rbf, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 5/5; 56/143] START C=1000.0, kernel=rbf, tol=scale..........................\n",
            "[CV 5/5; 56/143] END C=1000.0, kernel=rbf, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 1/5; 57/143] START C=10000.0, kernel=rbf, tol=0.1...........................\n",
            "[CV 1/5; 57/143] END C=10000.0, kernel=rbf, tol=0.1;, score=0.854 total time=   0.1s\n",
            "[CV 2/5; 57/143] START C=10000.0, kernel=rbf, tol=0.1...........................\n",
            "[CV 2/5; 57/143] END C=10000.0, kernel=rbf, tol=0.1;, score=0.873 total time=   0.2s\n",
            "[CV 3/5; 57/143] START C=10000.0, kernel=rbf, tol=0.1...........................\n",
            "[CV 3/5; 57/143] END C=10000.0, kernel=rbf, tol=0.1;, score=0.877 total time=   0.1s\n",
            "[CV 4/5; 57/143] START C=10000.0, kernel=rbf, tol=0.1...........................\n",
            "[CV 4/5; 57/143] END C=10000.0, kernel=rbf, tol=0.1;, score=0.884 total time=   0.1s\n",
            "[CV 5/5; 57/143] START C=10000.0, kernel=rbf, tol=0.1...........................\n",
            "[CV 5/5; 57/143] END C=10000.0, kernel=rbf, tol=0.1;, score=0.891 total time=   0.1s\n",
            "[CV 1/5; 58/143] START C=10000.0, kernel=rbf, tol=0.01..........................\n",
            "[CV 1/5; 58/143] END C=10000.0, kernel=rbf, tol=0.01;, score=0.854 total time=   0.2s\n",
            "[CV 2/5; 58/143] START C=10000.0, kernel=rbf, tol=0.01..........................\n",
            "[CV 2/5; 58/143] END C=10000.0, kernel=rbf, tol=0.01;, score=0.873 total time=   0.2s\n",
            "[CV 3/5; 58/143] START C=10000.0, kernel=rbf, tol=0.01..........................\n",
            "[CV 3/5; 58/143] END C=10000.0, kernel=rbf, tol=0.01;, score=0.881 total time=   0.2s\n",
            "[CV 4/5; 58/143] START C=10000.0, kernel=rbf, tol=0.01..........................\n",
            "[CV 4/5; 58/143] END C=10000.0, kernel=rbf, tol=0.01;, score=0.877 total time=   0.2s\n",
            "[CV 5/5; 58/143] START C=10000.0, kernel=rbf, tol=0.01..........................\n",
            "[CV 5/5; 58/143] END C=10000.0, kernel=rbf, tol=0.01;, score=0.891 total time=   0.2s\n",
            "[CV 1/5; 59/143] START C=10000.0, kernel=rbf, tol=0.001.........................\n",
            "[CV 1/5; 59/143] END C=10000.0, kernel=rbf, tol=0.001;, score=0.854 total time=   0.3s\n",
            "[CV 2/5; 59/143] START C=10000.0, kernel=rbf, tol=0.001.........................\n",
            "[CV 2/5; 59/143] END C=10000.0, kernel=rbf, tol=0.001;, score=0.873 total time=   0.4s\n",
            "[CV 3/5; 59/143] START C=10000.0, kernel=rbf, tol=0.001.........................\n",
            "[CV 3/5; 59/143] END C=10000.0, kernel=rbf, tol=0.001;, score=0.877 total time=   0.4s\n",
            "[CV 4/5; 59/143] START C=10000.0, kernel=rbf, tol=0.001.........................\n",
            "[CV 4/5; 59/143] END C=10000.0, kernel=rbf, tol=0.001;, score=0.877 total time=   0.4s\n",
            "[CV 5/5; 59/143] START C=10000.0, kernel=rbf, tol=0.001.........................\n",
            "[CV 5/5; 59/143] END C=10000.0, kernel=rbf, tol=0.001;, score=0.891 total time=   0.3s\n",
            "[CV 1/5; 60/143] START C=10000.0, kernel=rbf, tol=0.0001........................\n",
            "[CV 1/5; 60/143] END C=10000.0, kernel=rbf, tol=0.0001;, score=0.854 total time=   0.5s\n",
            "[CV 2/5; 60/143] START C=10000.0, kernel=rbf, tol=0.0001........................\n",
            "[CV 2/5; 60/143] END C=10000.0, kernel=rbf, tol=0.0001;, score=0.873 total time=   0.6s\n",
            "[CV 3/5; 60/143] START C=10000.0, kernel=rbf, tol=0.0001........................\n",
            "[CV 3/5; 60/143] END C=10000.0, kernel=rbf, tol=0.0001;, score=0.877 total time=   0.6s\n",
            "[CV 4/5; 60/143] START C=10000.0, kernel=rbf, tol=0.0001........................\n",
            "[CV 4/5; 60/143] END C=10000.0, kernel=rbf, tol=0.0001;, score=0.877 total time=   0.7s\n",
            "[CV 5/5; 60/143] START C=10000.0, kernel=rbf, tol=0.0001........................\n",
            "[CV 5/5; 60/143] END C=10000.0, kernel=rbf, tol=0.0001;, score=0.891 total time=   0.6s\n",
            "[CV 1/5; 61/143] START C=10000.0, kernel=rbf, tol=1e-05.........................\n",
            "[CV 1/5; 61/143] END C=10000.0, kernel=rbf, tol=1e-05;, score=0.854 total time=   0.7s\n",
            "[CV 2/5; 61/143] START C=10000.0, kernel=rbf, tol=1e-05.........................\n",
            "[CV 2/5; 61/143] END C=10000.0, kernel=rbf, tol=1e-05;, score=0.873 total time=   1.0s\n",
            "[CV 3/5; 61/143] START C=10000.0, kernel=rbf, tol=1e-05.........................\n",
            "[CV 3/5; 61/143] END C=10000.0, kernel=rbf, tol=1e-05;, score=0.877 total time=   0.9s\n",
            "[CV 4/5; 61/143] START C=10000.0, kernel=rbf, tol=1e-05.........................\n",
            "[CV 4/5; 61/143] END C=10000.0, kernel=rbf, tol=1e-05;, score=0.877 total time=   0.9s\n",
            "[CV 5/5; 61/143] START C=10000.0, kernel=rbf, tol=1e-05.........................\n",
            "[CV 5/5; 61/143] END C=10000.0, kernel=rbf, tol=1e-05;, score=0.891 total time=   0.8s\n",
            "[CV 1/5; 62/143] START C=10000.0, kernel=rbf, tol=scale.........................\n",
            "[CV 1/5; 62/143] END C=10000.0, kernel=rbf, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 2/5; 62/143] START C=10000.0, kernel=rbf, tol=scale.........................\n",
            "[CV 2/5; 62/143] END C=10000.0, kernel=rbf, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 3/5; 62/143] START C=10000.0, kernel=rbf, tol=scale.........................\n",
            "[CV 3/5; 62/143] END C=10000.0, kernel=rbf, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 4/5; 62/143] START C=10000.0, kernel=rbf, tol=scale.........................\n",
            "[CV 4/5; 62/143] END C=10000.0, kernel=rbf, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 5/5; 62/143] START C=10000.0, kernel=rbf, tol=scale.........................\n",
            "[CV 5/5; 62/143] END C=10000.0, kernel=rbf, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 1/5; 63/143] START C=100000.0, kernel=rbf, tol=0.1..........................\n",
            "[CV 1/5; 63/143] END C=100000.0, kernel=rbf, tol=0.1;, score=0.866 total time=   0.2s\n",
            "[CV 2/5; 63/143] START C=100000.0, kernel=rbf, tol=0.1..........................\n",
            "[CV 2/5; 63/143] END C=100000.0, kernel=rbf, tol=0.1;, score=0.896 total time=   0.3s\n",
            "[CV 3/5; 63/143] START C=100000.0, kernel=rbf, tol=0.1..........................\n",
            "[CV 3/5; 63/143] END C=100000.0, kernel=rbf, tol=0.1;, score=0.851 total time=   0.2s\n",
            "[CV 4/5; 63/143] START C=100000.0, kernel=rbf, tol=0.1..........................\n",
            "[CV 4/5; 63/143] END C=100000.0, kernel=rbf, tol=0.1;, score=0.877 total time=   0.3s\n",
            "[CV 5/5; 63/143] START C=100000.0, kernel=rbf, tol=0.1..........................\n",
            "[CV 5/5; 63/143] END C=100000.0, kernel=rbf, tol=0.1;, score=0.876 total time=   0.2s\n",
            "[CV 1/5; 64/143] START C=100000.0, kernel=rbf, tol=0.01.........................\n",
            "[CV 1/5; 64/143] END C=100000.0, kernel=rbf, tol=0.01;, score=0.873 total time=   0.3s\n",
            "[CV 2/5; 64/143] START C=100000.0, kernel=rbf, tol=0.01.........................\n",
            "[CV 2/5; 64/143] END C=100000.0, kernel=rbf, tol=0.01;, score=0.896 total time=   0.4s\n",
            "[CV 3/5; 64/143] START C=100000.0, kernel=rbf, tol=0.01.........................\n",
            "[CV 3/5; 64/143] END C=100000.0, kernel=rbf, tol=0.01;, score=0.847 total time=   0.3s\n",
            "[CV 4/5; 64/143] START C=100000.0, kernel=rbf, tol=0.01.........................\n",
            "[CV 4/5; 64/143] END C=100000.0, kernel=rbf, tol=0.01;, score=0.877 total time=   0.4s\n",
            "[CV 5/5; 64/143] START C=100000.0, kernel=rbf, tol=0.01.........................\n",
            "[CV 5/5; 64/143] END C=100000.0, kernel=rbf, tol=0.01;, score=0.876 total time=   0.4s\n",
            "[CV 1/5; 65/143] START C=100000.0, kernel=rbf, tol=0.001........................\n",
            "[CV 1/5; 65/143] END C=100000.0, kernel=rbf, tol=0.001;, score=0.877 total time=   0.4s\n",
            "[CV 2/5; 65/143] START C=100000.0, kernel=rbf, tol=0.001........................\n",
            "[CV 2/5; 65/143] END C=100000.0, kernel=rbf, tol=0.001;, score=0.896 total time=   0.8s\n",
            "[CV 3/5; 65/143] START C=100000.0, kernel=rbf, tol=0.001........................\n",
            "[CV 3/5; 65/143] END C=100000.0, kernel=rbf, tol=0.001;, score=0.847 total time=   0.5s\n",
            "[CV 4/5; 65/143] START C=100000.0, kernel=rbf, tol=0.001........................\n",
            "[CV 4/5; 65/143] END C=100000.0, kernel=rbf, tol=0.001;, score=0.877 total time=   0.8s\n",
            "[CV 5/5; 65/143] START C=100000.0, kernel=rbf, tol=0.001........................\n",
            "[CV 5/5; 65/143] END C=100000.0, kernel=rbf, tol=0.001;, score=0.876 total time=   0.8s\n",
            "[CV 1/5; 66/143] START C=100000.0, kernel=rbf, tol=0.0001.......................\n",
            "[CV 1/5; 66/143] END C=100000.0, kernel=rbf, tol=0.0001;, score=0.877 total time=   0.8s\n",
            "[CV 2/5; 66/143] START C=100000.0, kernel=rbf, tol=0.0001.......................\n",
            "[CV 2/5; 66/143] END C=100000.0, kernel=rbf, tol=0.0001;, score=0.896 total time=   1.5s\n",
            "[CV 3/5; 66/143] START C=100000.0, kernel=rbf, tol=0.0001.......................\n",
            "[CV 3/5; 66/143] END C=100000.0, kernel=rbf, tol=0.0001;, score=0.847 total time=   0.8s\n",
            "[CV 4/5; 66/143] START C=100000.0, kernel=rbf, tol=0.0001.......................\n",
            "[CV 4/5; 66/143] END C=100000.0, kernel=rbf, tol=0.0001;, score=0.877 total time=   1.5s\n",
            "[CV 5/5; 66/143] START C=100000.0, kernel=rbf, tol=0.0001.......................\n",
            "[CV 5/5; 66/143] END C=100000.0, kernel=rbf, tol=0.0001;, score=0.876 total time=   1.1s\n",
            "[CV 1/5; 67/143] START C=100000.0, kernel=rbf, tol=1e-05........................\n",
            "[CV 1/5; 67/143] END C=100000.0, kernel=rbf, tol=1e-05;, score=0.877 total time=   1.1s\n",
            "[CV 2/5; 67/143] START C=100000.0, kernel=rbf, tol=1e-05........................\n",
            "[CV 2/5; 67/143] END C=100000.0, kernel=rbf, tol=1e-05;, score=0.896 total time=   2.4s\n",
            "[CV 3/5; 67/143] START C=100000.0, kernel=rbf, tol=1e-05........................\n",
            "[CV 3/5; 67/143] END C=100000.0, kernel=rbf, tol=1e-05;, score=0.847 total time=   1.1s\n",
            "[CV 4/5; 67/143] START C=100000.0, kernel=rbf, tol=1e-05........................\n",
            "[CV 4/5; 67/143] END C=100000.0, kernel=rbf, tol=1e-05;, score=0.877 total time=   2.0s\n",
            "[CV 5/5; 67/143] START C=100000.0, kernel=rbf, tol=1e-05........................\n",
            "[CV 5/5; 67/143] END C=100000.0, kernel=rbf, tol=1e-05;, score=0.876 total time=   1.6s\n",
            "[CV 1/5; 68/143] START C=100000.0, kernel=rbf, tol=scale........................\n",
            "[CV 1/5; 68/143] END C=100000.0, kernel=rbf, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 2/5; 68/143] START C=100000.0, kernel=rbf, tol=scale........................\n",
            "[CV 2/5; 68/143] END C=100000.0, kernel=rbf, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 3/5; 68/143] START C=100000.0, kernel=rbf, tol=scale........................\n",
            "[CV 3/5; 68/143] END C=100000.0, kernel=rbf, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 4/5; 68/143] START C=100000.0, kernel=rbf, tol=scale........................\n",
            "[CV 4/5; 68/143] END C=100000.0, kernel=rbf, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 5/5; 68/143] START C=100000.0, kernel=rbf, tol=scale........................\n",
            "[CV 5/5; 68/143] END C=100000.0, kernel=rbf, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 1/5; 69/143] START C=1, degree=2, kernel=poly, tol=0.01.....................\n",
            "[CV 1/5; 69/143] END C=1, degree=2, kernel=poly, tol=0.01;, score=0.563 total time=   0.0s\n",
            "[CV 2/5; 69/143] START C=1, degree=2, kernel=poly, tol=0.01.....................\n",
            "[CV 2/5; 69/143] END C=1, degree=2, kernel=poly, tol=0.01;, score=0.563 total time=   0.0s\n",
            "[CV 3/5; 69/143] START C=1, degree=2, kernel=poly, tol=0.01.....................\n",
            "[CV 3/5; 69/143] END C=1, degree=2, kernel=poly, tol=0.01;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 69/143] START C=1, degree=2, kernel=poly, tol=0.01.....................\n",
            "[CV 4/5; 69/143] END C=1, degree=2, kernel=poly, tol=0.01;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 69/143] START C=1, degree=2, kernel=poly, tol=0.01.....................\n",
            "[CV 5/5; 69/143] END C=1, degree=2, kernel=poly, tol=0.01;, score=0.528 total time=   0.0s\n",
            "[CV 1/5; 70/143] START C=1, degree=2, kernel=poly, tol=0.001....................\n",
            "[CV 1/5; 70/143] END C=1, degree=2, kernel=poly, tol=0.001;, score=0.563 total time=   0.0s\n",
            "[CV 2/5; 70/143] START C=1, degree=2, kernel=poly, tol=0.001....................\n",
            "[CV 2/5; 70/143] END C=1, degree=2, kernel=poly, tol=0.001;, score=0.563 total time=   0.0s\n",
            "[CV 3/5; 70/143] START C=1, degree=2, kernel=poly, tol=0.001....................\n",
            "[CV 3/5; 70/143] END C=1, degree=2, kernel=poly, tol=0.001;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 70/143] START C=1, degree=2, kernel=poly, tol=0.001....................\n",
            "[CV 4/5; 70/143] END C=1, degree=2, kernel=poly, tol=0.001;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 70/143] START C=1, degree=2, kernel=poly, tol=0.001....................\n",
            "[CV 5/5; 70/143] END C=1, degree=2, kernel=poly, tol=0.001;, score=0.528 total time=   0.0s\n",
            "[CV 1/5; 71/143] START C=1, degree=2, kernel=poly, tol=0.0001...................\n",
            "[CV 1/5; 71/143] END C=1, degree=2, kernel=poly, tol=0.0001;, score=0.563 total time=   0.0s\n",
            "[CV 2/5; 71/143] START C=1, degree=2, kernel=poly, tol=0.0001...................\n",
            "[CV 2/5; 71/143] END C=1, degree=2, kernel=poly, tol=0.0001;, score=0.563 total time=   0.0s\n",
            "[CV 3/5; 71/143] START C=1, degree=2, kernel=poly, tol=0.0001...................\n",
            "[CV 3/5; 71/143] END C=1, degree=2, kernel=poly, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 71/143] START C=1, degree=2, kernel=poly, tol=0.0001...................\n",
            "[CV 4/5; 71/143] END C=1, degree=2, kernel=poly, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 71/143] START C=1, degree=2, kernel=poly, tol=0.0001...................\n",
            "[CV 5/5; 71/143] END C=1, degree=2, kernel=poly, tol=0.0001;, score=0.528 total time=   0.0s\n",
            "[CV 1/5; 72/143] START C=1, degree=2, kernel=poly, tol=1e-05....................\n",
            "[CV 1/5; 72/143] END C=1, degree=2, kernel=poly, tol=1e-05;, score=0.563 total time=   0.0s\n",
            "[CV 2/5; 72/143] START C=1, degree=2, kernel=poly, tol=1e-05....................\n",
            "[CV 2/5; 72/143] END C=1, degree=2, kernel=poly, tol=1e-05;, score=0.563 total time=   0.0s\n",
            "[CV 3/5; 72/143] START C=1, degree=2, kernel=poly, tol=1e-05....................\n",
            "[CV 3/5; 72/143] END C=1, degree=2, kernel=poly, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 72/143] START C=1, degree=2, kernel=poly, tol=1e-05....................\n",
            "[CV 4/5; 72/143] END C=1, degree=2, kernel=poly, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 72/143] START C=1, degree=2, kernel=poly, tol=1e-05....................\n",
            "[CV 5/5; 72/143] END C=1, degree=2, kernel=poly, tol=1e-05;, score=0.528 total time=   0.0s\n",
            "[CV 1/5; 73/143] START C=1, degree=2, kernel=poly, tol=scale....................\n",
            "[CV 1/5; 73/143] END C=1, degree=2, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 2/5; 73/143] START C=1, degree=2, kernel=poly, tol=scale....................\n",
            "[CV 2/5; 73/143] END C=1, degree=2, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 3/5; 73/143] START C=1, degree=2, kernel=poly, tol=scale....................\n",
            "[CV 3/5; 73/143] END C=1, degree=2, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 4/5; 73/143] START C=1, degree=2, kernel=poly, tol=scale....................\n",
            "[CV 4/5; 73/143] END C=1, degree=2, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 5/5; 73/143] START C=1, degree=2, kernel=poly, tol=scale....................\n",
            "[CV 5/5; 73/143] END C=1, degree=2, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 1/5; 74/143] START C=1, degree=3, kernel=poly, tol=0.01.....................\n",
            "[CV 1/5; 74/143] END C=1, degree=3, kernel=poly, tol=0.01;, score=0.515 total time=   0.0s\n",
            "[CV 2/5; 74/143] START C=1, degree=3, kernel=poly, tol=0.01.....................\n",
            "[CV 2/5; 74/143] END C=1, degree=3, kernel=poly, tol=0.01;, score=0.552 total time=   0.0s\n",
            "[CV 3/5; 74/143] START C=1, degree=3, kernel=poly, tol=0.01.....................\n",
            "[CV 3/5; 74/143] END C=1, degree=3, kernel=poly, tol=0.01;, score=0.493 total time=   0.0s\n",
            "[CV 4/5; 74/143] START C=1, degree=3, kernel=poly, tol=0.01.....................\n",
            "[CV 4/5; 74/143] END C=1, degree=3, kernel=poly, tol=0.01;, score=0.493 total time=   0.0s\n",
            "[CV 5/5; 74/143] START C=1, degree=3, kernel=poly, tol=0.01.....................\n",
            "[CV 5/5; 74/143] END C=1, degree=3, kernel=poly, tol=0.01;, score=0.547 total time=   0.0s\n",
            "[CV 1/5; 75/143] START C=1, degree=3, kernel=poly, tol=0.001....................\n",
            "[CV 1/5; 75/143] END C=1, degree=3, kernel=poly, tol=0.001;, score=0.515 total time=   0.0s\n",
            "[CV 2/5; 75/143] START C=1, degree=3, kernel=poly, tol=0.001....................\n",
            "[CV 2/5; 75/143] END C=1, degree=3, kernel=poly, tol=0.001;, score=0.552 total time=   0.0s\n",
            "[CV 3/5; 75/143] START C=1, degree=3, kernel=poly, tol=0.001....................\n",
            "[CV 3/5; 75/143] END C=1, degree=3, kernel=poly, tol=0.001;, score=0.493 total time=   0.0s\n",
            "[CV 4/5; 75/143] START C=1, degree=3, kernel=poly, tol=0.001....................\n",
            "[CV 4/5; 75/143] END C=1, degree=3, kernel=poly, tol=0.001;, score=0.493 total time=   0.0s\n",
            "[CV 5/5; 75/143] START C=1, degree=3, kernel=poly, tol=0.001....................\n",
            "[CV 5/5; 75/143] END C=1, degree=3, kernel=poly, tol=0.001;, score=0.547 total time=   0.0s\n",
            "[CV 1/5; 76/143] START C=1, degree=3, kernel=poly, tol=0.0001...................\n",
            "[CV 1/5; 76/143] END C=1, degree=3, kernel=poly, tol=0.0001;, score=0.515 total time=   0.0s\n",
            "[CV 2/5; 76/143] START C=1, degree=3, kernel=poly, tol=0.0001...................\n",
            "[CV 2/5; 76/143] END C=1, degree=3, kernel=poly, tol=0.0001;, score=0.556 total time=   0.0s\n",
            "[CV 3/5; 76/143] START C=1, degree=3, kernel=poly, tol=0.0001...................\n",
            "[CV 3/5; 76/143] END C=1, degree=3, kernel=poly, tol=0.0001;, score=0.493 total time=   0.0s\n",
            "[CV 4/5; 76/143] START C=1, degree=3, kernel=poly, tol=0.0001...................\n",
            "[CV 4/5; 76/143] END C=1, degree=3, kernel=poly, tol=0.0001;, score=0.493 total time=   0.0s\n",
            "[CV 5/5; 76/143] START C=1, degree=3, kernel=poly, tol=0.0001...................\n",
            "[CV 5/5; 76/143] END C=1, degree=3, kernel=poly, tol=0.0001;, score=0.547 total time=   0.0s\n",
            "[CV 1/5; 77/143] START C=1, degree=3, kernel=poly, tol=1e-05....................\n",
            "[CV 1/5; 77/143] END C=1, degree=3, kernel=poly, tol=1e-05;, score=0.515 total time=   0.0s\n",
            "[CV 2/5; 77/143] START C=1, degree=3, kernel=poly, tol=1e-05....................\n",
            "[CV 2/5; 77/143] END C=1, degree=3, kernel=poly, tol=1e-05;, score=0.556 total time=   0.0s\n",
            "[CV 3/5; 77/143] START C=1, degree=3, kernel=poly, tol=1e-05....................\n",
            "[CV 3/5; 77/143] END C=1, degree=3, kernel=poly, tol=1e-05;, score=0.493 total time=   0.0s\n",
            "[CV 4/5; 77/143] START C=1, degree=3, kernel=poly, tol=1e-05....................\n",
            "[CV 4/5; 77/143] END C=1, degree=3, kernel=poly, tol=1e-05;, score=0.493 total time=   0.0s\n",
            "[CV 5/5; 77/143] START C=1, degree=3, kernel=poly, tol=1e-05....................\n",
            "[CV 5/5; 77/143] END C=1, degree=3, kernel=poly, tol=1e-05;, score=0.547 total time=   0.0s\n",
            "[CV 1/5; 78/143] START C=1, degree=3, kernel=poly, tol=scale....................\n",
            "[CV 1/5; 78/143] END C=1, degree=3, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 2/5; 78/143] START C=1, degree=3, kernel=poly, tol=scale....................\n",
            "[CV 2/5; 78/143] END C=1, degree=3, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 3/5; 78/143] START C=1, degree=3, kernel=poly, tol=scale....................\n",
            "[CV 3/5; 78/143] END C=1, degree=3, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 4/5; 78/143] START C=1, degree=3, kernel=poly, tol=scale....................\n",
            "[CV 4/5; 78/143] END C=1, degree=3, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 5/5; 78/143] START C=1, degree=3, kernel=poly, tol=scale....................\n",
            "[CV 5/5; 78/143] END C=1, degree=3, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 1/5; 79/143] START C=1, degree=4, kernel=poly, tol=0.01.....................\n",
            "[CV 1/5; 79/143] END C=1, degree=4, kernel=poly, tol=0.01;, score=0.500 total time=   0.0s\n",
            "[CV 2/5; 79/143] START C=1, degree=4, kernel=poly, tol=0.01.....................\n",
            "[CV 2/5; 79/143] END C=1, degree=4, kernel=poly, tol=0.01;, score=0.515 total time=   0.0s\n",
            "[CV 3/5; 79/143] START C=1, degree=4, kernel=poly, tol=0.01.....................\n",
            "[CV 3/5; 79/143] END C=1, degree=4, kernel=poly, tol=0.01;, score=0.515 total time=   0.0s\n",
            "[CV 4/5; 79/143] START C=1, degree=4, kernel=poly, tol=0.01.....................\n",
            "[CV 4/5; 79/143] END C=1, degree=4, kernel=poly, tol=0.01;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 79/143] START C=1, degree=4, kernel=poly, tol=0.01.....................\n",
            "[CV 5/5; 79/143] END C=1, degree=4, kernel=poly, tol=0.01;, score=0.506 total time=   0.0s\n",
            "[CV 1/5; 80/143] START C=1, degree=4, kernel=poly, tol=0.001....................\n",
            "[CV 1/5; 80/143] END C=1, degree=4, kernel=poly, tol=0.001;, score=0.500 total time=   0.0s\n",
            "[CV 2/5; 80/143] START C=1, degree=4, kernel=poly, tol=0.001....................\n",
            "[CV 2/5; 80/143] END C=1, degree=4, kernel=poly, tol=0.001;, score=0.515 total time=   0.0s\n",
            "[CV 3/5; 80/143] START C=1, degree=4, kernel=poly, tol=0.001....................\n",
            "[CV 3/5; 80/143] END C=1, degree=4, kernel=poly, tol=0.001;, score=0.515 total time=   0.0s\n",
            "[CV 4/5; 80/143] START C=1, degree=4, kernel=poly, tol=0.001....................\n",
            "[CV 4/5; 80/143] END C=1, degree=4, kernel=poly, tol=0.001;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 80/143] START C=1, degree=4, kernel=poly, tol=0.001....................\n",
            "[CV 5/5; 80/143] END C=1, degree=4, kernel=poly, tol=0.001;, score=0.506 total time=   0.0s\n",
            "[CV 1/5; 81/143] START C=1, degree=4, kernel=poly, tol=0.0001...................\n",
            "[CV 1/5; 81/143] END C=1, degree=4, kernel=poly, tol=0.0001;, score=0.500 total time=   0.0s\n",
            "[CV 2/5; 81/143] START C=1, degree=4, kernel=poly, tol=0.0001...................\n",
            "[CV 2/5; 81/143] END C=1, degree=4, kernel=poly, tol=0.0001;, score=0.515 total time=   0.0s\n",
            "[CV 3/5; 81/143] START C=1, degree=4, kernel=poly, tol=0.0001...................\n",
            "[CV 3/5; 81/143] END C=1, degree=4, kernel=poly, tol=0.0001;, score=0.515 total time=   0.0s\n",
            "[CV 4/5; 81/143] START C=1, degree=4, kernel=poly, tol=0.0001...................\n",
            "[CV 4/5; 81/143] END C=1, degree=4, kernel=poly, tol=0.0001;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 81/143] START C=1, degree=4, kernel=poly, tol=0.0001...................\n",
            "[CV 5/5; 81/143] END C=1, degree=4, kernel=poly, tol=0.0001;, score=0.506 total time=   0.0s\n",
            "[CV 1/5; 82/143] START C=1, degree=4, kernel=poly, tol=1e-05....................\n",
            "[CV 1/5; 82/143] END C=1, degree=4, kernel=poly, tol=1e-05;, score=0.500 total time=   0.0s\n",
            "[CV 2/5; 82/143] START C=1, degree=4, kernel=poly, tol=1e-05....................\n",
            "[CV 2/5; 82/143] END C=1, degree=4, kernel=poly, tol=1e-05;, score=0.515 total time=   0.0s\n",
            "[CV 3/5; 82/143] START C=1, degree=4, kernel=poly, tol=1e-05....................\n",
            "[CV 3/5; 82/143] END C=1, degree=4, kernel=poly, tol=1e-05;, score=0.515 total time=   0.0s\n",
            "[CV 4/5; 82/143] START C=1, degree=4, kernel=poly, tol=1e-05....................\n",
            "[CV 4/5; 82/143] END C=1, degree=4, kernel=poly, tol=1e-05;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 82/143] START C=1, degree=4, kernel=poly, tol=1e-05....................\n",
            "[CV 5/5; 82/143] END C=1, degree=4, kernel=poly, tol=1e-05;, score=0.506 total time=   0.0s\n",
            "[CV 1/5; 83/143] START C=1, degree=4, kernel=poly, tol=scale....................\n",
            "[CV 1/5; 83/143] END C=1, degree=4, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 2/5; 83/143] START C=1, degree=4, kernel=poly, tol=scale....................\n",
            "[CV 2/5; 83/143] END C=1, degree=4, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 3/5; 83/143] START C=1, degree=4, kernel=poly, tol=scale....................\n",
            "[CV 3/5; 83/143] END C=1, degree=4, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 4/5; 83/143] START C=1, degree=4, kernel=poly, tol=scale....................\n",
            "[CV 4/5; 83/143] END C=1, degree=4, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 5/5; 83/143] START C=1, degree=4, kernel=poly, tol=scale....................\n",
            "[CV 5/5; 83/143] END C=1, degree=4, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 1/5; 84/143] START C=10, degree=2, kernel=poly, tol=0.01....................\n",
            "[CV 1/5; 84/143] END C=10, degree=2, kernel=poly, tol=0.01;, score=0.571 total time=   0.0s\n",
            "[CV 2/5; 84/143] START C=10, degree=2, kernel=poly, tol=0.01....................\n",
            "[CV 2/5; 84/143] END C=10, degree=2, kernel=poly, tol=0.01;, score=0.597 total time=   0.0s\n",
            "[CV 3/5; 84/143] START C=10, degree=2, kernel=poly, tol=0.01....................\n",
            "[CV 3/5; 84/143] END C=10, degree=2, kernel=poly, tol=0.01;, score=0.563 total time=   0.0s\n",
            "[CV 4/5; 84/143] START C=10, degree=2, kernel=poly, tol=0.01....................\n",
            "[CV 4/5; 84/143] END C=10, degree=2, kernel=poly, tol=0.01;, score=0.582 total time=   0.0s\n",
            "[CV 5/5; 84/143] START C=10, degree=2, kernel=poly, tol=0.01....................\n",
            "[CV 5/5; 84/143] END C=10, degree=2, kernel=poly, tol=0.01;, score=0.554 total time=   0.0s\n",
            "[CV 1/5; 85/143] START C=10, degree=2, kernel=poly, tol=0.001...................\n",
            "[CV 1/5; 85/143] END C=10, degree=2, kernel=poly, tol=0.001;, score=0.571 total time=   0.0s\n",
            "[CV 2/5; 85/143] START C=10, degree=2, kernel=poly, tol=0.001...................\n",
            "[CV 2/5; 85/143] END C=10, degree=2, kernel=poly, tol=0.001;, score=0.597 total time=   0.0s\n",
            "[CV 3/5; 85/143] START C=10, degree=2, kernel=poly, tol=0.001...................\n",
            "[CV 3/5; 85/143] END C=10, degree=2, kernel=poly, tol=0.001;, score=0.563 total time=   0.0s\n",
            "[CV 4/5; 85/143] START C=10, degree=2, kernel=poly, tol=0.001...................\n",
            "[CV 4/5; 85/143] END C=10, degree=2, kernel=poly, tol=0.001;, score=0.582 total time=   0.0s\n",
            "[CV 5/5; 85/143] START C=10, degree=2, kernel=poly, tol=0.001...................\n",
            "[CV 5/5; 85/143] END C=10, degree=2, kernel=poly, tol=0.001;, score=0.551 total time=   0.0s\n",
            "[CV 1/5; 86/143] START C=10, degree=2, kernel=poly, tol=0.0001..................\n",
            "[CV 1/5; 86/143] END C=10, degree=2, kernel=poly, tol=0.0001;, score=0.571 total time=   0.0s\n",
            "[CV 2/5; 86/143] START C=10, degree=2, kernel=poly, tol=0.0001..................\n",
            "[CV 2/5; 86/143] END C=10, degree=2, kernel=poly, tol=0.0001;, score=0.597 total time=   0.0s\n",
            "[CV 3/5; 86/143] START C=10, degree=2, kernel=poly, tol=0.0001..................\n",
            "[CV 3/5; 86/143] END C=10, degree=2, kernel=poly, tol=0.0001;, score=0.563 total time=   0.0s\n",
            "[CV 4/5; 86/143] START C=10, degree=2, kernel=poly, tol=0.0001..................\n",
            "[CV 4/5; 86/143] END C=10, degree=2, kernel=poly, tol=0.0001;, score=0.582 total time=   0.0s\n",
            "[CV 5/5; 86/143] START C=10, degree=2, kernel=poly, tol=0.0001..................\n",
            "[CV 5/5; 86/143] END C=10, degree=2, kernel=poly, tol=0.0001;, score=0.551 total time=   0.0s\n",
            "[CV 1/5; 87/143] START C=10, degree=2, kernel=poly, tol=1e-05...................\n",
            "[CV 1/5; 87/143] END C=10, degree=2, kernel=poly, tol=1e-05;, score=0.571 total time=   0.0s\n",
            "[CV 2/5; 87/143] START C=10, degree=2, kernel=poly, tol=1e-05...................\n",
            "[CV 2/5; 87/143] END C=10, degree=2, kernel=poly, tol=1e-05;, score=0.597 total time=   0.0s\n",
            "[CV 3/5; 87/143] START C=10, degree=2, kernel=poly, tol=1e-05...................\n",
            "[CV 3/5; 87/143] END C=10, degree=2, kernel=poly, tol=1e-05;, score=0.563 total time=   0.0s\n",
            "[CV 4/5; 87/143] START C=10, degree=2, kernel=poly, tol=1e-05...................\n",
            "[CV 4/5; 87/143] END C=10, degree=2, kernel=poly, tol=1e-05;, score=0.582 total time=   0.0s\n",
            "[CV 5/5; 87/143] START C=10, degree=2, kernel=poly, tol=1e-05...................\n",
            "[CV 5/5; 87/143] END C=10, degree=2, kernel=poly, tol=1e-05;, score=0.551 total time=   0.0s\n",
            "[CV 1/5; 88/143] START C=10, degree=2, kernel=poly, tol=scale...................\n",
            "[CV 1/5; 88/143] END C=10, degree=2, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 2/5; 88/143] START C=10, degree=2, kernel=poly, tol=scale...................\n",
            "[CV 2/5; 88/143] END C=10, degree=2, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 3/5; 88/143] START C=10, degree=2, kernel=poly, tol=scale...................\n",
            "[CV 3/5; 88/143] END C=10, degree=2, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 4/5; 88/143] START C=10, degree=2, kernel=poly, tol=scale...................\n",
            "[CV 4/5; 88/143] END C=10, degree=2, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 5/5; 88/143] START C=10, degree=2, kernel=poly, tol=scale...................\n",
            "[CV 5/5; 88/143] END C=10, degree=2, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 1/5; 89/143] START C=10, degree=3, kernel=poly, tol=0.01....................\n",
            "[CV 1/5; 89/143] END C=10, degree=3, kernel=poly, tol=0.01;, score=0.657 total time=   0.0s\n",
            "[CV 2/5; 89/143] START C=10, degree=3, kernel=poly, tol=0.01....................\n",
            "[CV 2/5; 89/143] END C=10, degree=3, kernel=poly, tol=0.01;, score=0.668 total time=   0.0s\n",
            "[CV 3/5; 89/143] START C=10, degree=3, kernel=poly, tol=0.01....................\n",
            "[CV 3/5; 89/143] END C=10, degree=3, kernel=poly, tol=0.01;, score=0.619 total time=   0.0s\n",
            "[CV 4/5; 89/143] START C=10, degree=3, kernel=poly, tol=0.01....................\n",
            "[CV 4/5; 89/143] END C=10, degree=3, kernel=poly, tol=0.01;, score=0.623 total time=   0.0s\n",
            "[CV 5/5; 89/143] START C=10, degree=3, kernel=poly, tol=0.01....................\n",
            "[CV 5/5; 89/143] END C=10, degree=3, kernel=poly, tol=0.01;, score=0.689 total time=   0.0s\n",
            "[CV 1/5; 90/143] START C=10, degree=3, kernel=poly, tol=0.001...................\n",
            "[CV 1/5; 90/143] END C=10, degree=3, kernel=poly, tol=0.001;, score=0.660 total time=   0.1s\n",
            "[CV 2/5; 90/143] START C=10, degree=3, kernel=poly, tol=0.001...................\n",
            "[CV 2/5; 90/143] END C=10, degree=3, kernel=poly, tol=0.001;, score=0.668 total time=   0.0s\n",
            "[CV 3/5; 90/143] START C=10, degree=3, kernel=poly, tol=0.001...................\n",
            "[CV 3/5; 90/143] END C=10, degree=3, kernel=poly, tol=0.001;, score=0.619 total time=   0.0s\n",
            "[CV 4/5; 90/143] START C=10, degree=3, kernel=poly, tol=0.001...................\n",
            "[CV 4/5; 90/143] END C=10, degree=3, kernel=poly, tol=0.001;, score=0.623 total time=   0.0s\n",
            "[CV 5/5; 90/143] START C=10, degree=3, kernel=poly, tol=0.001...................\n",
            "[CV 5/5; 90/143] END C=10, degree=3, kernel=poly, tol=0.001;, score=0.689 total time=   0.0s\n",
            "[CV 1/5; 91/143] START C=10, degree=3, kernel=poly, tol=0.0001..................\n",
            "[CV 1/5; 91/143] END C=10, degree=3, kernel=poly, tol=0.0001;, score=0.660 total time=   0.0s\n",
            "[CV 2/5; 91/143] START C=10, degree=3, kernel=poly, tol=0.0001..................\n",
            "[CV 2/5; 91/143] END C=10, degree=3, kernel=poly, tol=0.0001;, score=0.668 total time=   0.0s\n",
            "[CV 3/5; 91/143] START C=10, degree=3, kernel=poly, tol=0.0001..................\n",
            "[CV 3/5; 91/143] END C=10, degree=3, kernel=poly, tol=0.0001;, score=0.619 total time=   0.0s\n",
            "[CV 4/5; 91/143] START C=10, degree=3, kernel=poly, tol=0.0001..................\n",
            "[CV 4/5; 91/143] END C=10, degree=3, kernel=poly, tol=0.0001;, score=0.623 total time=   0.0s\n",
            "[CV 5/5; 91/143] START C=10, degree=3, kernel=poly, tol=0.0001..................\n",
            "[CV 5/5; 91/143] END C=10, degree=3, kernel=poly, tol=0.0001;, score=0.689 total time=   0.0s\n",
            "[CV 1/5; 92/143] START C=10, degree=3, kernel=poly, tol=1e-05...................\n",
            "[CV 1/5; 92/143] END C=10, degree=3, kernel=poly, tol=1e-05;, score=0.660 total time=   0.1s\n",
            "[CV 2/5; 92/143] START C=10, degree=3, kernel=poly, tol=1e-05...................\n",
            "[CV 2/5; 92/143] END C=10, degree=3, kernel=poly, tol=1e-05;, score=0.668 total time=   0.1s\n",
            "[CV 3/5; 92/143] START C=10, degree=3, kernel=poly, tol=1e-05...................\n",
            "[CV 3/5; 92/143] END C=10, degree=3, kernel=poly, tol=1e-05;, score=0.619 total time=   0.0s\n",
            "[CV 4/5; 92/143] START C=10, degree=3, kernel=poly, tol=1e-05...................\n",
            "[CV 4/5; 92/143] END C=10, degree=3, kernel=poly, tol=1e-05;, score=0.623 total time=   0.0s\n",
            "[CV 5/5; 92/143] START C=10, degree=3, kernel=poly, tol=1e-05...................\n",
            "[CV 5/5; 92/143] END C=10, degree=3, kernel=poly, tol=1e-05;, score=0.689 total time=   0.0s\n",
            "[CV 1/5; 93/143] START C=10, degree=3, kernel=poly, tol=scale...................\n",
            "[CV 1/5; 93/143] END C=10, degree=3, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 2/5; 93/143] START C=10, degree=3, kernel=poly, tol=scale...................\n",
            "[CV 2/5; 93/143] END C=10, degree=3, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 3/5; 93/143] START C=10, degree=3, kernel=poly, tol=scale...................\n",
            "[CV 3/5; 93/143] END C=10, degree=3, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 4/5; 93/143] START C=10, degree=3, kernel=poly, tol=scale...................\n",
            "[CV 4/5; 93/143] END C=10, degree=3, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 5/5; 93/143] START C=10, degree=3, kernel=poly, tol=scale...................\n",
            "[CV 5/5; 93/143] END C=10, degree=3, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 1/5; 94/143] START C=10, degree=4, kernel=poly, tol=0.01....................\n",
            "[CV 1/5; 94/143] END C=10, degree=4, kernel=poly, tol=0.01;, score=0.571 total time=   0.0s\n",
            "[CV 2/5; 94/143] START C=10, degree=4, kernel=poly, tol=0.01....................\n",
            "[CV 2/5; 94/143] END C=10, degree=4, kernel=poly, tol=0.01;, score=0.608 total time=   0.0s\n",
            "[CV 3/5; 94/143] START C=10, degree=4, kernel=poly, tol=0.01....................\n",
            "[CV 3/5; 94/143] END C=10, degree=4, kernel=poly, tol=0.01;, score=0.578 total time=   0.0s\n",
            "[CV 4/5; 94/143] START C=10, degree=4, kernel=poly, tol=0.01....................\n",
            "[CV 4/5; 94/143] END C=10, degree=4, kernel=poly, tol=0.01;, score=0.586 total time=   0.0s\n",
            "[CV 5/5; 94/143] START C=10, degree=4, kernel=poly, tol=0.01....................\n",
            "[CV 5/5; 94/143] END C=10, degree=4, kernel=poly, tol=0.01;, score=0.618 total time=   0.0s\n",
            "[CV 1/5; 95/143] START C=10, degree=4, kernel=poly, tol=0.001...................\n",
            "[CV 1/5; 95/143] END C=10, degree=4, kernel=poly, tol=0.001;, score=0.571 total time=   0.0s\n",
            "[CV 2/5; 95/143] START C=10, degree=4, kernel=poly, tol=0.001...................\n",
            "[CV 2/5; 95/143] END C=10, degree=4, kernel=poly, tol=0.001;, score=0.608 total time=   0.0s\n",
            "[CV 3/5; 95/143] START C=10, degree=4, kernel=poly, tol=0.001...................\n",
            "[CV 3/5; 95/143] END C=10, degree=4, kernel=poly, tol=0.001;, score=0.578 total time=   0.0s\n",
            "[CV 4/5; 95/143] START C=10, degree=4, kernel=poly, tol=0.001...................\n",
            "[CV 4/5; 95/143] END C=10, degree=4, kernel=poly, tol=0.001;, score=0.586 total time=   0.0s\n",
            "[CV 5/5; 95/143] START C=10, degree=4, kernel=poly, tol=0.001...................\n",
            "[CV 5/5; 95/143] END C=10, degree=4, kernel=poly, tol=0.001;, score=0.618 total time=   0.0s\n",
            "[CV 1/5; 96/143] START C=10, degree=4, kernel=poly, tol=0.0001..................\n",
            "[CV 1/5; 96/143] END C=10, degree=4, kernel=poly, tol=0.0001;, score=0.571 total time=   0.1s\n",
            "[CV 2/5; 96/143] START C=10, degree=4, kernel=poly, tol=0.0001..................\n",
            "[CV 2/5; 96/143] END C=10, degree=4, kernel=poly, tol=0.0001;, score=0.608 total time=   0.1s\n",
            "[CV 3/5; 96/143] START C=10, degree=4, kernel=poly, tol=0.0001..................\n",
            "[CV 3/5; 96/143] END C=10, degree=4, kernel=poly, tol=0.0001;, score=0.578 total time=   0.0s\n",
            "[CV 4/5; 96/143] START C=10, degree=4, kernel=poly, tol=0.0001..................\n",
            "[CV 4/5; 96/143] END C=10, degree=4, kernel=poly, tol=0.0001;, score=0.586 total time=   0.0s\n",
            "[CV 5/5; 96/143] START C=10, degree=4, kernel=poly, tol=0.0001..................\n",
            "[CV 5/5; 96/143] END C=10, degree=4, kernel=poly, tol=0.0001;, score=0.618 total time=   0.0s\n",
            "[CV 1/5; 97/143] START C=10, degree=4, kernel=poly, tol=1e-05...................\n",
            "[CV 1/5; 97/143] END C=10, degree=4, kernel=poly, tol=1e-05;, score=0.571 total time=   0.0s\n",
            "[CV 2/5; 97/143] START C=10, degree=4, kernel=poly, tol=1e-05...................\n",
            "[CV 2/5; 97/143] END C=10, degree=4, kernel=poly, tol=1e-05;, score=0.608 total time=   0.0s\n",
            "[CV 3/5; 97/143] START C=10, degree=4, kernel=poly, tol=1e-05...................\n",
            "[CV 3/5; 97/143] END C=10, degree=4, kernel=poly, tol=1e-05;, score=0.578 total time=   0.0s\n",
            "[CV 4/5; 97/143] START C=10, degree=4, kernel=poly, tol=1e-05...................\n",
            "[CV 4/5; 97/143] END C=10, degree=4, kernel=poly, tol=1e-05;, score=0.586 total time=   0.0s\n",
            "[CV 5/5; 97/143] START C=10, degree=4, kernel=poly, tol=1e-05...................\n",
            "[CV 5/5; 97/143] END C=10, degree=4, kernel=poly, tol=1e-05;, score=0.618 total time=   0.0s\n",
            "[CV 1/5; 98/143] START C=10, degree=4, kernel=poly, tol=scale...................\n",
            "[CV 1/5; 98/143] END C=10, degree=4, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 2/5; 98/143] START C=10, degree=4, kernel=poly, tol=scale...................\n",
            "[CV 2/5; 98/143] END C=10, degree=4, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 3/5; 98/143] START C=10, degree=4, kernel=poly, tol=scale...................\n",
            "[CV 3/5; 98/143] END C=10, degree=4, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 4/5; 98/143] START C=10, degree=4, kernel=poly, tol=scale...................\n",
            "[CV 4/5; 98/143] END C=10, degree=4, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 5/5; 98/143] START C=10, degree=4, kernel=poly, tol=scale...................\n",
            "[CV 5/5; 98/143] END C=10, degree=4, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 1/5; 99/143] START C=100, degree=2, kernel=poly, tol=0.01...................\n",
            "[CV 1/5; 99/143] END C=100, degree=2, kernel=poly, tol=0.01;, score=0.575 total time=   0.1s\n",
            "[CV 2/5; 99/143] START C=100, degree=2, kernel=poly, tol=0.01...................\n",
            "[CV 2/5; 99/143] END C=100, degree=2, kernel=poly, tol=0.01;, score=0.593 total time=   0.1s\n",
            "[CV 3/5; 99/143] START C=100, degree=2, kernel=poly, tol=0.01...................\n",
            "[CV 3/5; 99/143] END C=100, degree=2, kernel=poly, tol=0.01;, score=0.563 total time=   0.1s\n",
            "[CV 4/5; 99/143] START C=100, degree=2, kernel=poly, tol=0.01...................\n",
            "[CV 4/5; 99/143] END C=100, degree=2, kernel=poly, tol=0.01;, score=0.631 total time=   0.1s\n",
            "[CV 5/5; 99/143] START C=100, degree=2, kernel=poly, tol=0.01...................\n",
            "[CV 5/5; 99/143] END C=100, degree=2, kernel=poly, tol=0.01;, score=0.592 total time=   0.1s\n",
            "[CV 1/5; 100/143] START C=100, degree=2, kernel=poly, tol=0.001.................\n",
            "[CV 1/5; 100/143] END C=100, degree=2, kernel=poly, tol=0.001;, score=0.575 total time=   0.2s\n",
            "[CV 2/5; 100/143] START C=100, degree=2, kernel=poly, tol=0.001.................\n",
            "[CV 2/5; 100/143] END C=100, degree=2, kernel=poly, tol=0.001;, score=0.593 total time=   0.2s\n",
            "[CV 3/5; 100/143] START C=100, degree=2, kernel=poly, tol=0.001.................\n",
            "[CV 3/5; 100/143] END C=100, degree=2, kernel=poly, tol=0.001;, score=0.563 total time=   0.1s\n",
            "[CV 4/5; 100/143] START C=100, degree=2, kernel=poly, tol=0.001.................\n",
            "[CV 4/5; 100/143] END C=100, degree=2, kernel=poly, tol=0.001;, score=0.631 total time=   0.2s\n",
            "[CV 5/5; 100/143] START C=100, degree=2, kernel=poly, tol=0.001.................\n",
            "[CV 5/5; 100/143] END C=100, degree=2, kernel=poly, tol=0.001;, score=0.592 total time=   0.1s\n",
            "[CV 1/5; 101/143] START C=100, degree=2, kernel=poly, tol=0.0001................\n",
            "[CV 1/5; 101/143] END C=100, degree=2, kernel=poly, tol=0.0001;, score=0.575 total time=   0.3s\n",
            "[CV 2/5; 101/143] START C=100, degree=2, kernel=poly, tol=0.0001................\n",
            "[CV 2/5; 101/143] END C=100, degree=2, kernel=poly, tol=0.0001;, score=0.593 total time=   0.3s\n",
            "[CV 3/5; 101/143] START C=100, degree=2, kernel=poly, tol=0.0001................\n",
            "[CV 3/5; 101/143] END C=100, degree=2, kernel=poly, tol=0.0001;, score=0.563 total time=   0.2s\n",
            "[CV 4/5; 101/143] START C=100, degree=2, kernel=poly, tol=0.0001................\n",
            "[CV 4/5; 101/143] END C=100, degree=2, kernel=poly, tol=0.0001;, score=0.631 total time=   0.3s\n",
            "[CV 5/5; 101/143] START C=100, degree=2, kernel=poly, tol=0.0001................\n",
            "[CV 5/5; 101/143] END C=100, degree=2, kernel=poly, tol=0.0001;, score=0.592 total time=   0.2s\n",
            "[CV 1/5; 102/143] START C=100, degree=2, kernel=poly, tol=1e-05.................\n",
            "[CV 1/5; 102/143] END C=100, degree=2, kernel=poly, tol=1e-05;, score=0.575 total time=   0.5s\n",
            "[CV 2/5; 102/143] START C=100, degree=2, kernel=poly, tol=1e-05.................\n",
            "[CV 2/5; 102/143] END C=100, degree=2, kernel=poly, tol=1e-05;, score=0.593 total time=   0.4s\n",
            "[CV 3/5; 102/143] START C=100, degree=2, kernel=poly, tol=1e-05.................\n",
            "[CV 3/5; 102/143] END C=100, degree=2, kernel=poly, tol=1e-05;, score=0.563 total time=   0.2s\n",
            "[CV 4/5; 102/143] START C=100, degree=2, kernel=poly, tol=1e-05.................\n",
            "[CV 4/5; 102/143] END C=100, degree=2, kernel=poly, tol=1e-05;, score=0.631 total time=   0.4s\n",
            "[CV 5/5; 102/143] START C=100, degree=2, kernel=poly, tol=1e-05.................\n",
            "[CV 5/5; 102/143] END C=100, degree=2, kernel=poly, tol=1e-05;, score=0.592 total time=   0.3s\n",
            "[CV 1/5; 103/143] START C=100, degree=2, kernel=poly, tol=scale.................\n",
            "[CV 1/5; 103/143] END C=100, degree=2, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 2/5; 103/143] START C=100, degree=2, kernel=poly, tol=scale.................\n",
            "[CV 2/5; 103/143] END C=100, degree=2, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 3/5; 103/143] START C=100, degree=2, kernel=poly, tol=scale.................\n",
            "[CV 3/5; 103/143] END C=100, degree=2, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 4/5; 103/143] START C=100, degree=2, kernel=poly, tol=scale.................\n",
            "[CV 4/5; 103/143] END C=100, degree=2, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 5/5; 103/143] START C=100, degree=2, kernel=poly, tol=scale.................\n",
            "[CV 5/5; 103/143] END C=100, degree=2, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 1/5; 104/143] START C=100, degree=3, kernel=poly, tol=0.01..................\n",
            "[CV 1/5; 104/143] END C=100, degree=3, kernel=poly, tol=0.01;, score=0.754 total time=   0.1s\n",
            "[CV 2/5; 104/143] START C=100, degree=3, kernel=poly, tol=0.01..................\n",
            "[CV 2/5; 104/143] END C=100, degree=3, kernel=poly, tol=0.01;, score=0.728 total time=   0.1s\n",
            "[CV 3/5; 104/143] START C=100, degree=3, kernel=poly, tol=0.01..................\n",
            "[CV 3/5; 104/143] END C=100, degree=3, kernel=poly, tol=0.01;, score=0.724 total time=   0.1s\n",
            "[CV 4/5; 104/143] START C=100, degree=3, kernel=poly, tol=0.01..................\n",
            "[CV 4/5; 104/143] END C=100, degree=3, kernel=poly, tol=0.01;, score=0.754 total time=   0.1s\n",
            "[CV 5/5; 104/143] START C=100, degree=3, kernel=poly, tol=0.01..................\n",
            "[CV 5/5; 104/143] END C=100, degree=3, kernel=poly, tol=0.01;, score=0.798 total time=   0.1s\n",
            "[CV 1/5; 105/143] START C=100, degree=3, kernel=poly, tol=0.001.................\n",
            "[CV 1/5; 105/143] END C=100, degree=3, kernel=poly, tol=0.001;, score=0.754 total time=   0.2s\n",
            "[CV 2/5; 105/143] START C=100, degree=3, kernel=poly, tol=0.001.................\n",
            "[CV 2/5; 105/143] END C=100, degree=3, kernel=poly, tol=0.001;, score=0.728 total time=   0.3s\n",
            "[CV 3/5; 105/143] START C=100, degree=3, kernel=poly, tol=0.001.................\n",
            "[CV 3/5; 105/143] END C=100, degree=3, kernel=poly, tol=0.001;, score=0.728 total time=   0.1s\n",
            "[CV 4/5; 105/143] START C=100, degree=3, kernel=poly, tol=0.001.................\n",
            "[CV 4/5; 105/143] END C=100, degree=3, kernel=poly, tol=0.001;, score=0.754 total time=   0.2s\n",
            "[CV 5/5; 105/143] START C=100, degree=3, kernel=poly, tol=0.001.................\n",
            "[CV 5/5; 105/143] END C=100, degree=3, kernel=poly, tol=0.001;, score=0.798 total time=   0.2s\n",
            "[CV 1/5; 106/143] START C=100, degree=3, kernel=poly, tol=0.0001................\n",
            "[CV 1/5; 106/143] END C=100, degree=3, kernel=poly, tol=0.0001;, score=0.754 total time=   0.3s\n",
            "[CV 2/5; 106/143] START C=100, degree=3, kernel=poly, tol=0.0001................\n",
            "[CV 2/5; 106/143] END C=100, degree=3, kernel=poly, tol=0.0001;, score=0.728 total time=   0.4s\n",
            "[CV 3/5; 106/143] START C=100, degree=3, kernel=poly, tol=0.0001................\n",
            "[CV 3/5; 106/143] END C=100, degree=3, kernel=poly, tol=0.0001;, score=0.728 total time=   0.2s\n",
            "[CV 4/5; 106/143] START C=100, degree=3, kernel=poly, tol=0.0001................\n",
            "[CV 4/5; 106/143] END C=100, degree=3, kernel=poly, tol=0.0001;, score=0.754 total time=   0.3s\n",
            "[CV 5/5; 106/143] START C=100, degree=3, kernel=poly, tol=0.0001................\n",
            "[CV 5/5; 106/143] END C=100, degree=3, kernel=poly, tol=0.0001;, score=0.798 total time=   0.3s\n",
            "[CV 1/5; 107/143] START C=100, degree=3, kernel=poly, tol=1e-05.................\n",
            "[CV 1/5; 107/143] END C=100, degree=3, kernel=poly, tol=1e-05;, score=0.754 total time=   0.3s\n",
            "[CV 2/5; 107/143] START C=100, degree=3, kernel=poly, tol=1e-05.................\n",
            "[CV 2/5; 107/143] END C=100, degree=3, kernel=poly, tol=1e-05;, score=0.728 total time=   0.5s\n",
            "[CV 3/5; 107/143] START C=100, degree=3, kernel=poly, tol=1e-05.................\n",
            "[CV 3/5; 107/143] END C=100, degree=3, kernel=poly, tol=1e-05;, score=0.728 total time=   0.3s\n",
            "[CV 4/5; 107/143] START C=100, degree=3, kernel=poly, tol=1e-05.................\n",
            "[CV 4/5; 107/143] END C=100, degree=3, kernel=poly, tol=1e-05;, score=0.754 total time=   0.5s\n",
            "[CV 5/5; 107/143] START C=100, degree=3, kernel=poly, tol=1e-05.................\n",
            "[CV 5/5; 107/143] END C=100, degree=3, kernel=poly, tol=1e-05;, score=0.798 total time=   0.4s\n",
            "[CV 1/5; 108/143] START C=100, degree=3, kernel=poly, tol=scale.................\n",
            "[CV 1/5; 108/143] END C=100, degree=3, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 2/5; 108/143] START C=100, degree=3, kernel=poly, tol=scale.................\n",
            "[CV 2/5; 108/143] END C=100, degree=3, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 3/5; 108/143] START C=100, degree=3, kernel=poly, tol=scale.................\n",
            "[CV 3/5; 108/143] END C=100, degree=3, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 4/5; 108/143] START C=100, degree=3, kernel=poly, tol=scale.................\n",
            "[CV 4/5; 108/143] END C=100, degree=3, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 5/5; 108/143] START C=100, degree=3, kernel=poly, tol=scale.................\n",
            "[CV 5/5; 108/143] END C=100, degree=3, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 1/5; 109/143] START C=100, degree=4, kernel=poly, tol=0.01..................\n",
            "[CV 1/5; 109/143] END C=100, degree=4, kernel=poly, tol=0.01;, score=0.660 total time=   0.1s\n",
            "[CV 2/5; 109/143] START C=100, degree=4, kernel=poly, tol=0.01..................\n",
            "[CV 2/5; 109/143] END C=100, degree=4, kernel=poly, tol=0.01;, score=0.638 total time=   0.1s\n",
            "[CV 3/5; 109/143] START C=100, degree=4, kernel=poly, tol=0.01..................\n",
            "[CV 3/5; 109/143] END C=100, degree=4, kernel=poly, tol=0.01;, score=0.638 total time=   0.1s\n",
            "[CV 4/5; 109/143] START C=100, degree=4, kernel=poly, tol=0.01..................\n",
            "[CV 4/5; 109/143] END C=100, degree=4, kernel=poly, tol=0.01;, score=0.664 total time=   0.1s\n",
            "[CV 5/5; 109/143] START C=100, degree=4, kernel=poly, tol=0.01..................\n",
            "[CV 5/5; 109/143] END C=100, degree=4, kernel=poly, tol=0.01;, score=0.670 total time=   0.1s\n",
            "[CV 1/5; 110/143] START C=100, degree=4, kernel=poly, tol=0.001.................\n",
            "[CV 1/5; 110/143] END C=100, degree=4, kernel=poly, tol=0.001;, score=0.660 total time=   0.1s\n",
            "[CV 2/5; 110/143] START C=100, degree=4, kernel=poly, tol=0.001.................\n",
            "[CV 2/5; 110/143] END C=100, degree=4, kernel=poly, tol=0.001;, score=0.638 total time=   0.2s\n",
            "[CV 3/5; 110/143] START C=100, degree=4, kernel=poly, tol=0.001.................\n",
            "[CV 3/5; 110/143] END C=100, degree=4, kernel=poly, tol=0.001;, score=0.638 total time=   0.2s\n",
            "[CV 4/5; 110/143] START C=100, degree=4, kernel=poly, tol=0.001.................\n",
            "[CV 4/5; 110/143] END C=100, degree=4, kernel=poly, tol=0.001;, score=0.664 total time=   0.3s\n",
            "[CV 5/5; 110/143] START C=100, degree=4, kernel=poly, tol=0.001.................\n",
            "[CV 5/5; 110/143] END C=100, degree=4, kernel=poly, tol=0.001;, score=0.670 total time=   0.2s\n",
            "[CV 1/5; 111/143] START C=100, degree=4, kernel=poly, tol=0.0001................\n",
            "[CV 1/5; 111/143] END C=100, degree=4, kernel=poly, tol=0.0001;, score=0.660 total time=   0.2s\n",
            "[CV 2/5; 111/143] START C=100, degree=4, kernel=poly, tol=0.0001................\n",
            "[CV 2/5; 111/143] END C=100, degree=4, kernel=poly, tol=0.0001;, score=0.638 total time=   0.2s\n",
            "[CV 3/5; 111/143] START C=100, degree=4, kernel=poly, tol=0.0001................\n",
            "[CV 3/5; 111/143] END C=100, degree=4, kernel=poly, tol=0.0001;, score=0.638 total time=   0.2s\n",
            "[CV 4/5; 111/143] START C=100, degree=4, kernel=poly, tol=0.0001................\n",
            "[CV 4/5; 111/143] END C=100, degree=4, kernel=poly, tol=0.0001;, score=0.664 total time=   0.3s\n",
            "[CV 5/5; 111/143] START C=100, degree=4, kernel=poly, tol=0.0001................\n",
            "[CV 5/5; 111/143] END C=100, degree=4, kernel=poly, tol=0.0001;, score=0.670 total time=   0.3s\n",
            "[CV 1/5; 112/143] START C=100, degree=4, kernel=poly, tol=1e-05.................\n",
            "[CV 1/5; 112/143] END C=100, degree=4, kernel=poly, tol=1e-05;, score=0.660 total time=   0.2s\n",
            "[CV 2/5; 112/143] START C=100, degree=4, kernel=poly, tol=1e-05.................\n",
            "[CV 2/5; 112/143] END C=100, degree=4, kernel=poly, tol=1e-05;, score=0.638 total time=   0.2s\n",
            "[CV 3/5; 112/143] START C=100, degree=4, kernel=poly, tol=1e-05.................\n",
            "[CV 3/5; 112/143] END C=100, degree=4, kernel=poly, tol=1e-05;, score=0.638 total time=   0.3s\n",
            "[CV 4/5; 112/143] START C=100, degree=4, kernel=poly, tol=1e-05.................\n",
            "[CV 4/5; 112/143] END C=100, degree=4, kernel=poly, tol=1e-05;, score=0.664 total time=   0.5s\n",
            "[CV 5/5; 112/143] START C=100, degree=4, kernel=poly, tol=1e-05.................\n",
            "[CV 5/5; 112/143] END C=100, degree=4, kernel=poly, tol=1e-05;, score=0.670 total time=   0.4s\n",
            "[CV 1/5; 113/143] START C=100, degree=4, kernel=poly, tol=scale.................\n",
            "[CV 1/5; 113/143] END C=100, degree=4, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 2/5; 113/143] START C=100, degree=4, kernel=poly, tol=scale.................\n",
            "[CV 2/5; 113/143] END C=100, degree=4, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 3/5; 113/143] START C=100, degree=4, kernel=poly, tol=scale.................\n",
            "[CV 3/5; 113/143] END C=100, degree=4, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 4/5; 113/143] START C=100, degree=4, kernel=poly, tol=scale.................\n",
            "[CV 4/5; 113/143] END C=100, degree=4, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 5/5; 113/143] START C=100, degree=4, kernel=poly, tol=scale.................\n",
            "[CV 5/5; 113/143] END C=100, degree=4, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 1/5; 114/143] START C=1000, degree=2, kernel=poly, tol=0.01.................\n",
            "[CV 1/5; 114/143] END C=1000, degree=2, kernel=poly, tol=0.01;, score=0.586 total time=   0.6s\n",
            "[CV 2/5; 114/143] START C=1000, degree=2, kernel=poly, tol=0.01.................\n",
            "[CV 2/5; 114/143] END C=1000, degree=2, kernel=poly, tol=0.01;, score=0.571 total time=   0.9s\n",
            "[CV 3/5; 114/143] START C=1000, degree=2, kernel=poly, tol=0.01.................\n",
            "[CV 3/5; 114/143] END C=1000, degree=2, kernel=poly, tol=0.01;, score=0.556 total time=   1.0s\n",
            "[CV 4/5; 114/143] START C=1000, degree=2, kernel=poly, tol=0.01.................\n",
            "[CV 4/5; 114/143] END C=1000, degree=2, kernel=poly, tol=0.01;, score=0.642 total time=   0.9s\n",
            "[CV 5/5; 114/143] START C=1000, degree=2, kernel=poly, tol=0.01.................\n",
            "[CV 5/5; 114/143] END C=1000, degree=2, kernel=poly, tol=0.01;, score=0.610 total time=   0.9s\n",
            "[CV 1/5; 115/143] START C=1000, degree=2, kernel=poly, tol=0.001................\n",
            "[CV 1/5; 115/143] END C=1000, degree=2, kernel=poly, tol=0.001;, score=0.586 total time=   0.7s\n",
            "[CV 2/5; 115/143] START C=1000, degree=2, kernel=poly, tol=0.001................\n",
            "[CV 2/5; 115/143] END C=1000, degree=2, kernel=poly, tol=0.001;, score=0.571 total time=   1.2s\n",
            "[CV 3/5; 115/143] START C=1000, degree=2, kernel=poly, tol=0.001................\n",
            "[CV 3/5; 115/143] END C=1000, degree=2, kernel=poly, tol=0.001;, score=0.556 total time=   2.6s\n",
            "[CV 4/5; 115/143] START C=1000, degree=2, kernel=poly, tol=0.001................\n",
            "[CV 4/5; 115/143] END C=1000, degree=2, kernel=poly, tol=0.001;, score=0.642 total time=   1.3s\n",
            "[CV 5/5; 115/143] START C=1000, degree=2, kernel=poly, tol=0.001................\n",
            "[CV 5/5; 115/143] END C=1000, degree=2, kernel=poly, tol=0.001;, score=0.607 total time=   2.0s\n",
            "[CV 1/5; 116/143] START C=1000, degree=2, kernel=poly, tol=0.0001...............\n",
            "[CV 1/5; 116/143] END C=1000, degree=2, kernel=poly, tol=0.0001;, score=0.586 total time=   1.0s\n",
            "[CV 2/5; 116/143] START C=1000, degree=2, kernel=poly, tol=0.0001...............\n",
            "[CV 2/5; 116/143] END C=1000, degree=2, kernel=poly, tol=0.0001;, score=0.571 total time=   2.4s\n",
            "[CV 3/5; 116/143] START C=1000, degree=2, kernel=poly, tol=0.0001...............\n",
            "[CV 3/5; 116/143] END C=1000, degree=2, kernel=poly, tol=0.0001;, score=0.556 total time=   3.6s\n",
            "[CV 4/5; 116/143] START C=1000, degree=2, kernel=poly, tol=0.0001...............\n",
            "[CV 4/5; 116/143] END C=1000, degree=2, kernel=poly, tol=0.0001;, score=0.642 total time=   2.4s\n",
            "[CV 5/5; 116/143] START C=1000, degree=2, kernel=poly, tol=0.0001...............\n",
            "[CV 5/5; 116/143] END C=1000, degree=2, kernel=poly, tol=0.0001;, score=0.607 total time=   2.9s\n",
            "[CV 1/5; 117/143] START C=1000, degree=2, kernel=poly, tol=1e-05................\n",
            "[CV 1/5; 117/143] END C=1000, degree=2, kernel=poly, tol=1e-05;, score=0.586 total time=   1.3s\n",
            "[CV 2/5; 117/143] START C=1000, degree=2, kernel=poly, tol=1e-05................\n",
            "[CV 2/5; 117/143] END C=1000, degree=2, kernel=poly, tol=1e-05;, score=0.571 total time=   3.4s\n",
            "[CV 3/5; 117/143] START C=1000, degree=2, kernel=poly, tol=1e-05................\n",
            "[CV 3/5; 117/143] END C=1000, degree=2, kernel=poly, tol=1e-05;, score=0.556 total time=   5.3s\n",
            "[CV 4/5; 117/143] START C=1000, degree=2, kernel=poly, tol=1e-05................\n",
            "[CV 4/5; 117/143] END C=1000, degree=2, kernel=poly, tol=1e-05;, score=0.642 total time=   4.0s\n",
            "[CV 5/5; 117/143] START C=1000, degree=2, kernel=poly, tol=1e-05................\n",
            "[CV 5/5; 117/143] END C=1000, degree=2, kernel=poly, tol=1e-05;, score=0.607 total time=   4.1s\n",
            "[CV 1/5; 118/143] START C=1000, degree=2, kernel=poly, tol=scale................\n",
            "[CV 1/5; 118/143] END C=1000, degree=2, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 2/5; 118/143] START C=1000, degree=2, kernel=poly, tol=scale................\n",
            "[CV 2/5; 118/143] END C=1000, degree=2, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 3/5; 118/143] START C=1000, degree=2, kernel=poly, tol=scale................\n",
            "[CV 3/5; 118/143] END C=1000, degree=2, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 4/5; 118/143] START C=1000, degree=2, kernel=poly, tol=scale................\n",
            "[CV 4/5; 118/143] END C=1000, degree=2, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 5/5; 118/143] START C=1000, degree=2, kernel=poly, tol=scale................\n",
            "[CV 5/5; 118/143] END C=1000, degree=2, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 1/5; 119/143] START C=1000, degree=3, kernel=poly, tol=0.01.................\n",
            "[CV 1/5; 119/143] END C=1000, degree=3, kernel=poly, tol=0.01;, score=0.899 total time=   0.3s\n",
            "[CV 2/5; 119/143] START C=1000, degree=3, kernel=poly, tol=0.01.................\n",
            "[CV 2/5; 119/143] END C=1000, degree=3, kernel=poly, tol=0.01;, score=0.836 total time=   0.4s\n",
            "[CV 3/5; 119/143] START C=1000, degree=3, kernel=poly, tol=0.01.................\n",
            "[CV 3/5; 119/143] END C=1000, degree=3, kernel=poly, tol=0.01;, score=0.821 total time=   0.5s\n",
            "[CV 4/5; 119/143] START C=1000, degree=3, kernel=poly, tol=0.01.................\n",
            "[CV 4/5; 119/143] END C=1000, degree=3, kernel=poly, tol=0.01;, score=0.817 total time=   0.3s\n",
            "[CV 5/5; 119/143] START C=1000, degree=3, kernel=poly, tol=0.01.................\n",
            "[CV 5/5; 119/143] END C=1000, degree=3, kernel=poly, tol=0.01;, score=0.873 total time=   0.4s\n",
            "[CV 1/5; 120/143] START C=1000, degree=3, kernel=poly, tol=0.001................\n",
            "[CV 1/5; 120/143] END C=1000, degree=3, kernel=poly, tol=0.001;, score=0.899 total time=   0.5s\n",
            "[CV 2/5; 120/143] START C=1000, degree=3, kernel=poly, tol=0.001................\n",
            "[CV 2/5; 120/143] END C=1000, degree=3, kernel=poly, tol=0.001;, score=0.836 total time=   0.6s\n",
            "[CV 3/5; 120/143] START C=1000, degree=3, kernel=poly, tol=0.001................\n",
            "[CV 3/5; 120/143] END C=1000, degree=3, kernel=poly, tol=0.001;, score=0.821 total time=   0.8s\n",
            "[CV 4/5; 120/143] START C=1000, degree=3, kernel=poly, tol=0.001................\n",
            "[CV 4/5; 120/143] END C=1000, degree=3, kernel=poly, tol=0.001;, score=0.817 total time=   0.5s\n",
            "[CV 5/5; 120/143] START C=1000, degree=3, kernel=poly, tol=0.001................\n",
            "[CV 5/5; 120/143] END C=1000, degree=3, kernel=poly, tol=0.001;, score=0.873 total time=   0.6s\n",
            "[CV 1/5; 121/143] START C=1000, degree=3, kernel=poly, tol=0.0001...............\n",
            "[CV 1/5; 121/143] END C=1000, degree=3, kernel=poly, tol=0.0001;, score=0.899 total time=   0.9s\n",
            "[CV 2/5; 121/143] START C=1000, degree=3, kernel=poly, tol=0.0001...............\n",
            "[CV 2/5; 121/143] END C=1000, degree=3, kernel=poly, tol=0.0001;, score=0.836 total time=   0.9s\n",
            "[CV 3/5; 121/143] START C=1000, degree=3, kernel=poly, tol=0.0001...............\n",
            "[CV 3/5; 121/143] END C=1000, degree=3, kernel=poly, tol=0.0001;, score=0.821 total time=   1.2s\n",
            "[CV 4/5; 121/143] START C=1000, degree=3, kernel=poly, tol=0.0001...............\n",
            "[CV 4/5; 121/143] END C=1000, degree=3, kernel=poly, tol=0.0001;, score=0.817 total time=   0.9s\n",
            "[CV 5/5; 121/143] START C=1000, degree=3, kernel=poly, tol=0.0001...............\n",
            "[CV 5/5; 121/143] END C=1000, degree=3, kernel=poly, tol=0.0001;, score=0.873 total time=   0.8s\n",
            "[CV 1/5; 122/143] START C=1000, degree=3, kernel=poly, tol=1e-05................\n",
            "[CV 1/5; 122/143] END C=1000, degree=3, kernel=poly, tol=1e-05;, score=0.899 total time=   1.1s\n",
            "[CV 2/5; 122/143] START C=1000, degree=3, kernel=poly, tol=1e-05................\n",
            "[CV 2/5; 122/143] END C=1000, degree=3, kernel=poly, tol=1e-05;, score=0.836 total time=   1.3s\n",
            "[CV 3/5; 122/143] START C=1000, degree=3, kernel=poly, tol=1e-05................\n",
            "[CV 3/5; 122/143] END C=1000, degree=3, kernel=poly, tol=1e-05;, score=0.821 total time=   1.8s\n",
            "[CV 4/5; 122/143] START C=1000, degree=3, kernel=poly, tol=1e-05................\n",
            "[CV 4/5; 122/143] END C=1000, degree=3, kernel=poly, tol=1e-05;, score=0.817 total time=   1.0s\n",
            "[CV 5/5; 122/143] START C=1000, degree=3, kernel=poly, tol=1e-05................\n",
            "[CV 5/5; 122/143] END C=1000, degree=3, kernel=poly, tol=1e-05;, score=0.873 total time=   1.2s\n",
            "[CV 1/5; 123/143] START C=1000, degree=3, kernel=poly, tol=scale................\n",
            "[CV 1/5; 123/143] END C=1000, degree=3, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 2/5; 123/143] START C=1000, degree=3, kernel=poly, tol=scale................\n",
            "[CV 2/5; 123/143] END C=1000, degree=3, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 3/5; 123/143] START C=1000, degree=3, kernel=poly, tol=scale................\n",
            "[CV 3/5; 123/143] END C=1000, degree=3, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 4/5; 123/143] START C=1000, degree=3, kernel=poly, tol=scale................\n",
            "[CV 4/5; 123/143] END C=1000, degree=3, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 5/5; 123/143] START C=1000, degree=3, kernel=poly, tol=scale................\n",
            "[CV 5/5; 123/143] END C=1000, degree=3, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 1/5; 124/143] START C=1000, degree=4, kernel=poly, tol=0.01.................\n",
            "[CV 1/5; 124/143] END C=1000, degree=4, kernel=poly, tol=0.01;, score=0.821 total time=   0.7s\n",
            "[CV 2/5; 124/143] START C=1000, degree=4, kernel=poly, tol=0.01.................\n",
            "[CV 2/5; 124/143] END C=1000, degree=4, kernel=poly, tol=0.01;, score=0.709 total time=   0.7s\n",
            "[CV 3/5; 124/143] START C=1000, degree=4, kernel=poly, tol=0.01.................\n",
            "[CV 3/5; 124/143] END C=1000, degree=4, kernel=poly, tol=0.01;, score=0.735 total time=   0.6s\n",
            "[CV 4/5; 124/143] START C=1000, degree=4, kernel=poly, tol=0.01.................\n",
            "[CV 4/5; 124/143] END C=1000, degree=4, kernel=poly, tol=0.01;, score=0.746 total time=   0.8s\n",
            "[CV 5/5; 124/143] START C=1000, degree=4, kernel=poly, tol=0.01.................\n",
            "[CV 5/5; 124/143] END C=1000, degree=4, kernel=poly, tol=0.01;, score=0.734 total time=   0.7s\n",
            "[CV 1/5; 125/143] START C=1000, degree=4, kernel=poly, tol=0.001................\n",
            "[CV 1/5; 125/143] END C=1000, degree=4, kernel=poly, tol=0.001;, score=0.821 total time=   1.2s\n",
            "[CV 2/5; 125/143] START C=1000, degree=4, kernel=poly, tol=0.001................\n",
            "[CV 2/5; 125/143] END C=1000, degree=4, kernel=poly, tol=0.001;, score=0.709 total time=   1.2s\n",
            "[CV 3/5; 125/143] START C=1000, degree=4, kernel=poly, tol=0.001................\n",
            "[CV 3/5; 125/143] END C=1000, degree=4, kernel=poly, tol=0.001;, score=0.735 total time=   1.0s\n",
            "[CV 4/5; 125/143] START C=1000, degree=4, kernel=poly, tol=0.001................\n",
            "[CV 4/5; 125/143] END C=1000, degree=4, kernel=poly, tol=0.001;, score=0.746 total time=   1.1s\n",
            "[CV 5/5; 125/143] START C=1000, degree=4, kernel=poly, tol=0.001................\n",
            "[CV 5/5; 125/143] END C=1000, degree=4, kernel=poly, tol=0.001;, score=0.734 total time=   0.6s\n",
            "[CV 1/5; 126/143] START C=1000, degree=4, kernel=poly, tol=0.0001...............\n",
            "[CV 1/5; 126/143] END C=1000, degree=4, kernel=poly, tol=0.0001;, score=0.821 total time=   1.3s\n",
            "[CV 2/5; 126/143] START C=1000, degree=4, kernel=poly, tol=0.0001...............\n",
            "[CV 2/5; 126/143] END C=1000, degree=4, kernel=poly, tol=0.0001;, score=0.709 total time=   1.4s\n",
            "[CV 3/5; 126/143] START C=1000, degree=4, kernel=poly, tol=0.0001...............\n",
            "[CV 3/5; 126/143] END C=1000, degree=4, kernel=poly, tol=0.0001;, score=0.735 total time=   0.9s\n",
            "[CV 4/5; 126/143] START C=1000, degree=4, kernel=poly, tol=0.0001...............\n",
            "[CV 4/5; 126/143] END C=1000, degree=4, kernel=poly, tol=0.0001;, score=0.746 total time=   1.2s\n",
            "[CV 5/5; 126/143] START C=1000, degree=4, kernel=poly, tol=0.0001...............\n",
            "[CV 5/5; 126/143] END C=1000, degree=4, kernel=poly, tol=0.0001;, score=0.734 total time=   1.0s\n",
            "[CV 1/5; 127/143] START C=1000, degree=4, kernel=poly, tol=1e-05................\n",
            "[CV 1/5; 127/143] END C=1000, degree=4, kernel=poly, tol=1e-05;, score=0.821 total time=   1.7s\n",
            "[CV 2/5; 127/143] START C=1000, degree=4, kernel=poly, tol=1e-05................\n",
            "[CV 2/5; 127/143] END C=1000, degree=4, kernel=poly, tol=1e-05;, score=0.709 total time=   1.7s\n",
            "[CV 3/5; 127/143] START C=1000, degree=4, kernel=poly, tol=1e-05................\n",
            "[CV 3/5; 127/143] END C=1000, degree=4, kernel=poly, tol=1e-05;, score=0.735 total time=   1.0s\n",
            "[CV 4/5; 127/143] START C=1000, degree=4, kernel=poly, tol=1e-05................\n",
            "[CV 4/5; 127/143] END C=1000, degree=4, kernel=poly, tol=1e-05;, score=0.746 total time=   2.4s\n",
            "[CV 5/5; 127/143] START C=1000, degree=4, kernel=poly, tol=1e-05................\n",
            "[CV 5/5; 127/143] END C=1000, degree=4, kernel=poly, tol=1e-05;, score=0.734 total time=   1.2s\n",
            "[CV 1/5; 128/143] START C=1000, degree=4, kernel=poly, tol=scale................\n",
            "[CV 1/5; 128/143] END C=1000, degree=4, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 2/5; 128/143] START C=1000, degree=4, kernel=poly, tol=scale................\n",
            "[CV 2/5; 128/143] END C=1000, degree=4, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 3/5; 128/143] START C=1000, degree=4, kernel=poly, tol=scale................\n",
            "[CV 3/5; 128/143] END C=1000, degree=4, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 4/5; 128/143] START C=1000, degree=4, kernel=poly, tol=scale................\n",
            "[CV 4/5; 128/143] END C=1000, degree=4, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 5/5; 128/143] START C=1000, degree=4, kernel=poly, tol=scale................\n",
            "[CV 5/5; 128/143] END C=1000, degree=4, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 1/5; 129/143] START C=10000, degree=2, kernel=poly, tol=0.01................\n",
            "[CV 1/5; 129/143] END C=10000, degree=2, kernel=poly, tol=0.01;, score=0.575 total time=   7.4s\n",
            "[CV 2/5; 129/143] START C=10000, degree=2, kernel=poly, tol=0.01................\n",
            "[CV 2/5; 129/143] END C=10000, degree=2, kernel=poly, tol=0.01;, score=0.560 total time=   7.0s\n",
            "[CV 3/5; 129/143] START C=10000, degree=2, kernel=poly, tol=0.01................\n",
            "[CV 3/5; 129/143] END C=10000, degree=2, kernel=poly, tol=0.01;, score=0.601 total time=   5.9s\n",
            "[CV 4/5; 129/143] START C=10000, degree=2, kernel=poly, tol=0.01................\n",
            "[CV 4/5; 129/143] END C=10000, degree=2, kernel=poly, tol=0.01;, score=0.597 total time=   3.5s\n",
            "[CV 5/5; 129/143] START C=10000, degree=2, kernel=poly, tol=0.01................\n",
            "[CV 5/5; 129/143] END C=10000, degree=2, kernel=poly, tol=0.01;, score=0.625 total time=   6.0s\n",
            "[CV 1/5; 130/143] START C=10000, degree=2, kernel=poly, tol=0.001...............\n",
            "[CV 1/5; 130/143] END C=10000, degree=2, kernel=poly, tol=0.001;, score=0.575 total time=  15.1s\n",
            "[CV 2/5; 130/143] START C=10000, degree=2, kernel=poly, tol=0.001...............\n",
            "[CV 2/5; 130/143] END C=10000, degree=2, kernel=poly, tol=0.001;, score=0.560 total time=  19.4s\n",
            "[CV 3/5; 130/143] START C=10000, degree=2, kernel=poly, tol=0.001...............\n",
            "[CV 3/5; 130/143] END C=10000, degree=2, kernel=poly, tol=0.001;, score=0.601 total time=  11.5s\n",
            "[CV 4/5; 130/143] START C=10000, degree=2, kernel=poly, tol=0.001...............\n",
            "[CV 4/5; 130/143] END C=10000, degree=2, kernel=poly, tol=0.001;, score=0.601 total time=  12.4s\n",
            "[CV 5/5; 130/143] START C=10000, degree=2, kernel=poly, tol=0.001...............\n",
            "[CV 5/5; 130/143] END C=10000, degree=2, kernel=poly, tol=0.001;, score=0.629 total time=  21.5s\n",
            "[CV 1/5; 131/143] START C=10000, degree=2, kernel=poly, tol=0.0001..............\n",
            "[CV 1/5; 131/143] END C=10000, degree=2, kernel=poly, tol=0.0001;, score=0.575 total time=  45.5s\n",
            "[CV 2/5; 131/143] START C=10000, degree=2, kernel=poly, tol=0.0001..............\n",
            "[CV 2/5; 131/143] END C=10000, degree=2, kernel=poly, tol=0.0001;, score=0.560 total time=  49.5s\n",
            "[CV 3/5; 131/143] START C=10000, degree=2, kernel=poly, tol=0.0001..............\n",
            "[CV 3/5; 131/143] END C=10000, degree=2, kernel=poly, tol=0.0001;, score=0.601 total time=  34.2s\n",
            "[CV 4/5; 131/143] START C=10000, degree=2, kernel=poly, tol=0.0001..............\n",
            "[CV 4/5; 131/143] END C=10000, degree=2, kernel=poly, tol=0.0001;, score=0.601 total time=  27.6s\n",
            "[CV 5/5; 131/143] START C=10000, degree=2, kernel=poly, tol=0.0001..............\n",
            "[CV 5/5; 131/143] END C=10000, degree=2, kernel=poly, tol=0.0001;, score=0.629 total time=  38.9s\n",
            "[CV 1/5; 132/143] START C=10000, degree=2, kernel=poly, tol=1e-05...............\n",
            "[CV 1/5; 132/143] END C=10000, degree=2, kernel=poly, tol=1e-05;, score=0.575 total time= 1.0min\n",
            "[CV 2/5; 132/143] START C=10000, degree=2, kernel=poly, tol=1e-05...............\n",
            "[CV 2/5; 132/143] END C=10000, degree=2, kernel=poly, tol=1e-05;, score=0.560 total time=  39.1s\n",
            "[CV 3/5; 132/143] START C=10000, degree=2, kernel=poly, tol=1e-05...............\n",
            "[CV 3/5; 132/143] END C=10000, degree=2, kernel=poly, tol=1e-05;, score=0.601 total time=  37.4s\n",
            "[CV 4/5; 132/143] START C=10000, degree=2, kernel=poly, tol=1e-05...............\n",
            "[CV 4/5; 132/143] END C=10000, degree=2, kernel=poly, tol=1e-05;, score=0.601 total time=  30.7s\n",
            "[CV 5/5; 132/143] START C=10000, degree=2, kernel=poly, tol=1e-05...............\n",
            "[CV 5/5; 132/143] END C=10000, degree=2, kernel=poly, tol=1e-05;, score=0.629 total time=  53.7s\n",
            "[CV 1/5; 133/143] START C=10000, degree=2, kernel=poly, tol=scale...............\n",
            "[CV 1/5; 133/143] END C=10000, degree=2, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 2/5; 133/143] START C=10000, degree=2, kernel=poly, tol=scale...............\n",
            "[CV 2/5; 133/143] END C=10000, degree=2, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 3/5; 133/143] START C=10000, degree=2, kernel=poly, tol=scale...............\n",
            "[CV 3/5; 133/143] END C=10000, degree=2, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 4/5; 133/143] START C=10000, degree=2, kernel=poly, tol=scale...............\n",
            "[CV 4/5; 133/143] END C=10000, degree=2, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 5/5; 133/143] START C=10000, degree=2, kernel=poly, tol=scale...............\n",
            "[CV 5/5; 133/143] END C=10000, degree=2, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 1/5; 134/143] START C=10000, degree=3, kernel=poly, tol=0.01................\n",
            "[CV 1/5; 134/143] END C=10000, degree=3, kernel=poly, tol=0.01;, score=0.922 total time=   0.8s\n",
            "[CV 2/5; 134/143] START C=10000, degree=3, kernel=poly, tol=0.01................\n",
            "[CV 2/5; 134/143] END C=10000, degree=3, kernel=poly, tol=0.01;, score=0.851 total time=   1.4s\n",
            "[CV 3/5; 134/143] START C=10000, degree=3, kernel=poly, tol=0.01................\n",
            "[CV 3/5; 134/143] END C=10000, degree=3, kernel=poly, tol=0.01;, score=0.869 total time=   0.8s\n",
            "[CV 4/5; 134/143] START C=10000, degree=3, kernel=poly, tol=0.01................\n",
            "[CV 4/5; 134/143] END C=10000, degree=3, kernel=poly, tol=0.01;, score=0.869 total time=   0.9s\n",
            "[CV 5/5; 134/143] START C=10000, degree=3, kernel=poly, tol=0.01................\n",
            "[CV 5/5; 134/143] END C=10000, degree=3, kernel=poly, tol=0.01;, score=0.914 total time=   0.7s\n",
            "[CV 1/5; 135/143] START C=10000, degree=3, kernel=poly, tol=0.001...............\n",
            "[CV 1/5; 135/143] END C=10000, degree=3, kernel=poly, tol=0.001;, score=0.922 total time=   1.4s\n",
            "[CV 2/5; 135/143] START C=10000, degree=3, kernel=poly, tol=0.001...............\n",
            "[CV 2/5; 135/143] END C=10000, degree=3, kernel=poly, tol=0.001;, score=0.851 total time=   2.4s\n",
            "[CV 3/5; 135/143] START C=10000, degree=3, kernel=poly, tol=0.001...............\n",
            "[CV 3/5; 135/143] END C=10000, degree=3, kernel=poly, tol=0.001;, score=0.869 total time=   1.3s\n",
            "[CV 4/5; 135/143] START C=10000, degree=3, kernel=poly, tol=0.001...............\n",
            "[CV 4/5; 135/143] END C=10000, degree=3, kernel=poly, tol=0.001;, score=0.869 total time=   1.7s\n",
            "[CV 5/5; 135/143] START C=10000, degree=3, kernel=poly, tol=0.001...............\n",
            "[CV 5/5; 135/143] END C=10000, degree=3, kernel=poly, tol=0.001;, score=0.914 total time=   1.1s\n",
            "[CV 1/5; 136/143] START C=10000, degree=3, kernel=poly, tol=0.0001..............\n",
            "[CV 1/5; 136/143] END C=10000, degree=3, kernel=poly, tol=0.0001;, score=0.922 total time=   1.9s\n",
            "[CV 2/5; 136/143] START C=10000, degree=3, kernel=poly, tol=0.0001..............\n",
            "[CV 2/5; 136/143] END C=10000, degree=3, kernel=poly, tol=0.0001;, score=0.851 total time=   3.4s\n",
            "[CV 3/5; 136/143] START C=10000, degree=3, kernel=poly, tol=0.0001..............\n",
            "[CV 3/5; 136/143] END C=10000, degree=3, kernel=poly, tol=0.0001;, score=0.869 total time=   1.8s\n",
            "[CV 4/5; 136/143] START C=10000, degree=3, kernel=poly, tol=0.0001..............\n",
            "[CV 4/5; 136/143] END C=10000, degree=3, kernel=poly, tol=0.0001;, score=0.869 total time=   2.7s\n",
            "[CV 5/5; 136/143] START C=10000, degree=3, kernel=poly, tol=0.0001..............\n",
            "[CV 5/5; 136/143] END C=10000, degree=3, kernel=poly, tol=0.0001;, score=0.914 total time=   1.6s\n",
            "[CV 1/5; 137/143] START C=10000, degree=3, kernel=poly, tol=1e-05...............\n",
            "[CV 1/5; 137/143] END C=10000, degree=3, kernel=poly, tol=1e-05;, score=0.922 total time=   1.8s\n",
            "[CV 2/5; 137/143] START C=10000, degree=3, kernel=poly, tol=1e-05...............\n",
            "[CV 2/5; 137/143] END C=10000, degree=3, kernel=poly, tol=1e-05;, score=0.851 total time=   3.1s\n",
            "[CV 3/5; 137/143] START C=10000, degree=3, kernel=poly, tol=1e-05...............\n",
            "[CV 3/5; 137/143] END C=10000, degree=3, kernel=poly, tol=1e-05;, score=0.869 total time=   1.6s\n",
            "[CV 4/5; 137/143] START C=10000, degree=3, kernel=poly, tol=1e-05...............\n",
            "[CV 4/5; 137/143] END C=10000, degree=3, kernel=poly, tol=1e-05;, score=0.869 total time=   2.0s\n",
            "[CV 5/5; 137/143] START C=10000, degree=3, kernel=poly, tol=1e-05...............\n",
            "[CV 5/5; 137/143] END C=10000, degree=3, kernel=poly, tol=1e-05;, score=0.914 total time=   1.4s\n",
            "[CV 1/5; 138/143] START C=10000, degree=3, kernel=poly, tol=scale...............\n",
            "[CV 1/5; 138/143] END C=10000, degree=3, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 2/5; 138/143] START C=10000, degree=3, kernel=poly, tol=scale...............\n",
            "[CV 2/5; 138/143] END C=10000, degree=3, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 3/5; 138/143] START C=10000, degree=3, kernel=poly, tol=scale...............\n",
            "[CV 3/5; 138/143] END C=10000, degree=3, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 4/5; 138/143] START C=10000, degree=3, kernel=poly, tol=scale...............\n",
            "[CV 4/5; 138/143] END C=10000, degree=3, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 5/5; 138/143] START C=10000, degree=3, kernel=poly, tol=scale...............\n",
            "[CV 5/5; 138/143] END C=10000, degree=3, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 1/5; 139/143] START C=10000, degree=4, kernel=poly, tol=0.01................\n",
            "[CV 1/5; 139/143] END C=10000, degree=4, kernel=poly, tol=0.01;, score=0.862 total time=   0.9s\n",
            "[CV 2/5; 139/143] START C=10000, degree=4, kernel=poly, tol=0.01................\n",
            "[CV 2/5; 139/143] END C=10000, degree=4, kernel=poly, tol=0.01;, score=0.780 total time=   1.2s\n",
            "[CV 3/5; 139/143] START C=10000, degree=4, kernel=poly, tol=0.01................\n",
            "[CV 3/5; 139/143] END C=10000, degree=4, kernel=poly, tol=0.01;, score=0.795 total time=   1.4s\n",
            "[CV 4/5; 139/143] START C=10000, degree=4, kernel=poly, tol=0.01................\n",
            "[CV 4/5; 139/143] END C=10000, degree=4, kernel=poly, tol=0.01;, score=0.772 total time=   1.5s\n",
            "[CV 5/5; 139/143] START C=10000, degree=4, kernel=poly, tol=0.01................\n",
            "[CV 5/5; 139/143] END C=10000, degree=4, kernel=poly, tol=0.01;, score=0.820 total time=   0.6s\n",
            "[CV 1/5; 140/143] START C=10000, degree=4, kernel=poly, tol=0.001...............\n",
            "[CV 1/5; 140/143] END C=10000, degree=4, kernel=poly, tol=0.001;, score=0.862 total time=   1.6s\n",
            "[CV 2/5; 140/143] START C=10000, degree=4, kernel=poly, tol=0.001...............\n",
            "[CV 2/5; 140/143] END C=10000, degree=4, kernel=poly, tol=0.001;, score=0.780 total time=   1.6s\n",
            "[CV 3/5; 140/143] START C=10000, degree=4, kernel=poly, tol=0.001...............\n",
            "[CV 3/5; 140/143] END C=10000, degree=4, kernel=poly, tol=0.001;, score=0.795 total time=   2.0s\n",
            "[CV 4/5; 140/143] START C=10000, degree=4, kernel=poly, tol=0.001...............\n",
            "[CV 4/5; 140/143] END C=10000, degree=4, kernel=poly, tol=0.001;, score=0.772 total time=   2.0s\n",
            "[CV 5/5; 140/143] START C=10000, degree=4, kernel=poly, tol=0.001...............\n",
            "[CV 5/5; 140/143] END C=10000, degree=4, kernel=poly, tol=0.001;, score=0.820 total time=   1.0s\n",
            "[CV 1/5; 141/143] START C=10000, degree=4, kernel=poly, tol=0.0001..............\n",
            "[CV 1/5; 141/143] END C=10000, degree=4, kernel=poly, tol=0.0001;, score=0.862 total time=   3.0s\n",
            "[CV 2/5; 141/143] START C=10000, degree=4, kernel=poly, tol=0.0001..............\n",
            "[CV 2/5; 141/143] END C=10000, degree=4, kernel=poly, tol=0.0001;, score=0.780 total time=   3.6s\n",
            "[CV 3/5; 141/143] START C=10000, degree=4, kernel=poly, tol=0.0001..............\n",
            "[CV 3/5; 141/143] END C=10000, degree=4, kernel=poly, tol=0.0001;, score=0.795 total time=   3.6s\n",
            "[CV 4/5; 141/143] START C=10000, degree=4, kernel=poly, tol=0.0001..............\n",
            "[CV 4/5; 141/143] END C=10000, degree=4, kernel=poly, tol=0.0001;, score=0.772 total time=   3.7s\n",
            "[CV 5/5; 141/143] START C=10000, degree=4, kernel=poly, tol=0.0001..............\n",
            "[CV 5/5; 141/143] END C=10000, degree=4, kernel=poly, tol=0.0001;, score=0.820 total time=   2.4s\n",
            "[CV 1/5; 142/143] START C=10000, degree=4, kernel=poly, tol=1e-05...............\n",
            "[CV 1/5; 142/143] END C=10000, degree=4, kernel=poly, tol=1e-05;, score=0.862 total time=   4.6s\n",
            "[CV 2/5; 142/143] START C=10000, degree=4, kernel=poly, tol=1e-05...............\n",
            "[CV 2/5; 142/143] END C=10000, degree=4, kernel=poly, tol=1e-05;, score=0.780 total time=   4.8s\n",
            "[CV 3/5; 142/143] START C=10000, degree=4, kernel=poly, tol=1e-05...............\n",
            "[CV 3/5; 142/143] END C=10000, degree=4, kernel=poly, tol=1e-05;, score=0.795 total time=   4.6s\n",
            "[CV 4/5; 142/143] START C=10000, degree=4, kernel=poly, tol=1e-05...............\n",
            "[CV 4/5; 142/143] END C=10000, degree=4, kernel=poly, tol=1e-05;, score=0.772 total time=   4.8s\n",
            "[CV 5/5; 142/143] START C=10000, degree=4, kernel=poly, tol=1e-05...............\n",
            "[CV 5/5; 142/143] END C=10000, degree=4, kernel=poly, tol=1e-05;, score=0.820 total time=   3.4s\n",
            "[CV 1/5; 143/143] START C=10000, degree=4, kernel=poly, tol=scale...............\n",
            "[CV 1/5; 143/143] END C=10000, degree=4, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 2/5; 143/143] START C=10000, degree=4, kernel=poly, tol=scale...............\n",
            "[CV 2/5; 143/143] END C=10000, degree=4, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 3/5; 143/143] START C=10000, degree=4, kernel=poly, tol=scale...............\n",
            "[CV 3/5; 143/143] END C=10000, degree=4, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 4/5; 143/143] START C=10000, degree=4, kernel=poly, tol=scale...............\n",
            "[CV 4/5; 143/143] END C=10000, degree=4, kernel=poly, tol=scale;, score=nan total time=   0.0s\n",
            "[CV 5/5; 143/143] START C=10000, degree=4, kernel=poly, tol=scale...............\n",
            "[CV 5/5; 143/143] END C=10000, degree=4, kernel=poly, tol=scale;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "105 fits failed out of a total of 715.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "105 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 180, in fit\n",
            "    self._validate_params()\n",
            "  File \"c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'tol' parameter of SVC must be a float in the range (0.0, inf). Got 'scale' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.5220303  0.5220303  0.5220303  0.5220303  0.52352284 0.52352284\n",
            " 0.52352284 0.52352284 0.68636313 0.68636033 0.68561406 0.68561406\n",
            " 0.86556823 0.86706076 0.86780703 0.86706076 0.96116049 0.96115769\n",
            " 0.96115769 0.96115769 0.9768489  0.9768489  0.9768489  0.9768489\n",
            " 0.97834144 0.97834144 0.97834144 0.97834144 0.97759797 0.97834423\n",
            " 0.9790905  0.9790905  0.53697524 0.53324389 0.53399016 0.53399016\n",
            " 0.53399016        nan 0.66543686 0.66917938 0.66843032 0.66843032\n",
            " 0.66843032        nan 0.79463357 0.79687238 0.79612611 0.79687238\n",
            " 0.79687238        nan 0.85361675 0.85436302 0.85510929 0.85510929\n",
            " 0.85510929        nan 0.87603835 0.87529208 0.87454581 0.87454581\n",
            " 0.87454581        nan 0.87304209 0.87378836 0.87453463 0.87453463\n",
            " 0.87453463        nan 0.53994634 0.53994634 0.53994634 0.53994634\n",
            "        nan 0.51981106 0.51981106 0.52055733 0.52055733        nan\n",
            " 0.51157136 0.51157136 0.51157136 0.51157136        nan 0.57354799\n",
            " 0.57279893 0.57279893 0.57279893        nan 0.65126055 0.65200682\n",
            " 0.65200682 0.65200682        nan 0.59225222 0.59225222 0.59225222\n",
            " 0.59225222        nan 0.59074012 0.59074012 0.59074012 0.59074012\n",
            "        nan 0.75134161 0.75208788 0.75208788 0.75208788        nan\n",
            " 0.65423165 0.65423165 0.65423165 0.65423165        nan 0.5929929\n",
            " 0.59224384 0.59224384 0.59224384        nan 0.8491587  0.8491587\n",
            " 0.8491587  0.8491587         nan 0.74905529 0.74905529 0.74905529\n",
            " 0.74905529        nan 0.59151154 0.59300688 0.59300688 0.59300688\n",
            "        nan 0.88501034 0.88501034 0.88501034 0.88501034        nan\n",
            " 0.80583599 0.80583599 0.80583599 0.80583599        nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;svc&#x27;,\n",
              "                 GridSearchCV(cv=5, estimator=SVC(),\n",
              "                              param_grid=[{&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100.0,\n",
              "                                                 1000.0, 10000.0],\n",
              "                                           &#x27;kernel&#x27;: [&#x27;linear&#x27;],\n",
              "                                           &#x27;tol&#x27;: [0.01, 0.001, 0.0001, 1e-05]},\n",
              "                                          {&#x27;C&#x27;: [1, 10, 100.0, 1000.0, 10000.0,\n",
              "                                                 100000.0],\n",
              "                                           &#x27;kernel&#x27;: [&#x27;rbf&#x27;],\n",
              "                                           &#x27;tol&#x27;: [0.1, 0.01, 0.001, 0.0001,\n",
              "                                                   1e-05, &#x27;scale&#x27;]},\n",
              "                                          {&#x27;C&#x27;: [1, 10, 100, 1000, 10000],\n",
              "                                           &#x27;degree&#x27;: [2, 3, 4],\n",
              "                                           &#x27;kernel&#x27;: [&#x27;poly&#x27;],\n",
              "                                           &#x27;tol&#x27;: [0.01, 0.001, 0.0001, 1e-05,\n",
              "                                                   &#x27;scale&#x27;]}],\n",
              "                              verbose=10))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;svc&#x27;,\n",
              "                 GridSearchCV(cv=5, estimator=SVC(),\n",
              "                              param_grid=[{&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100.0,\n",
              "                                                 1000.0, 10000.0],\n",
              "                                           &#x27;kernel&#x27;: [&#x27;linear&#x27;],\n",
              "                                           &#x27;tol&#x27;: [0.01, 0.001, 0.0001, 1e-05]},\n",
              "                                          {&#x27;C&#x27;: [1, 10, 100.0, 1000.0, 10000.0,\n",
              "                                                 100000.0],\n",
              "                                           &#x27;kernel&#x27;: [&#x27;rbf&#x27;],\n",
              "                                           &#x27;tol&#x27;: [0.1, 0.01, 0.001, 0.0001,\n",
              "                                                   1e-05, &#x27;scale&#x27;]},\n",
              "                                          {&#x27;C&#x27;: [1, 10, 100, 1000, 10000],\n",
              "                                           &#x27;degree&#x27;: [2, 3, 4],\n",
              "                                           &#x27;kernel&#x27;: [&#x27;poly&#x27;],\n",
              "                                           &#x27;tol&#x27;: [0.01, 0.001, 0.0001, 1e-05,\n",
              "                                                   &#x27;scale&#x27;]}],\n",
              "                              verbose=10))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">svc: GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SVC(),\n",
              "             param_grid=[{&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100.0, 1000.0,\n",
              "                                10000.0],\n",
              "                          &#x27;kernel&#x27;: [&#x27;linear&#x27;],\n",
              "                          &#x27;tol&#x27;: [0.01, 0.001, 0.0001, 1e-05]},\n",
              "                         {&#x27;C&#x27;: [1, 10, 100.0, 1000.0, 10000.0, 100000.0],\n",
              "                          &#x27;kernel&#x27;: [&#x27;rbf&#x27;],\n",
              "                          &#x27;tol&#x27;: [0.1, 0.01, 0.001, 0.0001, 1e-05, &#x27;scale&#x27;]},\n",
              "                         {&#x27;C&#x27;: [1, 10, 100, 1000, 10000], &#x27;degree&#x27;: [2, 3, 4],\n",
              "                          &#x27;kernel&#x27;: [&#x27;poly&#x27;],\n",
              "                          &#x27;tol&#x27;: [0.01, 0.001, 0.0001, 1e-05, &#x27;scale&#x27;]}],\n",
              "             verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                ('svc',\n",
              "                 GridSearchCV(cv=5, estimator=SVC(),\n",
              "                              param_grid=[{'C': [0.001, 0.01, 0.1, 1, 10, 100.0,\n",
              "                                                 1000.0, 10000.0],\n",
              "                                           'kernel': ['linear'],\n",
              "                                           'tol': [0.01, 0.001, 0.0001, 1e-05]},\n",
              "                                          {'C': [1, 10, 100.0, 1000.0, 10000.0,\n",
              "                                                 100000.0],\n",
              "                                           'kernel': ['rbf'],\n",
              "                                           'tol': [0.1, 0.01, 0.001, 0.0001,\n",
              "                                                   1e-05, 'scale']},\n",
              "                                          {'C': [1, 10, 100, 1000, 10000],\n",
              "                                           'degree': [2, 3, 4],\n",
              "                                           'kernel': ['poly'],\n",
              "                                           'tol': [0.01, 0.001, 0.0001, 1e-05,\n",
              "                                                   'scale']}],\n",
              "                              verbose=10))])"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = [\n",
        "    {'kernel':['linear'] , 'C':[1e-3 , 1e-2 , 1e-1 , 1 , 10 , 1e2 ,1e3 , 1e4] , 'tol': [1e-2 , 1e-3 , 1e-4 , 1e-5]},\n",
        "    {'kernel': ['rbf'] , 'C':[1 , 10 , 1e2 ,1e3 ,1e4 , 1e5] , 'tol': [1e-1 , 1e-2 , 1e-3 , 1e-4 ,1e-5 , 'scale']},\n",
        "    {'kernel': ['poly'] , 'C':[1 , 10 ,100 ,1000 ,10000] , 'tol':[1e-2 ,1e-3 , 1e-4 , 1e-5 ,'scale'] , 'degree': [2 , 3, 4]}\n",
        "]\n",
        "\n",
        "clf = Pipeline([('scaler' , StandardScaler()) ,\n",
        "                ('svc' , GridSearchCV(SVC() ,\n",
        "                                      param_grid = param_grid,\n",
        "                                      cv = 5,\n",
        "                                      verbose =10,\n",
        "                                      refit = True))])\n",
        "\n",
        "clf.fit(X_train , y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10000.0, kernel=&#x27;linear&#x27;, tol=0.0001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" checked><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10000.0, kernel=&#x27;linear&#x27;, tol=0.0001)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "SVC(C=10000.0, kernel='linear', tol=0.0001)"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf['svc'].best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9790905025434624"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf['svc'].best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_val_predict = clf.predict(X_validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9847494553376906"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_validation , y_val_predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9900990099009901"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_predict = clf.predict(X_test)\n",
        "f1_score(y_test , y_predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "[CV 1/5; 1/96] START leaf_size=15, n_neighbors=2, p=1, weights=uniform..........\n",
            "[CV 1/5; 1/96] END leaf_size=15, n_neighbors=2, p=1, weights=uniform;, score=0.511 total time=   1.5s\n",
            "[CV 2/5; 1/96] START leaf_size=15, n_neighbors=2, p=1, weights=uniform..........\n",
            "[CV 2/5; 1/96] END leaf_size=15, n_neighbors=2, p=1, weights=uniform;, score=0.489 total time=   0.0s\n",
            "[CV 3/5; 1/96] START leaf_size=15, n_neighbors=2, p=1, weights=uniform..........\n",
            "[CV 3/5; 1/96] END leaf_size=15, n_neighbors=2, p=1, weights=uniform;, score=0.481 total time=   0.0s\n",
            "[CV 4/5; 1/96] START leaf_size=15, n_neighbors=2, p=1, weights=uniform..........\n",
            "[CV 4/5; 1/96] END leaf_size=15, n_neighbors=2, p=1, weights=uniform;, score=0.500 total time=   0.0s\n",
            "[CV 5/5; 1/96] START leaf_size=15, n_neighbors=2, p=1, weights=uniform..........\n",
            "[CV 5/5; 1/96] END leaf_size=15, n_neighbors=2, p=1, weights=uniform;, score=0.464 total time=   0.0s\n",
            "[CV 1/5; 2/96] START leaf_size=15, n_neighbors=2, p=1, weights=distanc..........\n",
            "[CV 1/5; 2/96] END leaf_size=15, n_neighbors=2, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 2/96] START leaf_size=15, n_neighbors=2, p=1, weights=distanc..........\n",
            "[CV 2/5; 2/96] END leaf_size=15, n_neighbors=2, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 2/96] START leaf_size=15, n_neighbors=2, p=1, weights=distanc..........\n",
            "[CV 3/5; 2/96] END leaf_size=15, n_neighbors=2, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 2/96] START leaf_size=15, n_neighbors=2, p=1, weights=distanc..........\n",
            "[CV 4/5; 2/96] END leaf_size=15, n_neighbors=2, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 2/96] START leaf_size=15, n_neighbors=2, p=1, weights=distanc..........\n",
            "[CV 5/5; 2/96] END leaf_size=15, n_neighbors=2, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 3/96] START leaf_size=15, n_neighbors=2, p=2, weights=uniform..........\n",
            "[CV 1/5; 3/96] END leaf_size=15, n_neighbors=2, p=2, weights=uniform;, score=0.470 total time=   0.4s\n",
            "[CV 2/5; 3/96] START leaf_size=15, n_neighbors=2, p=2, weights=uniform..........\n",
            "[CV 2/5; 3/96] END leaf_size=15, n_neighbors=2, p=2, weights=uniform;, score=0.493 total time=   0.0s\n",
            "[CV 3/5; 3/96] START leaf_size=15, n_neighbors=2, p=2, weights=uniform..........\n",
            "[CV 3/5; 3/96] END leaf_size=15, n_neighbors=2, p=2, weights=uniform;, score=0.511 total time=   0.0s\n",
            "[CV 4/5; 3/96] START leaf_size=15, n_neighbors=2, p=2, weights=uniform..........\n",
            "[CV 4/5; 3/96] END leaf_size=15, n_neighbors=2, p=2, weights=uniform;, score=0.511 total time=   0.0s\n",
            "[CV 5/5; 3/96] START leaf_size=15, n_neighbors=2, p=2, weights=uniform..........\n",
            "[CV 5/5; 3/96] END leaf_size=15, n_neighbors=2, p=2, weights=uniform;, score=0.479 total time=   0.0s\n",
            "[CV 1/5; 4/96] START leaf_size=15, n_neighbors=2, p=2, weights=distanc..........\n",
            "[CV 1/5; 4/96] END leaf_size=15, n_neighbors=2, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 4/96] START leaf_size=15, n_neighbors=2, p=2, weights=distanc..........\n",
            "[CV 2/5; 4/96] END leaf_size=15, n_neighbors=2, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 4/96] START leaf_size=15, n_neighbors=2, p=2, weights=distanc..........\n",
            "[CV 3/5; 4/96] END leaf_size=15, n_neighbors=2, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 4/96] START leaf_size=15, n_neighbors=2, p=2, weights=distanc..........\n",
            "[CV 4/5; 4/96] END leaf_size=15, n_neighbors=2, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 4/96] START leaf_size=15, n_neighbors=2, p=2, weights=distanc..........\n",
            "[CV 5/5; 4/96] END leaf_size=15, n_neighbors=2, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 5/96] START leaf_size=15, n_neighbors=3, p=1, weights=uniform..........\n",
            "[CV 1/5; 5/96] END leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.515 total time=   0.0s\n",
            "[CV 2/5; 5/96] START leaf_size=15, n_neighbors=3, p=1, weights=uniform..........\n",
            "[CV 2/5; 5/96] END leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.496 total time=   0.0s\n",
            "[CV 3/5; 5/96] START leaf_size=15, n_neighbors=3, p=1, weights=uniform..........\n",
            "[CV 3/5; 5/96] END leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.515 total time=   0.0s\n",
            "[CV 4/5; 5/96] START leaf_size=15, n_neighbors=3, p=1, weights=uniform..........\n",
            "[CV 4/5; 5/96] END leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.519 total time=   0.0s\n",
            "[CV 5/5; 5/96] START leaf_size=15, n_neighbors=3, p=1, weights=uniform..........\n",
            "[CV 5/5; 5/96] END leaf_size=15, n_neighbors=3, p=1, weights=uniform;, score=0.532 total time=   0.0s\n",
            "[CV 1/5; 6/96] START leaf_size=15, n_neighbors=3, p=1, weights=distanc..........\n",
            "[CV 1/5; 6/96] END leaf_size=15, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 6/96] START leaf_size=15, n_neighbors=3, p=1, weights=distanc..........\n",
            "[CV 2/5; 6/96] END leaf_size=15, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 6/96] START leaf_size=15, n_neighbors=3, p=1, weights=distanc..........\n",
            "[CV 3/5; 6/96] END leaf_size=15, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 6/96] START leaf_size=15, n_neighbors=3, p=1, weights=distanc..........\n",
            "[CV 4/5; 6/96] END leaf_size=15, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 6/96] START leaf_size=15, n_neighbors=3, p=1, weights=distanc..........\n",
            "[CV 5/5; 6/96] END leaf_size=15, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 7/96] START leaf_size=15, n_neighbors=3, p=2, weights=uniform..........\n",
            "[CV 1/5; 7/96] END leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.489 total time=   0.0s\n",
            "[CV 2/5; 7/96] START leaf_size=15, n_neighbors=3, p=2, weights=uniform..........\n",
            "[CV 2/5; 7/96] END leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.515 total time=   0.0s\n",
            "[CV 3/5; 7/96] START leaf_size=15, n_neighbors=3, p=2, weights=uniform..........\n",
            "[CV 3/5; 7/96] END leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.541 total time=   0.0s\n",
            "[CV 4/5; 7/96] START leaf_size=15, n_neighbors=3, p=2, weights=uniform..........\n",
            "[CV 4/5; 7/96] END leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.537 total time=   0.0s\n",
            "[CV 5/5; 7/96] START leaf_size=15, n_neighbors=3, p=2, weights=uniform..........\n",
            "[CV 5/5; 7/96] END leaf_size=15, n_neighbors=3, p=2, weights=uniform;, score=0.536 total time=   0.0s\n",
            "[CV 1/5; 8/96] START leaf_size=15, n_neighbors=3, p=2, weights=distanc..........\n",
            "[CV 1/5; 8/96] END leaf_size=15, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 8/96] START leaf_size=15, n_neighbors=3, p=2, weights=distanc..........\n",
            "[CV 2/5; 8/96] END leaf_size=15, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 8/96] START leaf_size=15, n_neighbors=3, p=2, weights=distanc..........\n",
            "[CV 3/5; 8/96] END leaf_size=15, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 8/96] START leaf_size=15, n_neighbors=3, p=2, weights=distanc..........\n",
            "[CV 4/5; 8/96] END leaf_size=15, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 8/96] START leaf_size=15, n_neighbors=3, p=2, weights=distanc..........\n",
            "[CV 5/5; 8/96] END leaf_size=15, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 9/96] START leaf_size=15, n_neighbors=4, p=1, weights=uniform..........\n",
            "[CV 1/5; 9/96] END leaf_size=15, n_neighbors=4, p=1, weights=uniform;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 9/96] START leaf_size=15, n_neighbors=4, p=1, weights=uniform..........\n",
            "[CV 2/5; 9/96] END leaf_size=15, n_neighbors=4, p=1, weights=uniform;, score=0.478 total time=   0.0s\n",
            "[CV 3/5; 9/96] START leaf_size=15, n_neighbors=4, p=1, weights=uniform..........\n",
            "[CV 3/5; 9/96] END leaf_size=15, n_neighbors=4, p=1, weights=uniform;, score=0.493 total time=   0.0s\n",
            "[CV 4/5; 9/96] START leaf_size=15, n_neighbors=4, p=1, weights=uniform..........\n",
            "[CV 4/5; 9/96] END leaf_size=15, n_neighbors=4, p=1, weights=uniform;, score=0.489 total time=   0.0s\n",
            "[CV 5/5; 9/96] START leaf_size=15, n_neighbors=4, p=1, weights=uniform..........\n",
            "[CV 5/5; 9/96] END leaf_size=15, n_neighbors=4, p=1, weights=uniform;, score=0.494 total time=   0.0s\n",
            "[CV 1/5; 10/96] START leaf_size=15, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 1/5; 10/96] END leaf_size=15, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 10/96] START leaf_size=15, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 2/5; 10/96] END leaf_size=15, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 10/96] START leaf_size=15, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 3/5; 10/96] END leaf_size=15, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 10/96] START leaf_size=15, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 4/5; 10/96] END leaf_size=15, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 10/96] START leaf_size=15, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 5/5; 10/96] END leaf_size=15, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 11/96] START leaf_size=15, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 1/5; 11/96] END leaf_size=15, n_neighbors=4, p=2, weights=uniform;, score=0.485 total time=   0.0s\n",
            "[CV 2/5; 11/96] START leaf_size=15, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 2/5; 11/96] END leaf_size=15, n_neighbors=4, p=2, weights=uniform;, score=0.455 total time=   0.0s\n",
            "[CV 3/5; 11/96] START leaf_size=15, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 3/5; 11/96] END leaf_size=15, n_neighbors=4, p=2, weights=uniform;, score=0.500 total time=   0.0s\n",
            "[CV 4/5; 11/96] START leaf_size=15, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 4/5; 11/96] END leaf_size=15, n_neighbors=4, p=2, weights=uniform;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 11/96] START leaf_size=15, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 5/5; 11/96] END leaf_size=15, n_neighbors=4, p=2, weights=uniform;, score=0.483 total time=   0.0s\n",
            "[CV 1/5; 12/96] START leaf_size=15, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 1/5; 12/96] END leaf_size=15, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 12/96] START leaf_size=15, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 2/5; 12/96] END leaf_size=15, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 12/96] START leaf_size=15, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 3/5; 12/96] END leaf_size=15, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 12/96] START leaf_size=15, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 4/5; 12/96] END leaf_size=15, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 12/96] START leaf_size=15, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 5/5; 12/96] END leaf_size=15, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 13/96] START leaf_size=15, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 1/5; 13/96] END leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.504 total time=   0.0s\n",
            "[CV 2/5; 13/96] START leaf_size=15, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 2/5; 13/96] END leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.515 total time=   0.0s\n",
            "[CV 3/5; 13/96] START leaf_size=15, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 3/5; 13/96] END leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.496 total time=   0.0s\n",
            "[CV 4/5; 13/96] START leaf_size=15, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 4/5; 13/96] END leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 13/96] START leaf_size=15, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 5/5; 13/96] END leaf_size=15, n_neighbors=5, p=1, weights=uniform;, score=0.491 total time=   0.0s\n",
            "[CV 1/5; 14/96] START leaf_size=15, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 1/5; 14/96] END leaf_size=15, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 14/96] START leaf_size=15, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 2/5; 14/96] END leaf_size=15, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 14/96] START leaf_size=15, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 3/5; 14/96] END leaf_size=15, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 14/96] START leaf_size=15, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 4/5; 14/96] END leaf_size=15, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 14/96] START leaf_size=15, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 5/5; 14/96] END leaf_size=15, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 15/96] START leaf_size=15, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 1/5; 15/96] END leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.500 total time=   0.0s\n",
            "[CV 2/5; 15/96] START leaf_size=15, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 2/5; 15/96] END leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.496 total time=   0.0s\n",
            "[CV 3/5; 15/96] START leaf_size=15, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 3/5; 15/96] END leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.478 total time=   0.0s\n",
            "[CV 4/5; 15/96] START leaf_size=15, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 4/5; 15/96] END leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.489 total time=   0.0s\n",
            "[CV 5/5; 15/96] START leaf_size=15, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 5/5; 15/96] END leaf_size=15, n_neighbors=5, p=2, weights=uniform;, score=0.562 total time=   0.0s\n",
            "[CV 1/5; 16/96] START leaf_size=15, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 1/5; 16/96] END leaf_size=15, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 16/96] START leaf_size=15, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 2/5; 16/96] END leaf_size=15, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 16/96] START leaf_size=15, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 3/5; 16/96] END leaf_size=15, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 16/96] START leaf_size=15, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 4/5; 16/96] END leaf_size=15, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 16/96] START leaf_size=15, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 5/5; 16/96] END leaf_size=15, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 17/96] START leaf_size=15, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 1/5; 17/96] END leaf_size=15, n_neighbors=6, p=1, weights=uniform;, score=0.567 total time=   0.0s\n",
            "[CV 2/5; 17/96] START leaf_size=15, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 2/5; 17/96] END leaf_size=15, n_neighbors=6, p=1, weights=uniform;, score=0.500 total time=   0.0s\n",
            "[CV 3/5; 17/96] START leaf_size=15, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 3/5; 17/96] END leaf_size=15, n_neighbors=6, p=1, weights=uniform;, score=0.481 total time=   0.0s\n",
            "[CV 4/5; 17/96] START leaf_size=15, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 4/5; 17/96] END leaf_size=15, n_neighbors=6, p=1, weights=uniform;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 17/96] START leaf_size=15, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 5/5; 17/96] END leaf_size=15, n_neighbors=6, p=1, weights=uniform;, score=0.487 total time=   0.0s\n",
            "[CV 1/5; 18/96] START leaf_size=15, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 1/5; 18/96] END leaf_size=15, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 18/96] START leaf_size=15, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 2/5; 18/96] END leaf_size=15, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 18/96] START leaf_size=15, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 3/5; 18/96] END leaf_size=15, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 18/96] START leaf_size=15, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 4/5; 18/96] END leaf_size=15, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 18/96] START leaf_size=15, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 5/5; 18/96] END leaf_size=15, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 19/96] START leaf_size=15, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 1/5; 19/96] END leaf_size=15, n_neighbors=6, p=2, weights=uniform;, score=0.474 total time=   0.0s\n",
            "[CV 2/5; 19/96] START leaf_size=15, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 2/5; 19/96] END leaf_size=15, n_neighbors=6, p=2, weights=uniform;, score=0.504 total time=   0.0s\n",
            "[CV 3/5; 19/96] START leaf_size=15, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 3/5; 19/96] END leaf_size=15, n_neighbors=6, p=2, weights=uniform;, score=0.493 total time=   0.0s\n",
            "[CV 4/5; 19/96] START leaf_size=15, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 4/5; 19/96] END leaf_size=15, n_neighbors=6, p=2, weights=uniform;, score=0.519 total time=   0.0s\n",
            "[CV 5/5; 19/96] START leaf_size=15, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 5/5; 19/96] END leaf_size=15, n_neighbors=6, p=2, weights=uniform;, score=0.554 total time=   0.0s\n",
            "[CV 1/5; 20/96] START leaf_size=15, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 1/5; 20/96] END leaf_size=15, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 20/96] START leaf_size=15, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 2/5; 20/96] END leaf_size=15, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 20/96] START leaf_size=15, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 3/5; 20/96] END leaf_size=15, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 20/96] START leaf_size=15, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 4/5; 20/96] END leaf_size=15, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 20/96] START leaf_size=15, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 5/5; 20/96] END leaf_size=15, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 21/96] START leaf_size=15, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 1/5; 21/96] END leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.545 total time=   0.0s\n",
            "[CV 2/5; 21/96] START leaf_size=15, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 2/5; 21/96] END leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.489 total time=   0.0s\n",
            "[CV 3/5; 21/96] START leaf_size=15, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 3/5; 21/96] END leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.500 total time=   0.0s\n",
            "[CV 4/5; 21/96] START leaf_size=15, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 4/5; 21/96] END leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.530 total time=   0.0s\n",
            "[CV 5/5; 21/96] START leaf_size=15, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 5/5; 21/96] END leaf_size=15, n_neighbors=7, p=1, weights=uniform;, score=0.509 total time=   0.0s\n",
            "[CV 1/5; 22/96] START leaf_size=15, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 1/5; 22/96] END leaf_size=15, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 22/96] START leaf_size=15, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 2/5; 22/96] END leaf_size=15, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 22/96] START leaf_size=15, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 3/5; 22/96] END leaf_size=15, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 22/96] START leaf_size=15, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 4/5; 22/96] END leaf_size=15, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 22/96] START leaf_size=15, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 5/5; 22/96] END leaf_size=15, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 23/96] START leaf_size=15, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 1/5; 23/96] END leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.519 total time=   0.0s\n",
            "[CV 2/5; 23/96] START leaf_size=15, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 2/5; 23/96] END leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.511 total time=   0.0s\n",
            "[CV 3/5; 23/96] START leaf_size=15, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 3/5; 23/96] END leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.504 total time=   0.0s\n",
            "[CV 4/5; 23/96] START leaf_size=15, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 4/5; 23/96] END leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.485 total time=   0.0s\n",
            "[CV 5/5; 23/96] START leaf_size=15, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 5/5; 23/96] END leaf_size=15, n_neighbors=7, p=2, weights=uniform;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 24/96] START leaf_size=15, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 1/5; 24/96] END leaf_size=15, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 24/96] START leaf_size=15, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 2/5; 24/96] END leaf_size=15, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 24/96] START leaf_size=15, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 3/5; 24/96] END leaf_size=15, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 24/96] START leaf_size=15, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 4/5; 24/96] END leaf_size=15, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 24/96] START leaf_size=15, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 5/5; 24/96] END leaf_size=15, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 25/96] START leaf_size=30, n_neighbors=2, p=1, weights=uniform.........\n",
            "[CV 1/5; 25/96] END leaf_size=30, n_neighbors=2, p=1, weights=uniform;, score=0.511 total time=   0.0s\n",
            "[CV 2/5; 25/96] START leaf_size=30, n_neighbors=2, p=1, weights=uniform.........\n",
            "[CV 2/5; 25/96] END leaf_size=30, n_neighbors=2, p=1, weights=uniform;, score=0.489 total time=   0.0s\n",
            "[CV 3/5; 25/96] START leaf_size=30, n_neighbors=2, p=1, weights=uniform.........\n",
            "[CV 3/5; 25/96] END leaf_size=30, n_neighbors=2, p=1, weights=uniform;, score=0.481 total time=   0.0s\n",
            "[CV 4/5; 25/96] START leaf_size=30, n_neighbors=2, p=1, weights=uniform.........\n",
            "[CV 4/5; 25/96] END leaf_size=30, n_neighbors=2, p=1, weights=uniform;, score=0.500 total time=   0.0s\n",
            "[CV 5/5; 25/96] START leaf_size=30, n_neighbors=2, p=1, weights=uniform.........\n",
            "[CV 5/5; 25/96] END leaf_size=30, n_neighbors=2, p=1, weights=uniform;, score=0.464 total time=   0.0s\n",
            "[CV 1/5; 26/96] START leaf_size=30, n_neighbors=2, p=1, weights=distanc.........\n",
            "[CV 1/5; 26/96] END leaf_size=30, n_neighbors=2, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 26/96] START leaf_size=30, n_neighbors=2, p=1, weights=distanc.........\n",
            "[CV 2/5; 26/96] END leaf_size=30, n_neighbors=2, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 26/96] START leaf_size=30, n_neighbors=2, p=1, weights=distanc.........\n",
            "[CV 3/5; 26/96] END leaf_size=30, n_neighbors=2, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 26/96] START leaf_size=30, n_neighbors=2, p=1, weights=distanc.........\n",
            "[CV 4/5; 26/96] END leaf_size=30, n_neighbors=2, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 26/96] START leaf_size=30, n_neighbors=2, p=1, weights=distanc.........\n",
            "[CV 5/5; 26/96] END leaf_size=30, n_neighbors=2, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 27/96] START leaf_size=30, n_neighbors=2, p=2, weights=uniform.........\n",
            "[CV 1/5; 27/96] END leaf_size=30, n_neighbors=2, p=2, weights=uniform;, score=0.470 total time=   0.0s\n",
            "[CV 2/5; 27/96] START leaf_size=30, n_neighbors=2, p=2, weights=uniform.........\n",
            "[CV 2/5; 27/96] END leaf_size=30, n_neighbors=2, p=2, weights=uniform;, score=0.493 total time=   0.0s\n",
            "[CV 3/5; 27/96] START leaf_size=30, n_neighbors=2, p=2, weights=uniform.........\n",
            "[CV 3/5; 27/96] END leaf_size=30, n_neighbors=2, p=2, weights=uniform;, score=0.511 total time=   0.0s\n",
            "[CV 4/5; 27/96] START leaf_size=30, n_neighbors=2, p=2, weights=uniform.........\n",
            "[CV 4/5; 27/96] END leaf_size=30, n_neighbors=2, p=2, weights=uniform;, score=0.511 total time=   0.0s\n",
            "[CV 5/5; 27/96] START leaf_size=30, n_neighbors=2, p=2, weights=uniform.........\n",
            "[CV 5/5; 27/96] END leaf_size=30, n_neighbors=2, p=2, weights=uniform;, score=0.479 total time=   0.0s\n",
            "[CV 1/5; 28/96] START leaf_size=30, n_neighbors=2, p=2, weights=distanc.........\n",
            "[CV 1/5; 28/96] END leaf_size=30, n_neighbors=2, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 28/96] START leaf_size=30, n_neighbors=2, p=2, weights=distanc.........\n",
            "[CV 2/5; 28/96] END leaf_size=30, n_neighbors=2, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 28/96] START leaf_size=30, n_neighbors=2, p=2, weights=distanc.........\n",
            "[CV 3/5; 28/96] END leaf_size=30, n_neighbors=2, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 28/96] START leaf_size=30, n_neighbors=2, p=2, weights=distanc.........\n",
            "[CV 4/5; 28/96] END leaf_size=30, n_neighbors=2, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 28/96] START leaf_size=30, n_neighbors=2, p=2, weights=distanc.........\n",
            "[CV 5/5; 28/96] END leaf_size=30, n_neighbors=2, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 29/96] START leaf_size=30, n_neighbors=3, p=1, weights=uniform.........\n",
            "[CV 1/5; 29/96] END leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.515 total time=   0.0s\n",
            "[CV 2/5; 29/96] START leaf_size=30, n_neighbors=3, p=1, weights=uniform.........\n",
            "[CV 2/5; 29/96] END leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.496 total time=   0.0s\n",
            "[CV 3/5; 29/96] START leaf_size=30, n_neighbors=3, p=1, weights=uniform.........\n",
            "[CV 3/5; 29/96] END leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.515 total time=   0.0s\n",
            "[CV 4/5; 29/96] START leaf_size=30, n_neighbors=3, p=1, weights=uniform.........\n",
            "[CV 4/5; 29/96] END leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.519 total time=   0.0s\n",
            "[CV 5/5; 29/96] START leaf_size=30, n_neighbors=3, p=1, weights=uniform.........\n",
            "[CV 5/5; 29/96] END leaf_size=30, n_neighbors=3, p=1, weights=uniform;, score=0.532 total time=   0.0s\n",
            "[CV 1/5; 30/96] START leaf_size=30, n_neighbors=3, p=1, weights=distanc.........\n",
            "[CV 1/5; 30/96] END leaf_size=30, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 30/96] START leaf_size=30, n_neighbors=3, p=1, weights=distanc.........\n",
            "[CV 2/5; 30/96] END leaf_size=30, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 30/96] START leaf_size=30, n_neighbors=3, p=1, weights=distanc.........\n",
            "[CV 3/5; 30/96] END leaf_size=30, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 30/96] START leaf_size=30, n_neighbors=3, p=1, weights=distanc.........\n",
            "[CV 4/5; 30/96] END leaf_size=30, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 30/96] START leaf_size=30, n_neighbors=3, p=1, weights=distanc.........\n",
            "[CV 5/5; 30/96] END leaf_size=30, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 31/96] START leaf_size=30, n_neighbors=3, p=2, weights=uniform.........\n",
            "[CV 1/5; 31/96] END leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.489 total time=   0.0s\n",
            "[CV 2/5; 31/96] START leaf_size=30, n_neighbors=3, p=2, weights=uniform.........\n",
            "[CV 2/5; 31/96] END leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.515 total time=   0.0s\n",
            "[CV 3/5; 31/96] START leaf_size=30, n_neighbors=3, p=2, weights=uniform.........\n",
            "[CV 3/5; 31/96] END leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.541 total time=   0.0s\n",
            "[CV 4/5; 31/96] START leaf_size=30, n_neighbors=3, p=2, weights=uniform.........\n",
            "[CV 4/5; 31/96] END leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.537 total time=   0.0s\n",
            "[CV 5/5; 31/96] START leaf_size=30, n_neighbors=3, p=2, weights=uniform.........\n",
            "[CV 5/5; 31/96] END leaf_size=30, n_neighbors=3, p=2, weights=uniform;, score=0.536 total time=   0.0s\n",
            "[CV 1/5; 32/96] START leaf_size=30, n_neighbors=3, p=2, weights=distanc.........\n",
            "[CV 1/5; 32/96] END leaf_size=30, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 32/96] START leaf_size=30, n_neighbors=3, p=2, weights=distanc.........\n",
            "[CV 2/5; 32/96] END leaf_size=30, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 32/96] START leaf_size=30, n_neighbors=3, p=2, weights=distanc.........\n",
            "[CV 3/5; 32/96] END leaf_size=30, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 32/96] START leaf_size=30, n_neighbors=3, p=2, weights=distanc.........\n",
            "[CV 4/5; 32/96] END leaf_size=30, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 32/96] START leaf_size=30, n_neighbors=3, p=2, weights=distanc.........\n",
            "[CV 5/5; 32/96] END leaf_size=30, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 33/96] START leaf_size=30, n_neighbors=4, p=1, weights=uniform.........\n",
            "[CV 1/5; 33/96] END leaf_size=30, n_neighbors=4, p=1, weights=uniform;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 33/96] START leaf_size=30, n_neighbors=4, p=1, weights=uniform.........\n",
            "[CV 2/5; 33/96] END leaf_size=30, n_neighbors=4, p=1, weights=uniform;, score=0.478 total time=   0.0s\n",
            "[CV 3/5; 33/96] START leaf_size=30, n_neighbors=4, p=1, weights=uniform.........\n",
            "[CV 3/5; 33/96] END leaf_size=30, n_neighbors=4, p=1, weights=uniform;, score=0.493 total time=   0.0s\n",
            "[CV 4/5; 33/96] START leaf_size=30, n_neighbors=4, p=1, weights=uniform.........\n",
            "[CV 4/5; 33/96] END leaf_size=30, n_neighbors=4, p=1, weights=uniform;, score=0.489 total time=   0.0s\n",
            "[CV 5/5; 33/96] START leaf_size=30, n_neighbors=4, p=1, weights=uniform.........\n",
            "[CV 5/5; 33/96] END leaf_size=30, n_neighbors=4, p=1, weights=uniform;, score=0.494 total time=   0.0s\n",
            "[CV 1/5; 34/96] START leaf_size=30, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 1/5; 34/96] END leaf_size=30, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 34/96] START leaf_size=30, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 2/5; 34/96] END leaf_size=30, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 34/96] START leaf_size=30, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 3/5; 34/96] END leaf_size=30, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 34/96] START leaf_size=30, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 4/5; 34/96] END leaf_size=30, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 34/96] START leaf_size=30, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 5/5; 34/96] END leaf_size=30, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 35/96] START leaf_size=30, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 1/5; 35/96] END leaf_size=30, n_neighbors=4, p=2, weights=uniform;, score=0.485 total time=   0.0s\n",
            "[CV 2/5; 35/96] START leaf_size=30, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 2/5; 35/96] END leaf_size=30, n_neighbors=4, p=2, weights=uniform;, score=0.455 total time=   0.0s\n",
            "[CV 3/5; 35/96] START leaf_size=30, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 3/5; 35/96] END leaf_size=30, n_neighbors=4, p=2, weights=uniform;, score=0.500 total time=   0.0s\n",
            "[CV 4/5; 35/96] START leaf_size=30, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 4/5; 35/96] END leaf_size=30, n_neighbors=4, p=2, weights=uniform;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 35/96] START leaf_size=30, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 5/5; 35/96] END leaf_size=30, n_neighbors=4, p=2, weights=uniform;, score=0.483 total time=   0.0s\n",
            "[CV 1/5; 36/96] START leaf_size=30, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 1/5; 36/96] END leaf_size=30, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 36/96] START leaf_size=30, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 2/5; 36/96] END leaf_size=30, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 36/96] START leaf_size=30, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 3/5; 36/96] END leaf_size=30, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 36/96] START leaf_size=30, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 4/5; 36/96] END leaf_size=30, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 36/96] START leaf_size=30, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 5/5; 36/96] END leaf_size=30, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 37/96] START leaf_size=30, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 1/5; 37/96] END leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.504 total time=   0.0s\n",
            "[CV 2/5; 37/96] START leaf_size=30, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 2/5; 37/96] END leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.515 total time=   0.0s\n",
            "[CV 3/5; 37/96] START leaf_size=30, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 3/5; 37/96] END leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.496 total time=   0.0s\n",
            "[CV 4/5; 37/96] START leaf_size=30, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 4/5; 37/96] END leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 37/96] START leaf_size=30, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 5/5; 37/96] END leaf_size=30, n_neighbors=5, p=1, weights=uniform;, score=0.491 total time=   0.0s\n",
            "[CV 1/5; 38/96] START leaf_size=30, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 1/5; 38/96] END leaf_size=30, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 38/96] START leaf_size=30, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 2/5; 38/96] END leaf_size=30, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 38/96] START leaf_size=30, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 3/5; 38/96] END leaf_size=30, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 38/96] START leaf_size=30, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 4/5; 38/96] END leaf_size=30, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 38/96] START leaf_size=30, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 5/5; 38/96] END leaf_size=30, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 39/96] START leaf_size=30, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 1/5; 39/96] END leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.500 total time=   0.0s\n",
            "[CV 2/5; 39/96] START leaf_size=30, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 2/5; 39/96] END leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.496 total time=   0.0s\n",
            "[CV 3/5; 39/96] START leaf_size=30, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 3/5; 39/96] END leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.478 total time=   0.0s\n",
            "[CV 4/5; 39/96] START leaf_size=30, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 4/5; 39/96] END leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.489 total time=   0.0s\n",
            "[CV 5/5; 39/96] START leaf_size=30, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 5/5; 39/96] END leaf_size=30, n_neighbors=5, p=2, weights=uniform;, score=0.562 total time=   0.0s\n",
            "[CV 1/5; 40/96] START leaf_size=30, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 1/5; 40/96] END leaf_size=30, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 40/96] START leaf_size=30, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 2/5; 40/96] END leaf_size=30, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 40/96] START leaf_size=30, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 3/5; 40/96] END leaf_size=30, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 40/96] START leaf_size=30, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 4/5; 40/96] END leaf_size=30, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 40/96] START leaf_size=30, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 5/5; 40/96] END leaf_size=30, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 41/96] START leaf_size=30, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 1/5; 41/96] END leaf_size=30, n_neighbors=6, p=1, weights=uniform;, score=0.567 total time=   0.0s\n",
            "[CV 2/5; 41/96] START leaf_size=30, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 2/5; 41/96] END leaf_size=30, n_neighbors=6, p=1, weights=uniform;, score=0.500 total time=   0.0s\n",
            "[CV 3/5; 41/96] START leaf_size=30, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 3/5; 41/96] END leaf_size=30, n_neighbors=6, p=1, weights=uniform;, score=0.481 total time=   0.0s\n",
            "[CV 4/5; 41/96] START leaf_size=30, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 4/5; 41/96] END leaf_size=30, n_neighbors=6, p=1, weights=uniform;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 41/96] START leaf_size=30, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 5/5; 41/96] END leaf_size=30, n_neighbors=6, p=1, weights=uniform;, score=0.487 total time=   0.0s\n",
            "[CV 1/5; 42/96] START leaf_size=30, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 1/5; 42/96] END leaf_size=30, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 42/96] START leaf_size=30, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 2/5; 42/96] END leaf_size=30, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 42/96] START leaf_size=30, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 3/5; 42/96] END leaf_size=30, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 42/96] START leaf_size=30, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 4/5; 42/96] END leaf_size=30, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 42/96] START leaf_size=30, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 5/5; 42/96] END leaf_size=30, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 43/96] START leaf_size=30, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 1/5; 43/96] END leaf_size=30, n_neighbors=6, p=2, weights=uniform;, score=0.474 total time=   0.0s\n",
            "[CV 2/5; 43/96] START leaf_size=30, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 2/5; 43/96] END leaf_size=30, n_neighbors=6, p=2, weights=uniform;, score=0.504 total time=   0.0s\n",
            "[CV 3/5; 43/96] START leaf_size=30, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 3/5; 43/96] END leaf_size=30, n_neighbors=6, p=2, weights=uniform;, score=0.493 total time=   0.0s\n",
            "[CV 4/5; 43/96] START leaf_size=30, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 4/5; 43/96] END leaf_size=30, n_neighbors=6, p=2, weights=uniform;, score=0.519 total time=   0.0s\n",
            "[CV 5/5; 43/96] START leaf_size=30, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 5/5; 43/96] END leaf_size=30, n_neighbors=6, p=2, weights=uniform;, score=0.554 total time=   0.0s\n",
            "[CV 1/5; 44/96] START leaf_size=30, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 1/5; 44/96] END leaf_size=30, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 44/96] START leaf_size=30, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 2/5; 44/96] END leaf_size=30, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 44/96] START leaf_size=30, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 3/5; 44/96] END leaf_size=30, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 44/96] START leaf_size=30, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 4/5; 44/96] END leaf_size=30, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 44/96] START leaf_size=30, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 5/5; 44/96] END leaf_size=30, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 45/96] START leaf_size=30, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 1/5; 45/96] END leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.545 total time=   0.0s\n",
            "[CV 2/5; 45/96] START leaf_size=30, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 2/5; 45/96] END leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.489 total time=   0.0s\n",
            "[CV 3/5; 45/96] START leaf_size=30, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 3/5; 45/96] END leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.500 total time=   0.0s\n",
            "[CV 4/5; 45/96] START leaf_size=30, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 4/5; 45/96] END leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.530 total time=   0.0s\n",
            "[CV 5/5; 45/96] START leaf_size=30, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 5/5; 45/96] END leaf_size=30, n_neighbors=7, p=1, weights=uniform;, score=0.509 total time=   0.0s\n",
            "[CV 1/5; 46/96] START leaf_size=30, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 1/5; 46/96] END leaf_size=30, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 46/96] START leaf_size=30, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 2/5; 46/96] END leaf_size=30, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 46/96] START leaf_size=30, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 3/5; 46/96] END leaf_size=30, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 46/96] START leaf_size=30, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 4/5; 46/96] END leaf_size=30, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 46/96] START leaf_size=30, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 5/5; 46/96] END leaf_size=30, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 47/96] START leaf_size=30, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 1/5; 47/96] END leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.519 total time=   0.0s\n",
            "[CV 2/5; 47/96] START leaf_size=30, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 2/5; 47/96] END leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.511 total time=   0.0s\n",
            "[CV 3/5; 47/96] START leaf_size=30, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 3/5; 47/96] END leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.504 total time=   0.0s\n",
            "[CV 4/5; 47/96] START leaf_size=30, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 4/5; 47/96] END leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.485 total time=   0.0s\n",
            "[CV 5/5; 47/96] START leaf_size=30, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 5/5; 47/96] END leaf_size=30, n_neighbors=7, p=2, weights=uniform;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 48/96] START leaf_size=30, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 1/5; 48/96] END leaf_size=30, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 48/96] START leaf_size=30, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 2/5; 48/96] END leaf_size=30, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 48/96] START leaf_size=30, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 3/5; 48/96] END leaf_size=30, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 48/96] START leaf_size=30, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 4/5; 48/96] END leaf_size=30, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 48/96] START leaf_size=30, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 5/5; 48/96] END leaf_size=30, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 49/96] START leaf_size=45, n_neighbors=2, p=1, weights=uniform.........\n",
            "[CV 1/5; 49/96] END leaf_size=45, n_neighbors=2, p=1, weights=uniform;, score=0.511 total time=   0.0s\n",
            "[CV 2/5; 49/96] START leaf_size=45, n_neighbors=2, p=1, weights=uniform.........\n",
            "[CV 2/5; 49/96] END leaf_size=45, n_neighbors=2, p=1, weights=uniform;, score=0.489 total time=   0.0s\n",
            "[CV 3/5; 49/96] START leaf_size=45, n_neighbors=2, p=1, weights=uniform.........\n",
            "[CV 3/5; 49/96] END leaf_size=45, n_neighbors=2, p=1, weights=uniform;, score=0.481 total time=   0.0s\n",
            "[CV 4/5; 49/96] START leaf_size=45, n_neighbors=2, p=1, weights=uniform.........\n",
            "[CV 4/5; 49/96] END leaf_size=45, n_neighbors=2, p=1, weights=uniform;, score=0.500 total time=   0.0s\n",
            "[CV 5/5; 49/96] START leaf_size=45, n_neighbors=2, p=1, weights=uniform.........\n",
            "[CV 5/5; 49/96] END leaf_size=45, n_neighbors=2, p=1, weights=uniform;, score=0.464 total time=   0.0s\n",
            "[CV 1/5; 50/96] START leaf_size=45, n_neighbors=2, p=1, weights=distanc.........\n",
            "[CV 1/5; 50/96] END leaf_size=45, n_neighbors=2, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 50/96] START leaf_size=45, n_neighbors=2, p=1, weights=distanc.........\n",
            "[CV 2/5; 50/96] END leaf_size=45, n_neighbors=2, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 50/96] START leaf_size=45, n_neighbors=2, p=1, weights=distanc.........\n",
            "[CV 3/5; 50/96] END leaf_size=45, n_neighbors=2, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 50/96] START leaf_size=45, n_neighbors=2, p=1, weights=distanc.........\n",
            "[CV 4/5; 50/96] END leaf_size=45, n_neighbors=2, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 50/96] START leaf_size=45, n_neighbors=2, p=1, weights=distanc.........\n",
            "[CV 5/5; 50/96] END leaf_size=45, n_neighbors=2, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 51/96] START leaf_size=45, n_neighbors=2, p=2, weights=uniform.........\n",
            "[CV 1/5; 51/96] END leaf_size=45, n_neighbors=2, p=2, weights=uniform;, score=0.470 total time=   0.0s\n",
            "[CV 2/5; 51/96] START leaf_size=45, n_neighbors=2, p=2, weights=uniform.........\n",
            "[CV 2/5; 51/96] END leaf_size=45, n_neighbors=2, p=2, weights=uniform;, score=0.493 total time=   0.0s\n",
            "[CV 3/5; 51/96] START leaf_size=45, n_neighbors=2, p=2, weights=uniform.........\n",
            "[CV 3/5; 51/96] END leaf_size=45, n_neighbors=2, p=2, weights=uniform;, score=0.511 total time=   0.0s\n",
            "[CV 4/5; 51/96] START leaf_size=45, n_neighbors=2, p=2, weights=uniform.........\n",
            "[CV 4/5; 51/96] END leaf_size=45, n_neighbors=2, p=2, weights=uniform;, score=0.511 total time=   0.0s\n",
            "[CV 5/5; 51/96] START leaf_size=45, n_neighbors=2, p=2, weights=uniform.........\n",
            "[CV 5/5; 51/96] END leaf_size=45, n_neighbors=2, p=2, weights=uniform;, score=0.479 total time=   0.0s\n",
            "[CV 1/5; 52/96] START leaf_size=45, n_neighbors=2, p=2, weights=distanc.........\n",
            "[CV 1/5; 52/96] END leaf_size=45, n_neighbors=2, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 52/96] START leaf_size=45, n_neighbors=2, p=2, weights=distanc.........\n",
            "[CV 2/5; 52/96] END leaf_size=45, n_neighbors=2, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 52/96] START leaf_size=45, n_neighbors=2, p=2, weights=distanc.........\n",
            "[CV 3/5; 52/96] END leaf_size=45, n_neighbors=2, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 52/96] START leaf_size=45, n_neighbors=2, p=2, weights=distanc.........\n",
            "[CV 4/5; 52/96] END leaf_size=45, n_neighbors=2, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 52/96] START leaf_size=45, n_neighbors=2, p=2, weights=distanc.........\n",
            "[CV 5/5; 52/96] END leaf_size=45, n_neighbors=2, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 53/96] START leaf_size=45, n_neighbors=3, p=1, weights=uniform.........\n",
            "[CV 1/5; 53/96] END leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.515 total time=   0.0s\n",
            "[CV 2/5; 53/96] START leaf_size=45, n_neighbors=3, p=1, weights=uniform.........\n",
            "[CV 2/5; 53/96] END leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.496 total time=   0.0s\n",
            "[CV 3/5; 53/96] START leaf_size=45, n_neighbors=3, p=1, weights=uniform.........\n",
            "[CV 3/5; 53/96] END leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.515 total time=   0.0s\n",
            "[CV 4/5; 53/96] START leaf_size=45, n_neighbors=3, p=1, weights=uniform.........\n",
            "[CV 4/5; 53/96] END leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.519 total time=   0.0s\n",
            "[CV 5/5; 53/96] START leaf_size=45, n_neighbors=3, p=1, weights=uniform.........\n",
            "[CV 5/5; 53/96] END leaf_size=45, n_neighbors=3, p=1, weights=uniform;, score=0.532 total time=   0.0s\n",
            "[CV 1/5; 54/96] START leaf_size=45, n_neighbors=3, p=1, weights=distanc.........\n",
            "[CV 1/5; 54/96] END leaf_size=45, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 54/96] START leaf_size=45, n_neighbors=3, p=1, weights=distanc.........\n",
            "[CV 2/5; 54/96] END leaf_size=45, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 54/96] START leaf_size=45, n_neighbors=3, p=1, weights=distanc.........\n",
            "[CV 3/5; 54/96] END leaf_size=45, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 54/96] START leaf_size=45, n_neighbors=3, p=1, weights=distanc.........\n",
            "[CV 4/5; 54/96] END leaf_size=45, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 54/96] START leaf_size=45, n_neighbors=3, p=1, weights=distanc.........\n",
            "[CV 5/5; 54/96] END leaf_size=45, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 55/96] START leaf_size=45, n_neighbors=3, p=2, weights=uniform.........\n",
            "[CV 1/5; 55/96] END leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.489 total time=   0.0s\n",
            "[CV 2/5; 55/96] START leaf_size=45, n_neighbors=3, p=2, weights=uniform.........\n",
            "[CV 2/5; 55/96] END leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.515 total time=   0.0s\n",
            "[CV 3/5; 55/96] START leaf_size=45, n_neighbors=3, p=2, weights=uniform.........\n",
            "[CV 3/5; 55/96] END leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.541 total time=   0.0s\n",
            "[CV 4/5; 55/96] START leaf_size=45, n_neighbors=3, p=2, weights=uniform.........\n",
            "[CV 4/5; 55/96] END leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.537 total time=   0.0s\n",
            "[CV 5/5; 55/96] START leaf_size=45, n_neighbors=3, p=2, weights=uniform.........\n",
            "[CV 5/5; 55/96] END leaf_size=45, n_neighbors=3, p=2, weights=uniform;, score=0.536 total time=   0.0s\n",
            "[CV 1/5; 56/96] START leaf_size=45, n_neighbors=3, p=2, weights=distanc.........\n",
            "[CV 1/5; 56/96] END leaf_size=45, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 56/96] START leaf_size=45, n_neighbors=3, p=2, weights=distanc.........\n",
            "[CV 2/5; 56/96] END leaf_size=45, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 56/96] START leaf_size=45, n_neighbors=3, p=2, weights=distanc.........\n",
            "[CV 3/5; 56/96] END leaf_size=45, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 56/96] START leaf_size=45, n_neighbors=3, p=2, weights=distanc.........\n",
            "[CV 4/5; 56/96] END leaf_size=45, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 56/96] START leaf_size=45, n_neighbors=3, p=2, weights=distanc.........\n",
            "[CV 5/5; 56/96] END leaf_size=45, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 57/96] START leaf_size=45, n_neighbors=4, p=1, weights=uniform.........\n",
            "[CV 1/5; 57/96] END leaf_size=45, n_neighbors=4, p=1, weights=uniform;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 57/96] START leaf_size=45, n_neighbors=4, p=1, weights=uniform.........\n",
            "[CV 2/5; 57/96] END leaf_size=45, n_neighbors=4, p=1, weights=uniform;, score=0.478 total time=   0.0s\n",
            "[CV 3/5; 57/96] START leaf_size=45, n_neighbors=4, p=1, weights=uniform.........\n",
            "[CV 3/5; 57/96] END leaf_size=45, n_neighbors=4, p=1, weights=uniform;, score=0.493 total time=   0.0s\n",
            "[CV 4/5; 57/96] START leaf_size=45, n_neighbors=4, p=1, weights=uniform.........\n",
            "[CV 4/5; 57/96] END leaf_size=45, n_neighbors=4, p=1, weights=uniform;, score=0.489 total time=   0.0s\n",
            "[CV 5/5; 57/96] START leaf_size=45, n_neighbors=4, p=1, weights=uniform.........\n",
            "[CV 5/5; 57/96] END leaf_size=45, n_neighbors=4, p=1, weights=uniform;, score=0.494 total time=   0.0s\n",
            "[CV 1/5; 58/96] START leaf_size=45, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 1/5; 58/96] END leaf_size=45, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 58/96] START leaf_size=45, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 2/5; 58/96] END leaf_size=45, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 58/96] START leaf_size=45, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 3/5; 58/96] END leaf_size=45, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 58/96] START leaf_size=45, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 4/5; 58/96] END leaf_size=45, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 58/96] START leaf_size=45, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 5/5; 58/96] END leaf_size=45, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 59/96] START leaf_size=45, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 1/5; 59/96] END leaf_size=45, n_neighbors=4, p=2, weights=uniform;, score=0.485 total time=   0.0s\n",
            "[CV 2/5; 59/96] START leaf_size=45, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 2/5; 59/96] END leaf_size=45, n_neighbors=4, p=2, weights=uniform;, score=0.455 total time=   0.0s\n",
            "[CV 3/5; 59/96] START leaf_size=45, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 3/5; 59/96] END leaf_size=45, n_neighbors=4, p=2, weights=uniform;, score=0.500 total time=   0.0s\n",
            "[CV 4/5; 59/96] START leaf_size=45, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 4/5; 59/96] END leaf_size=45, n_neighbors=4, p=2, weights=uniform;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 59/96] START leaf_size=45, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 5/5; 59/96] END leaf_size=45, n_neighbors=4, p=2, weights=uniform;, score=0.483 total time=   0.0s\n",
            "[CV 1/5; 60/96] START leaf_size=45, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 1/5; 60/96] END leaf_size=45, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 60/96] START leaf_size=45, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 2/5; 60/96] END leaf_size=45, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 60/96] START leaf_size=45, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 3/5; 60/96] END leaf_size=45, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 60/96] START leaf_size=45, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 4/5; 60/96] END leaf_size=45, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 60/96] START leaf_size=45, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 5/5; 60/96] END leaf_size=45, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 61/96] START leaf_size=45, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 1/5; 61/96] END leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.504 total time=   0.0s\n",
            "[CV 2/5; 61/96] START leaf_size=45, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 2/5; 61/96] END leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.515 total time=   0.0s\n",
            "[CV 3/5; 61/96] START leaf_size=45, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 3/5; 61/96] END leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.496 total time=   0.0s\n",
            "[CV 4/5; 61/96] START leaf_size=45, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 4/5; 61/96] END leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 61/96] START leaf_size=45, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 5/5; 61/96] END leaf_size=45, n_neighbors=5, p=1, weights=uniform;, score=0.491 total time=   0.0s\n",
            "[CV 1/5; 62/96] START leaf_size=45, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 1/5; 62/96] END leaf_size=45, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 62/96] START leaf_size=45, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 2/5; 62/96] END leaf_size=45, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 62/96] START leaf_size=45, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 3/5; 62/96] END leaf_size=45, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 62/96] START leaf_size=45, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 4/5; 62/96] END leaf_size=45, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 62/96] START leaf_size=45, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 5/5; 62/96] END leaf_size=45, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 63/96] START leaf_size=45, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 1/5; 63/96] END leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.500 total time=   0.0s\n",
            "[CV 2/5; 63/96] START leaf_size=45, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 2/5; 63/96] END leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.496 total time=   0.0s\n",
            "[CV 3/5; 63/96] START leaf_size=45, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 3/5; 63/96] END leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.478 total time=   0.0s\n",
            "[CV 4/5; 63/96] START leaf_size=45, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 4/5; 63/96] END leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.489 total time=   0.0s\n",
            "[CV 5/5; 63/96] START leaf_size=45, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 5/5; 63/96] END leaf_size=45, n_neighbors=5, p=2, weights=uniform;, score=0.562 total time=   0.0s\n",
            "[CV 1/5; 64/96] START leaf_size=45, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 1/5; 64/96] END leaf_size=45, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 64/96] START leaf_size=45, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 2/5; 64/96] END leaf_size=45, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 64/96] START leaf_size=45, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 3/5; 64/96] END leaf_size=45, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 64/96] START leaf_size=45, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 4/5; 64/96] END leaf_size=45, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 64/96] START leaf_size=45, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 5/5; 64/96] END leaf_size=45, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 65/96] START leaf_size=45, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 1/5; 65/96] END leaf_size=45, n_neighbors=6, p=1, weights=uniform;, score=0.567 total time=   0.0s\n",
            "[CV 2/5; 65/96] START leaf_size=45, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 2/5; 65/96] END leaf_size=45, n_neighbors=6, p=1, weights=uniform;, score=0.500 total time=   0.0s\n",
            "[CV 3/5; 65/96] START leaf_size=45, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 3/5; 65/96] END leaf_size=45, n_neighbors=6, p=1, weights=uniform;, score=0.481 total time=   0.0s\n",
            "[CV 4/5; 65/96] START leaf_size=45, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 4/5; 65/96] END leaf_size=45, n_neighbors=6, p=1, weights=uniform;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 65/96] START leaf_size=45, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 5/5; 65/96] END leaf_size=45, n_neighbors=6, p=1, weights=uniform;, score=0.487 total time=   0.0s\n",
            "[CV 1/5; 66/96] START leaf_size=45, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 1/5; 66/96] END leaf_size=45, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 66/96] START leaf_size=45, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 2/5; 66/96] END leaf_size=45, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 66/96] START leaf_size=45, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 3/5; 66/96] END leaf_size=45, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 66/96] START leaf_size=45, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 4/5; 66/96] END leaf_size=45, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 66/96] START leaf_size=45, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 5/5; 66/96] END leaf_size=45, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 67/96] START leaf_size=45, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 1/5; 67/96] END leaf_size=45, n_neighbors=6, p=2, weights=uniform;, score=0.474 total time=   0.0s\n",
            "[CV 2/5; 67/96] START leaf_size=45, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 2/5; 67/96] END leaf_size=45, n_neighbors=6, p=2, weights=uniform;, score=0.504 total time=   0.0s\n",
            "[CV 3/5; 67/96] START leaf_size=45, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 3/5; 67/96] END leaf_size=45, n_neighbors=6, p=2, weights=uniform;, score=0.493 total time=   0.0s\n",
            "[CV 4/5; 67/96] START leaf_size=45, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 4/5; 67/96] END leaf_size=45, n_neighbors=6, p=2, weights=uniform;, score=0.519 total time=   0.0s\n",
            "[CV 5/5; 67/96] START leaf_size=45, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 5/5; 67/96] END leaf_size=45, n_neighbors=6, p=2, weights=uniform;, score=0.554 total time=   0.0s\n",
            "[CV 1/5; 68/96] START leaf_size=45, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 1/5; 68/96] END leaf_size=45, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 68/96] START leaf_size=45, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 2/5; 68/96] END leaf_size=45, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 68/96] START leaf_size=45, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 3/5; 68/96] END leaf_size=45, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 68/96] START leaf_size=45, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 4/5; 68/96] END leaf_size=45, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 68/96] START leaf_size=45, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 5/5; 68/96] END leaf_size=45, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 69/96] START leaf_size=45, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 1/5; 69/96] END leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.545 total time=   0.0s\n",
            "[CV 2/5; 69/96] START leaf_size=45, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 2/5; 69/96] END leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.489 total time=   0.0s\n",
            "[CV 3/5; 69/96] START leaf_size=45, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 3/5; 69/96] END leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.500 total time=   0.0s\n",
            "[CV 4/5; 69/96] START leaf_size=45, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 4/5; 69/96] END leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.530 total time=   0.0s\n",
            "[CV 5/5; 69/96] START leaf_size=45, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 5/5; 69/96] END leaf_size=45, n_neighbors=7, p=1, weights=uniform;, score=0.509 total time=   0.0s\n",
            "[CV 1/5; 70/96] START leaf_size=45, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 1/5; 70/96] END leaf_size=45, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 70/96] START leaf_size=45, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 2/5; 70/96] END leaf_size=45, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 70/96] START leaf_size=45, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 3/5; 70/96] END leaf_size=45, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 70/96] START leaf_size=45, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 4/5; 70/96] END leaf_size=45, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 70/96] START leaf_size=45, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 5/5; 70/96] END leaf_size=45, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 71/96] START leaf_size=45, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 1/5; 71/96] END leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.519 total time=   0.0s\n",
            "[CV 2/5; 71/96] START leaf_size=45, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 2/5; 71/96] END leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.511 total time=   0.0s\n",
            "[CV 3/5; 71/96] START leaf_size=45, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 3/5; 71/96] END leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.504 total time=   0.0s\n",
            "[CV 4/5; 71/96] START leaf_size=45, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 4/5; 71/96] END leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.485 total time=   0.0s\n",
            "[CV 5/5; 71/96] START leaf_size=45, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 5/5; 71/96] END leaf_size=45, n_neighbors=7, p=2, weights=uniform;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 72/96] START leaf_size=45, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 1/5; 72/96] END leaf_size=45, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 72/96] START leaf_size=45, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 2/5; 72/96] END leaf_size=45, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 72/96] START leaf_size=45, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 3/5; 72/96] END leaf_size=45, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 72/96] START leaf_size=45, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 4/5; 72/96] END leaf_size=45, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 72/96] START leaf_size=45, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 5/5; 72/96] END leaf_size=45, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 73/96] START leaf_size=60, n_neighbors=2, p=1, weights=uniform.........\n",
            "[CV 1/5; 73/96] END leaf_size=60, n_neighbors=2, p=1, weights=uniform;, score=0.511 total time=   0.0s\n",
            "[CV 2/5; 73/96] START leaf_size=60, n_neighbors=2, p=1, weights=uniform.........\n",
            "[CV 2/5; 73/96] END leaf_size=60, n_neighbors=2, p=1, weights=uniform;, score=0.489 total time=   0.0s\n",
            "[CV 3/5; 73/96] START leaf_size=60, n_neighbors=2, p=1, weights=uniform.........\n",
            "[CV 3/5; 73/96] END leaf_size=60, n_neighbors=2, p=1, weights=uniform;, score=0.481 total time=   0.0s\n",
            "[CV 4/5; 73/96] START leaf_size=60, n_neighbors=2, p=1, weights=uniform.........\n",
            "[CV 4/5; 73/96] END leaf_size=60, n_neighbors=2, p=1, weights=uniform;, score=0.500 total time=   0.0s\n",
            "[CV 5/5; 73/96] START leaf_size=60, n_neighbors=2, p=1, weights=uniform.........\n",
            "[CV 5/5; 73/96] END leaf_size=60, n_neighbors=2, p=1, weights=uniform;, score=0.464 total time=   0.0s\n",
            "[CV 1/5; 74/96] START leaf_size=60, n_neighbors=2, p=1, weights=distanc.........\n",
            "[CV 1/5; 74/96] END leaf_size=60, n_neighbors=2, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 74/96] START leaf_size=60, n_neighbors=2, p=1, weights=distanc.........\n",
            "[CV 2/5; 74/96] END leaf_size=60, n_neighbors=2, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 74/96] START leaf_size=60, n_neighbors=2, p=1, weights=distanc.........\n",
            "[CV 3/5; 74/96] END leaf_size=60, n_neighbors=2, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 74/96] START leaf_size=60, n_neighbors=2, p=1, weights=distanc.........\n",
            "[CV 4/5; 74/96] END leaf_size=60, n_neighbors=2, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 74/96] START leaf_size=60, n_neighbors=2, p=1, weights=distanc.........\n",
            "[CV 5/5; 74/96] END leaf_size=60, n_neighbors=2, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 75/96] START leaf_size=60, n_neighbors=2, p=2, weights=uniform.........\n",
            "[CV 1/5; 75/96] END leaf_size=60, n_neighbors=2, p=2, weights=uniform;, score=0.470 total time=   0.0s\n",
            "[CV 2/5; 75/96] START leaf_size=60, n_neighbors=2, p=2, weights=uniform.........\n",
            "[CV 2/5; 75/96] END leaf_size=60, n_neighbors=2, p=2, weights=uniform;, score=0.493 total time=   0.0s\n",
            "[CV 3/5; 75/96] START leaf_size=60, n_neighbors=2, p=2, weights=uniform.........\n",
            "[CV 3/5; 75/96] END leaf_size=60, n_neighbors=2, p=2, weights=uniform;, score=0.511 total time=   0.0s\n",
            "[CV 4/5; 75/96] START leaf_size=60, n_neighbors=2, p=2, weights=uniform.........\n",
            "[CV 4/5; 75/96] END leaf_size=60, n_neighbors=2, p=2, weights=uniform;, score=0.511 total time=   0.0s\n",
            "[CV 5/5; 75/96] START leaf_size=60, n_neighbors=2, p=2, weights=uniform.........\n",
            "[CV 5/5; 75/96] END leaf_size=60, n_neighbors=2, p=2, weights=uniform;, score=0.479 total time=   0.0s\n",
            "[CV 1/5; 76/96] START leaf_size=60, n_neighbors=2, p=2, weights=distanc.........\n",
            "[CV 1/5; 76/96] END leaf_size=60, n_neighbors=2, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 76/96] START leaf_size=60, n_neighbors=2, p=2, weights=distanc.........\n",
            "[CV 2/5; 76/96] END leaf_size=60, n_neighbors=2, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 76/96] START leaf_size=60, n_neighbors=2, p=2, weights=distanc.........\n",
            "[CV 3/5; 76/96] END leaf_size=60, n_neighbors=2, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 76/96] START leaf_size=60, n_neighbors=2, p=2, weights=distanc.........\n",
            "[CV 4/5; 76/96] END leaf_size=60, n_neighbors=2, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 76/96] START leaf_size=60, n_neighbors=2, p=2, weights=distanc.........\n",
            "[CV 5/5; 76/96] END leaf_size=60, n_neighbors=2, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 77/96] START leaf_size=60, n_neighbors=3, p=1, weights=uniform.........\n",
            "[CV 1/5; 77/96] END leaf_size=60, n_neighbors=3, p=1, weights=uniform;, score=0.515 total time=   0.0s\n",
            "[CV 2/5; 77/96] START leaf_size=60, n_neighbors=3, p=1, weights=uniform.........\n",
            "[CV 2/5; 77/96] END leaf_size=60, n_neighbors=3, p=1, weights=uniform;, score=0.496 total time=   0.0s\n",
            "[CV 3/5; 77/96] START leaf_size=60, n_neighbors=3, p=1, weights=uniform.........\n",
            "[CV 3/5; 77/96] END leaf_size=60, n_neighbors=3, p=1, weights=uniform;, score=0.515 total time=   0.0s\n",
            "[CV 4/5; 77/96] START leaf_size=60, n_neighbors=3, p=1, weights=uniform.........\n",
            "[CV 4/5; 77/96] END leaf_size=60, n_neighbors=3, p=1, weights=uniform;, score=0.519 total time=   0.0s\n",
            "[CV 5/5; 77/96] START leaf_size=60, n_neighbors=3, p=1, weights=uniform.........\n",
            "[CV 5/5; 77/96] END leaf_size=60, n_neighbors=3, p=1, weights=uniform;, score=0.532 total time=   0.0s\n",
            "[CV 1/5; 78/96] START leaf_size=60, n_neighbors=3, p=1, weights=distanc.........\n",
            "[CV 1/5; 78/96] END leaf_size=60, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 78/96] START leaf_size=60, n_neighbors=3, p=1, weights=distanc.........\n",
            "[CV 2/5; 78/96] END leaf_size=60, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 78/96] START leaf_size=60, n_neighbors=3, p=1, weights=distanc.........\n",
            "[CV 3/5; 78/96] END leaf_size=60, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 78/96] START leaf_size=60, n_neighbors=3, p=1, weights=distanc.........\n",
            "[CV 4/5; 78/96] END leaf_size=60, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 78/96] START leaf_size=60, n_neighbors=3, p=1, weights=distanc.........\n",
            "[CV 5/5; 78/96] END leaf_size=60, n_neighbors=3, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 79/96] START leaf_size=60, n_neighbors=3, p=2, weights=uniform.........\n",
            "[CV 1/5; 79/96] END leaf_size=60, n_neighbors=3, p=2, weights=uniform;, score=0.489 total time=   0.0s\n",
            "[CV 2/5; 79/96] START leaf_size=60, n_neighbors=3, p=2, weights=uniform.........\n",
            "[CV 2/5; 79/96] END leaf_size=60, n_neighbors=3, p=2, weights=uniform;, score=0.515 total time=   0.0s\n",
            "[CV 3/5; 79/96] START leaf_size=60, n_neighbors=3, p=2, weights=uniform.........\n",
            "[CV 3/5; 79/96] END leaf_size=60, n_neighbors=3, p=2, weights=uniform;, score=0.541 total time=   0.0s\n",
            "[CV 4/5; 79/96] START leaf_size=60, n_neighbors=3, p=2, weights=uniform.........\n",
            "[CV 4/5; 79/96] END leaf_size=60, n_neighbors=3, p=2, weights=uniform;, score=0.537 total time=   0.0s\n",
            "[CV 5/5; 79/96] START leaf_size=60, n_neighbors=3, p=2, weights=uniform.........\n",
            "[CV 5/5; 79/96] END leaf_size=60, n_neighbors=3, p=2, weights=uniform;, score=0.536 total time=   0.0s\n",
            "[CV 1/5; 80/96] START leaf_size=60, n_neighbors=3, p=2, weights=distanc.........\n",
            "[CV 1/5; 80/96] END leaf_size=60, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 80/96] START leaf_size=60, n_neighbors=3, p=2, weights=distanc.........\n",
            "[CV 2/5; 80/96] END leaf_size=60, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 80/96] START leaf_size=60, n_neighbors=3, p=2, weights=distanc.........\n",
            "[CV 3/5; 80/96] END leaf_size=60, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 80/96] START leaf_size=60, n_neighbors=3, p=2, weights=distanc.........\n",
            "[CV 4/5; 80/96] END leaf_size=60, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 80/96] START leaf_size=60, n_neighbors=3, p=2, weights=distanc.........\n",
            "[CV 5/5; 80/96] END leaf_size=60, n_neighbors=3, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 81/96] START leaf_size=60, n_neighbors=4, p=1, weights=uniform.........\n",
            "[CV 1/5; 81/96] END leaf_size=60, n_neighbors=4, p=1, weights=uniform;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 81/96] START leaf_size=60, n_neighbors=4, p=1, weights=uniform.........\n",
            "[CV 2/5; 81/96] END leaf_size=60, n_neighbors=4, p=1, weights=uniform;, score=0.478 total time=   0.0s\n",
            "[CV 3/5; 81/96] START leaf_size=60, n_neighbors=4, p=1, weights=uniform.........\n",
            "[CV 3/5; 81/96] END leaf_size=60, n_neighbors=4, p=1, weights=uniform;, score=0.493 total time=   0.0s\n",
            "[CV 4/5; 81/96] START leaf_size=60, n_neighbors=4, p=1, weights=uniform.........\n",
            "[CV 4/5; 81/96] END leaf_size=60, n_neighbors=4, p=1, weights=uniform;, score=0.489 total time=   0.0s\n",
            "[CV 5/5; 81/96] START leaf_size=60, n_neighbors=4, p=1, weights=uniform.........\n",
            "[CV 5/5; 81/96] END leaf_size=60, n_neighbors=4, p=1, weights=uniform;, score=0.494 total time=   0.0s\n",
            "[CV 1/5; 82/96] START leaf_size=60, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 1/5; 82/96] END leaf_size=60, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 82/96] START leaf_size=60, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 2/5; 82/96] END leaf_size=60, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 82/96] START leaf_size=60, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 3/5; 82/96] END leaf_size=60, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 82/96] START leaf_size=60, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 4/5; 82/96] END leaf_size=60, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 82/96] START leaf_size=60, n_neighbors=4, p=1, weights=distanc.........\n",
            "[CV 5/5; 82/96] END leaf_size=60, n_neighbors=4, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 83/96] START leaf_size=60, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 1/5; 83/96] END leaf_size=60, n_neighbors=4, p=2, weights=uniform;, score=0.485 total time=   0.0s\n",
            "[CV 2/5; 83/96] START leaf_size=60, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 2/5; 83/96] END leaf_size=60, n_neighbors=4, p=2, weights=uniform;, score=0.455 total time=   0.0s\n",
            "[CV 3/5; 83/96] START leaf_size=60, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 3/5; 83/96] END leaf_size=60, n_neighbors=4, p=2, weights=uniform;, score=0.500 total time=   0.0s\n",
            "[CV 4/5; 83/96] START leaf_size=60, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 4/5; 83/96] END leaf_size=60, n_neighbors=4, p=2, weights=uniform;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 83/96] START leaf_size=60, n_neighbors=4, p=2, weights=uniform.........\n",
            "[CV 5/5; 83/96] END leaf_size=60, n_neighbors=4, p=2, weights=uniform;, score=0.483 total time=   0.0s\n",
            "[CV 1/5; 84/96] START leaf_size=60, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 1/5; 84/96] END leaf_size=60, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 84/96] START leaf_size=60, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 2/5; 84/96] END leaf_size=60, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 84/96] START leaf_size=60, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 3/5; 84/96] END leaf_size=60, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 84/96] START leaf_size=60, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 4/5; 84/96] END leaf_size=60, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 84/96] START leaf_size=60, n_neighbors=4, p=2, weights=distanc.........\n",
            "[CV 5/5; 84/96] END leaf_size=60, n_neighbors=4, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 85/96] START leaf_size=60, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 1/5; 85/96] END leaf_size=60, n_neighbors=5, p=1, weights=uniform;, score=0.504 total time=   0.0s\n",
            "[CV 2/5; 85/96] START leaf_size=60, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 2/5; 85/96] END leaf_size=60, n_neighbors=5, p=1, weights=uniform;, score=0.515 total time=   0.0s\n",
            "[CV 3/5; 85/96] START leaf_size=60, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 3/5; 85/96] END leaf_size=60, n_neighbors=5, p=1, weights=uniform;, score=0.496 total time=   0.0s\n",
            "[CV 4/5; 85/96] START leaf_size=60, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 4/5; 85/96] END leaf_size=60, n_neighbors=5, p=1, weights=uniform;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 85/96] START leaf_size=60, n_neighbors=5, p=1, weights=uniform.........\n",
            "[CV 5/5; 85/96] END leaf_size=60, n_neighbors=5, p=1, weights=uniform;, score=0.491 total time=   0.0s\n",
            "[CV 1/5; 86/96] START leaf_size=60, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 1/5; 86/96] END leaf_size=60, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 86/96] START leaf_size=60, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 2/5; 86/96] END leaf_size=60, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 86/96] START leaf_size=60, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 3/5; 86/96] END leaf_size=60, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 86/96] START leaf_size=60, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 4/5; 86/96] END leaf_size=60, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 86/96] START leaf_size=60, n_neighbors=5, p=1, weights=distanc.........\n",
            "[CV 5/5; 86/96] END leaf_size=60, n_neighbors=5, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 87/96] START leaf_size=60, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 1/5; 87/96] END leaf_size=60, n_neighbors=5, p=2, weights=uniform;, score=0.500 total time=   0.0s\n",
            "[CV 2/5; 87/96] START leaf_size=60, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 2/5; 87/96] END leaf_size=60, n_neighbors=5, p=2, weights=uniform;, score=0.496 total time=   0.0s\n",
            "[CV 3/5; 87/96] START leaf_size=60, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 3/5; 87/96] END leaf_size=60, n_neighbors=5, p=2, weights=uniform;, score=0.478 total time=   0.0s\n",
            "[CV 4/5; 87/96] START leaf_size=60, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 4/5; 87/96] END leaf_size=60, n_neighbors=5, p=2, weights=uniform;, score=0.489 total time=   0.0s\n",
            "[CV 5/5; 87/96] START leaf_size=60, n_neighbors=5, p=2, weights=uniform.........\n",
            "[CV 5/5; 87/96] END leaf_size=60, n_neighbors=5, p=2, weights=uniform;, score=0.562 total time=   0.0s\n",
            "[CV 1/5; 88/96] START leaf_size=60, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 1/5; 88/96] END leaf_size=60, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 88/96] START leaf_size=60, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 2/5; 88/96] END leaf_size=60, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 88/96] START leaf_size=60, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 3/5; 88/96] END leaf_size=60, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 88/96] START leaf_size=60, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 4/5; 88/96] END leaf_size=60, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 88/96] START leaf_size=60, n_neighbors=5, p=2, weights=distanc.........\n",
            "[CV 5/5; 88/96] END leaf_size=60, n_neighbors=5, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 89/96] START leaf_size=60, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 1/5; 89/96] END leaf_size=60, n_neighbors=6, p=1, weights=uniform;, score=0.567 total time=   0.0s\n",
            "[CV 2/5; 89/96] START leaf_size=60, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 2/5; 89/96] END leaf_size=60, n_neighbors=6, p=1, weights=uniform;, score=0.500 total time=   0.0s\n",
            "[CV 3/5; 89/96] START leaf_size=60, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 3/5; 89/96] END leaf_size=60, n_neighbors=6, p=1, weights=uniform;, score=0.481 total time=   0.0s\n",
            "[CV 4/5; 89/96] START leaf_size=60, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 4/5; 89/96] END leaf_size=60, n_neighbors=6, p=1, weights=uniform;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 89/96] START leaf_size=60, n_neighbors=6, p=1, weights=uniform.........\n",
            "[CV 5/5; 89/96] END leaf_size=60, n_neighbors=6, p=1, weights=uniform;, score=0.487 total time=   0.0s\n",
            "[CV 1/5; 90/96] START leaf_size=60, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 1/5; 90/96] END leaf_size=60, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 90/96] START leaf_size=60, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 2/5; 90/96] END leaf_size=60, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 90/96] START leaf_size=60, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 3/5; 90/96] END leaf_size=60, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 90/96] START leaf_size=60, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 4/5; 90/96] END leaf_size=60, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 90/96] START leaf_size=60, n_neighbors=6, p=1, weights=distanc.........\n",
            "[CV 5/5; 90/96] END leaf_size=60, n_neighbors=6, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 91/96] START leaf_size=60, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 1/5; 91/96] END leaf_size=60, n_neighbors=6, p=2, weights=uniform;, score=0.474 total time=   0.0s\n",
            "[CV 2/5; 91/96] START leaf_size=60, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 2/5; 91/96] END leaf_size=60, n_neighbors=6, p=2, weights=uniform;, score=0.504 total time=   0.0s\n",
            "[CV 3/5; 91/96] START leaf_size=60, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 3/5; 91/96] END leaf_size=60, n_neighbors=6, p=2, weights=uniform;, score=0.493 total time=   0.0s\n",
            "[CV 4/5; 91/96] START leaf_size=60, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 4/5; 91/96] END leaf_size=60, n_neighbors=6, p=2, weights=uniform;, score=0.519 total time=   0.0s\n",
            "[CV 5/5; 91/96] START leaf_size=60, n_neighbors=6, p=2, weights=uniform.........\n",
            "[CV 5/5; 91/96] END leaf_size=60, n_neighbors=6, p=2, weights=uniform;, score=0.554 total time=   0.0s\n",
            "[CV 1/5; 92/96] START leaf_size=60, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 1/5; 92/96] END leaf_size=60, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 92/96] START leaf_size=60, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 2/5; 92/96] END leaf_size=60, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 92/96] START leaf_size=60, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 3/5; 92/96] END leaf_size=60, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 92/96] START leaf_size=60, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 4/5; 92/96] END leaf_size=60, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 92/96] START leaf_size=60, n_neighbors=6, p=2, weights=distanc.........\n",
            "[CV 5/5; 92/96] END leaf_size=60, n_neighbors=6, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 93/96] START leaf_size=60, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 1/5; 93/96] END leaf_size=60, n_neighbors=7, p=1, weights=uniform;, score=0.545 total time=   0.0s\n",
            "[CV 2/5; 93/96] START leaf_size=60, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 2/5; 93/96] END leaf_size=60, n_neighbors=7, p=1, weights=uniform;, score=0.489 total time=   0.0s\n",
            "[CV 3/5; 93/96] START leaf_size=60, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 3/5; 93/96] END leaf_size=60, n_neighbors=7, p=1, weights=uniform;, score=0.500 total time=   0.0s\n",
            "[CV 4/5; 93/96] START leaf_size=60, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 4/5; 93/96] END leaf_size=60, n_neighbors=7, p=1, weights=uniform;, score=0.530 total time=   0.0s\n",
            "[CV 5/5; 93/96] START leaf_size=60, n_neighbors=7, p=1, weights=uniform.........\n",
            "[CV 5/5; 93/96] END leaf_size=60, n_neighbors=7, p=1, weights=uniform;, score=0.509 total time=   0.0s\n",
            "[CV 1/5; 94/96] START leaf_size=60, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 1/5; 94/96] END leaf_size=60, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 94/96] START leaf_size=60, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 2/5; 94/96] END leaf_size=60, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 94/96] START leaf_size=60, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 3/5; 94/96] END leaf_size=60, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 94/96] START leaf_size=60, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 4/5; 94/96] END leaf_size=60, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 94/96] START leaf_size=60, n_neighbors=7, p=1, weights=distanc.........\n",
            "[CV 5/5; 94/96] END leaf_size=60, n_neighbors=7, p=1, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 1/5; 95/96] START leaf_size=60, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 1/5; 95/96] END leaf_size=60, n_neighbors=7, p=2, weights=uniform;, score=0.519 total time=   0.0s\n",
            "[CV 2/5; 95/96] START leaf_size=60, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 2/5; 95/96] END leaf_size=60, n_neighbors=7, p=2, weights=uniform;, score=0.511 total time=   0.0s\n",
            "[CV 3/5; 95/96] START leaf_size=60, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 3/5; 95/96] END leaf_size=60, n_neighbors=7, p=2, weights=uniform;, score=0.504 total time=   0.1s\n",
            "[CV 4/5; 95/96] START leaf_size=60, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 4/5; 95/96] END leaf_size=60, n_neighbors=7, p=2, weights=uniform;, score=0.485 total time=   0.0s\n",
            "[CV 5/5; 95/96] START leaf_size=60, n_neighbors=7, p=2, weights=uniform.........\n",
            "[CV 5/5; 95/96] END leaf_size=60, n_neighbors=7, p=2, weights=uniform;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 96/96] START leaf_size=60, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 1/5; 96/96] END leaf_size=60, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 2/5; 96/96] START leaf_size=60, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 2/5; 96/96] END leaf_size=60, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 3/5; 96/96] START leaf_size=60, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 3/5; 96/96] END leaf_size=60, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 4/5; 96/96] START leaf_size=60, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 4/5; 96/96] END leaf_size=60, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n",
            "[CV 5/5; 96/96] START leaf_size=60, n_neighbors=7, p=2, weights=distanc.........\n",
            "[CV 5/5; 96/96] END leaf_size=60, n_neighbors=7, p=2, weights=distanc;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "240 fits failed out of a total of 480.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "240 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 213, in fit\n",
            "    self._validate_params()\n",
            "  File \"c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'weights' parameter of KNeighborsClassifier must be a str among {'uniform', 'distance'}, a callable or None. Got 'distanc' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.48915255        nan 0.49289508        nan 0.51532227        nan\n",
            " 0.52353402        nan 0.49514506        nan 0.48916653        nan\n",
            " 0.50559003        nan 0.50489686        nan 0.51155738        nan\n",
            " 0.50862262        nan 0.51455923        nan 0.50860026        nan\n",
            " 0.48915255        nan 0.49289508        nan 0.51532227        nan\n",
            " 0.52353402        nan 0.49514506        nan 0.48916653        nan\n",
            " 0.50559003        nan 0.50489686        nan 0.51155738        nan\n",
            " 0.50862262        nan 0.51455923        nan 0.50860026        nan\n",
            " 0.48915255        nan 0.49289508        nan 0.51532227        nan\n",
            " 0.52353402        nan 0.49514506        nan 0.48916653        nan\n",
            " 0.50559003        nan 0.50489686        nan 0.51155738        nan\n",
            " 0.50862262        nan 0.51455923        nan 0.50860026        nan\n",
            " 0.48915255        nan 0.49289508        nan 0.51532227        nan\n",
            " 0.52353402        nan 0.49514506        nan 0.48916653        nan\n",
            " 0.50559003        nan 0.50489686        nan 0.51155738        nan\n",
            " 0.50862262        nan 0.51455923        nan 0.50860026        nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;knnc&#x27;,\n",
              "                 GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
              "                              param_grid=[{&#x27;leaf_size&#x27;: [15, 30, 45, 60],\n",
              "                                           &#x27;n_neighbors&#x27;: [2, 3, 4, 5, 6, 7],\n",
              "                                           &#x27;p&#x27;: [1, 2],\n",
              "                                           &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distanc&#x27;]}],\n",
              "                              verbose=10))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;knnc&#x27;,\n",
              "                 GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
              "                              param_grid=[{&#x27;leaf_size&#x27;: [15, 30, 45, 60],\n",
              "                                           &#x27;n_neighbors&#x27;: [2, 3, 4, 5, 6, 7],\n",
              "                                           &#x27;p&#x27;: [1, 2],\n",
              "                                           &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distanc&#x27;]}],\n",
              "                              verbose=10))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">knnc: GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
              "             param_grid=[{&#x27;leaf_size&#x27;: [15, 30, 45, 60],\n",
              "                          &#x27;n_neighbors&#x27;: [2, 3, 4, 5, 6, 7], &#x27;p&#x27;: [1, 2],\n",
              "                          &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distanc&#x27;]}],\n",
              "             verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                ('knnc',\n",
              "                 GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
              "                              param_grid=[{'leaf_size': [15, 30, 45, 60],\n",
              "                                           'n_neighbors': [2, 3, 4, 5, 6, 7],\n",
              "                                           'p': [1, 2],\n",
              "                                           'weights': ['uniform', 'distanc']}],\n",
              "                              verbose=10))])"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "param_grid = [{\n",
        "    'n_neighbors': [2,3,4,5,6,7],\n",
        "    'weights': ['uniform' , 'distanc'],\n",
        "    'leaf_size': [15 ,30 ,45 ,60],\n",
        "    'p': [1 ,2]\n",
        "}]\n",
        "clf = Pipeline([('scaler', StandardScaler()) , \n",
        "                ('knnc' , GridSearchCV(KNeighborsClassifier(),\n",
        "                                      param_grid = param_grid,\n",
        "                                      cv =5,\n",
        "                                      refit = True,\n",
        "                                      verbose = 10))])\n",
        "clf.fit(X_train , y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(leaf_size=15, n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" checked><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(leaf_size=15, n_neighbors=3)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KNeighborsClassifier(leaf_size=15, n_neighbors=3)"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf['knnc'].best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.523534015316675"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf['knnc'].best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation f1-score: 0.5956521739130436\n",
            "Test f1-score: 0.6088888888888889\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "y_val_predict = clf.predict(X_validation)\n",
        "print('Validation f1-score:' , f1_score(y_validation , y_val_predict))\n",
        "y_predict = clf.predict(X_test)\n",
        "print('Test f1-score:' , f1_score(y_test , y_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 384 candidates, totalling 1920 fits\n",
            "[CV 1/5; 1/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 1/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.567 total time=   0.1s\n",
            "[CV 2/5; 1/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 1/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.578 total time=   0.0s\n",
            "[CV 3/5; 1/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 1/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.575 total time=   0.0s\n",
            "[CV 4/5; 1/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 1/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 5/5; 1/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 1/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.543 total time=   0.0s\n",
            "[CV 1/5; 2/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 2/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.485 total time=   0.0s\n",
            "[CV 2/5; 2/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 2/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.526 total time=   0.0s\n",
            "[CV 3/5; 2/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 2/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.466 total time=   0.0s\n",
            "[CV 4/5; 2/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 2/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.530 total time=   0.0s\n",
            "[CV 5/5; 2/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 2/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.528 total time=   0.0s\n",
            "[CV 1/5; 3/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 3/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 2/5; 3/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 3/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 3/5; 3/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 3/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.526 total time=   0.0s\n",
            "[CV 4/5; 3/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 3/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.619 total time=   0.0s\n",
            "[CV 5/5; 3/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 3/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 4/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 4/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.552 total time=   0.0s\n",
            "[CV 2/5; 4/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 4/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.504 total time=   0.0s\n",
            "[CV 3/5; 4/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 4/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.459 total time=   0.0s\n",
            "[CV 4/5; 4/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 4/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.489 total time=   0.0s\n",
            "[CV 5/5; 4/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 4/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.506 total time=   0.0s\n",
            "[CV 1/5; 5/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 5/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 5/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 5/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.511 total time=   0.0s\n",
            "[CV 3/5; 5/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 5/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.560 total time=   0.0s\n",
            "[CV 4/5; 5/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 5/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 5/5; 5/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 5/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.562 total time=   0.0s\n",
            "[CV 1/5; 6/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 6/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.474 total time=   0.0s\n",
            "[CV 2/5; 6/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 6/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.433 total time=   0.0s\n",
            "[CV 3/5; 6/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 6/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.534 total time=   0.0s\n",
            "[CV 4/5; 6/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 6/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.511 total time=   0.0s\n",
            "[CV 5/5; 6/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 6/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.502 total time=   0.0s\n",
            "[CV 1/5; 7/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 7/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.519 total time=   0.0s\n",
            "[CV 2/5; 7/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 7/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.567 total time=   0.0s\n",
            "[CV 3/5; 7/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 7/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.526 total time=   0.0s\n",
            "[CV 4/5; 7/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 7/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.608 total time=   0.0s\n",
            "[CV 5/5; 7/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 7/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.569 total time=   0.0s\n",
            "[CV 1/5; 8/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 8/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.504 total time=   0.0s\n",
            "[CV 2/5; 8/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 8/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.515 total time=   0.0s\n",
            "[CV 3/5; 8/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 8/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.493 total time=   0.0s\n",
            "[CV 4/5; 8/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 8/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.489 total time=   0.0s\n",
            "[CV 5/5; 8/384] START criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 8/384] END criterion=gini, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.472 total time=   0.0s\n",
            "[CV 1/5; 9/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 9/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.560 total time=   0.0s\n",
            "[CV 2/5; 9/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 9/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.526 total time=   0.0s\n",
            "[CV 3/5; 9/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 9/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.560 total time=   0.0s\n",
            "[CV 4/5; 9/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 9/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.500 total time=   0.0s\n",
            "[CV 5/5; 9/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 9/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 10/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 10/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.563 total time=   0.0s\n",
            "[CV 2/5; 10/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 10/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 10/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 10/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.466 total time=   0.0s\n",
            "[CV 4/5; 10/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 10/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.556 total time=   0.0s\n",
            "[CV 5/5; 10/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 10/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.472 total time=   0.0s\n",
            "[CV 1/5; 11/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 11/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.634 total time=   0.0s\n",
            "[CV 2/5; 11/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 11/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.534 total time=   0.0s\n",
            "[CV 3/5; 11/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 11/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.616 total time=   0.0s\n",
            "[CV 4/5; 11/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 11/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.578 total time=   0.0s\n",
            "[CV 5/5; 11/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 11/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.513 total time=   0.0s\n",
            "[CV 1/5; 12/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 12/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.485 total time=   0.0s\n",
            "[CV 2/5; 12/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 12/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.530 total time=   0.0s\n",
            "[CV 3/5; 12/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 12/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.433 total time=   0.0s\n",
            "[CV 4/5; 12/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 12/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.575 total time=   0.0s\n",
            "[CV 5/5; 12/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 12/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.494 total time=   0.0s\n",
            "[CV 1/5; 13/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 13/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.563 total time=   0.0s\n",
            "[CV 2/5; 13/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 13/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 3/5; 13/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 13/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.578 total time=   0.0s\n",
            "[CV 4/5; 13/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 13/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.504 total time=   0.0s\n",
            "[CV 5/5; 13/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 13/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.543 total time=   0.0s\n",
            "[CV 1/5; 14/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 14/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.519 total time=   0.0s\n",
            "[CV 2/5; 14/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 14/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.575 total time=   0.0s\n",
            "[CV 3/5; 14/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 14/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.560 total time=   0.0s\n",
            "[CV 4/5; 14/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 14/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.504 total time=   0.0s\n",
            "[CV 5/5; 14/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 14/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.491 total time=   0.0s\n",
            "[CV 1/5; 15/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 15/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.534 total time=   0.0s\n",
            "[CV 2/5; 15/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 15/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.575 total time=   0.0s\n",
            "[CV 3/5; 15/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 15/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.515 total time=   0.0s\n",
            "[CV 4/5; 15/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 15/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.534 total time=   0.0s\n",
            "[CV 5/5; 15/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 15/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.569 total time=   0.0s\n",
            "[CV 1/5; 16/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 16/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 16/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 16/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.567 total time=   0.0s\n",
            "[CV 3/5; 16/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 16/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.437 total time=   0.0s\n",
            "[CV 4/5; 16/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 16/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.545 total time=   0.0s\n",
            "[CV 5/5; 16/384] START criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 16/384] END criterion=gini, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.528 total time=   0.0s\n",
            "[CV 1/5; 17/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 17/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.545 total time=   0.0s\n",
            "[CV 2/5; 17/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 17/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.500 total time=   0.0s\n",
            "[CV 3/5; 17/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 17/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.563 total time=   0.0s\n",
            "[CV 4/5; 17/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 17/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.604 total time=   0.0s\n",
            "[CV 5/5; 17/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 17/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.502 total time=   0.0s\n",
            "[CV 1/5; 18/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 18/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.511 total time=   0.0s\n",
            "[CV 2/5; 18/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 18/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.451 total time=   0.0s\n",
            "[CV 3/5; 18/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 18/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.496 total time=   0.0s\n",
            "[CV 4/5; 18/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 18/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.545 total time=   0.0s\n",
            "[CV 5/5; 18/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 18/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.502 total time=   0.0s\n",
            "[CV 1/5; 19/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 19/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.545 total time=   0.0s\n",
            "[CV 2/5; 19/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 19/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.534 total time=   0.0s\n",
            "[CV 3/5; 19/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 19/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.489 total time=   0.0s\n",
            "[CV 4/5; 19/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 19/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 5/5; 19/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 19/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.562 total time=   0.0s\n",
            "[CV 1/5; 20/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 20/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.500 total time=   0.0s\n",
            "[CV 2/5; 20/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 20/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.537 total time=   0.0s\n",
            "[CV 3/5; 20/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 20/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.504 total time=   0.0s\n",
            "[CV 4/5; 20/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 20/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.526 total time=   0.0s\n",
            "[CV 5/5; 20/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 20/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.494 total time=   0.0s\n",
            "[CV 1/5; 21/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 21/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 2/5; 21/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 21/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.534 total time=   0.0s\n",
            "[CV 3/5; 21/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 21/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.504 total time=   0.0s\n",
            "[CV 4/5; 21/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 21/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.552 total time=   0.0s\n",
            "[CV 5/5; 21/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 21/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.562 total time=   0.0s\n",
            "[CV 1/5; 22/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 22/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.493 total time=   0.0s\n",
            "[CV 2/5; 22/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 22/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.485 total time=   0.0s\n",
            "[CV 3/5; 22/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 22/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.571 total time=   0.0s\n",
            "[CV 4/5; 22/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 22/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.556 total time=   0.0s\n",
            "[CV 5/5; 22/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 22/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.472 total time=   0.0s\n",
            "[CV 1/5; 23/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 23/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.563 total time=   0.0s\n",
            "[CV 2/5; 23/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 23/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.470 total time=   0.0s\n",
            "[CV 3/5; 23/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 23/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.582 total time=   0.0s\n",
            "[CV 4/5; 23/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 23/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.545 total time=   0.0s\n",
            "[CV 5/5; 23/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 23/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.502 total time=   0.0s\n",
            "[CV 1/5; 24/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 24/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.537 total time=   0.0s\n",
            "[CV 2/5; 24/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 24/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.493 total time=   0.0s\n",
            "[CV 3/5; 24/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 24/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.519 total time=   0.0s\n",
            "[CV 4/5; 24/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 24/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.552 total time=   0.0s\n",
            "[CV 5/5; 24/384] START criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 24/384] END criterion=gini, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.517 total time=   0.0s\n",
            "[CV 1/5; 25/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 25/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.537 total time=   0.0s\n",
            "[CV 2/5; 25/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 25/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.507 total time=   0.0s\n",
            "[CV 3/5; 25/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 25/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.530 total time=   0.0s\n",
            "[CV 4/5; 25/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 25/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.489 total time=   0.0s\n",
            "[CV 5/5; 25/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 25/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.536 total time=   0.0s\n",
            "[CV 1/5; 26/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 26/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.560 total time=   0.0s\n",
            "[CV 2/5; 26/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 26/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.500 total time=   0.0s\n",
            "[CV 3/5; 26/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 26/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.474 total time=   0.0s\n",
            "[CV 4/5; 26/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 26/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.451 total time=   0.0s\n",
            "[CV 5/5; 26/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 26/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 27/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=best\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 27/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.549 total time=   0.0s\n",
            "[CV 2/5; 27/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 27/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 3/5; 27/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 27/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.567 total time=   0.0s\n",
            "[CV 4/5; 27/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 27/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.563 total time=   0.0s\n",
            "[CV 5/5; 27/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 27/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.528 total time=   0.0s\n",
            "[CV 1/5; 28/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 28/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.549 total time=   0.0s\n",
            "[CV 2/5; 28/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 28/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.493 total time=   0.0s\n",
            "[CV 3/5; 28/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 28/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.549 total time=   0.0s\n",
            "[CV 4/5; 28/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 28/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.515 total time=   0.0s\n",
            "[CV 5/5; 28/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 28/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.487 total time=   0.0s\n",
            "[CV 1/5; 29/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 29/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.560 total time=   0.0s\n",
            "[CV 2/5; 29/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 29/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 3/5; 29/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 29/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.507 total time=   0.0s\n",
            "[CV 4/5; 29/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 29/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 5/5; 29/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 29/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 30/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 30/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.545 total time=   0.0s\n",
            "[CV 2/5; 30/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 30/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.455 total time=   0.0s\n",
            "[CV 3/5; 30/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 30/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.470 total time=   0.0s\n",
            "[CV 4/5; 30/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 30/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.530 total time=   0.0s\n",
            "[CV 5/5; 30/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 30/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.513 total time=   0.0s\n",
            "[CV 1/5; 31/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 31/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.500 total time=   0.0s\n",
            "[CV 2/5; 31/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 31/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.578 total time=   0.0s\n",
            "[CV 3/5; 31/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 31/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.500 total time=   0.0s\n",
            "[CV 4/5; 31/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 31/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.563 total time=   0.0s\n",
            "[CV 5/5; 31/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 31/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.547 total time=   0.0s\n",
            "[CV 1/5; 32/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 32/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.526 total time=   0.0s\n",
            "[CV 2/5; 32/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 32/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.500 total time=   0.0s\n",
            "[CV 3/5; 32/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 32/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.478 total time=   0.0s\n",
            "[CV 4/5; 32/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 32/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.496 total time=   0.0s\n",
            "[CV 5/5; 32/384] START criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 32/384] END criterion=gini, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.528 total time=   0.0s\n",
            "[CV 1/5; 33/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 33/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.549 total time=   0.0s\n",
            "[CV 2/5; 33/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 33/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.537 total time=   0.0s\n",
            "[CV 3/5; 33/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 33/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.549 total time=   0.0s\n",
            "[CV 4/5; 33/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 33/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.537 total time=   0.0s\n",
            "[CV 5/5; 33/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 33/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.569 total time=   0.0s\n",
            "[CV 1/5; 34/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 34/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.563 total time=   0.0s\n",
            "[CV 2/5; 34/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 34/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.485 total time=   0.0s\n",
            "[CV 3/5; 34/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 34/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.478 total time=   0.0s\n",
            "[CV 4/5; 34/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 34/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.504 total time=   0.0s\n",
            "[CV 5/5; 34/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 34/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 35/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 35/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.575 total time=   0.0s\n",
            "[CV 2/5; 35/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 35/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.504 total time=   0.0s\n",
            "[CV 3/5; 35/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 35/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.567 total time=   0.0s\n",
            "[CV 4/5; 35/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 35/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.511 total time=   0.0s\n",
            "[CV 5/5; 35/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 35/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.543 total time=   0.0s\n",
            "[CV 1/5; 36/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 36/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.519 total time=   0.0s\n",
            "[CV 2/5; 36/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 36/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.541 total time=   0.0s\n",
            "[CV 3/5; 36/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 36/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.470 total time=   0.0s\n",
            "[CV 4/5; 36/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 36/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.474 total time=   0.0s\n",
            "[CV 5/5; 36/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 36/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.464 total time=   0.0s\n",
            "[CV 1/5; 37/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 37/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.534 total time=   0.0s\n",
            "[CV 2/5; 37/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 37/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.552 total time=   0.0s\n",
            "[CV 3/5; 37/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 37/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.459 total time=   0.0s\n",
            "[CV 4/5; 37/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 37/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.552 total time=   0.0s\n",
            "[CV 5/5; 37/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 37/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.547 total time=   0.0s\n",
            "[CV 1/5; 38/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 38/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.590 total time=   0.0s\n",
            "[CV 2/5; 38/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 38/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.507 total time=   0.0s\n",
            "[CV 3/5; 38/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 38/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.519 total time=   0.0s\n",
            "[CV 4/5; 38/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 38/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.549 total time=   0.0s\n",
            "[CV 5/5; 38/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 38/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.494 total time=   0.0s\n",
            "[CV 1/5; 39/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 39/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.563 total time=   0.0s\n",
            "[CV 2/5; 39/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 39/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.526 total time=   0.0s\n",
            "[CV 3/5; 39/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 39/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.552 total time=   0.0s\n",
            "[CV 4/5; 39/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 39/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.549 total time=   0.0s\n",
            "[CV 5/5; 39/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 39/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.431 total time=   0.0s\n",
            "[CV 1/5; 40/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 40/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.537 total time=   0.0s\n",
            "[CV 2/5; 40/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 40/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.481 total time=   0.0s\n",
            "[CV 3/5; 40/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 40/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.530 total time=   0.0s\n",
            "[CV 4/5; 40/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 40/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.597 total time=   0.0s\n",
            "[CV 5/5; 40/384] START criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 40/384] END criterion=gini, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.498 total time=   0.0s\n",
            "[CV 1/5; 41/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 41/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.567 total time=   0.0s\n",
            "[CV 2/5; 41/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 41/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.560 total time=   0.0s\n",
            "[CV 3/5; 41/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 41/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 41/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 41/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.481 total time=   0.0s\n",
            "[CV 5/5; 41/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 41/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.554 total time=   0.0s\n",
            "[CV 1/5; 42/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 42/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.563 total time=   0.0s\n",
            "[CV 2/5; 42/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 42/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.530 total time=   0.0s\n",
            "[CV 3/5; 42/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 42/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.507 total time=   0.0s\n",
            "[CV 4/5; 42/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 42/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.429 total time=   0.0s\n",
            "[CV 5/5; 42/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 42/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.491 total time=   0.0s\n",
            "[CV 1/5; 43/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 43/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.571 total time=   0.0s\n",
            "[CV 2/5; 43/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 43/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.537 total time=   0.0s\n",
            "[CV 3/5; 43/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 43/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 4/5; 43/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 43/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.575 total time=   0.0s\n",
            "[CV 5/5; 43/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 43/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.543 total time=   0.0s\n",
            "[CV 1/5; 44/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 44/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.545 total time=   0.0s\n",
            "[CV 2/5; 44/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 44/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.470 total time=   0.0s\n",
            "[CV 3/5; 44/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 44/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.444 total time=   0.0s\n",
            "[CV 4/5; 44/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 44/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.433 total time=   0.0s\n",
            "[CV 5/5; 44/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 44/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.461 total time=   0.0s\n",
            "[CV 1/5; 45/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 45/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.578 total time=   0.0s\n",
            "[CV 2/5; 45/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 45/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 3/5; 45/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 45/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.597 total time=   0.0s\n",
            "[CV 4/5; 45/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 45/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.560 total time=   0.0s\n",
            "[CV 5/5; 45/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 45/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.607 total time=   0.0s\n",
            "[CV 1/5; 46/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 46/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.530 total time=   0.0s\n",
            "[CV 2/5; 46/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 46/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.481 total time=   0.0s\n",
            "[CV 3/5; 46/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 46/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.530 total time=   0.0s\n",
            "[CV 4/5; 46/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 46/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.537 total time=   0.0s\n",
            "[CV 5/5; 46/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 46/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.539 total time=   0.0s\n",
            "[CV 1/5; 47/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 47/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.537 total time=   0.0s\n",
            "[CV 2/5; 47/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 47/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.511 total time=   0.0s\n",
            "[CV 3/5; 47/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 47/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.534 total time=   0.0s\n",
            "[CV 4/5; 47/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 47/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.586 total time=   0.0s\n",
            "[CV 5/5; 47/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 47/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.483 total time=   0.0s\n",
            "[CV 1/5; 48/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 48/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.515 total time=   0.0s\n",
            "[CV 2/5; 48/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 48/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.507 total time=   0.0s\n",
            "[CV 3/5; 48/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 48/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.444 total time=   0.0s\n",
            "[CV 4/5; 48/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 48/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.567 total time=   0.0s\n",
            "[CV 5/5; 48/384] START criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 48/384] END criterion=gini, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.491 total time=   0.0s\n",
            "[CV 1/5; 49/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 49/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.422 total time=   0.0s\n",
            "[CV 2/5; 49/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 49/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.526 total time=   0.0s\n",
            "[CV 3/5; 49/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 49/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.578 total time=   0.0s\n",
            "[CV 4/5; 49/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 49/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.563 total time=   0.0s\n",
            "[CV 5/5; 49/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 49/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.551 total time=   0.0s\n",
            "[CV 1/5; 50/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 50/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.515 total time=   0.0s\n",
            "[CV 2/5; 50/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 50/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.500 total time=   0.0s\n",
            "[CV 3/5; 50/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 50/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.496 total time=   0.0s\n",
            "[CV 4/5; 50/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 50/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.485 total time=   0.0s\n",
            "[CV 5/5; 50/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 50/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.487 total time=   0.0s\n",
            "[CV 1/5; 51/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 51/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.537 total time=   0.0s\n",
            "[CV 2/5; 51/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 51/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.537 total time=   0.0s\n",
            "[CV 3/5; 51/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 51/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.519 total time=   0.0s\n",
            "[CV 4/5; 51/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 51/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.481 total time=   0.0s\n",
            "[CV 5/5; 51/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 51/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.536 total time=   0.0s\n",
            "[CV 1/5; 52/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 52/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.511 total time=   0.0s\n",
            "[CV 2/5; 52/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 52/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.493 total time=   0.0s\n",
            "[CV 3/5; 52/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 52/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.526 total time=   0.0s\n",
            "[CV 4/5; 52/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 52/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.552 total time=   0.0s\n",
            "[CV 5/5; 52/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 52/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.479 total time=   0.0s\n",
            "[CV 1/5; 53/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 53/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.590 total time=   0.0s\n",
            "[CV 2/5; 53/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 53/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.575 total time=   0.0s\n",
            "[CV 3/5; 53/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 53/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 4/5; 53/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 53/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.507 total time=   0.0s\n",
            "[CV 5/5; 53/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 53/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 54/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 54/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.470 total time=   0.0s\n",
            "[CV 2/5; 54/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 54/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.485 total time=   0.0s\n",
            "[CV 3/5; 54/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 54/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.511 total time=   0.0s\n",
            "[CV 4/5; 54/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 54/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.451 total time=   0.0s\n",
            "[CV 5/5; 54/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 54/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.528 total time=   0.0s\n",
            "[CV 1/5; 55/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 55/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.549 total time=   0.0s\n",
            "[CV 2/5; 55/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 55/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.519 total time=   0.0s\n",
            "[CV 3/5; 55/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 55/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.560 total time=   0.0s\n",
            "[CV 4/5; 55/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 55/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 5/5; 55/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 55/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.528 total time=   0.0s\n",
            "[CV 1/5; 56/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 56/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.563 total time=   0.0s\n",
            "[CV 2/5; 56/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 56/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.519 total time=   0.0s\n",
            "[CV 3/5; 56/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 56/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.534 total time=   0.0s\n",
            "[CV 4/5; 56/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 56/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.537 total time=   0.0s\n",
            "[CV 5/5; 56/384] START criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 56/384] END criterion=gini, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.513 total time=   0.0s\n",
            "[CV 1/5; 57/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 57/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.560 total time=   0.0s\n",
            "[CV 2/5; 57/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 57/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.563 total time=   0.0s\n",
            "[CV 3/5; 57/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 57/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.474 total time=   0.0s\n",
            "[CV 4/5; 57/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 57/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.537 total time=   0.0s\n",
            "[CV 5/5; 57/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 57/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 58/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 58/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.500 total time=   0.0s\n",
            "[CV 2/5; 58/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 58/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.478 total time=   0.0s\n",
            "[CV 3/5; 58/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 58/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.496 total time=   0.0s\n",
            "[CV 4/5; 58/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 58/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.507 total time=   0.0s\n",
            "[CV 5/5; 58/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 58/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.513 total time=   0.0s\n",
            "[CV 1/5; 59/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 59/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.552 total time=   0.0s\n",
            "[CV 2/5; 59/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 59/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.466 total time=   0.0s\n",
            "[CV 3/5; 59/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 59/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 4/5; 59/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 59/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.526 total time=   0.0s\n",
            "[CV 5/5; 59/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 59/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.532 total time=   0.0s\n",
            "[CV 1/5; 60/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 60/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.549 total time=   0.0s\n",
            "[CV 2/5; 60/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 60/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.410 total time=   0.0s\n",
            "[CV 3/5; 60/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 60/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.519 total time=   0.0s\n",
            "[CV 4/5; 60/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 60/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.526 total time=   0.0s\n",
            "[CV 5/5; 60/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 60/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 61/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 61/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 2/5; 61/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 61/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.496 total time=   0.0s\n",
            "[CV 3/5; 61/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 61/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.552 total time=   0.0s\n",
            "[CV 4/5; 61/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 61/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.597 total time=   0.0s\n",
            "[CV 5/5; 61/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 61/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.566 total time=   0.0s\n",
            "[CV 1/5; 62/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 62/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.526 total time=   0.0s\n",
            "[CV 2/5; 62/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 62/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.504 total time=   0.0s\n",
            "[CV 3/5; 62/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 62/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.481 total time=   0.0s\n",
            "[CV 4/5; 62/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 62/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.504 total time=   0.0s\n",
            "[CV 5/5; 62/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 62/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 63/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 63/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.530 total time=   0.0s\n",
            "[CV 2/5; 63/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 63/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.507 total time=   0.0s\n",
            "[CV 3/5; 63/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 63/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.552 total time=   0.0s\n",
            "[CV 4/5; 63/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 63/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.582 total time=   0.0s\n",
            "[CV 5/5; 63/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 63/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.554 total time=   0.0s\n",
            "[CV 1/5; 64/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 64/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.537 total time=   0.0s\n",
            "[CV 2/5; 64/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 64/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.519 total time=   0.0s\n",
            "[CV 3/5; 64/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 64/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.511 total time=   0.0s\n",
            "[CV 4/5; 64/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 64/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.552 total time=   0.0s\n",
            "[CV 5/5; 64/384] START criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 64/384] END criterion=gini, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.551 total time=   0.0s\n",
            "[CV 1/5; 65/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 65/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.567 total time=   0.0s\n",
            "[CV 2/5; 65/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 65/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.496 total time=   0.0s\n",
            "[CV 3/5; 65/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 65/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.560 total time=   0.0s\n",
            "[CV 4/5; 65/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 65/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.534 total time=   0.0s\n",
            "[CV 5/5; 65/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 65/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.494 total time=   0.0s\n",
            "[CV 1/5; 66/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 66/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.530 total time=   0.0s\n",
            "[CV 2/5; 66/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 66/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.515 total time=   0.0s\n",
            "[CV 3/5; 66/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 66/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.485 total time=   0.0s\n",
            "[CV 4/5; 66/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 66/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.526 total time=   0.0s\n",
            "[CV 5/5; 66/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 66/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.483 total time=   0.0s\n",
            "[CV 1/5; 67/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 67/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.537 total time=   0.0s\n",
            "[CV 2/5; 67/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 67/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.519 total time=   0.0s\n",
            "[CV 3/5; 67/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 67/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.459 total time=   0.0s\n",
            "[CV 4/5; 67/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 67/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.515 total time=   0.0s\n",
            "[CV 5/5; 67/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 67/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.487 total time=   0.0s\n",
            "[CV 1/5; 68/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 68/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.537 total time=   0.0s\n",
            "[CV 2/5; 68/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 68/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.489 total time=   0.0s\n",
            "[CV 3/5; 68/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 68/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.549 total time=   0.0s\n",
            "[CV 4/5; 68/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 68/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.541 total time=   0.0s\n",
            "[CV 5/5; 68/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 68/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.468 total time=   0.0s\n",
            "[CV 1/5; 69/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 69/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.560 total time=   0.0s\n",
            "[CV 2/5; 69/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 69/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.530 total time=   0.0s\n",
            "[CV 3/5; 69/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 69/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.537 total time=   0.0s\n",
            "[CV 4/5; 69/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 69/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.552 total time=   0.0s\n",
            "[CV 5/5; 69/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 69/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.562 total time=   0.0s\n",
            "[CV 1/5; 70/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 70/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.604 total time=   0.0s\n",
            "[CV 2/5; 70/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 70/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.541 total time=   0.0s\n",
            "[CV 3/5; 70/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 70/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.507 total time=   0.0s\n",
            "[CV 4/5; 70/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 70/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.481 total time=   0.0s\n",
            "[CV 5/5; 70/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 70/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.513 total time=   0.0s\n",
            "[CV 1/5; 71/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 71/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 2/5; 71/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 71/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.515 total time=   0.0s\n",
            "[CV 3/5; 71/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 71/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.537 total time=   0.0s\n",
            "[CV 4/5; 71/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 71/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 5/5; 71/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 71/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.536 total time=   0.0s\n",
            "[CV 1/5; 72/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 72/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.519 total time=   0.0s\n",
            "[CV 2/5; 72/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 72/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.493 total time=   0.0s\n",
            "[CV 3/5; 72/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 72/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.448 total time=   0.0s\n",
            "[CV 4/5; 72/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 72/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.541 total time=   0.0s\n",
            "[CV 5/5; 72/384] START criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 72/384] END criterion=gini, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 73/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 73/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.511 total time=   0.0s\n",
            "[CV 2/5; 73/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 73/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 3/5; 73/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 73/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.519 total time=   0.0s\n",
            "[CV 4/5; 73/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 73/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 5/5; 73/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 73/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.457 total time=   0.0s\n",
            "[CV 1/5; 74/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 74/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.534 total time=   0.0s\n",
            "[CV 2/5; 74/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 74/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.489 total time=   0.0s\n",
            "[CV 3/5; 74/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 74/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.478 total time=   0.0s\n",
            "[CV 4/5; 74/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 74/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.601 total time=   0.0s\n",
            "[CV 5/5; 74/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 74/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 75/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 75/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.552 total time=   0.0s\n",
            "[CV 2/5; 75/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 75/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.534 total time=   0.0s\n",
            "[CV 3/5; 75/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 75/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.489 total time=   0.0s\n",
            "[CV 4/5; 75/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 75/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.634 total time=   0.0s\n",
            "[CV 5/5; 75/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 75/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.551 total time=   0.0s\n",
            "[CV 1/5; 76/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 76/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.537 total time=   0.0s\n",
            "[CV 2/5; 76/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 76/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.478 total time=   0.0s\n",
            "[CV 3/5; 76/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 76/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.470 total time=   0.0s\n",
            "[CV 4/5; 76/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 76/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.534 total time=   0.0s\n",
            "[CV 5/5; 76/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 76/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.468 total time=   0.0s\n",
            "[CV 1/5; 77/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 77/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.549 total time=   0.0s\n",
            "[CV 2/5; 77/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 77/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 3/5; 77/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 77/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.567 total time=   0.0s\n",
            "[CV 4/5; 77/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 77/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 5/5; 77/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 77/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.513 total time=   0.0s\n",
            "[CV 1/5; 78/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 78/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.537 total time=   0.0s\n",
            "[CV 2/5; 78/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 78/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.511 total time=   0.0s\n",
            "[CV 3/5; 78/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 78/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.489 total time=   0.0s\n",
            "[CV 4/5; 78/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 78/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.560 total time=   0.0s\n",
            "[CV 5/5; 78/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 78/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.502 total time=   0.0s\n",
            "[CV 1/5; 79/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 79/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.534 total time=   0.0s\n",
            "[CV 2/5; 79/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 79/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.530 total time=   0.0s\n",
            "[CV 3/5; 79/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 79/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.500 total time=   0.0s\n",
            "[CV 4/5; 79/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 79/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.575 total time=   0.0s\n",
            "[CV 5/5; 79/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 79/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 80/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 80/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 80/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 80/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.519 total time=   0.0s\n",
            "[CV 3/5; 80/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 80/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.511 total time=   0.0s\n",
            "[CV 4/5; 80/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 80/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.500 total time=   0.0s\n",
            "[CV 5/5; 80/384] START criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 80/384] END criterion=gini, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.472 total time=   0.0s\n",
            "[CV 1/5; 81/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 81/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.567 total time=   0.0s\n",
            "[CV 2/5; 81/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 81/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.496 total time=   0.0s\n",
            "[CV 3/5; 81/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 81/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.560 total time=   0.0s\n",
            "[CV 4/5; 81/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 81/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.567 total time=   0.0s\n",
            "[CV 5/5; 81/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 81/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.509 total time=   0.0s\n",
            "[CV 1/5; 82/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 82/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.549 total time=   0.0s\n",
            "[CV 2/5; 82/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 82/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.493 total time=   0.0s\n",
            "[CV 3/5; 82/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 82/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.507 total time=   0.0s\n",
            "[CV 4/5; 82/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 82/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.545 total time=   0.0s\n",
            "[CV 5/5; 82/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 82/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.479 total time=   0.0s\n",
            "[CV 1/5; 83/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 83/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.534 total time=   0.0s\n",
            "[CV 2/5; 83/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 83/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.552 total time=   0.0s\n",
            "[CV 3/5; 83/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 83/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.526 total time=   0.0s\n",
            "[CV 4/5; 83/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 83/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 5/5; 83/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 83/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.532 total time=   0.0s\n",
            "[CV 1/5; 84/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 84/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.511 total time=   0.0s\n",
            "[CV 2/5; 84/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 84/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.515 total time=   0.0s\n",
            "[CV 3/5; 84/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 84/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.485 total time=   0.0s\n",
            "[CV 4/5; 84/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 84/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.496 total time=   0.0s\n",
            "[CV 5/5; 84/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 84/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.479 total time=   0.0s\n",
            "[CV 1/5; 85/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 85/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.526 total time=   0.0s\n",
            "[CV 2/5; 85/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 85/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.537 total time=   0.0s\n",
            "[CV 3/5; 85/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 85/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.563 total time=   0.0s\n",
            "[CV 4/5; 85/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 85/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.466 total time=   0.0s\n",
            "[CV 5/5; 85/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 85/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.539 total time=   0.0s\n",
            "[CV 1/5; 86/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 86/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.507 total time=   0.0s\n",
            "[CV 2/5; 86/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 86/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.511 total time=   0.0s\n",
            "[CV 3/5; 86/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 86/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.470 total time=   0.0s\n",
            "[CV 4/5; 86/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 86/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.534 total time=   0.0s\n",
            "[CV 5/5; 86/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 86/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.472 total time=   0.0s\n",
            "[CV 1/5; 87/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 87/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.526 total time=   0.0s\n",
            "[CV 2/5; 87/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 87/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 3/5; 87/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 87/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.552 total time=   0.0s\n",
            "[CV 4/5; 87/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 87/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.552 total time=   0.0s\n",
            "[CV 5/5; 87/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 87/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.509 total time=   0.0s\n",
            "[CV 1/5; 88/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 88/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.493 total time=   0.0s\n",
            "[CV 2/5; 88/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 88/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.519 total time=   0.0s\n",
            "[CV 3/5; 88/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 88/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.478 total time=   0.0s\n",
            "[CV 4/5; 88/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 88/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.545 total time=   0.0s\n",
            "[CV 5/5; 88/384] START criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 88/384] END criterion=gini, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.494 total time=   0.0s\n",
            "[CV 1/5; 89/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 89/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.530 total time=   0.0s\n",
            "[CV 2/5; 89/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 89/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.601 total time=   0.0s\n",
            "[CV 3/5; 89/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 89/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.534 total time=   0.0s\n",
            "[CV 4/5; 89/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 89/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.545 total time=   0.0s\n",
            "[CV 5/5; 89/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 89/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.502 total time=   0.0s\n",
            "[CV 1/5; 90/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 90/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.504 total time=   0.0s\n",
            "[CV 2/5; 90/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 90/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.459 total time=   0.0s\n",
            "[CV 3/5; 90/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 90/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.519 total time=   0.0s\n",
            "[CV 4/5; 90/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 90/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.545 total time=   0.0s\n",
            "[CV 5/5; 90/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 90/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.506 total time=   0.0s\n",
            "[CV 1/5; 91/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 91/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.526 total time=   0.0s\n",
            "[CV 2/5; 91/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 91/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.500 total time=   0.0s\n",
            "[CV 3/5; 91/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 91/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.552 total time=   0.0s\n",
            "[CV 4/5; 91/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 91/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.578 total time=   0.0s\n",
            "[CV 5/5; 91/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 91/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.596 total time=   0.0s\n",
            "[CV 1/5; 92/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 92/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.560 total time=   0.0s\n",
            "[CV 2/5; 92/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 92/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.500 total time=   0.0s\n",
            "[CV 3/5; 92/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 92/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.534 total time=   0.0s\n",
            "[CV 4/5; 92/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 92/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.455 total time=   0.0s\n",
            "[CV 5/5; 92/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 92/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.457 total time=   0.0s\n",
            "[CV 1/5; 93/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 93/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.515 total time=   0.0s\n",
            "[CV 2/5; 93/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 93/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.519 total time=   0.0s\n",
            "[CV 3/5; 93/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 93/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.511 total time=   0.0s\n",
            "[CV 4/5; 93/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 93/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.507 total time=   0.0s\n",
            "[CV 5/5; 93/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 93/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.614 total time=   0.0s\n",
            "[CV 1/5; 94/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 94/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.575 total time=   0.0s\n",
            "[CV 2/5; 94/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 94/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.515 total time=   0.0s\n",
            "[CV 3/5; 94/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 94/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.534 total time=   0.0s\n",
            "[CV 4/5; 94/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 94/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.474 total time=   0.0s\n",
            "[CV 5/5; 94/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 94/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.494 total time=   0.0s\n",
            "[CV 1/5; 95/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 95/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 2/5; 95/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 95/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.481 total time=   0.0s\n",
            "[CV 3/5; 95/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 95/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.537 total time=   0.0s\n",
            "[CV 4/5; 95/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 95/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.560 total time=   0.0s\n",
            "[CV 5/5; 95/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 95/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.536 total time=   0.0s\n",
            "[CV 1/5; 96/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 96/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.541 total time=   0.0s\n",
            "[CV 2/5; 96/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 96/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.500 total time=   0.0s\n",
            "[CV 3/5; 96/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 96/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.466 total time=   0.0s\n",
            "[CV 4/5; 96/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 96/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 96/384] START criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 96/384] END criterion=gini, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 97/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 97/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.653 total time=   0.0s\n",
            "[CV 2/5; 97/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 97/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.724 total time=   0.0s\n",
            "[CV 3/5; 97/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 97/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.769 total time=   0.0s\n",
            "[CV 4/5; 97/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 97/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.739 total time=   0.0s\n",
            "[CV 5/5; 97/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 97/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.734 total time=   0.0s\n",
            "[CV 1/5; 98/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 98/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.590 total time=   0.0s\n",
            "[CV 2/5; 98/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 98/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.511 total time=   0.0s\n",
            "[CV 3/5; 98/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 98/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.601 total time=   0.0s\n",
            "[CV 4/5; 98/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 98/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.616 total time=   0.0s\n",
            "[CV 5/5; 98/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 98/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.704 total time=   0.0s\n",
            "[CV 1/5; 99/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 99/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.649 total time=   0.0s\n",
            "[CV 2/5; 99/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 99/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.746 total time=   0.0s\n",
            "[CV 3/5; 99/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 99/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.754 total time=   0.0s\n",
            "[CV 4/5; 99/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 99/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.720 total time=   0.0s\n",
            "[CV 5/5; 99/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 99/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.723 total time=   0.0s\n",
            "[CV 1/5; 100/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 100/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.597 total time=   0.0s\n",
            "[CV 2/5; 100/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 100/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.623 total time=   0.0s\n",
            "[CV 3/5; 100/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 100/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.515 total time=   0.0s\n",
            "[CV 4/5; 100/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 100/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.552 total time=   0.0s\n",
            "[CV 5/5; 100/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 100/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 101/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 101/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.631 total time=   0.0s\n",
            "[CV 2/5; 101/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 101/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.724 total time=   0.0s\n",
            "[CV 3/5; 101/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 101/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.754 total time=   0.0s\n",
            "[CV 4/5; 101/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 101/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.761 total time=   0.0s\n",
            "[CV 5/5; 101/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 101/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.708 total time=   0.0s\n",
            "[CV 1/5; 102/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 102/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.578 total time=   0.0s\n",
            "[CV 2/5; 102/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 102/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.601 total time=   0.0s\n",
            "[CV 3/5; 102/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 102/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.590 total time=   0.0s\n",
            "[CV 4/5; 102/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 102/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.593 total time=   0.0s\n",
            "[CV 5/5; 102/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 102/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.502 total time=   0.0s\n",
            "[CV 1/5; 103/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 103/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.675 total time=   0.0s\n",
            "[CV 2/5; 103/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 103/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.720 total time=   0.0s\n",
            "[CV 3/5; 103/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 103/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.787 total time=   0.0s\n",
            "[CV 4/5; 103/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 103/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.739 total time=   0.0s\n",
            "[CV 5/5; 103/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 103/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.719 total time=   0.0s\n",
            "[CV 1/5; 104/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 104/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.619 total time=   0.0s\n",
            "[CV 2/5; 104/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 104/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.578 total time=   0.0s\n",
            "[CV 3/5; 104/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 104/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.496 total time=   0.0s\n",
            "[CV 4/5; 104/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 104/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.552 total time=   0.0s\n",
            "[CV 5/5; 104/384] START criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 104/384] END criterion=gini, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.517 total time=   0.0s\n",
            "[CV 1/5; 105/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 105/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.657 total time=   0.0s\n",
            "[CV 2/5; 105/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 105/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.701 total time=   0.0s\n",
            "[CV 3/5; 105/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 105/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.791 total time=   0.0s\n",
            "[CV 4/5; 105/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 105/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.754 total time=   0.0s\n",
            "[CV 5/5; 105/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 105/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.723 total time=   0.0s\n",
            "[CV 1/5; 106/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 106/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.608 total time=   0.0s\n",
            "[CV 2/5; 106/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 106/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.556 total time=   0.0s\n",
            "[CV 3/5; 106/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 106/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.541 total time=   0.0s\n",
            "[CV 4/5; 106/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 106/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.668 total time=   0.0s\n",
            "[CV 5/5; 106/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 106/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.618 total time=   0.0s\n",
            "[CV 1/5; 107/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 107/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.660 total time=   0.0s\n",
            "[CV 2/5; 107/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 107/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.705 total time=   0.0s\n",
            "[CV 3/5; 107/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 107/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.784 total time=   0.0s\n",
            "[CV 4/5; 107/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 107/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.754 total time=   0.0s\n",
            "[CV 5/5; 107/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 107/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.723 total time=   0.0s\n",
            "[CV 1/5; 108/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 108/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.668 total time=   0.0s\n",
            "[CV 2/5; 108/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 108/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.660 total time=   0.0s\n",
            "[CV 3/5; 108/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 108/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.560 total time=   0.0s\n",
            "[CV 4/5; 108/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 108/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.552 total time=   0.0s\n",
            "[CV 5/5; 108/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 108/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.532 total time=   0.0s\n",
            "[CV 1/5; 109/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 109/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.664 total time=   0.0s\n",
            "[CV 2/5; 109/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 109/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.705 total time=   0.0s\n",
            "[CV 3/5; 109/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 109/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.772 total time=   0.0s\n",
            "[CV 4/5; 109/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 109/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.772 total time=   0.0s\n",
            "[CV 5/5; 109/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 109/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.734 total time=   0.0s\n",
            "[CV 1/5; 110/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 110/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.582 total time=   0.0s\n",
            "[CV 2/5; 110/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 110/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.567 total time=   0.0s\n",
            "[CV 3/5; 110/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 110/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.515 total time=   0.0s\n",
            "[CV 4/5; 110/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 110/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.619 total time=   0.0s\n",
            "[CV 5/5; 110/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 110/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.678 total time=   0.0s\n",
            "[CV 1/5; 111/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 111/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.672 total time=   0.0s\n",
            "[CV 2/5; 111/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 111/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.698 total time=   0.0s\n",
            "[CV 3/5; 111/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 111/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.784 total time=   0.0s\n",
            "[CV 4/5; 111/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 111/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.757 total time=   0.0s\n",
            "[CV 5/5; 111/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 111/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.730 total time=   0.0s\n",
            "[CV 1/5; 112/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 112/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.545 total time=   0.0s\n",
            "[CV 2/5; 112/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 112/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.649 total time=   0.0s\n",
            "[CV 3/5; 112/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 112/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.563 total time=   0.0s\n",
            "[CV 4/5; 112/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 112/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 112/384] START criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 112/384] END criterion=gini, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.614 total time=   0.0s\n",
            "[CV 1/5; 113/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 113/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.687 total time=   0.0s\n",
            "[CV 2/5; 113/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 113/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.690 total time=   0.0s\n",
            "[CV 3/5; 113/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 113/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.810 total time=   0.0s\n",
            "[CV 4/5; 113/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 113/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.784 total time=   0.0s\n",
            "[CV 5/5; 113/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 113/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.723 total time=   0.0s\n",
            "[CV 1/5; 114/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 114/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.571 total time=   0.0s\n",
            "[CV 2/5; 114/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 114/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.567 total time=   0.0s\n",
            "[CV 3/5; 114/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 114/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.541 total time=   0.0s\n",
            "[CV 4/5; 114/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 114/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.571 total time=   0.0s\n",
            "[CV 5/5; 114/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 114/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.596 total time=   0.0s\n",
            "[CV 1/5; 115/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 115/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.690 total time=   0.0s\n",
            "[CV 2/5; 115/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 115/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.731 total time=   0.0s\n",
            "[CV 3/5; 115/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 115/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.810 total time=   0.0s\n",
            "[CV 4/5; 115/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 115/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.757 total time=   0.0s\n",
            "[CV 5/5; 115/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 115/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.742 total time=   0.0s\n",
            "[CV 1/5; 116/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 116/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.597 total time=   0.0s\n",
            "[CV 2/5; 116/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 116/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.519 total time=   0.0s\n",
            "[CV 3/5; 116/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 116/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.515 total time=   0.0s\n",
            "[CV 4/5; 116/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 116/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.590 total time=   0.0s\n",
            "[CV 5/5; 116/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 116/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.592 total time=   0.0s\n",
            "[CV 1/5; 117/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 117/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.690 total time=   0.0s\n",
            "[CV 2/5; 117/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 117/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.731 total time=   0.0s\n",
            "[CV 3/5; 117/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 117/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.780 total time=   0.0s\n",
            "[CV 4/5; 117/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 117/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.754 total time=   0.0s\n",
            "[CV 5/5; 117/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 117/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.730 total time=   0.0s\n",
            "[CV 1/5; 118/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 118/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.575 total time=   0.0s\n",
            "[CV 2/5; 118/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 118/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.582 total time=   0.0s\n",
            "[CV 3/5; 118/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 118/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.567 total time=   0.0s\n",
            "[CV 4/5; 118/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 118/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.515 total time=   0.0s\n",
            "[CV 5/5; 118/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 118/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.712 total time=   0.0s\n",
            "[CV 1/5; 119/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 119/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.683 total time=   0.0s\n",
            "[CV 2/5; 119/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 119/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.739 total time=   0.0s\n",
            "[CV 3/5; 119/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 119/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.780 total time=   0.0s\n",
            "[CV 4/5; 119/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 119/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.780 total time=   0.0s\n",
            "[CV 5/5; 119/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 119/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.745 total time=   0.0s\n",
            "[CV 1/5; 120/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 120/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.675 total time=   0.0s\n",
            "[CV 2/5; 120/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 120/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.545 total time=   0.0s\n",
            "[CV 3/5; 120/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 120/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.578 total time=   0.0s\n",
            "[CV 4/5; 120/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 120/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.660 total time=   0.0s\n",
            "[CV 5/5; 120/384] START criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 120/384] END criterion=gini, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.603 total time=   0.0s\n",
            "[CV 1/5; 121/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 121/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.701 total time=   0.0s\n",
            "[CV 2/5; 121/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 121/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.716 total time=   0.0s\n",
            "[CV 3/5; 121/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 121/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.784 total time=   0.0s\n",
            "[CV 4/5; 121/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 121/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.754 total time=   0.0s\n",
            "[CV 5/5; 121/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 121/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.760 total time=   0.0s\n",
            "[CV 1/5; 122/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 122/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.545 total time=   0.0s\n",
            "[CV 2/5; 122/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 122/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.604 total time=   0.0s\n",
            "[CV 3/5; 122/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 122/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 122/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 122/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.612 total time=   0.0s\n",
            "[CV 5/5; 122/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 122/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.708 total time=   0.0s\n",
            "[CV 1/5; 123/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 123/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.701 total time=   0.0s\n",
            "[CV 2/5; 123/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 123/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.713 total time=   0.0s\n",
            "[CV 3/5; 123/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 123/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.787 total time=   0.0s\n",
            "[CV 4/5; 123/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 123/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.757 total time=   0.0s\n",
            "[CV 5/5; 123/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 123/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.753 total time=   0.0s\n",
            "[CV 1/5; 124/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 124/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.571 total time=   0.0s\n",
            "[CV 2/5; 124/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 124/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.567 total time=   0.0s\n",
            "[CV 3/5; 124/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 124/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.507 total time=   0.0s\n",
            "[CV 4/5; 124/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 124/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.563 total time=   0.0s\n",
            "[CV 5/5; 124/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 124/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.577 total time=   0.0s\n",
            "[CV 1/5; 125/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 125/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.701 total time=   0.0s\n",
            "[CV 2/5; 125/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 125/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.705 total time=   0.0s\n",
            "[CV 3/5; 125/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 125/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.769 total time=   0.0s\n",
            "[CV 4/5; 125/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 125/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.754 total time=   0.0s\n",
            "[CV 5/5; 125/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 125/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.745 total time=   0.0s\n",
            "[CV 1/5; 126/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 126/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.627 total time=   0.0s\n",
            "[CV 2/5; 126/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 126/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.567 total time=   0.0s\n",
            "[CV 3/5; 126/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 126/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.578 total time=   0.0s\n",
            "[CV 4/5; 126/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 126/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.545 total time=   0.0s\n",
            "[CV 5/5; 126/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 126/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.618 total time=   0.0s\n",
            "[CV 1/5; 127/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 127/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.701 total time=   0.0s\n",
            "[CV 2/5; 127/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 127/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.709 total time=   0.0s\n",
            "[CV 3/5; 127/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 127/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.787 total time=   0.0s\n",
            "[CV 4/5; 127/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 127/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.754 total time=   0.0s\n",
            "[CV 5/5; 127/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 127/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.753 total time=   0.0s\n",
            "[CV 1/5; 128/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 128/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.560 total time=   0.0s\n",
            "[CV 2/5; 128/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 128/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.571 total time=   0.0s\n",
            "[CV 3/5; 128/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 128/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.489 total time=   0.0s\n",
            "[CV 4/5; 128/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 128/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.575 total time=   0.0s\n",
            "[CV 5/5; 128/384] START criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 128/384] END criterion=gini, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.625 total time=   0.0s\n",
            "[CV 1/5; 129/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 129/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.563 total time=   0.0s\n",
            "[CV 2/5; 129/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 129/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.526 total time=   0.0s\n",
            "[CV 3/5; 129/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 129/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.578 total time=   0.0s\n",
            "[CV 4/5; 129/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 129/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.563 total time=   0.0s\n",
            "[CV 5/5; 129/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 129/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.479 total time=   0.0s\n",
            "[CV 1/5; 130/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 130/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.545 total time=   0.0s\n",
            "[CV 2/5; 130/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 130/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.504 total time=   0.0s\n",
            "[CV 3/5; 130/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 130/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.496 total time=   0.0s\n",
            "[CV 4/5; 130/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 130/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.526 total time=   0.0s\n",
            "[CV 5/5; 130/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 130/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.502 total time=   0.0s\n",
            "[CV 1/5; 131/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 131/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.526 total time=   0.0s\n",
            "[CV 2/5; 131/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 131/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.530 total time=   0.0s\n",
            "[CV 3/5; 131/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 131/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 4/5; 131/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 131/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.575 total time=   0.0s\n",
            "[CV 5/5; 131/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 131/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.513 total time=   0.0s\n",
            "[CV 1/5; 132/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 132/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.545 total time=   0.0s\n",
            "[CV 2/5; 132/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 132/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 132/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 132/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.571 total time=   0.0s\n",
            "[CV 4/5; 132/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 132/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 132/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 132/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.554 total time=   0.0s\n",
            "[CV 1/5; 133/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 133/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.552 total time=   0.0s\n",
            "[CV 2/5; 133/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 133/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.549 total time=   0.0s\n",
            "[CV 3/5; 133/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 133/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.515 total time=   0.0s\n",
            "[CV 4/5; 133/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 133/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 5/5; 133/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 133/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.506 total time=   0.0s\n",
            "[CV 1/5; 134/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 134/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.526 total time=   0.0s\n",
            "[CV 2/5; 134/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 134/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.500 total time=   0.0s\n",
            "[CV 3/5; 134/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 134/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.541 total time=   0.0s\n",
            "[CV 4/5; 134/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 134/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.474 total time=   0.0s\n",
            "[CV 5/5; 134/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 134/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.513 total time=   0.0s\n",
            "[CV 1/5; 135/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 135/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 2/5; 135/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 135/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.560 total time=   0.0s\n",
            "[CV 3/5; 135/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 135/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.507 total time=   0.0s\n",
            "[CV 4/5; 135/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 135/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 5/5; 135/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 135/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.562 total time=   0.0s\n",
            "[CV 1/5; 136/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 136/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.578 total time=   0.0s\n",
            "[CV 2/5; 136/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 136/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.511 total time=   0.0s\n",
            "[CV 3/5; 136/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 136/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.541 total time=   0.0s\n",
            "[CV 4/5; 136/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 136/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.496 total time=   0.0s\n",
            "[CV 5/5; 136/384] START criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 136/384] END criterion=entropy, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.536 total time=   0.0s\n",
            "[CV 1/5; 137/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 137/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.496 total time=   0.0s\n",
            "[CV 2/5; 137/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 137/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.567 total time=   0.0s\n",
            "[CV 3/5; 137/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 137/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.537 total time=   0.0s\n",
            "[CV 4/5; 137/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 137/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 137/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 137/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.528 total time=   0.0s\n",
            "[CV 1/5; 138/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 138/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.552 total time=   0.0s\n",
            "[CV 2/5; 138/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 138/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.489 total time=   0.0s\n",
            "[CV 3/5; 138/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 138/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.507 total time=   0.0s\n",
            "[CV 4/5; 138/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 138/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.545 total time=   0.0s\n",
            "[CV 5/5; 138/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 138/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.539 total time=   0.0s\n",
            "[CV 1/5; 139/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 139/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.616 total time=   0.0s\n",
            "[CV 2/5; 139/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 139/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 3/5; 139/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 139/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 139/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 139/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.519 total time=   0.0s\n",
            "[CV 5/5; 139/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 139/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.536 total time=   0.0s\n",
            "[CV 1/5; 140/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 140/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.515 total time=   0.0s\n",
            "[CV 2/5; 140/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 140/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.489 total time=   0.0s\n",
            "[CV 3/5; 140/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 140/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.537 total time=   0.0s\n",
            "[CV 4/5; 140/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 140/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.515 total time=   0.0s\n",
            "[CV 5/5; 140/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 140/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.494 total time=   0.0s\n",
            "[CV 1/5; 141/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 141/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.515 total time=   0.0s\n",
            "[CV 2/5; 141/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 141/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.526 total time=   0.0s\n",
            "[CV 3/5; 141/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 141/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.519 total time=   0.0s\n",
            "[CV 4/5; 141/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 141/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.601 total time=   0.0s\n",
            "[CV 5/5; 141/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 141/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.506 total time=   0.0s\n",
            "[CV 1/5; 142/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 142/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.504 total time=   0.0s\n",
            "[CV 2/5; 142/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 142/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.448 total time=   0.0s\n",
            "[CV 3/5; 142/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 142/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.493 total time=   0.0s\n",
            "[CV 4/5; 142/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 142/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.545 total time=   0.0s\n",
            "[CV 5/5; 142/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 142/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.472 total time=   0.0s\n",
            "[CV 1/5; 143/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 143/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.534 total time=   0.0s\n",
            "[CV 2/5; 143/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 143/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.563 total time=   0.0s\n",
            "[CV 3/5; 143/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 143/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 4/5; 143/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 143/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.563 total time=   0.0s\n",
            "[CV 5/5; 143/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 143/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.502 total time=   0.0s\n",
            "[CV 1/5; 144/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 144/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.582 total time=   0.0s\n",
            "[CV 2/5; 144/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 144/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.530 total time=   0.0s\n",
            "[CV 3/5; 144/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 144/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.485 total time=   0.0s\n",
            "[CV 4/5; 144/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 144/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.504 total time=   0.0s\n",
            "[CV 5/5; 144/384] START criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 144/384] END criterion=entropy, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.502 total time=   0.0s\n",
            "[CV 1/5; 145/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 145/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.493 total time=   0.0s\n",
            "[CV 2/5; 145/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 145/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 3/5; 145/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 145/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.526 total time=   0.0s\n",
            "[CV 4/5; 145/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 145/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 5/5; 145/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 145/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.509 total time=   0.0s\n",
            "[CV 1/5; 146/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 146/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.537 total time=   0.0s\n",
            "[CV 2/5; 146/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 146/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 146/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 146/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.466 total time=   0.0s\n",
            "[CV 4/5; 146/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 146/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.511 total time=   0.0s\n",
            "[CV 5/5; 146/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 146/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 147/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 147/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.623 total time=   0.0s\n",
            "[CV 2/5; 147/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 147/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.563 total time=   0.0s\n",
            "[CV 3/5; 147/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 147/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.530 total time=   0.0s\n",
            "[CV 4/5; 147/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 147/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.586 total time=   0.0s\n",
            "[CV 5/5; 147/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 147/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.517 total time=   0.0s\n",
            "[CV 1/5; 148/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 148/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.448 total time=   0.0s\n",
            "[CV 2/5; 148/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 148/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.534 total time=   0.0s\n",
            "[CV 3/5; 148/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 148/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.500 total time=   0.0s\n",
            "[CV 4/5; 148/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 148/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.481 total time=   0.0s\n",
            "[CV 5/5; 148/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 148/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.532 total time=   0.0s\n",
            "[CV 1/5; 149/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 149/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.534 total time=   0.0s\n",
            "[CV 2/5; 149/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 149/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.519 total time=   0.0s\n",
            "[CV 3/5; 149/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 149/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.478 total time=   0.0s\n",
            "[CV 4/5; 149/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 149/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.612 total time=   0.0s\n",
            "[CV 5/5; 149/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 149/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.509 total time=   0.0s\n",
            "[CV 1/5; 150/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 150/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.534 total time=   0.0s\n",
            "[CV 2/5; 150/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 150/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.519 total time=   0.0s\n",
            "[CV 3/5; 150/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 150/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.552 total time=   0.0s\n",
            "[CV 4/5; 150/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 150/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.519 total time=   0.0s\n",
            "[CV 5/5; 150/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 150/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.509 total time=   0.0s\n",
            "[CV 1/5; 151/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 151/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.504 total time=   0.0s\n",
            "[CV 2/5; 151/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 151/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.526 total time=   0.0s\n",
            "[CV 3/5; 151/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 151/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.590 total time=   0.0s\n",
            "[CV 4/5; 151/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 151/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.590 total time=   0.0s\n",
            "[CV 5/5; 151/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 151/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.502 total time=   0.0s\n",
            "[CV 1/5; 152/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 152/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.511 total time=   0.0s\n",
            "[CV 2/5; 152/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 152/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.507 total time=   0.0s\n",
            "[CV 3/5; 152/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 152/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 152/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 152/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.496 total time=   0.0s\n",
            "[CV 5/5; 152/384] START criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 152/384] END criterion=entropy, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.528 total time=   0.0s\n",
            "[CV 1/5; 153/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 153/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.519 total time=   0.0s\n",
            "[CV 2/5; 153/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 153/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.500 total time=   0.0s\n",
            "[CV 3/5; 153/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 153/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.485 total time=   0.0s\n",
            "[CV 4/5; 153/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 153/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.563 total time=   0.0s\n",
            "[CV 5/5; 153/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 153/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.513 total time=   0.0s\n",
            "[CV 1/5; 154/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 154/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.511 total time=   0.0s\n",
            "[CV 2/5; 154/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 154/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.459 total time=   0.0s\n",
            "[CV 3/5; 154/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 154/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.470 total time=   0.0s\n",
            "[CV 4/5; 154/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 154/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.496 total time=   0.0s\n",
            "[CV 5/5; 154/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 154/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 155/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 155/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.619 total time=   0.0s\n",
            "[CV 2/5; 155/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=best\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 155/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.526 total time=   0.0s\n",
            "[CV 3/5; 155/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 155/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.500 total time=   0.0s\n",
            "[CV 4/5; 155/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 155/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.507 total time=   0.0s\n",
            "[CV 5/5; 155/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 155/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.573 total time=   0.0s\n",
            "[CV 1/5; 156/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 156/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.519 total time=   0.0s\n",
            "[CV 2/5; 156/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 156/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.470 total time=   0.0s\n",
            "[CV 3/5; 156/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 156/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.451 total time=   0.0s\n",
            "[CV 4/5; 156/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 156/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.489 total time=   0.0s\n",
            "[CV 5/5; 156/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 156/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.509 total time=   0.0s\n",
            "[CV 1/5; 157/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 157/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.563 total time=   0.0s\n",
            "[CV 2/5; 157/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 157/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.537 total time=   0.0s\n",
            "[CV 3/5; 157/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 157/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.578 total time=   0.0s\n",
            "[CV 4/5; 157/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 157/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.534 total time=   0.0s\n",
            "[CV 5/5; 157/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 157/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.513 total time=   0.0s\n",
            "[CV 1/5; 158/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 158/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.526 total time=   0.0s\n",
            "[CV 2/5; 158/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 158/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.515 total time=   0.0s\n",
            "[CV 3/5; 158/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 158/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.534 total time=   0.0s\n",
            "[CV 4/5; 158/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 158/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.504 total time=   0.0s\n",
            "[CV 5/5; 158/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 158/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.461 total time=   0.0s\n",
            "[CV 1/5; 159/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 159/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 2/5; 159/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 159/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 3/5; 159/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 159/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.534 total time=   0.0s\n",
            "[CV 4/5; 159/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 159/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.500 total time=   0.0s\n",
            "[CV 5/5; 159/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 159/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.577 total time=   0.0s\n",
            "[CV 1/5; 160/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 160/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.571 total time=   0.0s\n",
            "[CV 2/5; 160/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 160/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.485 total time=   0.0s\n",
            "[CV 3/5; 160/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=random\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 160/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.507 total time=   0.0s\n",
            "[CV 4/5; 160/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 160/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.526 total time=   0.0s\n",
            "[CV 5/5; 160/384] START criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 160/384] END criterion=entropy, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 161/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 161/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.578 total time=   0.0s\n",
            "[CV 2/5; 161/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 161/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.563 total time=   0.0s\n",
            "[CV 3/5; 161/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 161/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.612 total time=   0.0s\n",
            "[CV 4/5; 161/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 161/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 161/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 161/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.566 total time=   0.0s\n",
            "[CV 1/5; 162/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 162/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 162/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 162/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.463 total time=   0.0s\n",
            "[CV 3/5; 162/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 162/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.526 total time=   0.0s\n",
            "[CV 4/5; 162/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 162/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.511 total time=   0.0s\n",
            "[CV 5/5; 162/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 162/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.502 total time=   0.0s\n",
            "[CV 1/5; 163/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 163/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.563 total time=   0.0s\n",
            "[CV 2/5; 163/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 163/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.582 total time=   0.0s\n",
            "[CV 3/5; 163/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 163/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.515 total time=   0.0s\n",
            "[CV 4/5; 163/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 163/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.590 total time=   0.0s\n",
            "[CV 5/5; 163/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 163/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 164/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 164/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.537 total time=   0.0s\n",
            "[CV 2/5; 164/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 164/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.459 total time=   0.0s\n",
            "[CV 3/5; 164/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 164/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.470 total time=   0.0s\n",
            "[CV 4/5; 164/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 164/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.552 total time=   0.0s\n",
            "[CV 5/5; 164/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 164/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.461 total time=   0.0s\n",
            "[CV 1/5; 165/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 165/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 2/5; 165/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 165/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.571 total time=   0.0s\n",
            "[CV 3/5; 165/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 165/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 4/5; 165/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 165/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.578 total time=   0.0s\n",
            "[CV 5/5; 165/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 165/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.509 total time=   0.0s\n",
            "[CV 1/5; 166/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 166/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.530 total time=   0.0s\n",
            "[CV 2/5; 166/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 166/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.563 total time=   0.0s\n",
            "[CV 3/5; 166/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 166/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.478 total time=   0.0s\n",
            "[CV 4/5; 166/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 166/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.496 total time=   0.0s\n",
            "[CV 5/5; 166/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 166/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.502 total time=   0.0s\n",
            "[CV 1/5; 167/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 167/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.552 total time=   0.0s\n",
            "[CV 2/5; 167/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 167/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.586 total time=   0.0s\n",
            "[CV 3/5; 167/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 167/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 4/5; 167/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 167/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.526 total time=   0.0s\n",
            "[CV 5/5; 167/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 167/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.461 total time=   0.0s\n",
            "[CV 1/5; 168/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 168/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.560 total time=   0.0s\n",
            "[CV 2/5; 168/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 168/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 168/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 168/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.470 total time=   0.0s\n",
            "[CV 4/5; 168/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 168/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.530 total time=   0.0s\n",
            "[CV 5/5; 168/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 168/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.532 total time=   0.0s\n",
            "[CV 1/5; 169/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 169/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.552 total time=   0.0s\n",
            "[CV 2/5; 169/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 169/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.504 total time=   0.0s\n",
            "[CV 3/5; 169/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 169/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.560 total time=   0.0s\n",
            "[CV 4/5; 169/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 169/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.578 total time=   0.0s\n",
            "[CV 5/5; 169/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 169/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.536 total time=   0.0s\n",
            "[CV 1/5; 170/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 170/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.537 total time=   0.0s\n",
            "[CV 2/5; 170/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 170/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.478 total time=   0.0s\n",
            "[CV 3/5; 170/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 170/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.586 total time=   0.0s\n",
            "[CV 4/5; 170/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 170/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.552 total time=   0.0s\n",
            "[CV 5/5; 170/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 170/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.509 total time=   0.0s\n",
            "[CV 1/5; 171/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 171/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.575 total time=   0.0s\n",
            "[CV 2/5; 171/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 171/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 3/5; 171/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 171/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.590 total time=   0.0s\n",
            "[CV 4/5; 171/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 171/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.474 total time=   0.0s\n",
            "[CV 5/5; 171/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 171/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.547 total time=   0.0s\n",
            "[CV 1/5; 172/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 172/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.556 total time=   0.0s\n",
            "[CV 2/5; 172/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 172/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.556 total time=   0.0s\n",
            "[CV 3/5; 172/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 172/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.500 total time=   0.0s\n",
            "[CV 4/5; 172/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 172/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.515 total time=   0.0s\n",
            "[CV 5/5; 172/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 172/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.547 total time=   0.0s\n",
            "[CV 1/5; 173/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 173/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.519 total time=   0.0s\n",
            "[CV 2/5; 173/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 173/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.549 total time=   0.0s\n",
            "[CV 3/5; 173/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 173/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.504 total time=   0.0s\n",
            "[CV 4/5; 173/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 173/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 5/5; 173/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 173/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.532 total time=   0.0s\n",
            "[CV 1/5; 174/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 174/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.556 total time=   0.0s\n",
            "[CV 2/5; 174/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 174/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.519 total time=   0.0s\n",
            "[CV 3/5; 174/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 174/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.478 total time=   0.0s\n",
            "[CV 4/5; 174/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 174/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.463 total time=   0.0s\n",
            "[CV 5/5; 174/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 174/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.468 total time=   0.0s\n",
            "[CV 1/5; 175/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 175/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.552 total time=   0.0s\n",
            "[CV 2/5; 175/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 175/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.560 total time=   0.0s\n",
            "[CV 3/5; 175/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 175/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.582 total time=   0.0s\n",
            "[CV 4/5; 175/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 175/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 5/5; 175/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 175/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.562 total time=   0.0s\n",
            "[CV 1/5; 176/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 176/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 176/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 176/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.511 total time=   0.0s\n",
            "[CV 3/5; 176/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 176/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.504 total time=   0.0s\n",
            "[CV 4/5; 176/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 176/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.489 total time=   0.0s\n",
            "[CV 5/5; 176/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 176/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.536 total time=   0.0s\n",
            "[CV 1/5; 177/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 177/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.612 total time=   0.0s\n",
            "[CV 2/5; 177/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 177/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.537 total time=   0.0s\n",
            "[CV 3/5; 177/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 177/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.519 total time=   0.0s\n",
            "[CV 4/5; 177/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 177/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.571 total time=   0.0s\n",
            "[CV 5/5; 177/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 177/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.487 total time=   0.0s\n",
            "[CV 1/5; 178/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 178/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.507 total time=   0.0s\n",
            "[CV 2/5; 178/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 178/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.511 total time=   0.0s\n",
            "[CV 3/5; 178/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 178/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.541 total time=   0.0s\n",
            "[CV 4/5; 178/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 178/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.545 total time=   0.0s\n",
            "[CV 5/5; 178/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 178/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.536 total time=   0.0s\n",
            "[CV 1/5; 179/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 179/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.608 total time=   0.0s\n",
            "[CV 2/5; 179/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 179/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.601 total time=   0.0s\n",
            "[CV 3/5; 179/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 179/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.545 total time=   0.0s\n",
            "[CV 4/5; 179/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 179/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 5/5; 179/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 179/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.517 total time=   0.0s\n",
            "[CV 1/5; 180/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 180/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.545 total time=   0.0s\n",
            "[CV 2/5; 180/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 180/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.545 total time=   0.0s\n",
            "[CV 3/5; 180/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 180/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.582 total time=   0.0s\n",
            "[CV 4/5; 180/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 180/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.511 total time=   0.0s\n",
            "[CV 5/5; 180/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 180/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.491 total time=   0.0s\n",
            "[CV 1/5; 181/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 181/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.493 total time=   0.0s\n",
            "[CV 2/5; 181/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 181/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.578 total time=   0.0s\n",
            "[CV 3/5; 181/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 181/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.560 total time=   0.0s\n",
            "[CV 4/5; 181/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 181/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.608 total time=   0.0s\n",
            "[CV 5/5; 181/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 181/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.581 total time=   0.0s\n",
            "[CV 1/5; 182/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 182/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.504 total time=   0.0s\n",
            "[CV 2/5; 182/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 182/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.485 total time=   0.0s\n",
            "[CV 3/5; 182/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 182/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.459 total time=   0.0s\n",
            "[CV 4/5; 182/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 182/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.545 total time=   0.0s\n",
            "[CV 5/5; 182/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 182/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.509 total time=   0.0s\n",
            "[CV 1/5; 183/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 183/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.563 total time=   0.0s\n",
            "[CV 2/5; 183/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 183/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.500 total time=   0.0s\n",
            "[CV 3/5; 183/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 183/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.519 total time=   0.0s\n",
            "[CV 4/5; 183/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 183/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.507 total time=   0.0s\n",
            "[CV 5/5; 183/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 183/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 184/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 184/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.507 total time=   0.0s\n",
            "[CV 2/5; 184/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 184/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.515 total time=   0.0s\n",
            "[CV 3/5; 184/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 184/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.463 total time=   0.0s\n",
            "[CV 4/5; 184/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 184/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.489 total time=   0.0s\n",
            "[CV 5/5; 184/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 184/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.536 total time=   0.0s\n",
            "[CV 1/5; 185/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 185/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.560 total time=   0.0s\n",
            "[CV 2/5; 185/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 185/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.545 total time=   0.0s\n",
            "[CV 3/5; 185/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 185/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.567 total time=   0.0s\n",
            "[CV 4/5; 185/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 185/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.563 total time=   0.0s\n",
            "[CV 5/5; 185/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 185/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.491 total time=   0.0s\n",
            "[CV 1/5; 186/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 186/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.485 total time=   0.0s\n",
            "[CV 2/5; 186/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 186/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.504 total time=   0.0s\n",
            "[CV 3/5; 186/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 186/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.470 total time=   0.0s\n",
            "[CV 4/5; 186/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 186/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.507 total time=   0.0s\n",
            "[CV 5/5; 186/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 186/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.494 total time=   0.0s\n",
            "[CV 1/5; 187/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 187/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.534 total time=   0.0s\n",
            "[CV 2/5; 187/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 187/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.537 total time=   0.0s\n",
            "[CV 3/5; 187/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 187/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.567 total time=   0.0s\n",
            "[CV 4/5; 187/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 187/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.485 total time=   0.0s\n",
            "[CV 5/5; 187/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 187/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.543 total time=   0.0s\n",
            "[CV 1/5; 188/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 188/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.541 total time=   0.0s\n",
            "[CV 2/5; 188/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 188/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.448 total time=   0.0s\n",
            "[CV 3/5; 188/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 188/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.530 total time=   0.0s\n",
            "[CV 4/5; 188/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 188/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.537 total time=   0.0s\n",
            "[CV 5/5; 188/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 188/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.419 total time=   0.0s\n",
            "[CV 1/5; 189/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 189/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.586 total time=   0.0s\n",
            "[CV 2/5; 189/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 189/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.526 total time=   0.0s\n",
            "[CV 3/5; 189/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 189/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.578 total time=   0.0s\n",
            "[CV 4/5; 189/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 189/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.537 total time=   0.0s\n",
            "[CV 5/5; 189/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 189/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.562 total time=   0.0s\n",
            "[CV 1/5; 190/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 190/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.515 total time=   0.0s\n",
            "[CV 2/5; 190/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 190/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.466 total time=   0.0s\n",
            "[CV 3/5; 190/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 190/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.485 total time=   0.0s\n",
            "[CV 4/5; 190/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 190/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.530 total time=   0.0s\n",
            "[CV 5/5; 190/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 190/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.573 total time=   0.0s\n",
            "[CV 1/5; 191/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 191/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.534 total time=   0.0s\n",
            "[CV 2/5; 191/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 191/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.612 total time=   0.0s\n",
            "[CV 3/5; 191/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 191/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 4/5; 191/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 191/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.526 total time=   0.0s\n",
            "[CV 5/5; 191/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 191/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.547 total time=   0.0s\n",
            "[CV 1/5; 192/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 192/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.478 total time=   0.0s\n",
            "[CV 2/5; 192/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 192/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.515 total time=   0.0s\n",
            "[CV 3/5; 192/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 192/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.478 total time=   0.0s\n",
            "[CV 4/5; 192/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 192/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.549 total time=   0.0s\n",
            "[CV 5/5; 192/384] START criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 192/384] END criterion=entropy, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.536 total time=   0.0s\n",
            "[CV 1/5; 193/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 193/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.571 total time=   0.0s\n",
            "[CV 2/5; 193/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 193/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.601 total time=   0.0s\n",
            "[CV 3/5; 193/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 193/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.515 total time=   0.0s\n",
            "[CV 4/5; 193/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 193/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.478 total time=   0.0s\n",
            "[CV 5/5; 193/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 193/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.494 total time=   0.0s\n",
            "[CV 1/5; 194/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 194/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.500 total time=   0.0s\n",
            "[CV 2/5; 194/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 194/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.493 total time=   0.0s\n",
            "[CV 3/5; 194/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 194/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 194/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 194/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.519 total time=   0.0s\n",
            "[CV 5/5; 194/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 194/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.513 total time=   0.0s\n",
            "[CV 1/5; 195/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 195/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.534 total time=   0.0s\n",
            "[CV 2/5; 195/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 195/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 3/5; 195/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 195/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.549 total time=   0.0s\n",
            "[CV 4/5; 195/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 195/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.537 total time=   0.0s\n",
            "[CV 5/5; 195/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 195/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.498 total time=   0.0s\n",
            "[CV 1/5; 196/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 196/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.526 total time=   0.0s\n",
            "[CV 2/5; 196/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 196/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.466 total time=   0.0s\n",
            "[CV 3/5; 196/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 196/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.511 total time=   0.0s\n",
            "[CV 4/5; 196/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 196/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.537 total time=   0.0s\n",
            "[CV 5/5; 196/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 196/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.498 total time=   0.0s\n",
            "[CV 1/5; 197/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 197/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 2/5; 197/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 197/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 3/5; 197/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 197/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.515 total time=   0.0s\n",
            "[CV 4/5; 197/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 197/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.571 total time=   0.0s\n",
            "[CV 5/5; 197/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 197/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.509 total time=   0.0s\n",
            "[CV 1/5; 198/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 198/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.496 total time=   0.0s\n",
            "[CV 2/5; 198/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 198/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 198/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 198/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.526 total time=   0.0s\n",
            "[CV 4/5; 198/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 198/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.537 total time=   0.0s\n",
            "[CV 5/5; 198/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 198/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.562 total time=   0.0s\n",
            "[CV 1/5; 199/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 199/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.549 total time=   0.0s\n",
            "[CV 2/5; 199/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 199/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 3/5; 199/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 199/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.534 total time=   0.0s\n",
            "[CV 4/5; 199/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 199/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.545 total time=   0.0s\n",
            "[CV 5/5; 199/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 199/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.483 total time=   0.0s\n",
            "[CV 1/5; 200/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 200/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.560 total time=   0.0s\n",
            "[CV 2/5; 200/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 200/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.519 total time=   0.0s\n",
            "[CV 3/5; 200/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 200/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.496 total time=   0.0s\n",
            "[CV 4/5; 200/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 200/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.459 total time=   0.0s\n",
            "[CV 5/5; 200/384] START criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 200/384] END criterion=entropy, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.487 total time=   0.0s\n",
            "[CV 1/5; 201/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 201/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.530 total time=   0.0s\n",
            "[CV 2/5; 201/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 201/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.507 total time=   0.0s\n",
            "[CV 3/5; 201/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 201/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 201/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 201/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.496 total time=   0.0s\n",
            "[CV 5/5; 201/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 201/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.509 total time=   0.0s\n",
            "[CV 1/5; 202/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 202/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.567 total time=   0.0s\n",
            "[CV 2/5; 202/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 202/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.489 total time=   0.0s\n",
            "[CV 3/5; 202/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 202/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.519 total time=   0.0s\n",
            "[CV 4/5; 202/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 202/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.511 total time=   0.0s\n",
            "[CV 5/5; 202/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 202/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.509 total time=   0.0s\n",
            "[CV 1/5; 203/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 203/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.567 total time=   0.0s\n",
            "[CV 2/5; 203/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 203/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.515 total time=   0.0s\n",
            "[CV 3/5; 203/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 203/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.511 total time=   0.0s\n",
            "[CV 4/5; 203/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 203/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.601 total time=   0.0s\n",
            "[CV 5/5; 203/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 203/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.509 total time=   0.0s\n",
            "[CV 1/5; 204/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 204/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.511 total time=   0.0s\n",
            "[CV 2/5; 204/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 204/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.489 total time=   0.0s\n",
            "[CV 3/5; 204/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 204/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.500 total time=   0.0s\n",
            "[CV 4/5; 204/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 204/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.552 total time=   0.0s\n",
            "[CV 5/5; 204/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 204/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.468 total time=   0.0s\n",
            "[CV 1/5; 205/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 205/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 2/5; 205/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 205/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.552 total time=   0.0s\n",
            "[CV 3/5; 205/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 205/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.537 total time=   0.0s\n",
            "[CV 4/5; 205/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 205/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.571 total time=   0.0s\n",
            "[CV 5/5; 205/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 205/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.603 total time=   0.0s\n",
            "[CV 1/5; 206/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 206/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.560 total time=   0.0s\n",
            "[CV 2/5; 206/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 206/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.507 total time=   0.0s\n",
            "[CV 3/5; 206/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 206/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.563 total time=   0.0s\n",
            "[CV 4/5; 206/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 206/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.511 total time=   0.0s\n",
            "[CV 5/5; 206/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 206/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.498 total time=   0.0s\n",
            "[CV 1/5; 207/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 207/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.534 total time=   0.0s\n",
            "[CV 2/5; 207/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 207/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 3/5; 207/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 207/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.552 total time=   0.0s\n",
            "[CV 4/5; 207/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 207/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 207/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 207/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 208/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 208/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.530 total time=   0.0s\n",
            "[CV 2/5; 208/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 208/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.519 total time=   0.0s\n",
            "[CV 3/5; 208/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 208/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.507 total time=   0.0s\n",
            "[CV 4/5; 208/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 208/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.537 total time=   0.0s\n",
            "[CV 5/5; 208/384] START criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 208/384] END criterion=entropy, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.509 total time=   0.0s\n",
            "[CV 1/5; 209/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 209/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 2/5; 209/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 209/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.537 total time=   0.0s\n",
            "[CV 3/5; 209/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 209/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.511 total time=   0.0s\n",
            "[CV 4/5; 209/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 209/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 209/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 209/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.539 total time=   0.0s\n",
            "[CV 1/5; 210/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 210/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.526 total time=   0.0s\n",
            "[CV 2/5; 210/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 210/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.451 total time=   0.0s\n",
            "[CV 3/5; 210/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 210/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.515 total time=   0.0s\n",
            "[CV 4/5; 210/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 210/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.545 total time=   0.0s\n",
            "[CV 5/5; 210/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 210/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.536 total time=   0.0s\n",
            "[CV 1/5; 211/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 211/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.549 total time=   0.0s\n",
            "[CV 2/5; 211/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 211/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.549 total time=   0.0s\n",
            "[CV 3/5; 211/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 211/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.563 total time=   0.0s\n",
            "[CV 4/5; 211/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 211/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.578 total time=   0.0s\n",
            "[CV 5/5; 211/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 211/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.528 total time=   0.0s\n",
            "[CV 1/5; 212/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 212/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.541 total time=   0.0s\n",
            "[CV 2/5; 212/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 212/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.470 total time=   0.0s\n",
            "[CV 3/5; 212/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 212/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.444 total time=   0.0s\n",
            "[CV 4/5; 212/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 212/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.500 total time=   0.0s\n",
            "[CV 5/5; 212/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 212/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.506 total time=   0.0s\n",
            "[CV 1/5; 213/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 213/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.560 total time=   0.0s\n",
            "[CV 2/5; 213/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 213/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.545 total time=   0.0s\n",
            "[CV 3/5; 213/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 213/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 4/5; 213/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 213/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.563 total time=   0.0s\n",
            "[CV 5/5; 213/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 213/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.532 total time=   0.0s\n",
            "[CV 1/5; 214/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 214/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.493 total time=   0.0s\n",
            "[CV 2/5; 214/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 214/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.459 total time=   0.0s\n",
            "[CV 3/5; 214/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 214/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.530 total time=   0.0s\n",
            "[CV 4/5; 214/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 214/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.582 total time=   0.0s\n",
            "[CV 5/5; 214/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 214/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.509 total time=   0.0s\n",
            "[CV 1/5; 215/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 215/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.515 total time=   0.0s\n",
            "[CV 2/5; 215/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 215/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.496 total time=   0.0s\n",
            "[CV 3/5; 215/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 215/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.470 total time=   0.0s\n",
            "[CV 4/5; 215/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 215/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.575 total time=   0.0s\n",
            "[CV 5/5; 215/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 215/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.517 total time=   0.0s\n",
            "[CV 1/5; 216/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 216/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.556 total time=   0.0s\n",
            "[CV 2/5; 216/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 216/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.496 total time=   0.0s\n",
            "[CV 3/5; 216/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 216/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.433 total time=   0.0s\n",
            "[CV 4/5; 216/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 216/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.481 total time=   0.0s\n",
            "[CV 5/5; 216/384] START criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 216/384] END criterion=entropy, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 217/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 217/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.507 total time=   0.0s\n",
            "[CV 2/5; 217/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 217/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.549 total time=   0.0s\n",
            "[CV 3/5; 217/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 217/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 4/5; 217/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 217/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.571 total time=   0.0s\n",
            "[CV 5/5; 217/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 217/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.502 total time=   0.0s\n",
            "[CV 1/5; 218/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 218/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.552 total time=   0.0s\n",
            "[CV 2/5; 218/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 218/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.485 total time=   0.0s\n",
            "[CV 3/5; 218/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 218/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.470 total time=   0.0s\n",
            "[CV 4/5; 218/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 218/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.582 total time=   0.0s\n",
            "[CV 5/5; 218/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 218/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 219/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 219/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.463 total time=   0.0s\n",
            "[CV 2/5; 219/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 219/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.549 total time=   0.0s\n",
            "[CV 3/5; 219/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 219/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.530 total time=   0.0s\n",
            "[CV 4/5; 219/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 219/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.552 total time=   0.0s\n",
            "[CV 5/5; 219/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 219/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.539 total time=   0.0s\n",
            "[CV 1/5; 220/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 220/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.578 total time=   0.0s\n",
            "[CV 2/5; 220/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 220/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.530 total time=   0.0s\n",
            "[CV 3/5; 220/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 220/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.504 total time=   0.0s\n",
            "[CV 4/5; 220/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 220/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.530 total time=   0.0s\n",
            "[CV 5/5; 220/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 220/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.528 total time=   0.0s\n",
            "[CV 1/5; 221/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 221/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.526 total time=   0.0s\n",
            "[CV 2/5; 221/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 221/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.560 total time=   0.0s\n",
            "[CV 3/5; 221/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 221/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.545 total time=   0.0s\n",
            "[CV 4/5; 221/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 221/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.567 total time=   0.0s\n",
            "[CV 5/5; 221/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 221/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.509 total time=   0.0s\n",
            "[CV 1/5; 222/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 222/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.511 total time=   0.0s\n",
            "[CV 2/5; 222/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 222/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.481 total time=   0.0s\n",
            "[CV 3/5; 222/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 222/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.575 total time=   0.0s\n",
            "[CV 4/5; 222/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 222/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 222/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 222/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.543 total time=   0.0s\n",
            "[CV 1/5; 223/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 223/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.575 total time=   0.0s\n",
            "[CV 2/5; 223/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 223/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.534 total time=   0.0s\n",
            "[CV 3/5; 223/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 223/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.489 total time=   0.0s\n",
            "[CV 4/5; 223/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 223/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.575 total time=   0.0s\n",
            "[CV 5/5; 223/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 223/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.528 total time=   0.0s\n",
            "[CV 1/5; 224/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 224/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.578 total time=   0.0s\n",
            "[CV 2/5; 224/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 224/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.526 total time=   0.0s\n",
            "[CV 3/5; 224/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 224/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.500 total time=   0.0s\n",
            "[CV 4/5; 224/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 224/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.474 total time=   0.0s\n",
            "[CV 5/5; 224/384] START criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 224/384] END criterion=entropy, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.506 total time=   0.0s\n",
            "[CV 1/5; 225/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 225/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.649 total time=   0.0s\n",
            "[CV 2/5; 225/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 225/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.701 total time=   0.0s\n",
            "[CV 3/5; 225/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 225/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.705 total time=   0.0s\n",
            "[CV 4/5; 225/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 225/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.746 total time=   0.0s\n",
            "[CV 5/5; 225/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 225/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.779 total time=   0.0s\n",
            "[CV 1/5; 226/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 226/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.660 total time=   0.0s\n",
            "[CV 2/5; 226/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 226/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.549 total time=   0.0s\n",
            "[CV 3/5; 226/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 226/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.612 total time=   0.0s\n",
            "[CV 4/5; 226/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 226/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.575 total time=   0.0s\n",
            "[CV 5/5; 226/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 226/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.625 total time=   0.0s\n",
            "[CV 1/5; 227/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 227/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.657 total time=   0.0s\n",
            "[CV 2/5; 227/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 227/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.690 total time=   0.0s\n",
            "[CV 3/5; 227/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 227/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.716 total time=   0.0s\n",
            "[CV 4/5; 227/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 227/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.769 total time=   0.0s\n",
            "[CV 5/5; 227/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 227/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.787 total time=   0.0s\n",
            "[CV 1/5; 228/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 228/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.590 total time=   0.0s\n",
            "[CV 2/5; 228/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 228/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.642 total time=   0.0s\n",
            "[CV 3/5; 228/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 228/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.638 total time=   0.0s\n",
            "[CV 4/5; 228/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 228/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.649 total time=   0.0s\n",
            "[CV 5/5; 228/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 228/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.581 total time=   0.0s\n",
            "[CV 1/5; 229/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 229/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.683 total time=   0.0s\n",
            "[CV 2/5; 229/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 229/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.694 total time=   0.0s\n",
            "[CV 3/5; 229/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 229/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.698 total time=   0.0s\n",
            "[CV 4/5; 229/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 229/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.750 total time=   0.0s\n",
            "[CV 5/5; 229/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 229/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.783 total time=   0.0s\n",
            "[CV 1/5; 230/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 230/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.638 total time=   0.0s\n",
            "[CV 2/5; 230/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 230/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.604 total time=   0.0s\n",
            "[CV 3/5; 230/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 230/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.582 total time=   0.0s\n",
            "[CV 4/5; 230/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 230/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.571 total time=   0.0s\n",
            "[CV 5/5; 230/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 230/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.573 total time=   0.0s\n",
            "[CV 1/5; 231/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 231/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.698 total time=   0.1s\n",
            "[CV 2/5; 231/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 231/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.690 total time=   0.0s\n",
            "[CV 3/5; 231/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 231/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.694 total time=   0.0s\n",
            "[CV 4/5; 231/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 231/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.757 total time=   0.0s\n",
            "[CV 5/5; 231/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 231/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.790 total time=   0.0s\n",
            "[CV 1/5; 232/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 232/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.604 total time=   0.0s\n",
            "[CV 2/5; 232/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 232/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.649 total time=   0.0s\n",
            "[CV 3/5; 232/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 232/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.631 total time=   0.0s\n",
            "[CV 4/5; 232/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 232/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.586 total time=   0.0s\n",
            "[CV 5/5; 232/384] START criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 232/384] END criterion=entropy, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.584 total time=   0.0s\n",
            "[CV 1/5; 233/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 233/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.672 total time=   0.0s\n",
            "[CV 2/5; 233/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 233/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.698 total time=   0.0s\n",
            "[CV 3/5; 233/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 233/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.713 total time=   0.0s\n",
            "[CV 4/5; 233/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 233/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.784 total time=   0.0s\n",
            "[CV 5/5; 233/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 233/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.787 total time=   0.0s\n",
            "[CV 1/5; 234/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 234/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.660 total time=   0.0s\n",
            "[CV 2/5; 234/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 234/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.541 total time=   0.0s\n",
            "[CV 3/5; 234/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 234/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.552 total time=   0.0s\n",
            "[CV 4/5; 234/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 234/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.616 total time=   0.0s\n",
            "[CV 5/5; 234/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 234/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.596 total time=   0.0s\n",
            "[CV 1/5; 235/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 235/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.649 total time=   0.0s\n",
            "[CV 2/5; 235/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 235/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.694 total time=   0.0s\n",
            "[CV 3/5; 235/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 235/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.713 total time=   0.0s\n",
            "[CV 4/5; 235/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 235/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.769 total time=   0.0s\n",
            "[CV 5/5; 235/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 235/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.787 total time=   0.0s\n",
            "[CV 1/5; 236/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 236/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.575 total time=   0.0s\n",
            "[CV 2/5; 236/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 236/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.619 total time=   0.0s\n",
            "[CV 3/5; 236/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 236/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.552 total time=   0.0s\n",
            "[CV 4/5; 236/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 236/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 236/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 236/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.667 total time=   0.0s\n",
            "[CV 1/5; 237/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 237/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.672 total time=   0.0s\n",
            "[CV 2/5; 237/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 237/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.690 total time=   0.0s\n",
            "[CV 3/5; 237/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 237/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.705 total time=   0.0s\n",
            "[CV 4/5; 237/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 237/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.787 total time=   0.0s\n",
            "[CV 5/5; 237/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 237/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.787 total time=   0.0s\n",
            "[CV 1/5; 238/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 238/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.586 total time=   0.0s\n",
            "[CV 2/5; 238/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 238/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.616 total time=   0.0s\n",
            "[CV 3/5; 238/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 238/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.578 total time=   0.0s\n",
            "[CV 4/5; 238/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 238/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.631 total time=   0.0s\n",
            "[CV 5/5; 238/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 238/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.551 total time=   0.0s\n",
            "[CV 1/5; 239/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 239/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.679 total time=   0.0s\n",
            "[CV 2/5; 239/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 239/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.701 total time=   0.0s\n",
            "[CV 3/5; 239/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 239/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.716 total time=   0.0s\n",
            "[CV 4/5; 239/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 239/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.765 total time=   0.0s\n",
            "[CV 5/5; 239/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 239/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.775 total time=   0.0s\n",
            "[CV 1/5; 240/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 240/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.590 total time=   0.0s\n",
            "[CV 2/5; 240/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 240/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.552 total time=   0.0s\n",
            "[CV 3/5; 240/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 240/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.627 total time=   0.0s\n",
            "[CV 4/5; 240/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 240/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.552 total time=   0.0s\n",
            "[CV 5/5; 240/384] START criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 240/384] END criterion=entropy, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.614 total time=   0.0s\n",
            "[CV 1/5; 241/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 241/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.705 total time=   0.0s\n",
            "[CV 2/5; 241/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 241/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.694 total time=   0.0s\n",
            "[CV 3/5; 241/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 241/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.705 total time=   0.0s\n",
            "[CV 4/5; 241/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 241/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.784 total time=   0.0s\n",
            "[CV 5/5; 241/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 241/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.779 total time=   0.0s\n",
            "[CV 1/5; 242/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 242/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.545 total time=   0.0s\n",
            "[CV 2/5; 242/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 242/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.668 total time=   0.0s\n",
            "[CV 3/5; 242/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 242/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.556 total time=   0.0s\n",
            "[CV 4/5; 242/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 242/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.649 total time=   0.0s\n",
            "[CV 5/5; 242/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 242/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.588 total time=   0.0s\n",
            "[CV 1/5; 243/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 243/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.660 total time=   0.0s\n",
            "[CV 2/5; 243/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 243/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.724 total time=   0.0s\n",
            "[CV 3/5; 243/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 243/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.705 total time=   0.0s\n",
            "[CV 4/5; 243/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 243/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.780 total time=   0.0s\n",
            "[CV 5/5; 243/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 243/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.787 total time=   0.0s\n",
            "[CV 1/5; 244/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 244/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.552 total time=   0.0s\n",
            "[CV 2/5; 244/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 244/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.560 total time=   0.0s\n",
            "[CV 3/5; 244/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 244/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.638 total time=   0.0s\n",
            "[CV 4/5; 244/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 244/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.560 total time=   0.0s\n",
            "[CV 5/5; 244/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 244/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.603 total time=   0.0s\n",
            "[CV 1/5; 245/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 245/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.698 total time=   0.0s\n",
            "[CV 2/5; 245/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 245/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.701 total time=   0.0s\n",
            "[CV 3/5; 245/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 245/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.701 total time=   0.0s\n",
            "[CV 4/5; 245/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 245/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.780 total time=   0.0s\n",
            "[CV 5/5; 245/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 245/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.783 total time=   0.0s\n",
            "[CV 1/5; 246/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 246/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.578 total time=   0.0s\n",
            "[CV 2/5; 246/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 246/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.601 total time=   0.0s\n",
            "[CV 3/5; 246/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 246/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.575 total time=   0.0s\n",
            "[CV 4/5; 246/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 246/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.541 total time=   0.0s\n",
            "[CV 5/5; 246/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 246/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.573 total time=   0.0s\n",
            "[CV 1/5; 247/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 247/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.743 total time=   0.0s\n",
            "[CV 2/5; 247/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 247/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.720 total time=   0.0s\n",
            "[CV 3/5; 247/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 247/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.698 total time=   0.0s\n",
            "[CV 4/5; 247/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 247/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.780 total time=   0.0s\n",
            "[CV 5/5; 247/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 247/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.783 total time=   0.0s\n",
            "[CV 1/5; 248/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 248/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.549 total time=   0.0s\n",
            "[CV 2/5; 248/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 248/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.515 total time=   0.0s\n",
            "[CV 3/5; 248/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 248/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.582 total time=   0.0s\n",
            "[CV 4/5; 248/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 248/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.616 total time=   0.0s\n",
            "[CV 5/5; 248/384] START criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 248/384] END criterion=entropy, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.607 total time=   0.0s\n",
            "[CV 1/5; 249/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 249/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.716 total time=   0.0s\n",
            "[CV 2/5; 249/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 249/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.675 total time=   0.0s\n",
            "[CV 3/5; 249/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 249/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.698 total time=   0.0s\n",
            "[CV 4/5; 249/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 249/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.780 total time=   0.0s\n",
            "[CV 5/5; 249/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 249/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.783 total time=   0.0s\n",
            "[CV 1/5; 250/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 250/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.582 total time=   0.0s\n",
            "[CV 2/5; 250/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 250/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.571 total time=   0.0s\n",
            "[CV 3/5; 250/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 250/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.526 total time=   0.0s\n",
            "[CV 4/5; 250/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 250/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.545 total time=   0.0s\n",
            "[CV 5/5; 250/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 250/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.704 total time=   0.0s\n",
            "[CV 1/5; 251/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 251/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.757 total time=   0.0s\n",
            "[CV 2/5; 251/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 251/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.709 total time=   0.0s\n",
            "[CV 3/5; 251/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 251/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.713 total time=   0.0s\n",
            "[CV 4/5; 251/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 251/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.765 total time=   0.0s\n",
            "[CV 5/5; 251/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 251/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.783 total time=   0.0s\n",
            "[CV 1/5; 252/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 252/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.675 total time=   0.0s\n",
            "[CV 2/5; 252/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 252/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.571 total time=   0.0s\n",
            "[CV 3/5; 252/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 252/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.612 total time=   0.0s\n",
            "[CV 4/5; 252/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 252/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.575 total time=   0.0s\n",
            "[CV 5/5; 252/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 252/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.603 total time=   0.0s\n",
            "[CV 1/5; 253/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 253/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.709 total time=   0.0s\n",
            "[CV 2/5; 253/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 253/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.675 total time=   0.0s\n",
            "[CV 3/5; 253/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 253/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.705 total time=   0.0s\n",
            "[CV 4/5; 253/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 253/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.772 total time=   0.0s\n",
            "[CV 5/5; 253/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 253/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.787 total time=   0.0s\n",
            "[CV 1/5; 254/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 254/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.597 total time=   0.0s\n",
            "[CV 2/5; 254/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 254/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.616 total time=   0.0s\n",
            "[CV 3/5; 254/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 254/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.638 total time=   0.0s\n",
            "[CV 4/5; 254/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 254/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.593 total time=   0.0s\n",
            "[CV 5/5; 254/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 254/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.588 total time=   0.0s\n",
            "[CV 1/5; 255/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 255/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.690 total time=   0.0s\n",
            "[CV 2/5; 255/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 255/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.709 total time=   0.0s\n",
            "[CV 3/5; 255/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 255/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.705 total time=   0.0s\n",
            "[CV 4/5; 255/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 255/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.772 total time=   0.0s\n",
            "[CV 5/5; 255/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 255/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.775 total time=   0.0s\n",
            "[CV 1/5; 256/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 256/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.575 total time=   0.0s\n",
            "[CV 2/5; 256/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 256/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.519 total time=   0.0s\n",
            "[CV 3/5; 256/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 256/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.586 total time=   0.0s\n",
            "[CV 4/5; 256/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 256/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.623 total time=   0.0s\n",
            "[CV 5/5; 256/384] START criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 256/384] END criterion=entropy, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 257/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 257/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.567 total time=   0.0s\n",
            "[CV 2/5; 257/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 257/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.522 total time=   0.0s\n",
            "[CV 3/5; 257/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 257/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.478 total time=   0.0s\n",
            "[CV 4/5; 257/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 257/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.612 total time=   0.0s\n",
            "[CV 5/5; 257/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 257/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.536 total time=   0.0s\n",
            "[CV 1/5; 258/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 258/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.541 total time=   0.0s\n",
            "[CV 2/5; 258/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 258/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.526 total time=   0.0s\n",
            "[CV 3/5; 258/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 258/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.515 total time=   0.0s\n",
            "[CV 4/5; 258/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 258/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.489 total time=   0.0s\n",
            "[CV 5/5; 258/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 258/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.513 total time=   0.0s\n",
            "[CV 1/5; 259/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 259/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.575 total time=   0.0s\n",
            "[CV 2/5; 259/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 259/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.515 total time=   0.0s\n",
            "[CV 3/5; 259/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 259/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.493 total time=   0.0s\n",
            "[CV 4/5; 259/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 259/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.571 total time=   0.0s\n",
            "[CV 5/5; 259/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 259/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.588 total time=   0.0s\n",
            "[CV 1/5; 260/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 260/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.534 total time=   0.0s\n",
            "[CV 2/5; 260/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 260/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.575 total time=   0.0s\n",
            "[CV 3/5; 260/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 260/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.444 total time=   0.0s\n",
            "[CV 4/5; 260/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 260/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.478 total time=   0.0s\n",
            "[CV 5/5; 260/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 260/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.513 total time=   0.0s\n",
            "[CV 1/5; 261/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 261/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.545 total time=   0.0s\n",
            "[CV 2/5; 261/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 261/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 3/5; 261/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 261/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.549 total time=   0.0s\n",
            "[CV 4/5; 261/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 261/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.530 total time=   0.0s\n",
            "[CV 5/5; 261/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 261/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.547 total time=   0.0s\n",
            "[CV 1/5; 262/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 262/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.549 total time=   0.0s\n",
            "[CV 2/5; 262/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 262/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.541 total time=   0.0s\n",
            "[CV 3/5; 262/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 262/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.507 total time=   0.0s\n",
            "[CV 4/5; 262/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 262/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.537 total time=   0.0s\n",
            "[CV 5/5; 262/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 262/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.487 total time=   0.0s\n",
            "[CV 1/5; 263/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 263/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.612 total time=   0.0s\n",
            "[CV 2/5; 263/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 263/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.507 total time=   0.0s\n",
            "[CV 3/5; 263/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 263/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.530 total time=   0.0s\n",
            "[CV 4/5; 263/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 263/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.496 total time=   0.0s\n",
            "[CV 5/5; 263/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 263/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.536 total time=   0.0s\n",
            "[CV 1/5; 264/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 264/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.541 total time=   0.0s\n",
            "[CV 2/5; 264/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 264/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.515 total time=   0.0s\n",
            "[CV 3/5; 264/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 264/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.466 total time=   0.0s\n",
            "[CV 4/5; 264/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 264/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.493 total time=   0.0s\n",
            "[CV 5/5; 264/384] START criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 264/384] END criterion=log_loss, max_features=auto, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.468 total time=   0.0s\n",
            "[CV 1/5; 265/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 265/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.571 total time=   0.0s\n",
            "[CV 2/5; 265/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 265/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.549 total time=   0.0s\n",
            "[CV 3/5; 265/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 265/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.534 total time=   0.0s\n",
            "[CV 4/5; 265/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 265/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.537 total time=   0.0s\n",
            "[CV 5/5; 265/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 265/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.566 total time=   0.0s\n",
            "[CV 1/5; 266/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 266/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.530 total time=   0.0s\n",
            "[CV 2/5; 266/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 266/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.507 total time=   0.0s\n",
            "[CV 3/5; 266/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 266/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.474 total time=   0.0s\n",
            "[CV 4/5; 266/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 266/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.534 total time=   0.0s\n",
            "[CV 5/5; 266/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 266/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.513 total time=   0.0s\n",
            "[CV 1/5; 267/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 267/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.597 total time=   0.0s\n",
            "[CV 2/5; 267/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 267/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.560 total time=   0.0s\n",
            "[CV 3/5; 267/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 267/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 4/5; 267/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 267/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 5/5; 267/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 267/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.513 total time=   0.0s\n",
            "[CV 1/5; 268/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 268/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.519 total time=   0.0s\n",
            "[CV 2/5; 268/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 268/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.526 total time=   0.0s\n",
            "[CV 3/5; 268/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 268/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.507 total time=   0.0s\n",
            "[CV 4/5; 268/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 268/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 268/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 268/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.547 total time=   0.0s\n",
            "[CV 1/5; 269/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 269/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.549 total time=   0.0s\n",
            "[CV 2/5; 269/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 269/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.545 total time=   0.0s\n",
            "[CV 3/5; 269/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 269/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.489 total time=   0.0s\n",
            "[CV 4/5; 269/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 269/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.470 total time=   0.0s\n",
            "[CV 5/5; 269/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 269/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.566 total time=   0.0s\n",
            "[CV 1/5; 270/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 270/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.474 total time=   0.0s\n",
            "[CV 2/5; 270/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 270/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.496 total time=   0.0s\n",
            "[CV 3/5; 270/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 270/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.519 total time=   0.0s\n",
            "[CV 4/5; 270/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 270/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.485 total time=   0.0s\n",
            "[CV 5/5; 270/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 270/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.479 total time=   0.0s\n",
            "[CV 1/5; 271/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5; 271/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.560 total time=   0.0s\n",
            "[CV 2/5; 271/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 271/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.586 total time=   0.0s\n",
            "[CV 3/5; 271/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 271/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.593 total time=   0.0s\n",
            "[CV 4/5; 271/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 271/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.582 total time=   0.0s\n",
            "[CV 5/5; 271/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 271/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.498 total time=   0.0s\n",
            "[CV 1/5; 272/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 272/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.455 total time=   0.0s\n",
            "[CV 2/5; 272/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 272/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.507 total time=   0.0s\n",
            "[CV 3/5; 272/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 272/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.537 total time=   0.0s\n",
            "[CV 4/5; 272/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 272/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.511 total time=   0.0s\n",
            "[CV 5/5; 272/384] START criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 272/384] END criterion=log_loss, max_features=auto, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 273/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 273/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 273/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 273/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.552 total time=   0.0s\n",
            "[CV 3/5; 273/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 273/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.545 total time=   0.0s\n",
            "[CV 4/5; 273/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 273/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.511 total time=   0.0s\n",
            "[CV 5/5; 273/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 273/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.547 total time=   0.0s\n",
            "[CV 1/5; 274/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 274/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.545 total time=   0.0s\n",
            "[CV 2/5; 274/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 274/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.519 total time=   0.0s\n",
            "[CV 3/5; 274/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 274/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.507 total time=   0.0s\n",
            "[CV 4/5; 274/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 274/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.549 total time=   0.0s\n",
            "[CV 5/5; 274/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 274/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.438 total time=   0.0s\n",
            "[CV 1/5; 275/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 275/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.563 total time=   0.0s\n",
            "[CV 2/5; 275/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 275/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.537 total time=   0.0s\n",
            "[CV 3/5; 275/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 275/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.571 total time=   0.0s\n",
            "[CV 4/5; 275/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 275/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.537 total time=   0.0s\n",
            "[CV 5/5; 275/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 275/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.506 total time=   0.0s\n",
            "[CV 1/5; 276/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 276/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.500 total time=   0.0s\n",
            "[CV 2/5; 276/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 276/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.481 total time=   0.0s\n",
            "[CV 3/5; 276/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 276/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.515 total time=   0.0s\n",
            "[CV 4/5; 276/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 276/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.549 total time=   0.0s\n",
            "[CV 5/5; 276/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 276/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.528 total time=   0.0s\n",
            "[CV 1/5; 277/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 277/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.597 total time=   0.0s\n",
            "[CV 2/5; 277/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 277/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.560 total time=   0.0s\n",
            "[CV 3/5; 277/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 277/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.560 total time=   0.0s\n",
            "[CV 4/5; 277/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 277/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.578 total time=   0.0s\n",
            "[CV 5/5; 277/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 277/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.528 total time=   0.0s\n",
            "[CV 1/5; 278/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 278/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.500 total time=   0.0s\n",
            "[CV 2/5; 278/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 278/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.511 total time=   0.0s\n",
            "[CV 3/5; 278/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 278/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.504 total time=   0.0s\n",
            "[CV 4/5; 278/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 278/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.534 total time=   0.0s\n",
            "[CV 5/5; 278/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 278/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.494 total time=   0.0s\n",
            "[CV 1/5; 279/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 279/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.526 total time=   0.0s\n",
            "[CV 2/5; 279/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 279/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 3/5; 279/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 279/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 4/5; 279/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 279/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.530 total time=   0.0s\n",
            "[CV 5/5; 279/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 279/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.513 total time=   0.0s\n",
            "[CV 1/5; 280/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 280/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.549 total time=   0.0s\n",
            "[CV 2/5; 280/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 280/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.504 total time=   0.0s\n",
            "[CV 3/5; 280/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 280/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.549 total time=   0.0s\n",
            "[CV 4/5; 280/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 280/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.541 total time=   0.0s\n",
            "[CV 5/5; 280/384] START criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=random\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 280/384] END criterion=log_loss, max_features=auto, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.509 total time=   0.0s\n",
            "[CV 1/5; 281/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 281/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.552 total time=   0.0s\n",
            "[CV 2/5; 281/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 281/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.526 total time=   0.0s\n",
            "[CV 3/5; 281/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 281/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.631 total time=   0.0s\n",
            "[CV 4/5; 281/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 281/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.519 total time=   0.0s\n",
            "[CV 5/5; 281/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 281/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.539 total time=   0.0s\n",
            "[CV 1/5; 282/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 282/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.515 total time=   0.0s\n",
            "[CV 2/5; 282/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 282/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.470 total time=   0.0s\n",
            "[CV 3/5; 282/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 282/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.481 total time=   0.0s\n",
            "[CV 4/5; 282/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 282/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.500 total time=   0.0s\n",
            "[CV 5/5; 282/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 282/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 283/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 283/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.590 total time=   0.0s\n",
            "[CV 2/5; 283/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 283/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 3/5; 283/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 283/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.612 total time=   0.0s\n",
            "[CV 4/5; 283/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 283/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.590 total time=   0.0s\n",
            "[CV 5/5; 283/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 283/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.539 total time=   0.0s\n",
            "[CV 1/5; 284/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 284/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.537 total time=   0.0s\n",
            "[CV 2/5; 284/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 284/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.500 total time=   0.0s\n",
            "[CV 3/5; 284/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 284/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.504 total time=   0.0s\n",
            "[CV 4/5; 284/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 284/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.478 total time=   0.0s\n",
            "[CV 5/5; 284/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 284/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.491 total time=   0.0s\n",
            "[CV 1/5; 285/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 285/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.604 total time=   0.0s\n",
            "[CV 2/5; 285/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=best\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 285/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.530 total time=   0.0s\n",
            "[CV 3/5; 285/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 285/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 4/5; 285/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 285/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.519 total time=   0.0s\n",
            "[CV 5/5; 285/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 285/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.547 total time=   0.0s\n",
            "[CV 1/5; 286/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 286/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.541 total time=   0.0s\n",
            "[CV 2/5; 286/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 286/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.474 total time=   0.0s\n",
            "[CV 3/5; 286/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 286/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.485 total time=   0.0s\n",
            "[CV 4/5; 286/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 286/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.511 total time=   0.0s\n",
            "[CV 5/5; 286/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 286/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.494 total time=   0.0s\n",
            "[CV 1/5; 287/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 287/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.489 total time=   0.0s\n",
            "[CV 2/5; 287/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 287/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.560 total time=   0.0s\n",
            "[CV 3/5; 287/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 287/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 4/5; 287/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 287/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.578 total time=   0.0s\n",
            "[CV 5/5; 287/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 287/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.517 total time=   0.0s\n",
            "[CV 1/5; 288/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 288/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.541 total time=   0.0s\n",
            "[CV 2/5; 288/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 288/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.519 total time=   0.0s\n",
            "[CV 3/5; 288/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 288/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 288/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 288/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.515 total time=   0.0s\n",
            "[CV 5/5; 288/384] START criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 288/384] END criterion=log_loss, max_features=auto, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.506 total time=   0.0s\n",
            "[CV 1/5; 289/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 289/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.545 total time=   0.0s\n",
            "[CV 2/5; 289/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 289/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.507 total time=   0.0s\n",
            "[CV 3/5; 289/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 289/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.578 total time=   0.0s\n",
            "[CV 4/5; 289/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 289/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.590 total time=   0.0s\n",
            "[CV 5/5; 289/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 289/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.502 total time=   0.0s\n",
            "[CV 1/5; 290/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 290/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.541 total time=   0.0s\n",
            "[CV 2/5; 290/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 290/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.489 total time=   0.0s\n",
            "[CV 3/5; 290/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 290/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.496 total time=   0.0s\n",
            "[CV 4/5; 290/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 290/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.530 total time=   0.0s\n",
            "[CV 5/5; 290/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 290/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.498 total time=   0.0s\n",
            "[CV 1/5; 291/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 291/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.545 total time=   0.0s\n",
            "[CV 2/5; 291/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 291/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.582 total time=   0.0s\n",
            "[CV 3/5; 291/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 291/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.563 total time=   0.0s\n",
            "[CV 4/5; 291/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 291/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.526 total time=   0.0s\n",
            "[CV 5/5; 291/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 291/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.543 total time=   0.0s\n",
            "[CV 1/5; 292/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 292/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.481 total time=   0.0s\n",
            "[CV 2/5; 292/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 292/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.463 total time=   0.0s\n",
            "[CV 3/5; 292/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 292/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.470 total time=   0.0s\n",
            "[CV 4/5; 292/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 292/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.493 total time=   0.0s\n",
            "[CV 5/5; 292/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 292/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.479 total time=   0.0s\n",
            "[CV 1/5; 293/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 293/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.519 total time=   0.0s\n",
            "[CV 2/5; 293/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 293/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.563 total time=   0.0s\n",
            "[CV 3/5; 293/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 293/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 4/5; 293/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 293/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.597 total time=   0.0s\n",
            "[CV 5/5; 293/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 293/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.528 total time=   0.0s\n",
            "[CV 1/5; 294/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 294/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.507 total time=   0.0s\n",
            "[CV 2/5; 294/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 294/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.534 total time=   0.0s\n",
            "[CV 3/5; 294/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 294/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.485 total time=   0.0s\n",
            "[CV 4/5; 294/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 294/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.534 total time=   0.0s\n",
            "[CV 5/5; 294/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 294/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.494 total time=   0.0s\n",
            "[CV 1/5; 295/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 295/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.586 total time=   0.0s\n",
            "[CV 2/5; 295/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 295/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.586 total time=   0.0s\n",
            "[CV 3/5; 295/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 295/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.567 total time=   0.0s\n",
            "[CV 4/5; 295/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 295/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.534 total time=   0.0s\n",
            "[CV 5/5; 295/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 295/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.449 total time=   0.0s\n",
            "[CV 1/5; 296/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 296/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.500 total time=   0.0s\n",
            "[CV 2/5; 296/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 296/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.526 total time=   0.0s\n",
            "[CV 3/5; 296/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 296/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.519 total time=   0.0s\n",
            "[CV 4/5; 296/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 296/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.537 total time=   0.0s\n",
            "[CV 5/5; 296/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 296/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.461 total time=   0.0s\n",
            "[CV 1/5; 297/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 297/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.545 total time=   0.0s\n",
            "[CV 2/5; 297/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 297/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.627 total time=   0.0s\n",
            "[CV 3/5; 297/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 297/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.537 total time=   0.0s\n",
            "[CV 4/5; 297/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 297/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.519 total time=   0.0s\n",
            "[CV 5/5; 297/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 297/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.539 total time=   0.0s\n",
            "[CV 1/5; 298/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 298/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.504 total time=   0.0s\n",
            "[CV 2/5; 298/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 298/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.515 total time=   0.0s\n",
            "[CV 3/5; 298/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 298/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.489 total time=   0.0s\n",
            "[CV 4/5; 298/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 298/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.474 total time=   0.0s\n",
            "[CV 5/5; 298/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 298/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.491 total time=   0.0s\n",
            "[CV 1/5; 299/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 299/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.515 total time=   0.0s\n",
            "[CV 2/5; 299/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 299/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.575 total time=   0.0s\n",
            "[CV 3/5; 299/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 299/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.660 total time=   0.0s\n",
            "[CV 4/5; 299/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 299/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.549 total time=   0.0s\n",
            "[CV 5/5; 299/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 299/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.577 total time=   0.0s\n",
            "[CV 1/5; 300/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 300/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.556 total time=   0.0s\n",
            "[CV 2/5; 300/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 300/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.481 total time=   0.0s\n",
            "[CV 3/5; 300/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 300/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.414 total time=   0.0s\n",
            "[CV 4/5; 300/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 300/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.481 total time=   0.0s\n",
            "[CV 5/5; 300/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 300/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.442 total time=   0.0s\n",
            "[CV 1/5; 301/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 301/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.571 total time=   0.0s\n",
            "[CV 2/5; 301/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 301/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.590 total time=   0.0s\n",
            "[CV 3/5; 301/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 301/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.493 total time=   0.0s\n",
            "[CV 4/5; 301/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 301/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.560 total time=   0.0s\n",
            "[CV 5/5; 301/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 301/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.562 total time=   0.0s\n",
            "[CV 1/5; 302/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 302/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.493 total time=   0.0s\n",
            "[CV 2/5; 302/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 302/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.507 total time=   0.0s\n",
            "[CV 3/5; 302/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 302/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.496 total time=   0.0s\n",
            "[CV 4/5; 302/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 302/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.511 total time=   0.0s\n",
            "[CV 5/5; 302/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 302/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.566 total time=   0.0s\n",
            "[CV 1/5; 303/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 303/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.507 total time=   0.0s\n",
            "[CV 2/5; 303/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 303/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.530 total time=   0.0s\n",
            "[CV 3/5; 303/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 303/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 4/5; 303/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 303/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.545 total time=   0.0s\n",
            "[CV 5/5; 303/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 303/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 304/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 304/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.511 total time=   0.0s\n",
            "[CV 2/5; 304/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 304/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.556 total time=   0.0s\n",
            "[CV 3/5; 304/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 304/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.478 total time=   0.0s\n",
            "[CV 4/5; 304/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 304/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.478 total time=   0.0s\n",
            "[CV 5/5; 304/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 304/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.461 total time=   0.0s\n",
            "[CV 1/5; 305/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 305/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 2/5; 305/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 305/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.582 total time=   0.0s\n",
            "[CV 3/5; 305/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 305/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.545 total time=   0.0s\n",
            "[CV 4/5; 305/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 305/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.519 total time=   0.0s\n",
            "[CV 5/5; 305/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 305/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.539 total time=   0.0s\n",
            "[CV 1/5; 306/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 306/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.496 total time=   0.0s\n",
            "[CV 2/5; 306/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 306/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.537 total time=   0.0s\n",
            "[CV 3/5; 306/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 306/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 306/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 306/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.575 total time=   0.0s\n",
            "[CV 5/5; 306/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 306/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.472 total time=   0.0s\n",
            "[CV 1/5; 307/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 307/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.545 total time=   0.0s\n",
            "[CV 2/5; 307/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 307/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.534 total time=   0.0s\n",
            "[CV 3/5; 307/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 307/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.590 total time=   0.0s\n",
            "[CV 4/5; 307/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 307/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 307/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 307/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.543 total time=   0.0s\n",
            "[CV 1/5; 308/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 308/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.507 total time=   0.0s\n",
            "[CV 2/5; 308/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 308/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.534 total time=   0.0s\n",
            "[CV 3/5; 308/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 308/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.541 total time=   0.0s\n",
            "[CV 4/5; 308/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 308/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.489 total time=   0.0s\n",
            "[CV 5/5; 308/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 308/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.468 total time=   0.0s\n",
            "[CV 1/5; 309/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 309/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.534 total time=   0.0s\n",
            "[CV 2/5; 309/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 309/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.500 total time=   0.0s\n",
            "[CV 3/5; 309/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 309/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.526 total time=   0.0s\n",
            "[CV 4/5; 309/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 309/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.563 total time=   0.0s\n",
            "[CV 5/5; 309/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 309/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.551 total time=   0.0s\n",
            "[CV 1/5; 310/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 310/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.493 total time=   0.0s\n",
            "[CV 2/5; 310/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 310/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.485 total time=   0.0s\n",
            "[CV 3/5; 310/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 310/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.474 total time=   0.0s\n",
            "[CV 4/5; 310/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 310/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.481 total time=   0.0s\n",
            "[CV 5/5; 310/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 310/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.491 total time=   0.0s\n",
            "[CV 1/5; 311/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 311/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.571 total time=   0.0s\n",
            "[CV 2/5; 311/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 311/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.567 total time=   0.0s\n",
            "[CV 3/5; 311/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 311/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.515 total time=   0.0s\n",
            "[CV 4/5; 311/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 311/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.601 total time=   0.0s\n",
            "[CV 5/5; 311/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 311/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.491 total time=   0.0s\n",
            "[CV 1/5; 312/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 312/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.493 total time=   0.0s\n",
            "[CV 2/5; 312/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 312/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.474 total time=   0.0s\n",
            "[CV 3/5; 312/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 312/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.560 total time=   0.0s\n",
            "[CV 4/5; 312/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 312/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.582 total time=   0.0s\n",
            "[CV 5/5; 312/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 312/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.539 total time=   0.0s\n",
            "[CV 1/5; 313/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 313/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.582 total time=   0.0s\n",
            "[CV 2/5; 313/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 313/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 3/5; 313/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 313/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 4/5; 313/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 313/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.537 total time=   0.0s\n",
            "[CV 5/5; 313/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 313/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.487 total time=   0.0s\n",
            "[CV 1/5; 314/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 314/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.519 total time=   0.0s\n",
            "[CV 2/5; 314/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 314/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.478 total time=   0.0s\n",
            "[CV 3/5; 314/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 314/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.504 total time=   0.0s\n",
            "[CV 4/5; 314/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 314/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.549 total time=   0.0s\n",
            "[CV 5/5; 314/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 314/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.491 total time=   0.0s\n",
            "[CV 1/5; 315/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 315/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.537 total time=   0.0s\n",
            "[CV 2/5; 315/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 315/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.519 total time=   0.0s\n",
            "[CV 3/5; 315/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 315/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.526 total time=   0.0s\n",
            "[CV 4/5; 315/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 315/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.567 total time=   0.0s\n",
            "[CV 5/5; 315/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 315/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.509 total time=   0.0s\n",
            "[CV 1/5; 316/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 316/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.608 total time=   0.0s\n",
            "[CV 2/5; 316/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 316/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.474 total time=   0.0s\n",
            "[CV 3/5; 316/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 316/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.466 total time=   0.0s\n",
            "[CV 4/5; 316/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 316/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.545 total time=   0.0s\n",
            "[CV 5/5; 316/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 316/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.536 total time=   0.0s\n",
            "[CV 1/5; 317/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 317/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.504 total time=   0.0s\n",
            "[CV 2/5; 317/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 317/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.504 total time=   0.0s\n",
            "[CV 3/5; 317/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 317/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.563 total time=   0.0s\n",
            "[CV 4/5; 317/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 317/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.571 total time=   0.0s\n",
            "[CV 5/5; 317/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 317/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.543 total time=   0.0s\n",
            "[CV 1/5; 318/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 318/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.515 total time=   0.0s\n",
            "[CV 2/5; 318/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 318/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.485 total time=   0.0s\n",
            "[CV 3/5; 318/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 318/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.537 total time=   0.0s\n",
            "[CV 4/5; 318/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 318/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.556 total time=   0.0s\n",
            "[CV 5/5; 318/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 318/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.528 total time=   0.0s\n",
            "[CV 1/5; 319/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 319/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 2/5; 319/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 319/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.530 total time=   0.0s\n",
            "[CV 3/5; 319/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 319/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.582 total time=   0.0s\n",
            "[CV 4/5; 319/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 319/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.526 total time=   0.0s\n",
            "[CV 5/5; 319/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 319/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.509 total time=   0.0s\n",
            "[CV 1/5; 320/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 320/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.485 total time=   0.0s\n",
            "[CV 2/5; 320/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 320/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.504 total time=   0.0s\n",
            "[CV 3/5; 320/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 320/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.534 total time=   0.0s\n",
            "[CV 4/5; 320/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 320/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.545 total time=   0.0s\n",
            "[CV 5/5; 320/384] START criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 320/384] END criterion=log_loss, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.494 total time=   0.0s\n",
            "[CV 1/5; 321/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 321/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 2/5; 321/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 321/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.470 total time=   0.0s\n",
            "[CV 3/5; 321/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 321/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.590 total time=   0.0s\n",
            "[CV 4/5; 321/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 321/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.504 total time=   0.0s\n",
            "[CV 5/5; 321/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 321/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.517 total time=   0.0s\n",
            "[CV 1/5; 322/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 322/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.537 total time=   0.0s\n",
            "[CV 2/5; 322/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 322/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.496 total time=   0.0s\n",
            "[CV 3/5; 322/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 322/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.511 total time=   0.0s\n",
            "[CV 4/5; 322/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 322/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 322/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 322/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.502 total time=   0.0s\n",
            "[CV 1/5; 323/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 323/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.537 total time=   0.0s\n",
            "[CV 2/5; 323/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 323/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 3/5; 323/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 323/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.545 total time=   0.0s\n",
            "[CV 4/5; 323/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 323/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 5/5; 323/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 323/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.584 total time=   0.0s\n",
            "[CV 1/5; 324/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 324/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.530 total time=   0.0s\n",
            "[CV 2/5; 324/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 324/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.560 total time=   0.0s\n",
            "[CV 3/5; 324/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 324/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.537 total time=   0.0s\n",
            "[CV 4/5; 324/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 324/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.507 total time=   0.0s\n",
            "[CV 5/5; 324/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 324/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.554 total time=   0.0s\n",
            "[CV 1/5; 325/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 325/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.504 total time=   0.0s\n",
            "[CV 2/5; 325/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 325/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.604 total time=   0.0s\n",
            "[CV 3/5; 325/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 325/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.563 total time=   0.0s\n",
            "[CV 4/5; 325/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 325/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.575 total time=   0.0s\n",
            "[CV 5/5; 325/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 325/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.479 total time=   0.0s\n",
            "[CV 1/5; 326/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 326/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.530 total time=   0.0s\n",
            "[CV 2/5; 326/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 326/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.493 total time=   0.0s\n",
            "[CV 3/5; 326/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 326/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.463 total time=   0.0s\n",
            "[CV 4/5; 326/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 326/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.504 total time=   0.0s\n",
            "[CV 5/5; 326/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 326/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.494 total time=   0.0s\n",
            "[CV 1/5; 327/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 327/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.534 total time=   0.0s\n",
            "[CV 2/5; 327/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 327/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 3/5; 327/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 327/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.537 total time=   0.0s\n",
            "[CV 4/5; 327/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 327/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.552 total time=   0.0s\n",
            "[CV 5/5; 327/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 327/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.558 total time=   0.0s\n",
            "[CV 1/5; 328/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 328/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.537 total time=   0.0s\n",
            "[CV 2/5; 328/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 328/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.575 total time=   0.0s\n",
            "[CV 3/5; 328/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 328/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.511 total time=   0.0s\n",
            "[CV 4/5; 328/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 328/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.496 total time=   0.0s\n",
            "[CV 5/5; 328/384] START criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 328/384] END criterion=log_loss, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.536 total time=   0.0s\n",
            "[CV 1/5; 329/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 329/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.515 total time=   0.0s\n",
            "[CV 2/5; 329/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 329/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 3/5; 329/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 329/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.563 total time=   0.0s\n",
            "[CV 4/5; 329/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 329/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.504 total time=   0.0s\n",
            "[CV 5/5; 329/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 329/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.551 total time=   0.0s\n",
            "[CV 1/5; 330/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 330/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.567 total time=   0.0s\n",
            "[CV 2/5; 330/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 330/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.481 total time=   0.0s\n",
            "[CV 3/5; 330/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 330/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.500 total time=   0.0s\n",
            "[CV 4/5; 330/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 330/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.519 total time=   0.0s\n",
            "[CV 5/5; 330/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 330/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.506 total time=   0.0s\n",
            "[CV 1/5; 331/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 331/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.575 total time=   0.0s\n",
            "[CV 2/5; 331/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 331/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.478 total time=   0.0s\n",
            "[CV 3/5; 331/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 331/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.575 total time=   0.0s\n",
            "[CV 4/5; 331/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 331/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.575 total time=   0.0s\n",
            "[CV 5/5; 331/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 331/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.487 total time=   0.0s\n",
            "[CV 1/5; 332/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 332/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 332/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 332/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.444 total time=   0.0s\n",
            "[CV 3/5; 332/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 332/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.515 total time=   0.0s\n",
            "[CV 4/5; 332/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 332/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.549 total time=   0.0s\n",
            "[CV 5/5; 332/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 332/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.506 total time=   0.0s\n",
            "[CV 1/5; 333/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 333/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.627 total time=   0.0s\n",
            "[CV 2/5; 333/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 333/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 3/5; 333/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 333/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 333/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 333/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.504 total time=   0.0s\n",
            "[CV 5/5; 333/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 333/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.551 total time=   0.0s\n",
            "[CV 1/5; 334/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 334/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.526 total time=   0.0s\n",
            "[CV 2/5; 334/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 334/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.511 total time=   0.0s\n",
            "[CV 3/5; 334/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 334/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.534 total time=   0.0s\n",
            "[CV 4/5; 334/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 334/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.515 total time=   0.0s\n",
            "[CV 5/5; 334/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 334/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.483 total time=   0.0s\n",
            "[CV 1/5; 335/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 335/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.549 total time=   0.0s\n",
            "[CV 2/5; 335/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 335/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.507 total time=   0.0s\n",
            "[CV 3/5; 335/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 335/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 4/5; 335/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 335/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.534 total time=   0.0s\n",
            "[CV 5/5; 335/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 335/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 336/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 336/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.567 total time=   0.0s\n",
            "[CV 2/5; 336/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 336/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.444 total time=   0.0s\n",
            "[CV 3/5; 336/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 336/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.493 total time=   0.0s\n",
            "[CV 4/5; 336/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 336/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.433 total time=   0.0s\n",
            "[CV 5/5; 336/384] START criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 336/384] END criterion=log_loss, max_features=log2, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.502 total time=   0.0s\n",
            "[CV 1/5; 337/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 337/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.545 total time=   0.0s\n",
            "[CV 2/5; 337/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 337/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.481 total time=   0.0s\n",
            "[CV 3/5; 337/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 337/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.515 total time=   0.0s\n",
            "[CV 4/5; 337/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 337/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.597 total time=   0.0s\n",
            "[CV 5/5; 337/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 337/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 338/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 338/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.496 total time=   0.0s\n",
            "[CV 2/5; 338/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 338/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.541 total time=   0.0s\n",
            "[CV 3/5; 338/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 338/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.451 total time=   0.0s\n",
            "[CV 4/5; 338/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 338/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.496 total time=   0.0s\n",
            "[CV 5/5; 338/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 338/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.517 total time=   0.0s\n",
            "[CV 1/5; 339/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 339/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.493 total time=   0.0s\n",
            "[CV 2/5; 339/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 339/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.526 total time=   0.0s\n",
            "[CV 3/5; 339/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 339/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.552 total time=   0.0s\n",
            "[CV 4/5; 339/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 339/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.530 total time=   0.0s\n",
            "[CV 5/5; 339/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 339/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 340/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 340/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.496 total time=   0.0s\n",
            "[CV 2/5; 340/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 340/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.534 total time=   0.0s\n",
            "[CV 3/5; 340/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 340/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.537 total time=   0.0s\n",
            "[CV 4/5; 340/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 340/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.522 total time=   0.0s\n",
            "[CV 5/5; 340/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 340/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.566 total time=   0.0s\n",
            "[CV 1/5; 341/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 341/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.612 total time=   0.0s\n",
            "[CV 2/5; 341/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 341/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.560 total time=   0.0s\n",
            "[CV 3/5; 341/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 341/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.522 total time=   0.0s\n",
            "[CV 4/5; 341/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 341/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.485 total time=   0.0s\n",
            "[CV 5/5; 341/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 341/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.532 total time=   0.0s\n",
            "[CV 1/5; 342/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 342/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.549 total time=   0.0s\n",
            "[CV 2/5; 342/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 342/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.466 total time=   0.0s\n",
            "[CV 3/5; 342/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 342/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.500 total time=   0.0s\n",
            "[CV 4/5; 342/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 342/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.519 total time=   0.0s\n",
            "[CV 5/5; 342/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 342/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.491 total time=   0.0s\n",
            "[CV 1/5; 343/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 343/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.578 total time=   0.0s\n",
            "[CV 2/5; 343/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 343/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 3/5; 343/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 343/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 4/5; 343/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 343/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.541 total time=   0.0s\n",
            "[CV 5/5; 343/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 343/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.506 total time=   0.0s\n",
            "[CV 1/5; 344/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 344/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.556 total time=   0.0s\n",
            "[CV 2/5; 344/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 344/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.496 total time=   0.0s\n",
            "[CV 3/5; 344/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 344/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.549 total time=   0.0s\n",
            "[CV 4/5; 344/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 344/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.489 total time=   0.0s\n",
            "[CV 5/5; 344/384] START criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 344/384] END criterion=log_loss, max_features=log2, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.487 total time=   0.0s\n",
            "[CV 1/5; 345/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 345/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.526 total time=   0.0s\n",
            "[CV 2/5; 345/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 345/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.571 total time=   0.0s\n",
            "[CV 3/5; 345/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 345/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.500 total time=   0.0s\n",
            "[CV 4/5; 345/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 345/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.597 total time=   0.0s\n",
            "[CV 5/5; 345/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 345/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.543 total time=   0.0s\n",
            "[CV 1/5; 346/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 346/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.530 total time=   0.0s\n",
            "[CV 2/5; 346/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 346/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.493 total time=   0.0s\n",
            "[CV 3/5; 346/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 346/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.493 total time=   0.0s\n",
            "[CV 4/5; 346/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 346/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.474 total time=   0.0s\n",
            "[CV 5/5; 346/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 346/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.547 total time=   0.0s\n",
            "[CV 1/5; 347/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 347/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 2/5; 347/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 347/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.552 total time=   0.0s\n",
            "[CV 3/5; 347/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 347/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.504 total time=   0.0s\n",
            "[CV 4/5; 347/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 347/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 5/5; 347/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 347/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 348/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 348/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.496 total time=   0.0s\n",
            "[CV 2/5; 348/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 348/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.515 total time=   0.0s\n",
            "[CV 3/5; 348/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 348/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.537 total time=   0.0s\n",
            "[CV 4/5; 348/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 348/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.485 total time=   0.0s\n",
            "[CV 5/5; 348/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 348/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.442 total time=   0.0s\n",
            "[CV 1/5; 349/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 349/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.522 total time=   0.0s\n",
            "[CV 2/5; 349/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 349/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.556 total time=   0.0s\n",
            "[CV 3/5; 349/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 349/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.493 total time=   0.0s\n",
            "[CV 4/5; 349/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 349/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.519 total time=   0.0s\n",
            "[CV 5/5; 349/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 349/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.536 total time=   0.0s\n",
            "[CV 1/5; 350/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 350/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.526 total time=   0.0s\n",
            "[CV 2/5; 350/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 350/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.496 total time=   0.0s\n",
            "[CV 3/5; 350/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 350/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.530 total time=   0.0s\n",
            "[CV 4/5; 350/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 350/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.507 total time=   0.0s\n",
            "[CV 5/5; 350/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 350/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.476 total time=   0.0s\n",
            "[CV 1/5; 351/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 351/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.545 total time=   0.0s\n",
            "[CV 2/5; 351/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 351/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.552 total time=   0.0s\n",
            "[CV 3/5; 351/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 351/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.504 total time=   0.0s\n",
            "[CV 4/5; 351/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 351/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.586 total time=   0.0s\n",
            "[CV 5/5; 351/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 351/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.524 total time=   0.0s\n",
            "[CV 1/5; 352/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 352/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.526 total time=   0.0s\n",
            "[CV 2/5; 352/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 352/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.504 total time=   0.0s\n",
            "[CV 3/5; 352/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 352/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.493 total time=   0.0s\n",
            "[CV 4/5; 352/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 352/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.537 total time=   0.0s\n",
            "[CV 5/5; 352/384] START criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 352/384] END criterion=log_loss, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.461 total time=   0.0s\n",
            "[CV 1/5; 353/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 353/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.664 total time=   0.0s\n",
            "[CV 2/5; 353/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 353/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.701 total time=   0.0s\n",
            "[CV 3/5; 353/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 353/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.683 total time=   0.0s\n",
            "[CV 4/5; 353/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 353/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.776 total time=   0.0s\n",
            "[CV 5/5; 353/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 353/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.787 total time=   0.0s\n",
            "[CV 1/5; 354/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 354/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.604 total time=   0.0s\n",
            "[CV 2/5; 354/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 354/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.571 total time=   0.0s\n",
            "[CV 3/5; 354/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 354/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.481 total time=   0.0s\n",
            "[CV 4/5; 354/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 354/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.664 total time=   0.0s\n",
            "[CV 5/5; 354/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 354/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=2, splitter=random;, score=0.584 total time=   0.0s\n",
            "[CV 1/5; 355/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 355/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.646 total time=   0.0s\n",
            "[CV 2/5; 355/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 355/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.705 total time=   0.0s\n",
            "[CV 3/5; 355/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 355/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.698 total time=   0.0s\n",
            "[CV 4/5; 355/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 355/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.765 total time=   0.0s\n",
            "[CV 5/5; 355/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 355/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=best;, score=0.775 total time=   0.0s\n",
            "[CV 1/5; 356/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 356/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.552 total time=   0.0s\n",
            "[CV 2/5; 356/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 356/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.552 total time=   0.0s\n",
            "[CV 3/5; 356/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 356/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.619 total time=   0.0s\n",
            "[CV 4/5; 356/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 356/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.575 total time=   0.0s\n",
            "[CV 5/5; 356/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 356/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.629 total time=   0.0s\n",
            "[CV 1/5; 357/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 357/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.660 total time=   0.0s\n",
            "[CV 2/5; 357/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 357/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.701 total time=   0.0s\n",
            "[CV 3/5; 357/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 357/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.690 total time=   0.0s\n",
            "[CV 4/5; 357/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 357/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.780 total time=   0.0s\n",
            "[CV 5/5; 357/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 357/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.787 total time=   0.0s\n",
            "[CV 1/5; 358/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 358/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.541 total time=   0.0s\n",
            "[CV 2/5; 358/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 358/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.590 total time=   0.0s\n",
            "[CV 3/5; 358/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 358/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.481 total time=   0.0s\n",
            "[CV 4/5; 358/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 358/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.567 total time=   0.0s\n",
            "[CV 5/5; 358/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 358/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.633 total time=   0.0s\n",
            "[CV 1/5; 359/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 359/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.668 total time=   0.1s\n",
            "[CV 2/5; 359/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 359/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.701 total time=   0.0s\n",
            "[CV 3/5; 359/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 359/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.698 total time=   0.0s\n",
            "[CV 4/5; 359/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 359/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.750 total time=   0.0s\n",
            "[CV 5/5; 359/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 359/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.783 total time=   0.0s\n",
            "[CV 1/5; 360/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 360/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.552 total time=   0.0s\n",
            "[CV 2/5; 360/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 360/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.489 total time=   0.0s\n",
            "[CV 3/5; 360/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 360/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.560 total time=   0.0s\n",
            "[CV 4/5; 360/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 360/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.631 total time=   0.0s\n",
            "[CV 5/5; 360/384] START criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 360/384] END criterion=log_loss, max_features=None, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.633 total time=   0.0s\n",
            "[CV 1/5; 361/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 361/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.653 total time=   0.0s\n",
            "[CV 2/5; 361/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 361/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.694 total time=   0.0s\n",
            "[CV 3/5; 361/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 361/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.720 total time=   0.0s\n",
            "[CV 4/5; 361/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 361/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.769 total time=   0.0s\n",
            "[CV 5/5; 361/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 361/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.783 total time=   0.0s\n",
            "[CV 1/5; 362/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 362/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.601 total time=   0.0s\n",
            "[CV 2/5; 362/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 362/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.541 total time=   0.0s\n",
            "[CV 3/5; 362/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 362/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.631 total time=   0.0s\n",
            "[CV 4/5; 362/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 362/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.586 total time=   0.0s\n",
            "[CV 5/5; 362/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 362/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 363/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 363/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.653 total time=   0.0s\n",
            "[CV 2/5; 363/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 363/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.705 total time=   0.0s\n",
            "[CV 3/5; 363/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 363/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.713 total time=   0.0s\n",
            "[CV 4/5; 363/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 363/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.776 total time=   0.0s\n",
            "[CV 5/5; 363/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 363/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.805 total time=   0.0s\n",
            "[CV 1/5; 364/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 364/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.597 total time=   0.0s\n",
            "[CV 2/5; 364/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 364/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.631 total time=   0.0s\n",
            "[CV 3/5; 364/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 364/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.593 total time=   0.0s\n",
            "[CV 4/5; 364/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 364/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.590 total time=   0.0s\n",
            "[CV 5/5; 364/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 364/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.622 total time=   0.0s\n",
            "[CV 1/5; 365/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 365/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.672 total time=   0.0s\n",
            "[CV 2/5; 365/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 365/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.687 total time=   0.0s\n",
            "[CV 3/5; 365/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 365/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.709 total time=   0.0s\n",
            "[CV 4/5; 365/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 365/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.765 total time=   0.0s\n",
            "[CV 5/5; 365/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 365/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.772 total time=   0.0s\n",
            "[CV 1/5; 366/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 366/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.616 total time=   0.0s\n",
            "[CV 2/5; 366/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 366/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.616 total time=   0.0s\n",
            "[CV 3/5; 366/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 366/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.593 total time=   0.0s\n",
            "[CV 4/5; 366/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 366/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.545 total time=   0.0s\n",
            "[CV 5/5; 366/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 366/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.592 total time=   0.0s\n",
            "[CV 1/5; 367/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 367/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.713 total time=   0.0s\n",
            "[CV 2/5; 367/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 367/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.679 total time=   0.0s\n",
            "[CV 3/5; 367/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 367/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.709 total time=   0.0s\n",
            "[CV 4/5; 367/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 367/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.772 total time=   0.0s\n",
            "[CV 5/5; 367/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 367/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.779 total time=   0.0s\n",
            "[CV 1/5; 368/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 368/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.631 total time=   0.0s\n",
            "[CV 2/5; 368/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 368/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.556 total time=   0.0s\n",
            "[CV 3/5; 368/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 368/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.493 total time=   0.0s\n",
            "[CV 4/5; 368/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 368/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.619 total time=   0.0s\n",
            "[CV 5/5; 368/384] START criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 368/384] END criterion=log_loss, max_features=None, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.667 total time=   0.0s\n",
            "[CV 1/5; 369/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 369/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.694 total time=   0.0s\n",
            "[CV 2/5; 369/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 369/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.701 total time=   0.0s\n",
            "[CV 3/5; 369/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 369/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.698 total time=   0.0s\n",
            "[CV 4/5; 369/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 369/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.780 total time=   0.0s\n",
            "[CV 5/5; 369/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 369/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=best;, score=0.787 total time=   0.0s\n",
            "[CV 1/5; 370/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 370/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.623 total time=   0.0s\n",
            "[CV 2/5; 370/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 370/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.590 total time=   0.0s\n",
            "[CV 3/5; 370/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 370/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.619 total time=   0.0s\n",
            "[CV 4/5; 370/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 370/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.601 total time=   0.0s\n",
            "[CV 5/5; 370/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 370/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=2, splitter=random;, score=0.629 total time=   0.0s\n",
            "[CV 1/5; 371/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 371/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.672 total time=   0.0s\n",
            "[CV 2/5; 371/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 371/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.716 total time=   0.0s\n",
            "[CV 3/5; 371/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 371/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.713 total time=   0.0s\n",
            "[CV 4/5; 371/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 371/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.776 total time=   0.0s\n",
            "[CV 5/5; 371/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 371/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=best;, score=0.775 total time=   0.0s\n",
            "[CV 1/5; 372/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 372/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.556 total time=   0.0s\n",
            "[CV 2/5; 372/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 372/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.526 total time=   0.0s\n",
            "[CV 3/5; 372/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 372/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.481 total time=   0.0s\n",
            "[CV 4/5; 372/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 372/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.642 total time=   0.0s\n",
            "[CV 5/5; 372/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 372/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=3, splitter=random;, score=0.566 total time=   0.0s\n",
            "[CV 1/5; 373/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 373/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.687 total time=   0.0s\n",
            "[CV 2/5; 373/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 373/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.690 total time=   0.0s\n",
            "[CV 3/5; 373/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 373/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.709 total time=   0.0s\n",
            "[CV 4/5; 373/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 373/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.791 total time=   0.0s\n",
            "[CV 5/5; 373/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 373/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=best;, score=0.779 total time=   0.0s\n",
            "[CV 1/5; 374/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 374/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.590 total time=   0.0s\n",
            "[CV 2/5; 374/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 374/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.586 total time=   0.0s\n",
            "[CV 3/5; 374/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 374/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.563 total time=   0.0s\n",
            "[CV 4/5; 374/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 374/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.507 total time=   0.0s\n",
            "[CV 5/5; 374/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 374/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=4, splitter=random;, score=0.618 total time=   0.0s\n",
            "[CV 1/5; 375/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 375/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.668 total time=   0.0s\n",
            "[CV 2/5; 375/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 375/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.716 total time=   0.0s\n",
            "[CV 3/5; 375/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 375/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.701 total time=   0.0s\n",
            "[CV 4/5; 375/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 375/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.776 total time=   0.0s\n",
            "[CV 5/5; 375/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 375/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=best;, score=0.783 total time=   0.0s\n",
            "[CV 1/5; 376/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 376/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.597 total time=   0.0s\n",
            "[CV 2/5; 376/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 376/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.575 total time=   0.0s\n",
            "[CV 3/5; 376/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 376/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.646 total time=   0.0s\n",
            "[CV 4/5; 376/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 376/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.612 total time=   0.0s\n",
            "[CV 5/5; 376/384] START criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 376/384] END criterion=log_loss, max_features=None, min_samples_leaf=3, min_samples_split=5, splitter=random;, score=0.547 total time=   0.0s\n",
            "[CV 1/5; 377/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 1/5; 377/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.709 total time=   0.0s\n",
            "[CV 2/5; 377/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 2/5; 377/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.668 total time=   0.0s\n",
            "[CV 3/5; 377/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 3/5; 377/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.713 total time=   0.0s\n",
            "[CV 4/5; 377/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 4/5; 377/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.776 total time=   0.0s\n",
            "[CV 5/5; 377/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=best\n",
            "[CV 5/5; 377/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.790 total time=   0.0s\n",
            "[CV 1/5; 378/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 1/5; 378/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.664 total time=   0.0s\n",
            "[CV 2/5; 378/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 2/5; 378/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.601 total time=   0.0s\n",
            "[CV 3/5; 378/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 3/5; 378/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.601 total time=   0.0s\n",
            "[CV 4/5; 378/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 4/5; 378/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.519 total time=   0.0s\n",
            "[CV 5/5; 378/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=random\n",
            "[CV 5/5; 378/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.558 total time=   0.0s\n",
            "[CV 1/5; 379/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 1/5; 379/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.698 total time=   0.0s\n",
            "[CV 2/5; 379/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 2/5; 379/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.687 total time=   0.0s\n",
            "[CV 3/5; 379/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 3/5; 379/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.690 total time=   0.0s\n",
            "[CV 4/5; 379/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 4/5; 379/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.776 total time=   0.0s\n",
            "[CV 5/5; 379/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=best\n",
            "[CV 5/5; 379/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.787 total time=   0.0s\n",
            "[CV 1/5; 380/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 1/5; 380/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.653 total time=   0.0s\n",
            "[CV 2/5; 380/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 2/5; 380/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.549 total time=   0.0s\n",
            "[CV 3/5; 380/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 3/5; 380/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.642 total time=   0.0s\n",
            "[CV 4/5; 380/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 4/5; 380/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.511 total time=   0.0s\n",
            "[CV 5/5; 380/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=random\n",
            "[CV 5/5; 380/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.521 total time=   0.0s\n",
            "[CV 1/5; 381/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 1/5; 381/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.709 total time=   0.0s\n",
            "[CV 2/5; 381/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 2/5; 381/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.687 total time=   0.0s\n",
            "[CV 3/5; 381/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 3/5; 381/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.713 total time=   0.0s\n",
            "[CV 4/5; 381/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 4/5; 381/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.772 total time=   0.0s\n",
            "[CV 5/5; 381/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=best\n",
            "[CV 5/5; 381/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.783 total time=   0.0s\n",
            "[CV 1/5; 382/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 1/5; 382/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.601 total time=   0.0s\n",
            "[CV 2/5; 382/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 2/5; 382/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.504 total time=   0.0s\n",
            "[CV 3/5; 382/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 3/5; 382/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.604 total time=   0.0s\n",
            "[CV 4/5; 382/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 4/5; 382/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.672 total time=   0.0s\n",
            "[CV 5/5; 382/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=random\n",
            "[CV 5/5; 382/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.569 total time=   0.0s\n",
            "[CV 1/5; 383/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 1/5; 383/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.701 total time=   0.0s\n",
            "[CV 2/5; 383/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 2/5; 383/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.690 total time=   0.0s\n",
            "[CV 3/5; 383/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 3/5; 383/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.690 total time=   0.0s\n",
            "[CV 4/5; 383/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 4/5; 383/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.772 total time=   0.0s\n",
            "[CV 5/5; 383/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=best\n",
            "[CV 5/5; 383/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=best;, score=0.787 total time=   0.0s\n",
            "[CV 1/5; 384/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 1/5; 384/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.556 total time=   0.0s\n",
            "[CV 2/5; 384/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 2/5; 384/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.552 total time=   0.0s\n",
            "[CV 3/5; 384/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 3/5; 384/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.537 total time=   0.0s\n",
            "[CV 4/5; 384/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 4/5; 384/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.515 total time=   0.0s\n",
            "[CV 5/5; 384/384] START criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=random\n",
            "[CV 5/5; 384/384] END criterion=log_loss, max_features=None, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.524 total time=   0.0s\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;knnc&#x27;,\n",
              "                 GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
              "                              param_grid=[{&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;,\n",
              "                                                         &#x27;log_loss&#x27;],\n",
              "                                           &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;,\n",
              "                                                            &#x27;log2&#x27;, None],\n",
              "                                           &#x27;min_samples_leaf&#x27;: [1, 2, 3, 4],\n",
              "                                           &#x27;min_samples_split&#x27;: [2, 3, 4, 5],\n",
              "                                           &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]}],\n",
              "                              verbose=10))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;knnc&#x27;,\n",
              "                 GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
              "                              param_grid=[{&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;,\n",
              "                                                         &#x27;log_loss&#x27;],\n",
              "                                           &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;,\n",
              "                                                            &#x27;log2&#x27;, None],\n",
              "                                           &#x27;min_samples_leaf&#x27;: [1, 2, 3, 4],\n",
              "                                           &#x27;min_samples_split&#x27;: [2, 3, 4, 5],\n",
              "                                           &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]}],\n",
              "                              verbose=10))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">knnc: GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
              "             param_grid=[{&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
              "                          &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n",
              "                          &#x27;min_samples_leaf&#x27;: [1, 2, 3, 4],\n",
              "                          &#x27;min_samples_split&#x27;: [2, 3, 4, 5],\n",
              "                          &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]}],\n",
              "             verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                ('knnc',\n",
              "                 GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
              "                              param_grid=[{'criterion': ['gini', 'entropy',\n",
              "                                                         'log_loss'],\n",
              "                                           'max_features': ['auto', 'sqrt',\n",
              "                                                            'log2', None],\n",
              "                                           'min_samples_leaf': [1, 2, 3, 4],\n",
              "                                           'min_samples_split': [2, 3, 4, 5],\n",
              "                                           'splitter': ['best', 'random']}],\n",
              "                              verbose=10))])"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "param_grid = [{'criterion': ['gini' , 'entropy', 'log_loss'],\n",
        "               'splitter': ['best' , 'random'],\n",
        "               'min_samples_split':[2 , 3, 4, 5],\n",
        "               'min_samples_leaf': [1 , 2, 3, 4],\n",
        "               'max_features': ['auto' , 'sqrt' , 'log2' , None]}]\n",
        "\n",
        "clf = Pipeline([('scaler', StandardScaler()),\n",
        "                ('knnc' , GridSearchCV(DecisionTreeClassifier(),\n",
        "                          param_grid = param_grid,\n",
        "                          cv = 5,\n",
        "                          refit = True,\n",
        "                          verbose = 10))])\n",
        "\n",
        "clf.fit(X_train , y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(min_samples_leaf=3, min_samples_split=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" checked><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(min_samples_leaf=3, min_samples_split=3)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "DecisionTreeClassifier(min_samples_leaf=3, min_samples_split=3)"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf['knnc'].best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7460758007714238"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf['knnc'].best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation f1-score: 0.745011086474501\n",
            "Test f1-score: 0.6509186351706037\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "y_val_predict = clf.predict(X_validation)\n",
        "print('Validation f1-score:' , f1_score(y_validation , y_val_predict))\n",
        "y_predict = clf.predict(X_test)\n",
        "print('Test f1-score:' , f1_score(y_test , y_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
            "[CV 1/5; 1/108] START C=0.1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 1/108] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001;, score=0.903 total time=   0.0s\n",
            "[CV 2/5; 1/108] START C=0.1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 1/108] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001;, score=0.907 total time=   0.0s\n",
            "[CV 3/5; 1/108] START C=0.1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 1/108] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001;, score=0.899 total time=   0.0s\n",
            "[CV 4/5; 1/108] START C=0.1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 1/108] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001;, score=0.918 total time=   0.0s\n",
            "[CV 5/5; 1/108] START C=0.1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 1/108] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001;, score=0.929 total time=   0.0s\n",
            "[CV 1/5; 2/108] START C=0.1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 2/108] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.903 total time=   0.0s\n",
            "[CV 2/5; 2/108] START C=0.1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 2/108] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.907 total time=   0.0s\n",
            "[CV 3/5; 2/108] START C=0.1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 2/108] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.899 total time=   0.0s\n",
            "[CV 4/5; 2/108] START C=0.1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 2/108] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.922 total time=   0.0s\n",
            "[CV 5/5; 2/108] START C=0.1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 2/108] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.929 total time=   0.0s\n",
            "[CV 1/5; 3/108] START C=0.1, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 3/108] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.903 total time=   0.0s\n",
            "[CV 2/5; 3/108] START C=0.1, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 3/108] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.907 total time=   0.0s\n",
            "[CV 3/5; 3/108] START C=0.1, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 3/108] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.899 total time=   0.0s\n",
            "[CV 4/5; 3/108] START C=0.1, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 3/108] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.922 total time=   0.0s\n",
            "[CV 5/5; 3/108] START C=0.1, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 3/108] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.929 total time=   0.0s\n",
            "[CV 1/5; 4/108] START C=0.1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 4/108] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001;, score=0.709 total time=   0.0s\n",
            "[CV 2/5; 4/108] START C=0.1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 4/108] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001;, score=0.694 total time=   0.0s\n",
            "[CV 3/5; 4/108] START C=0.1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 4/108] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001;, score=0.713 total time=   0.0s\n",
            "[CV 4/5; 4/108] START C=0.1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 4/108] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001;, score=0.694 total time=   0.0s\n",
            "[CV 5/5; 4/108] START C=0.1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 4/108] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001;, score=0.734 total time=   0.0s\n",
            "[CV 1/5; 5/108] START C=0.1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 5/108] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.709 total time=   0.0s\n",
            "[CV 2/5; 5/108] START C=0.1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 5/108] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.694 total time=   0.0s\n",
            "[CV 3/5; 5/108] START C=0.1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 5/108] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.713 total time=   0.0s\n",
            "[CV 4/5; 5/108] START C=0.1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 5/108] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.694 total time=   0.0s\n",
            "[CV 5/5; 5/108] START C=0.1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 5/108] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.734 total time=   0.0s\n",
            "[CV 1/5; 6/108] START C=0.1, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 6/108] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.709 total time=   0.0s\n",
            "[CV 2/5; 6/108] START C=0.1, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 6/108] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.694 total time=   0.0s\n",
            "[CV 3/5; 6/108] START C=0.1, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 6/108] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.713 total time=   0.0s\n",
            "[CV 4/5; 6/108] START C=0.1, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 6/108] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.694 total time=   0.0s\n",
            "[CV 5/5; 6/108] START C=0.1, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 6/108] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.734 total time=   0.0s\n",
            "[CV 1/5; 7/108] START C=0.1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 7/108] END C=0.1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001;, score=0.903 total time=   0.0s\n",
            "[CV 2/5; 7/108] START C=0.1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 7/108] END C=0.1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001;, score=0.907 total time=   0.0s\n",
            "[CV 3/5; 7/108] START C=0.1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 7/108] END C=0.1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001;, score=0.899 total time=   0.0s\n",
            "[CV 4/5; 7/108] START C=0.1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 7/108] END C=0.1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001;, score=0.918 total time=   0.0s\n",
            "[CV 5/5; 7/108] START C=0.1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 7/108] END C=0.1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001;, score=0.929 total time=   0.0s\n",
            "[CV 1/5; 8/108] START C=0.1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 8/108] END C=0.1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.903 total time=   0.0s\n",
            "[CV 2/5; 8/108] START C=0.1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 8/108] END C=0.1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.907 total time=   0.0s\n",
            "[CV 3/5; 8/108] START C=0.1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 8/108] END C=0.1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.899 total time=   0.0s\n",
            "[CV 4/5; 8/108] START C=0.1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 8/108] END C=0.1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.922 total time=   0.0s\n",
            "[CV 5/5; 8/108] START C=0.1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 8/108] END C=0.1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.929 total time=   0.0s\n",
            "[CV 1/5; 9/108] START C=0.1, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 9/108] END C=0.1, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.903 total time=   0.0s\n",
            "[CV 2/5; 9/108] START C=0.1, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 9/108] END C=0.1, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.907 total time=   0.4s\n",
            "[CV 3/5; 9/108] START C=0.1, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 9/108] END C=0.1, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.899 total time=   0.0s\n",
            "[CV 4/5; 9/108] START C=0.1, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 9/108] END C=0.1, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.922 total time=   0.0s\n",
            "[CV 5/5; 9/108] START C=0.1, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 9/108] END C=0.1, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.929 total time=   0.0s\n",
            "[CV 1/5; 10/108] START C=0.1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 10/108] END C=0.1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001;, score=0.709 total time=   0.0s\n",
            "[CV 2/5; 10/108] START C=0.1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 10/108] END C=0.1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001;, score=0.694 total time=   0.0s\n",
            "[CV 3/5; 10/108] START C=0.1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 10/108] END C=0.1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001;, score=0.713 total time=   0.0s\n",
            "[CV 4/5; 10/108] START C=0.1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 10/108] END C=0.1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001;, score=0.694 total time=   0.0s\n",
            "[CV 5/5; 10/108] START C=0.1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 10/108] END C=0.1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001;, score=0.734 total time=   0.0s\n",
            "[CV 1/5; 11/108] START C=0.1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 11/108] END C=0.1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.709 total time=   0.0s\n",
            "[CV 2/5; 11/108] START C=0.1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 11/108] END C=0.1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.694 total time=   0.0s\n",
            "[CV 3/5; 11/108] START C=0.1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 11/108] END C=0.1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.713 total time=   0.0s\n",
            "[CV 4/5; 11/108] START C=0.1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 11/108] END C=0.1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.694 total time=   0.0s\n",
            "[CV 5/5; 11/108] START C=0.1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 11/108] END C=0.1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.734 total time=   0.0s\n",
            "[CV 1/5; 12/108] START C=0.1, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 12/108] END C=0.1, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.709 total time=   0.0s\n",
            "[CV 2/5; 12/108] START C=0.1, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 12/108] END C=0.1, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.694 total time=   0.0s\n",
            "[CV 3/5; 12/108] START C=0.1, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 12/108] END C=0.1, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.713 total time=   0.0s\n",
            "[CV 4/5; 12/108] START C=0.1, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 12/108] END C=0.1, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.694 total time=   0.0s\n",
            "[CV 5/5; 12/108] START C=0.1, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 12/108] END C=0.1, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.734 total time=   0.0s\n",
            "[CV 1/5; 13/108] START C=0.1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 13/108] END C=0.1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001;, score=0.903 total time=   0.0s\n",
            "[CV 2/5; 13/108] START C=0.1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 13/108] END C=0.1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001;, score=0.907 total time=   0.0s\n",
            "[CV 3/5; 13/108] START C=0.1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 13/108] END C=0.1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001;, score=0.899 total time=   0.0s\n",
            "[CV 4/5; 13/108] START C=0.1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 13/108] END C=0.1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001;, score=0.918 total time=   0.0s\n",
            "[CV 5/5; 13/108] START C=0.1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 13/108] END C=0.1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001;, score=0.929 total time=   0.0s\n",
            "[CV 1/5; 14/108] START C=0.1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 14/108] END C=0.1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.903 total time=   0.0s\n",
            "[CV 2/5; 14/108] START C=0.1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 14/108] END C=0.1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.907 total time=   0.0s\n",
            "[CV 3/5; 14/108] START C=0.1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 14/108] END C=0.1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.899 total time=   0.0s\n",
            "[CV 4/5; 14/108] START C=0.1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 14/108] END C=0.1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.922 total time=   0.0s\n",
            "[CV 5/5; 14/108] START C=0.1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 14/108] END C=0.1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.929 total time=   0.0s\n",
            "[CV 1/5; 15/108] START C=0.1, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 15/108] END C=0.1, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.903 total time=   0.0s\n",
            "[CV 2/5; 15/108] START C=0.1, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 15/108] END C=0.1, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.907 total time=   0.2s\n",
            "[CV 3/5; 15/108] START C=0.1, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 15/108] END C=0.1, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.899 total time=   0.0s\n",
            "[CV 4/5; 15/108] START C=0.1, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 15/108] END C=0.1, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.922 total time=   0.0s\n",
            "[CV 5/5; 15/108] START C=0.1, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 15/108] END C=0.1, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.929 total time=   0.0s\n",
            "[CV 1/5; 16/108] START C=0.1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 16/108] END C=0.1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001;, score=0.709 total time=   0.0s\n",
            "[CV 2/5; 16/108] START C=0.1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 16/108] END C=0.1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001;, score=0.694 total time=   0.0s\n",
            "[CV 3/5; 16/108] START C=0.1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 16/108] END C=0.1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001;, score=0.713 total time=   0.0s\n",
            "[CV 4/5; 16/108] START C=0.1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 16/108] END C=0.1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001;, score=0.694 total time=   0.0s\n",
            "[CV 5/5; 16/108] START C=0.1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 16/108] END C=0.1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001;, score=0.734 total time=   0.0s\n",
            "[CV 1/5; 17/108] START C=0.1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 17/108] END C=0.1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.709 total time=   0.0s\n",
            "[CV 2/5; 17/108] START C=0.1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 17/108] END C=0.1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.694 total time=   0.0s\n",
            "[CV 3/5; 17/108] START C=0.1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 17/108] END C=0.1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.713 total time=   0.0s\n",
            "[CV 4/5; 17/108] START C=0.1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 17/108] END C=0.1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.694 total time=   0.0s\n",
            "[CV 5/5; 17/108] START C=0.1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 17/108] END C=0.1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.734 total time=   0.0s\n",
            "[CV 1/5; 18/108] START C=0.1, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 18/108] END C=0.1, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.709 total time=   0.0s\n",
            "[CV 2/5; 18/108] START C=0.1, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 18/108] END C=0.1, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.694 total time=   0.0s\n",
            "[CV 3/5; 18/108] START C=0.1, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 18/108] END C=0.1, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.713 total time=   0.0s\n",
            "[CV 4/5; 18/108] START C=0.1, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 18/108] END C=0.1, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.694 total time=   0.0s\n",
            "[CV 5/5; 18/108] START C=0.1, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 18/108] END C=0.1, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.734 total time=   0.0s\n",
            "[CV 1/5; 19/108] START C=1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 19/108] END C=1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001;, score=0.993 total time=   0.1s\n",
            "[CV 2/5; 19/108] START C=1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 19/108] END C=1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001;, score=0.993 total time=   0.1s\n",
            "[CV 3/5; 19/108] START C=1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 19/108] END C=1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001;, score=0.966 total time=   0.1s\n",
            "[CV 4/5; 19/108] START C=1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 19/108] END C=1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001;, score=0.978 total time=   0.1s\n",
            "[CV 5/5; 19/108] START C=1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 19/108] END C=1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001;, score=0.985 total time=   0.1s\n",
            "[CV 1/5; 20/108] START C=1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 20/108] END C=1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.993 total time=   0.3s\n",
            "[CV 2/5; 20/108] START C=1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 20/108] END C=1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.993 total time=   0.2s\n",
            "[CV 3/5; 20/108] START C=1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 20/108] END C=1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.966 total time=   0.2s\n",
            "[CV 4/5; 20/108] START C=1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 20/108] END C=1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.978 total time=   0.2s\n",
            "[CV 5/5; 20/108] START C=1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 20/108] END C=1, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.985 total time=   0.2s\n",
            "[CV 1/5; 21/108] START C=1, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 21/108] END C=1, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.993 total time=   0.4s\n",
            "[CV 2/5; 21/108] START C=1, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 21/108] END C=1, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.993 total time=   0.4s\n",
            "[CV 3/5; 21/108] START C=1, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 21/108] END C=1, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.966 total time=   0.4s\n",
            "[CV 4/5; 21/108] START C=1, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 21/108] END C=1, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.978 total time=   0.5s\n",
            "[CV 5/5; 21/108] START C=1, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 21/108] END C=1, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.985 total time=   0.4s\n",
            "[CV 1/5; 22/108] START C=1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 22/108] END C=1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001;, score=0.866 total time=   0.0s\n",
            "[CV 2/5; 22/108] START C=1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 22/108] END C=1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001;, score=0.862 total time=   0.0s\n",
            "[CV 3/5; 22/108] START C=1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 22/108] END C=1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001;, score=0.862 total time=   0.0s\n",
            "[CV 4/5; 22/108] START C=1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 22/108] END C=1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001;, score=0.866 total time=   0.0s\n",
            "[CV 5/5; 22/108] START C=1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 22/108] END C=1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001;, score=0.858 total time=   0.0s\n",
            "[CV 1/5; 23/108] START C=1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 23/108] END C=1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.866 total time=   0.0s\n",
            "[CV 2/5; 23/108] START C=1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 23/108] END C=1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.862 total time=   0.0s\n",
            "[CV 3/5; 23/108] START C=1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 23/108] END C=1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.862 total time=   0.0s\n",
            "[CV 4/5; 23/108] START C=1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 23/108] END C=1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.866 total time=   0.0s\n",
            "[CV 5/5; 23/108] START C=1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 23/108] END C=1, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.858 total time=   0.0s\n",
            "[CV 1/5; 24/108] START C=1, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 24/108] END C=1, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.866 total time=   0.0s\n",
            "[CV 2/5; 24/108] START C=1, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 24/108] END C=1, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.862 total time=   0.0s\n",
            "[CV 3/5; 24/108] START C=1, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 24/108] END C=1, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.862 total time=   0.0s\n",
            "[CV 4/5; 24/108] START C=1, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 24/108] END C=1, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.866 total time=   0.0s\n",
            "[CV 5/5; 24/108] START C=1, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 24/108] END C=1, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.858 total time=   0.0s\n",
            "[CV 1/5; 25/108] START C=1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 25/108] END C=1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001;, score=0.993 total time=   0.2s\n",
            "[CV 2/5; 25/108] START C=1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 25/108] END C=1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001;, score=0.993 total time=   0.1s\n",
            "[CV 3/5; 25/108] START C=1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 25/108] END C=1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001;, score=0.966 total time=   0.1s\n",
            "[CV 4/5; 25/108] START C=1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 25/108] END C=1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001;, score=0.974 total time=   0.2s\n",
            "[CV 5/5; 25/108] START C=1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 25/108] END C=1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001;, score=0.985 total time=   0.1s\n",
            "[CV 1/5; 26/108] START C=1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 26/108] END C=1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.993 total time=   0.2s\n",
            "[CV 2/5; 26/108] START C=1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 26/108] END C=1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.993 total time=   0.2s\n",
            "[CV 3/5; 26/108] START C=1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 26/108] END C=1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.966 total time=   0.2s\n",
            "[CV 4/5; 26/108] START C=1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 26/108] END C=1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.978 total time=   0.2s\n",
            "[CV 5/5; 26/108] START C=1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 26/108] END C=1, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.985 total time=   0.2s\n",
            "[CV 1/5; 27/108] START C=1, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 27/108] END C=1, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.993 total time=   0.4s\n",
            "[CV 2/5; 27/108] START C=1, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 27/108] END C=1, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.993 total time=   0.4s\n",
            "[CV 3/5; 27/108] START C=1, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 27/108] END C=1, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.966 total time=   0.3s\n",
            "[CV 4/5; 27/108] START C=1, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 27/108] END C=1, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.978 total time=   0.4s\n",
            "[CV 5/5; 27/108] START C=1, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 27/108] END C=1, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.985 total time=   0.4s\n",
            "[CV 1/5; 28/108] START C=1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 28/108] END C=1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001;, score=0.866 total time=   0.0s\n",
            "[CV 2/5; 28/108] START C=1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 28/108] END C=1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001;, score=0.862 total time=   0.0s\n",
            "[CV 3/5; 28/108] START C=1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 28/108] END C=1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001;, score=0.862 total time=   0.0s\n",
            "[CV 4/5; 28/108] START C=1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 28/108] END C=1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001;, score=0.866 total time=   0.0s\n",
            "[CV 5/5; 28/108] START C=1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 28/108] END C=1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001;, score=0.858 total time=   0.0s\n",
            "[CV 1/5; 29/108] START C=1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 29/108] END C=1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.866 total time=   0.0s\n",
            "[CV 2/5; 29/108] START C=1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 29/108] END C=1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.862 total time=   0.0s\n",
            "[CV 3/5; 29/108] START C=1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 29/108] END C=1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.862 total time=   0.0s\n",
            "[CV 4/5; 29/108] START C=1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 29/108] END C=1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.866 total time=   0.0s\n",
            "[CV 5/5; 29/108] START C=1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 29/108] END C=1, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.858 total time=   0.0s\n",
            "[CV 1/5; 30/108] START C=1, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 30/108] END C=1, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.866 total time=   0.0s\n",
            "[CV 2/5; 30/108] START C=1, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 30/108] END C=1, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.862 total time=   0.0s\n",
            "[CV 3/5; 30/108] START C=1, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 30/108] END C=1, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.862 total time=   0.0s\n",
            "[CV 4/5; 30/108] START C=1, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 30/108] END C=1, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.866 total time=   0.0s\n",
            "[CV 5/5; 30/108] START C=1, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 30/108] END C=1, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.858 total time=   0.0s\n",
            "[CV 1/5; 31/108] START C=1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 31/108] END C=1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001;, score=0.993 total time=   0.2s\n",
            "[CV 2/5; 31/108] START C=1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 31/108] END C=1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001;, score=0.993 total time=   0.1s\n",
            "[CV 3/5; 31/108] START C=1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 31/108] END C=1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001;, score=0.966 total time=   0.1s\n",
            "[CV 4/5; 31/108] START C=1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 31/108] END C=1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001;, score=0.974 total time=   0.2s\n",
            "[CV 5/5; 31/108] START C=1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 31/108] END C=1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001;, score=0.985 total time=   0.1s\n",
            "[CV 1/5; 32/108] START C=1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 32/108] END C=1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.993 total time=   0.3s\n",
            "[CV 2/5; 32/108] START C=1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 32/108] END C=1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.993 total time=   0.2s\n",
            "[CV 3/5; 32/108] START C=1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 32/108] END C=1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.966 total time=   0.2s\n",
            "[CV 4/5; 32/108] START C=1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 32/108] END C=1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.978 total time=   0.2s\n",
            "[CV 5/5; 32/108] START C=1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 32/108] END C=1, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.985 total time=   0.2s\n",
            "[CV 1/5; 33/108] START C=1, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 33/108] END C=1, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.993 total time=   0.5s\n",
            "[CV 2/5; 33/108] START C=1, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 33/108] END C=1, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.993 total time=   0.4s\n",
            "[CV 3/5; 33/108] START C=1, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 33/108] END C=1, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.966 total time=   0.4s\n",
            "[CV 4/5; 33/108] START C=1, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 33/108] END C=1, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.978 total time=   0.5s\n",
            "[CV 5/5; 33/108] START C=1, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 33/108] END C=1, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.985 total time=   0.4s\n",
            "[CV 1/5; 34/108] START C=1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 34/108] END C=1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001;, score=0.866 total time=   0.0s\n",
            "[CV 2/5; 34/108] START C=1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 34/108] END C=1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001;, score=0.862 total time=   0.0s\n",
            "[CV 3/5; 34/108] START C=1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 34/108] END C=1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001;, score=0.862 total time=   0.0s\n",
            "[CV 4/5; 34/108] START C=1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 34/108] END C=1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001;, score=0.866 total time=   0.0s\n",
            "[CV 5/5; 34/108] START C=1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 34/108] END C=1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001;, score=0.858 total time=   0.0s\n",
            "[CV 1/5; 35/108] START C=1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 35/108] END C=1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.866 total time=   0.0s\n",
            "[CV 2/5; 35/108] START C=1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 35/108] END C=1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.862 total time=   0.0s\n",
            "[CV 3/5; 35/108] START C=1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 35/108] END C=1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.862 total time=   0.0s\n",
            "[CV 4/5; 35/108] START C=1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 35/108] END C=1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.866 total time=   0.0s\n",
            "[CV 5/5; 35/108] START C=1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 35/108] END C=1, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.858 total time=   0.0s\n",
            "[CV 1/5; 36/108] START C=1, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 36/108] END C=1, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.866 total time=   0.0s\n",
            "[CV 2/5; 36/108] START C=1, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 36/108] END C=1, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.862 total time=   0.0s\n",
            "[CV 3/5; 36/108] START C=1, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 36/108] END C=1, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.862 total time=   0.0s\n",
            "[CV 4/5; 36/108] START C=1, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 36/108] END C=1, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.866 total time=   0.0s\n",
            "[CV 5/5; 36/108] START C=1, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 36/108] END C=1, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.858 total time=   0.0s\n",
            "[CV 1/5; 37/108] START C=10.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 37/108] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001;, score=0.981 total time=   0.9s\n",
            "[CV 2/5; 37/108] START C=10.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 37/108] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001;, score=0.981 total time=   1.0s\n",
            "[CV 3/5; 37/108] START C=10.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 37/108] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001;, score=0.966 total time=   1.0s\n",
            "[CV 4/5; 37/108] START C=10.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 37/108] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001;, score=0.974 total time=   0.9s\n",
            "[CV 5/5; 37/108] START C=10.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 37/108] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001;, score=0.981 total time=   0.9s\n",
            "[CV 1/5; 38/108] START C=10.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 38/108] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.981 total time=   2.3s\n",
            "[CV 2/5; 38/108] START C=10.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 38/108] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.981 total time=   2.5s\n",
            "[CV 3/5; 38/108] START C=10.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 38/108] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.966 total time=   2.7s\n",
            "[CV 4/5; 38/108] START C=10.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 38/108] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.974 total time=   2.2s\n",
            "[CV 5/5; 38/108] START C=10.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 38/108] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.981 total time=   2.3s\n",
            "[CV 1/5; 39/108] START C=10.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 39/108] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.981 total time=   3.9s\n",
            "[CV 2/5; 39/108] START C=10.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 39/108] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.981 total time=   4.0s\n",
            "[CV 3/5; 39/108] START C=10.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 39/108] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.966 total time=   3.9s\n",
            "[CV 4/5; 39/108] START C=10.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 39/108] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.974 total time=   3.4s\n",
            "[CV 5/5; 39/108] START C=10.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 39/108] END C=10.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.981 total time=   3.9s\n",
            "[CV 1/5; 40/108] START C=10.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 40/108] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001;, score=0.974 total time=   0.0s\n",
            "[CV 2/5; 40/108] START C=10.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 40/108] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 3/5; 40/108] START C=10.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 40/108] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 40/108] START C=10.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 40/108] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001;, score=0.959 total time=   0.0s\n",
            "[CV 5/5; 40/108] START C=10.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 40/108] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001;, score=0.940 total time=   0.0s\n",
            "[CV 1/5; 41/108] START C=10.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 41/108] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.974 total time=   0.0s\n",
            "[CV 2/5; 41/108] START C=10.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 41/108] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 3/5; 41/108] START C=10.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 41/108] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 41/108] START C=10.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 41/108] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.959 total time=   0.0s\n",
            "[CV 5/5; 41/108] START C=10.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 41/108] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 1/5; 42/108] START C=10.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 42/108] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.974 total time=   0.0s\n",
            "[CV 2/5; 42/108] START C=10.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 42/108] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 3/5; 42/108] START C=10.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 42/108] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 42/108] START C=10.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 42/108] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.959 total time=   0.0s\n",
            "[CV 5/5; 42/108] START C=10.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 42/108] END C=10.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 1/5; 43/108] START C=10.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 43/108] END C=10.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001;, score=0.981 total time=   1.1s\n",
            "[CV 2/5; 43/108] START C=10.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 43/108] END C=10.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001;, score=0.981 total time=   1.0s\n",
            "[CV 3/5; 43/108] START C=10.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 43/108] END C=10.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001;, score=0.966 total time=   0.9s\n",
            "[CV 4/5; 43/108] START C=10.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 43/108] END C=10.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001;, score=0.974 total time=   0.9s\n",
            "[CV 5/5; 43/108] START C=10.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 43/108] END C=10.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001;, score=0.981 total time=   0.9s\n",
            "[CV 1/5; 44/108] START C=10.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 44/108] END C=10.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.981 total time=   2.3s\n",
            "[CV 2/5; 44/108] START C=10.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 44/108] END C=10.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.981 total time=   2.6s\n",
            "[CV 3/5; 44/108] START C=10.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 44/108] END C=10.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.966 total time=   2.3s\n",
            "[CV 4/5; 44/108] START C=10.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 44/108] END C=10.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.974 total time=   1.9s\n",
            "[CV 5/5; 44/108] START C=10.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 44/108] END C=10.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.981 total time=   2.5s\n",
            "[CV 1/5; 45/108] START C=10.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 45/108] END C=10.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.981 total time=   3.7s\n",
            "[CV 2/5; 45/108] START C=10.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 45/108] END C=10.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.981 total time=   4.1s\n",
            "[CV 3/5; 45/108] START C=10.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 45/108] END C=10.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.966 total time=   4.2s\n",
            "[CV 4/5; 45/108] START C=10.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 45/108] END C=10.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.974 total time=   3.2s\n",
            "[CV 5/5; 45/108] START C=10.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 45/108] END C=10.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.981 total time=   4.0s\n",
            "[CV 1/5; 46/108] START C=10.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 46/108] END C=10.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001;, score=0.974 total time=   0.0s\n",
            "[CV 2/5; 46/108] START C=10.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 46/108] END C=10.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 3/5; 46/108] START C=10.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 46/108] END C=10.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 46/108] START C=10.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 46/108] END C=10.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001;, score=0.959 total time=   0.0s\n",
            "[CV 5/5; 46/108] START C=10.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 46/108] END C=10.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001;, score=0.940 total time=   0.0s\n",
            "[CV 1/5; 47/108] START C=10.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 47/108] END C=10.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.974 total time=   0.0s\n",
            "[CV 2/5; 47/108] START C=10.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 47/108] END C=10.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 3/5; 47/108] START C=10.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 47/108] END C=10.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 47/108] START C=10.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 47/108] END C=10.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.959 total time=   0.0s\n",
            "[CV 5/5; 47/108] START C=10.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 47/108] END C=10.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 1/5; 48/108] START C=10.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 48/108] END C=10.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.974 total time=   0.0s\n",
            "[CV 2/5; 48/108] START C=10.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 48/108] END C=10.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 3/5; 48/108] START C=10.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 48/108] END C=10.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 48/108] START C=10.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 48/108] END C=10.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.959 total time=   0.0s\n",
            "[CV 5/5; 48/108] START C=10.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 48/108] END C=10.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 1/5; 49/108] START C=10.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 49/108] END C=10.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001;, score=0.981 total time=   0.8s\n",
            "[CV 2/5; 49/108] START C=10.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 49/108] END C=10.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001;, score=0.981 total time=   1.1s\n",
            "[CV 3/5; 49/108] START C=10.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 49/108] END C=10.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001;, score=0.966 total time=   1.1s\n",
            "[CV 4/5; 49/108] START C=10.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 49/108] END C=10.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001;, score=0.974 total time=   1.0s\n",
            "[CV 5/5; 49/108] START C=10.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 49/108] END C=10.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001;, score=0.981 total time=   1.0s\n",
            "[CV 1/5; 50/108] START C=10.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 50/108] END C=10.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.981 total time=   2.2s\n",
            "[CV 2/5; 50/108] START C=10.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 50/108] END C=10.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.981 total time=   2.4s\n",
            "[CV 3/5; 50/108] START C=10.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 50/108] END C=10.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.966 total time=   2.3s\n",
            "[CV 4/5; 50/108] START C=10.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 50/108] END C=10.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.974 total time=   2.0s\n",
            "[CV 5/5; 50/108] START C=10.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 50/108] END C=10.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.981 total time=   2.4s\n",
            "[CV 1/5; 51/108] START C=10.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 51/108] END C=10.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.981 total time=   3.7s\n",
            "[CV 2/5; 51/108] START C=10.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 51/108] END C=10.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.981 total time=   4.1s\n",
            "[CV 3/5; 51/108] START C=10.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 51/108] END C=10.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.966 total time=   4.4s\n",
            "[CV 4/5; 51/108] START C=10.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 51/108] END C=10.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.974 total time=   3.3s\n",
            "[CV 5/5; 51/108] START C=10.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 51/108] END C=10.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.981 total time=   4.1s\n",
            "[CV 1/5; 52/108] START C=10.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 52/108] END C=10.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001;, score=0.974 total time=   0.0s\n",
            "[CV 2/5; 52/108] START C=10.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 52/108] END C=10.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001;, score=0.948 total time=   0.0s\n",
            "[CV 3/5; 52/108] START C=10.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 52/108] END C=10.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 52/108] START C=10.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 52/108] END C=10.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001;, score=0.959 total time=   0.0s\n",
            "[CV 5/5; 52/108] START C=10.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 52/108] END C=10.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001;, score=0.940 total time=   0.0s\n",
            "[CV 1/5; 53/108] START C=10.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 53/108] END C=10.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.974 total time=   0.0s\n",
            "[CV 2/5; 53/108] START C=10.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 53/108] END C=10.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.948 total time=   0.0s\n",
            "[CV 3/5; 53/108] START C=10.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 53/108] END C=10.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 53/108] START C=10.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 53/108] END C=10.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.959 total time=   0.0s\n",
            "[CV 5/5; 53/108] START C=10.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 53/108] END C=10.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.940 total time=   0.0s\n",
            "[CV 1/5; 54/108] START C=10.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 54/108] END C=10.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.974 total time=   0.0s\n",
            "[CV 2/5; 54/108] START C=10.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 54/108] END C=10.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.948 total time=   0.0s\n",
            "[CV 3/5; 54/108] START C=10.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 54/108] END C=10.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.944 total time=   0.0s\n",
            "[CV 4/5; 54/108] START C=10.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 54/108] END C=10.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.959 total time=   0.0s\n",
            "[CV 5/5; 54/108] START C=10.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 54/108] END C=10.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.940 total time=   0.0s\n",
            "[CV 1/5; 55/108] START C=100.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 55/108] END C=100.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001;, score=0.985 total time=   2.0s\n",
            "[CV 2/5; 55/108] START C=100.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 55/108] END C=100.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001;, score=0.989 total time=   2.0s\n",
            "[CV 3/5; 55/108] START C=100.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 55/108] END C=100.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001;, score=0.963 total time=   2.1s\n",
            "[CV 4/5; 55/108] START C=100.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 55/108] END C=100.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001;, score=0.974 total time=   1.5s\n",
            "[CV 5/5; 55/108] START C=100.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 55/108] END C=100.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001;, score=0.981 total time=   2.1s\n",
            "[CV 1/5; 56/108] START C=100.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 56/108] END C=100.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.985 total time=   5.9s\n",
            "[CV 2/5; 56/108] START C=100.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 56/108] END C=100.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.989 total time=   5.5s\n",
            "[CV 3/5; 56/108] START C=100.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 56/108] END C=100.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.966 total time=   8.8s\n",
            "[CV 4/5; 56/108] START C=100.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 56/108] END C=100.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.974 total time=   4.4s\n",
            "[CV 5/5; 56/108] START C=100.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 56/108] END C=100.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.981 total time=   5.6s\n",
            "[CV 1/5; 57/108] START C=100.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 57/108] END C=100.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.985 total time=  10.8s\n",
            "[CV 2/5; 57/108] START C=100.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 57/108] END C=100.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.989 total time=  10.1s\n",
            "[CV 3/5; 57/108] START C=100.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 57/108] END C=100.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.966 total time=  18.8s\n",
            "[CV 4/5; 57/108] START C=100.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 57/108] END C=100.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.974 total time=   8.1s\n",
            "[CV 5/5; 57/108] START C=100.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 57/108] END C=100.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.981 total time=   9.7s\n",
            "[CV 1/5; 58/108] START C=100.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 58/108] END C=100.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001;, score=0.978 total time=   0.0s\n",
            "[CV 2/5; 58/108] START C=100.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 58/108] END C=100.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001;, score=0.989 total time=   0.0s\n",
            "[CV 3/5; 58/108] START C=100.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 58/108] END C=100.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001;, score=0.966 total time=   0.0s\n",
            "[CV 4/5; 58/108] START C=100.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 58/108] END C=100.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001;, score=0.974 total time=   0.0s\n",
            "[CV 5/5; 58/108] START C=100.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 58/108] END C=100.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001;, score=0.978 total time=   0.0s\n",
            "[CV 1/5; 59/108] START C=100.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 59/108] END C=100.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.978 total time=   0.0s\n",
            "[CV 2/5; 59/108] START C=100.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 59/108] END C=100.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.989 total time=   0.0s\n",
            "[CV 3/5; 59/108] START C=100.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 59/108] END C=100.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.966 total time=   0.0s\n",
            "[CV 4/5; 59/108] START C=100.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 59/108] END C=100.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.974 total time=   0.0s\n",
            "[CV 5/5; 59/108] START C=100.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 59/108] END C=100.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.978 total time=   0.0s\n",
            "[CV 1/5; 60/108] START C=100.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 60/108] END C=100.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.978 total time=   0.0s\n",
            "[CV 2/5; 60/108] START C=100.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 60/108] END C=100.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.989 total time=   0.0s\n",
            "[CV 3/5; 60/108] START C=100.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 60/108] END C=100.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.966 total time=   0.0s\n",
            "[CV 4/5; 60/108] START C=100.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 60/108] END C=100.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.974 total time=   0.0s\n",
            "[CV 5/5; 60/108] START C=100.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 60/108] END C=100.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.978 total time=   0.0s\n",
            "[CV 1/5; 61/108] START C=100.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 61/108] END C=100.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001;, score=0.985 total time=   2.3s\n",
            "[CV 2/5; 61/108] START C=100.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 61/108] END C=100.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001;, score=0.989 total time=   2.1s\n",
            "[CV 3/5; 61/108] START C=100.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 61/108] END C=100.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001;, score=0.963 total time=   2.3s\n",
            "[CV 4/5; 61/108] START C=100.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 61/108] END C=100.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001;, score=0.974 total time=   1.5s\n",
            "[CV 5/5; 61/108] START C=100.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 61/108] END C=100.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001;, score=0.981 total time=   2.1s\n",
            "[CV 1/5; 62/108] START C=100.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 62/108] END C=100.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.985 total time=   5.9s\n",
            "[CV 2/5; 62/108] START C=100.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 62/108] END C=100.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.989 total time=   5.5s\n",
            "[CV 3/5; 62/108] START C=100.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 62/108] END C=100.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.966 total time=   9.5s\n",
            "[CV 4/5; 62/108] START C=100.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 62/108] END C=100.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.974 total time=   4.5s\n",
            "[CV 5/5; 62/108] START C=100.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 62/108] END C=100.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.981 total time=   5.6s\n",
            "[CV 1/5; 63/108] START C=100.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 63/108] END C=100.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.985 total time=  10.6s\n",
            "[CV 2/5; 63/108] START C=100.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 63/108] END C=100.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.989 total time=  10.3s\n",
            "[CV 3/5; 63/108] START C=100.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 63/108] END C=100.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.966 total time=  20.5s\n",
            "[CV 4/5; 63/108] START C=100.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 63/108] END C=100.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.974 total time=   8.9s\n",
            "[CV 5/5; 63/108] START C=100.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 63/108] END C=100.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.981 total time=   9.8s\n",
            "[CV 1/5; 64/108] START C=100.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 64/108] END C=100.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001;, score=0.978 total time=   0.0s\n",
            "[CV 2/5; 64/108] START C=100.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 64/108] END C=100.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001;, score=0.989 total time=   0.0s\n",
            "[CV 3/5; 64/108] START C=100.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 64/108] END C=100.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001;, score=0.966 total time=   0.0s\n",
            "[CV 4/5; 64/108] START C=100.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 64/108] END C=100.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001;, score=0.974 total time=   0.0s\n",
            "[CV 5/5; 64/108] START C=100.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 64/108] END C=100.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001;, score=0.978 total time=   0.0s\n",
            "[CV 1/5; 65/108] START C=100.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 65/108] END C=100.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.978 total time=   0.0s\n",
            "[CV 2/5; 65/108] START C=100.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 65/108] END C=100.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.989 total time=   0.0s\n",
            "[CV 3/5; 65/108] START C=100.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 65/108] END C=100.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.966 total time=   0.0s\n",
            "[CV 4/5; 65/108] START C=100.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 65/108] END C=100.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.974 total time=   0.0s\n",
            "[CV 5/5; 65/108] START C=100.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 65/108] END C=100.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.978 total time=   0.0s\n",
            "[CV 1/5; 66/108] START C=100.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 66/108] END C=100.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.978 total time=   0.0s\n",
            "[CV 2/5; 66/108] START C=100.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 66/108] END C=100.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.989 total time=   0.0s\n",
            "[CV 3/5; 66/108] START C=100.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 66/108] END C=100.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.966 total time=   0.0s\n",
            "[CV 4/5; 66/108] START C=100.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 66/108] END C=100.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.974 total time=   0.0s\n",
            "[CV 5/5; 66/108] START C=100.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 66/108] END C=100.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.978 total time=   0.0s\n",
            "[CV 1/5; 67/108] START C=100.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 67/108] END C=100.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001;, score=0.985 total time=   2.1s\n",
            "[CV 2/5; 67/108] START C=100.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 67/108] END C=100.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001;, score=0.989 total time=   2.0s\n",
            "[CV 3/5; 67/108] START C=100.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 67/108] END C=100.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001;, score=0.966 total time=   2.6s\n",
            "[CV 4/5; 67/108] START C=100.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 67/108] END C=100.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001;, score=0.974 total time=   1.8s\n",
            "[CV 5/5; 67/108] START C=100.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 67/108] END C=100.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001;, score=0.981 total time=   2.5s\n",
            "[CV 1/5; 68/108] START C=100.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 68/108] END C=100.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.985 total time=   5.9s\n",
            "[CV 2/5; 68/108] START C=100.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 68/108] END C=100.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.989 total time=   5.8s\n",
            "[CV 3/5; 68/108] START C=100.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 68/108] END C=100.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.966 total time=   9.7s\n",
            "[CV 4/5; 68/108] START C=100.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 68/108] END C=100.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.974 total time=   4.7s\n",
            "[CV 5/5; 68/108] START C=100.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 68/108] END C=100.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.981 total time=   5.9s\n",
            "[CV 1/5; 69/108] START C=100.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 69/108] END C=100.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.985 total time=  10.4s\n",
            "[CV 2/5; 69/108] START C=100.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 69/108] END C=100.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.989 total time=   9.7s\n",
            "[CV 3/5; 69/108] START C=100.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 69/108] END C=100.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.966 total time=  19.5s\n",
            "[CV 4/5; 69/108] START C=100.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 69/108] END C=100.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.974 total time=   8.1s\n",
            "[CV 5/5; 69/108] START C=100.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 69/108] END C=100.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.981 total time=  10.2s\n",
            "[CV 1/5; 70/108] START C=100.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 70/108] END C=100.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001;, score=0.978 total time=   0.0s\n",
            "[CV 2/5; 70/108] START C=100.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 70/108] END C=100.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001;, score=0.989 total time=   0.0s\n",
            "[CV 3/5; 70/108] START C=100.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 70/108] END C=100.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001;, score=0.966 total time=   0.0s\n",
            "[CV 4/5; 70/108] START C=100.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 70/108] END C=100.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001;, score=0.974 total time=   0.0s\n",
            "[CV 5/5; 70/108] START C=100.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 70/108] END C=100.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001;, score=0.978 total time=   0.0s\n",
            "[CV 1/5; 71/108] START C=100.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 71/108] END C=100.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.978 total time=   0.0s\n",
            "[CV 2/5; 71/108] START C=100.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 71/108] END C=100.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.989 total time=   0.0s\n",
            "[CV 3/5; 71/108] START C=100.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 71/108] END C=100.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.966 total time=   0.0s\n",
            "[CV 4/5; 71/108] START C=100.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 71/108] END C=100.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.974 total time=   0.0s\n",
            "[CV 5/5; 71/108] START C=100.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 71/108] END C=100.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.978 total time=   0.0s\n",
            "[CV 1/5; 72/108] START C=100.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 72/108] END C=100.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.978 total time=   0.0s\n",
            "[CV 2/5; 72/108] START C=100.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 72/108] END C=100.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.989 total time=   0.0s\n",
            "[CV 3/5; 72/108] START C=100.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 72/108] END C=100.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.966 total time=   0.0s\n",
            "[CV 4/5; 72/108] START C=100.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 72/108] END C=100.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.974 total time=   0.0s\n",
            "[CV 5/5; 72/108] START C=100.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 72/108] END C=100.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.978 total time=   0.0s\n",
            "[CV 1/5; 73/108] START C=1000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 73/108] END C=1000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001;, score=0.985 total time=   2.6s\n",
            "[CV 2/5; 73/108] START C=1000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 73/108] END C=1000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001;, score=0.985 total time=   2.7s\n",
            "[CV 3/5; 73/108] START C=1000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 73/108] END C=1000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001;, score=0.966 total time=   2.9s\n",
            "[CV 4/5; 73/108] START C=1000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 73/108] END C=1000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001;, score=0.974 total time=   1.8s\n",
            "[CV 5/5; 73/108] START C=1000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 73/108] END C=1000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001;, score=0.974 total time=   2.5s\n",
            "[CV 1/5; 74/108] START C=1000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 74/108] END C=1000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.981 total time=   8.0s\n",
            "[CV 2/5; 74/108] START C=1000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 74/108] END C=1000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.989 total time=   7.5s\n",
            "[CV 3/5; 74/108] START C=1000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 74/108] END C=1000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.966 total time=  12.5s\n",
            "[CV 4/5; 74/108] START C=1000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 74/108] END C=1000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.974 total time=   6.1s\n",
            "[CV 5/5; 74/108] START C=1000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 74/108] END C=1000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.970 total time=   8.0s\n",
            "[CV 1/5; 75/108] START C=1000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 75/108] END C=1000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.981 total time=  18.1s\n",
            "[CV 2/5; 75/108] START C=1000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 75/108] END C=1000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.985 total time=  16.4s\n",
            "[CV 3/5; 75/108] START C=1000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 75/108] END C=1000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.966 total time=  28.0s\n",
            "[CV 4/5; 75/108] START C=1000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 75/108] END C=1000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.974 total time=  16.0s\n",
            "[CV 5/5; 75/108] START C=1000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 75/108] END C=1000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.970 total time=  14.9s\n",
            "[CV 1/5; 76/108] START C=1000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 76/108] END C=1000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001;, score=0.981 total time=   0.0s\n",
            "[CV 2/5; 76/108] START C=1000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 76/108] END C=1000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001;, score=0.989 total time=   0.0s\n",
            "[CV 3/5; 76/108] START C=1000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 76/108] END C=1000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001;, score=0.963 total time=   0.0s\n",
            "[CV 4/5; 76/108] START C=1000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 76/108] END C=1000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001;, score=0.970 total time=   0.0s\n",
            "[CV 5/5; 76/108] START C=1000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 76/108] END C=1000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001;, score=0.974 total time=   0.0s\n",
            "[CV 1/5; 77/108] START C=1000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 77/108] END C=1000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.978 total time=   0.0s\n",
            "[CV 2/5; 77/108] START C=1000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 77/108] END C=1000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.989 total time=   0.0s\n",
            "[CV 3/5; 77/108] START C=1000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 77/108] END C=1000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.963 total time=   0.0s\n",
            "[CV 4/5; 77/108] START C=1000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 77/108] END C=1000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.970 total time=   0.0s\n",
            "[CV 5/5; 77/108] START C=1000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 77/108] END C=1000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.974 total time=   0.0s\n",
            "[CV 1/5; 78/108] START C=1000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 78/108] END C=1000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.978 total time=   0.0s\n",
            "[CV 2/5; 78/108] START C=1000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 78/108] END C=1000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.989 total time=   0.0s\n",
            "[CV 3/5; 78/108] START C=1000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 78/108] END C=1000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.963 total time=   0.0s\n",
            "[CV 4/5; 78/108] START C=1000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 78/108] END C=1000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.970 total time=   0.0s\n",
            "[CV 5/5; 78/108] START C=1000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 78/108] END C=1000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.974 total time=   0.0s\n",
            "[CV 1/5; 79/108] START C=1000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 79/108] END C=1000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001;, score=0.985 total time=   2.4s\n",
            "[CV 2/5; 79/108] START C=1000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 79/108] END C=1000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001;, score=0.985 total time=   2.4s\n",
            "[CV 3/5; 79/108] START C=1000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 79/108] END C=1000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001;, score=0.966 total time=   3.3s\n",
            "[CV 4/5; 79/108] START C=1000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 79/108] END C=1000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001;, score=0.974 total time=   2.1s\n",
            "[CV 5/5; 79/108] START C=1000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 79/108] END C=1000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001;, score=0.974 total time=   2.3s\n",
            "[CV 1/5; 80/108] START C=1000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 80/108] END C=1000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.981 total time=   8.1s\n",
            "[CV 2/5; 80/108] START C=1000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 80/108] END C=1000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.989 total time=   7.3s\n",
            "[CV 3/5; 80/108] START C=1000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 80/108] END C=1000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.966 total time=  13.2s\n",
            "[CV 4/5; 80/108] START C=1000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 80/108] END C=1000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.974 total time=   6.5s\n",
            "[CV 5/5; 80/108] START C=1000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 80/108] END C=1000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.970 total time=   7.3s\n",
            "[CV 1/5; 81/108] START C=1000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 81/108] END C=1000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.981 total time=  21.3s\n",
            "[CV 2/5; 81/108] START C=1000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 81/108] END C=1000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.985 total time=  17.2s\n",
            "[CV 3/5; 81/108] START C=1000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 81/108] END C=1000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.966 total time=  29.8s\n",
            "[CV 4/5; 81/108] START C=1000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 81/108] END C=1000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.974 total time=  15.6s\n",
            "[CV 5/5; 81/108] START C=1000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 81/108] END C=1000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.970 total time=  14.3s\n",
            "[CV 1/5; 82/108] START C=1000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 82/108] END C=1000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001;, score=0.981 total time=   0.0s\n",
            "[CV 2/5; 82/108] START C=1000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 82/108] END C=1000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001;, score=0.989 total time=   0.0s\n",
            "[CV 3/5; 82/108] START C=1000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 82/108] END C=1000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001;, score=0.963 total time=   0.0s\n",
            "[CV 4/5; 82/108] START C=1000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 82/108] END C=1000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001;, score=0.970 total time=   0.0s\n",
            "[CV 5/5; 82/108] START C=1000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 82/108] END C=1000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001;, score=0.974 total time=   0.0s\n",
            "[CV 1/5; 83/108] START C=1000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 83/108] END C=1000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.978 total time=   0.0s\n",
            "[CV 2/5; 83/108] START C=1000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 83/108] END C=1000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.989 total time=   0.0s\n",
            "[CV 3/5; 83/108] START C=1000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 83/108] END C=1000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.963 total time=   0.0s\n",
            "[CV 4/5; 83/108] START C=1000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 83/108] END C=1000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.970 total time=   0.0s\n",
            "[CV 5/5; 83/108] START C=1000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 83/108] END C=1000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.974 total time=   0.0s\n",
            "[CV 1/5; 84/108] START C=1000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 84/108] END C=1000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.978 total time=   0.0s\n",
            "[CV 2/5; 84/108] START C=1000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 84/108] END C=1000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.989 total time=   0.0s\n",
            "[CV 3/5; 84/108] START C=1000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 84/108] END C=1000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.963 total time=   0.0s\n",
            "[CV 4/5; 84/108] START C=1000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 84/108] END C=1000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.970 total time=   0.0s\n",
            "[CV 5/5; 84/108] START C=1000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 84/108] END C=1000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.974 total time=   0.0s\n",
            "[CV 1/5; 85/108] START C=1000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 85/108] END C=1000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001;, score=0.985 total time=   2.6s\n",
            "[CV 2/5; 85/108] START C=1000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 85/108] END C=1000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001;, score=0.985 total time=   2.8s\n",
            "[CV 3/5; 85/108] START C=1000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 85/108] END C=1000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001;, score=0.966 total time=   2.9s\n",
            "[CV 4/5; 85/108] START C=1000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 85/108] END C=1000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001;, score=0.974 total time=   2.2s\n",
            "[CV 5/5; 85/108] START C=1000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 85/108] END C=1000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001;, score=0.974 total time=   2.5s\n",
            "[CV 1/5; 86/108] START C=1000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 86/108] END C=1000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.981 total time=   8.0s\n",
            "[CV 2/5; 86/108] START C=1000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 86/108] END C=1000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.989 total time=   7.4s\n",
            "[CV 3/5; 86/108] START C=1000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 86/108] END C=1000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.966 total time=  12.2s\n",
            "[CV 4/5; 86/108] START C=1000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 86/108] END C=1000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.974 total time=   6.4s\n",
            "[CV 5/5; 86/108] START C=1000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 86/108] END C=1000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.970 total time=   7.1s\n",
            "[CV 1/5; 87/108] START C=1000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 87/108] END C=1000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.981 total time=  18.8s\n",
            "[CV 2/5; 87/108] START C=1000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 87/108] END C=1000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.985 total time=  16.9s\n",
            "[CV 3/5; 87/108] START C=1000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 87/108] END C=1000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.966 total time=  28.9s\n",
            "[CV 4/5; 87/108] START C=1000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 87/108] END C=1000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.974 total time=  14.9s\n",
            "[CV 5/5; 87/108] START C=1000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 87/108] END C=1000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.970 total time=  13.8s\n",
            "[CV 1/5; 88/108] START C=1000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 88/108] END C=1000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001;, score=0.981 total time=   0.0s\n",
            "[CV 2/5; 88/108] START C=1000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 88/108] END C=1000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001;, score=0.989 total time=   0.0s\n",
            "[CV 3/5; 88/108] START C=1000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 88/108] END C=1000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001;, score=0.963 total time=   0.0s\n",
            "[CV 4/5; 88/108] START C=1000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 88/108] END C=1000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001;, score=0.970 total time=   0.0s\n",
            "[CV 5/5; 88/108] START C=1000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 88/108] END C=1000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001;, score=0.974 total time=   0.0s\n",
            "[CV 1/5; 89/108] START C=1000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 89/108] END C=1000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.978 total time=   0.0s\n",
            "[CV 2/5; 89/108] START C=1000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 89/108] END C=1000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.989 total time=   0.0s\n",
            "[CV 3/5; 89/108] START C=1000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 89/108] END C=1000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.963 total time=   0.0s\n",
            "[CV 4/5; 89/108] START C=1000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 89/108] END C=1000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.970 total time=   0.0s\n",
            "[CV 5/5; 89/108] START C=1000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 89/108] END C=1000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.974 total time=   0.0s\n",
            "[CV 1/5; 90/108] START C=1000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 90/108] END C=1000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.978 total time=   0.0s\n",
            "[CV 2/5; 90/108] START C=1000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 90/108] END C=1000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.989 total time=   0.0s\n",
            "[CV 3/5; 90/108] START C=1000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 90/108] END C=1000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.963 total time=   0.0s\n",
            "[CV 4/5; 90/108] START C=1000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 90/108] END C=1000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.970 total time=   0.0s\n",
            "[CV 5/5; 90/108] START C=1000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 90/108] END C=1000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.974 total time=   0.0s\n",
            "[CV 1/5; 91/108] START C=10000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 91/108] END C=10000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001;, score=0.985 total time=   2.5s\n",
            "[CV 2/5; 91/108] START C=10000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 91/108] END C=10000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001;, score=0.985 total time=   2.3s\n",
            "[CV 3/5; 91/108] START C=10000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 91/108] END C=10000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001;, score=0.966 total time=   3.3s\n",
            "[CV 4/5; 91/108] START C=10000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 91/108] END C=10000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001;, score=0.974 total time=   1.8s\n",
            "[CV 5/5; 91/108] START C=10000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 91/108] END C=10000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.001;, score=0.974 total time=   2.4s\n",
            "[CV 1/5; 92/108] START C=10000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 92/108] END C=10000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.981 total time=   8.6s\n",
            "[CV 2/5; 92/108] START C=10000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 92/108] END C=10000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.989 total time=   7.8s\n",
            "[CV 3/5; 92/108] START C=10000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 92/108] END C=10000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.966 total time=  13.2s\n",
            "[CV 4/5; 92/108] START C=10000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 92/108] END C=10000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.974 total time=   6.9s\n",
            "[CV 5/5; 92/108] START C=10000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 92/108] END C=10000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.970 total time=   7.6s\n",
            "[CV 1/5; 93/108] START C=10000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 93/108] END C=10000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.981 total time=  21.3s\n",
            "[CV 2/5; 93/108] START C=10000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 93/108] END C=10000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.985 total time=  17.6s\n",
            "[CV 3/5; 93/108] START C=10000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 93/108] END C=10000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.966 total time=  36.2s\n",
            "[CV 4/5; 93/108] START C=10000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 93/108] END C=10000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.974 total time=  15.7s\n",
            "[CV 5/5; 93/108] START C=10000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 93/108] END C=10000.0, max_iter=1000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.970 total time=  16.0s\n",
            "[CV 1/5; 94/108] START C=10000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 94/108] END C=10000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001;, score=0.981 total time=   0.0s\n",
            "[CV 2/5; 94/108] START C=10000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 94/108] END C=10000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001;, score=0.989 total time=   0.0s\n",
            "[CV 3/5; 94/108] START C=10000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 94/108] END C=10000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001;, score=0.966 total time=   0.0s\n",
            "[CV 4/5; 94/108] START C=10000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 94/108] END C=10000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001;, score=0.974 total time=   0.0s\n",
            "[CV 5/5; 94/108] START C=10000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 94/108] END C=10000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.001;, score=0.970 total time=   0.0s\n",
            "[CV 1/5; 95/108] START C=10000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 95/108] END C=10000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.981 total time=   0.0s\n",
            "[CV 2/5; 95/108] START C=10000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 95/108] END C=10000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.989 total time=   0.0s\n",
            "[CV 3/5; 95/108] START C=10000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 95/108] END C=10000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.966 total time=   0.0s\n",
            "[CV 4/5; 95/108] START C=10000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 95/108] END C=10000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.974 total time=   0.0s\n",
            "[CV 5/5; 95/108] START C=10000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 95/108] END C=10000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.970 total time=   0.0s\n",
            "[CV 1/5; 96/108] START C=10000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 96/108] END C=10000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.981 total time=   0.0s\n",
            "[CV 2/5; 96/108] START C=10000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 96/108] END C=10000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.989 total time=   0.0s\n",
            "[CV 3/5; 96/108] START C=10000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 96/108] END C=10000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.966 total time=   0.0s\n",
            "[CV 4/5; 96/108] START C=10000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 96/108] END C=10000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.974 total time=   0.0s\n",
            "[CV 5/5; 96/108] START C=10000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 96/108] END C=10000.0, max_iter=1000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.970 total time=   0.0s\n",
            "[CV 1/5; 97/108] START C=10000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 97/108] END C=10000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001;, score=0.981 total time=   2.6s\n",
            "[CV 2/5; 97/108] START C=10000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 97/108] END C=10000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001;, score=0.985 total time=   2.4s\n",
            "[CV 3/5; 97/108] START C=10000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 97/108] END C=10000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001;, score=0.966 total time=   3.8s\n",
            "[CV 4/5; 97/108] START C=10000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 97/108] END C=10000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001;, score=0.974 total time=   2.2s\n",
            "[CV 5/5; 97/108] START C=10000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 97/108] END C=10000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.001;, score=0.974 total time=   2.6s\n",
            "[CV 1/5; 98/108] START C=10000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 98/108] END C=10000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.981 total time=   8.4s\n",
            "[CV 2/5; 98/108] START C=10000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 98/108] END C=10000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.989 total time=   7.9s\n",
            "[CV 3/5; 98/108] START C=10000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 98/108] END C=10000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.966 total time=  13.7s\n",
            "[CV 4/5; 98/108] START C=10000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 98/108] END C=10000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.974 total time=   6.1s\n",
            "[CV 5/5; 98/108] START C=10000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 98/108] END C=10000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.970 total time=   7.7s\n",
            "[CV 1/5; 99/108] START C=10000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 99/108] END C=10000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.981 total time=  21.3s\n",
            "[CV 2/5; 99/108] START C=10000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 99/108] END C=10000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.985 total time=  17.9s\n",
            "[CV 3/5; 99/108] START C=10000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 99/108] END C=10000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.966 total time= 8.3min\n",
            "[CV 4/5; 99/108] START C=10000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 99/108] END C=10000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.974 total time=  22.7s\n",
            "[CV 5/5; 99/108] START C=10000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 99/108] END C=10000.0, max_iter=10000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.970 total time=  14.7s\n",
            "[CV 1/5; 100/108] START C=10000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 100/108] END C=10000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001;, score=0.981 total time=   0.0s\n",
            "[CV 2/5; 100/108] START C=10000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 100/108] END C=10000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001;, score=0.989 total time=   0.0s\n",
            "[CV 3/5; 100/108] START C=10000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 100/108] END C=10000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001;, score=0.966 total time=   0.0s\n",
            "[CV 4/5; 100/108] START C=10000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 100/108] END C=10000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001;, score=0.974 total time=   0.0s\n",
            "[CV 5/5; 100/108] START C=10000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 100/108] END C=10000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.001;, score=0.970 total time=   0.0s\n",
            "[CV 1/5; 101/108] START C=10000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 101/108] END C=10000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.981 total time=   0.0s\n",
            "[CV 2/5; 101/108] START C=10000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 101/108] END C=10000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.989 total time=   0.0s\n",
            "[CV 3/5; 101/108] START C=10000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 101/108] END C=10000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.966 total time=   0.0s\n",
            "[CV 4/5; 101/108] START C=10000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 101/108] END C=10000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.974 total time=   0.0s\n",
            "[CV 5/5; 101/108] START C=10000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 101/108] END C=10000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.970 total time=   0.0s\n",
            "[CV 1/5; 102/108] START C=10000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 102/108] END C=10000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.981 total time=   0.0s\n",
            "[CV 2/5; 102/108] START C=10000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 102/108] END C=10000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.989 total time=   0.0s\n",
            "[CV 3/5; 102/108] START C=10000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 102/108] END C=10000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.966 total time=   0.0s\n",
            "[CV 4/5; 102/108] START C=10000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 102/108] END C=10000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.974 total time=   0.0s\n",
            "[CV 5/5; 102/108] START C=10000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 102/108] END C=10000.0, max_iter=10000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.970 total time=   0.0s\n",
            "[CV 1/5; 103/108] START C=10000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 103/108] END C=10000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001;, score=0.985 total time=   2.5s\n",
            "[CV 2/5; 103/108] START C=10000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 103/108] END C=10000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001;, score=0.985 total time=   2.4s\n",
            "[CV 3/5; 103/108] START C=10000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 103/108] END C=10000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001;, score=0.966 total time=   3.3s\n",
            "[CV 4/5; 103/108] START C=10000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 103/108] END C=10000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001;, score=0.974 total time=   1.8s\n",
            "[CV 5/5; 103/108] START C=10000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 103/108] END C=10000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.001;, score=0.974 total time=   2.2s\n",
            "[CV 1/5; 104/108] START C=10000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 104/108] END C=10000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.981 total time=   8.3s\n",
            "[CV 2/5; 104/108] START C=10000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 104/108] END C=10000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.989 total time=   8.2s\n",
            "[CV 3/5; 104/108] START C=10000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 104/108] END C=10000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.966 total time=  13.0s\n",
            "[CV 4/5; 104/108] START C=10000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 104/108] END C=10000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.974 total time=   6.3s\n",
            "[CV 5/5; 104/108] START C=10000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 104/108] END C=10000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=0.0001;, score=0.970 total time=   7.9s\n",
            "[CV 1/5; 105/108] START C=10000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 105/108] END C=10000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.981 total time=  20.6s\n",
            "[CV 2/5; 105/108] START C=10000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 105/108] END C=10000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.985 total time=  17.5s\n",
            "[CV 3/5; 105/108] START C=10000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\falla\\miniconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5; 105/108] END C=10000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.966 total time=75.5min\n",
            "[CV 4/5; 105/108] START C=10000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 105/108] END C=10000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.974 total time=  16.3s\n",
            "[CV 5/5; 105/108] START C=10000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 105/108] END C=10000.0, max_iter=100000, penalty=l1, solver=liblinear, tol=1e-05;, score=0.970 total time=  14.7s\n",
            "[CV 1/5; 106/108] START C=10000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 1/5; 106/108] END C=10000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001;, score=0.981 total time=   0.0s\n",
            "[CV 2/5; 106/108] START C=10000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 2/5; 106/108] END C=10000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001;, score=0.989 total time=   0.0s\n",
            "[CV 3/5; 106/108] START C=10000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 3/5; 106/108] END C=10000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001;, score=0.966 total time=   0.0s\n",
            "[CV 4/5; 106/108] START C=10000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 4/5; 106/108] END C=10000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001;, score=0.974 total time=   0.0s\n",
            "[CV 5/5; 106/108] START C=10000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001\n",
            "[CV 5/5; 106/108] END C=10000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.001;, score=0.970 total time=   0.0s\n",
            "[CV 1/5; 107/108] START C=10000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 1/5; 107/108] END C=10000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.981 total time=   0.0s\n",
            "[CV 2/5; 107/108] START C=10000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 2/5; 107/108] END C=10000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.989 total time=   0.0s\n",
            "[CV 3/5; 107/108] START C=10000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 3/5; 107/108] END C=10000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.966 total time=   0.0s\n",
            "[CV 4/5; 107/108] START C=10000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 4/5; 107/108] END C=10000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.974 total time=   0.0s\n",
            "[CV 5/5; 107/108] START C=10000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001\n",
            "[CV 5/5; 107/108] END C=10000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=0.0001;, score=0.970 total time=   0.0s\n",
            "[CV 1/5; 108/108] START C=10000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 1/5; 108/108] END C=10000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.981 total time=   0.0s\n",
            "[CV 2/5; 108/108] START C=10000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 2/5; 108/108] END C=10000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.989 total time=   0.0s\n",
            "[CV 3/5; 108/108] START C=10000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 3/5; 108/108] END C=10000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.966 total time=   0.0s\n",
            "[CV 4/5; 108/108] START C=10000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 4/5; 108/108] END C=10000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.974 total time=   0.0s\n",
            "[CV 5/5; 108/108] START C=10000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05\n",
            "[CV 5/5; 108/108] END C=10000.0, max_iter=100000, penalty=l2, solver=liblinear, tol=1e-05;, score=0.970 total time=   0.0s\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;lr&#x27;,\n",
              "                 GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
              "                              param_grid=[{&#x27;C&#x27;: [0.1, 1, 10.0, 100.0, 1000.0,\n",
              "                                                 10000.0],\n",
              "                                           &#x27;max_iter&#x27;: [1000, 10000, 100000],\n",
              "                                           &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
              "                                           &#x27;solver&#x27;: [&#x27;liblinear&#x27;],\n",
              "                                           &#x27;tol&#x27;: [0.001, 0.0001, 1e-05]}],\n",
              "                              verbose=10))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;lr&#x27;,\n",
              "                 GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
              "                              param_grid=[{&#x27;C&#x27;: [0.1, 1, 10.0, 100.0, 1000.0,\n",
              "                                                 10000.0],\n",
              "                                           &#x27;max_iter&#x27;: [1000, 10000, 100000],\n",
              "                                           &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
              "                                           &#x27;solver&#x27;: [&#x27;liblinear&#x27;],\n",
              "                                           &#x27;tol&#x27;: [0.001, 0.0001, 1e-05]}],\n",
              "                              verbose=10))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">lr: GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
              "             param_grid=[{&#x27;C&#x27;: [0.1, 1, 10.0, 100.0, 1000.0, 10000.0],\n",
              "                          &#x27;max_iter&#x27;: [1000, 10000, 100000],\n",
              "                          &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;], &#x27;solver&#x27;: [&#x27;liblinear&#x27;],\n",
              "                          &#x27;tol&#x27;: [0.001, 0.0001, 1e-05]}],\n",
              "             verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                ('lr',\n",
              "                 GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
              "                              param_grid=[{'C': [0.1, 1, 10.0, 100.0, 1000.0,\n",
              "                                                 10000.0],\n",
              "                                           'max_iter': [1000, 10000, 100000],\n",
              "                                           'penalty': ['l1', 'l2'],\n",
              "                                           'solver': ['liblinear'],\n",
              "                                           'tol': [0.001, 0.0001, 1e-05]}],\n",
              "                              verbose=10))])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "param_grid = [\n",
        "    {'solver': ['liblinear'] , 'penalty': ['l1','l2'] , 'tol':[1e-3 , 1e-4 , 1e-5 ] , 'C': [1e-1 , 1 ,1e1,1e2 ,1e3 ,1e4] , 'max_iter': [1000 ,10000 ,100000]},\n",
        "    #{'solver': ['lbfgs'] , 'penalty':['l2' , None] , 'tol':[1e-3 , 1e-4,1e-5 ,1e-6 ,1e-7] , 'C': [1e-1 , 1 ,10 , 1e2 ,1e3 ,1e4 ,1e5 ,1e6]},\n",
        "    #{'solver': ['newton-cg' , 'newton-cholesky'] , 'penalty' : ['l2' , None] , 'tol': [1e-3 , 1e-4 ,1e-5 ,1e-6 ,1e-7] , 'C':[1e-1 , 1 ,10 ,1e2 ,1e3 ,1e4 ,1e5 ,1e6]},\n",
        "    #{'solver': ['sag'] , 'penalty': ['l2' , None] , 'tol': [1e-3 , 1e-4 ,1e-5 ,1e-6 ,1e-7] , 'C':[1e-1 , 1 , 10 ,1e2 , 1e3 ,1e4 ,1e5 ,1e6]},\n",
        "    #{'solver': ['saga'] , 'penalty': ['l1' , 'l2' , 'elasticnet' , None] , 'tol': [1e-3 , 1e-4 , 1e-5 , 1e-6 ,1e-7] , 'C':[1e-1 , 1 ,10 ,1e2 ,1e3 ,1e4 ,1e5 ,1e6]}\n",
        "] \n",
        "\n",
        "clf = Pipeline([('scaler' , StandardScaler()),\n",
        "                ('lr' ,GridSearchCV(LogisticRegression(),\n",
        "                       param_grid = param_grid,\n",
        "                       cv =5,\n",
        "                       refit =True,\n",
        "                       verbose =10))])\n",
        "\n",
        "clf.fit(X_train , y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1, max_iter=1000, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;,\n",
              "                   tol=0.001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, max_iter=1000, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;,\n",
              "                   tol=0.001)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(C=1, max_iter=1000, penalty='l1', solver='liblinear',\n",
              "                   tol=0.001)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf['lr'].best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9828246408407402"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf['lr'].best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation f1-score: 0.9846827133479211\n",
            "Test f1-score: 0.9617224880382775\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "y_val_predict = clf.predict(X_validation)\n",
        "print('Validation f1-score:' , f1_score(y_validation , y_val_predict))\n",
        "y_predict = clf.predict(X_test)\n",
        "print('Test f1-score:' , f1_score(y_test , y_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "history_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
